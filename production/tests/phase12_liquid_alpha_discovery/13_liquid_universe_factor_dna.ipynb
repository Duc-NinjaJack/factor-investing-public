{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Liquid Universe Factor DNA Analysis\n",
    "\n",
    "**Objective**: Implement the new \"liquid-universe-first\" backtesting pipeline and conduct quintile analysis for standalone Quality, Value, and Momentum factors on the ASC-VN-Liquid-150 universe.\n",
    "\n",
    "**Critical Architecture Change**: Unlike previous notebooks, this pipeline filters the universe BEFORE any factor ranking occurs, ensuring we only evaluate signals on truly investable stocks.\n",
    "\n",
    "## Strategic Context\n",
    "\n",
    "This notebook represents the pivot from our previous \"liquidity-last\" architecture to a new \"liquid-universe-first\" approach. The original strategy showed phenomenal alpha (~2.1 Sharpe) but was concentrated in untradable micro-cap stocks. This analysis will establish a realistic performance baseline for our existing factors within the investable universe.\n",
    "\n",
    "**Universe Definition**: Top 200 stocks by 63-day ADTV, refreshed quarterly, with baseline ADTV threshold of 10B VND (ASC-VN-Liquid-150).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Environment Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, date, timedelta\n",
    "import warnings\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"‚úÖ Environment setup complete\")\n",
    "print(f\"Analysis date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database connection setup\n",
    "def create_db_connection():\n",
    "    \"\"\"Create database connection using config file\"\"\"\n",
    "    config_path = Path('../../../config/database.yml')\n",
    "    \n",
    "    with open(config_path, 'r') as f:\n",
    "        db_config = yaml.safe_load(f)\n",
    "    \n",
    "    conn_params = db_config['production']\n",
    "    connection_string = (\n",
    "        f\"mysql+pymysql://{conn_params['username']}:{conn_params['password']}\"\n",
    "        f\"@{conn_params['host']}/{conn_params['schema_name']}\"\n",
    "    )\n",
    "    \n",
    "    engine = create_engine(connection_string, pool_pre_ping=True)\n",
    "    return engine\n",
    "\n",
    "# Create database connection\n",
    "engine = create_db_connection()\n",
    "print(\"‚úÖ Database connection established\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Liquid Universe Constructor\n",
    "\n",
    "This section implements the core \"liquid-universe-first\" logic. The universe is constructed BEFORE any factor analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_adtv_universe(engine, as_of_date: str, lookback_days: int = 63, top_n: int = 200, min_adtv_bn: float = 10.0):\n",
    "    \"\"\"\n",
    "    Calculate liquid universe based on ADTV criteria.\n",
    "    \n",
    "    Parameters:\n",
    "    - as_of_date: Date for universe construction (T-2 to avoid look-ahead bias)\n",
    "    - lookback_days: Days to calculate ADTV (default 63 = ~3 months)\n",
    "    - top_n: Number of most liquid stocks to select\n",
    "    - min_adtv_bn: Minimum ADTV threshold in billion VND\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with liquid universe tickers and their ADTV metrics\n",
    "    \"\"\"\n",
    "    # Calculate lookback start date\n",
    "    as_of_dt = pd.to_datetime(as_of_date)\n",
    "    start_date = (as_of_dt - timedelta(days=lookback_days)).strftime('%Y-%m-%d')\n",
    "    \n",
    "    print(f\"üîç Calculating ADTV universe for {as_of_date}\")\n",
    "    print(f\"   Lookback period: {start_date} to {as_of_date} ({lookback_days} days)\")\n",
    "    print(f\"   Criteria: Top {top_n} stocks with ADTV >= {min_adtv_bn}B VND\")\n",
    "    \n",
    "    # Query to calculate ADTV by ticker\n",
    "    adtv_query = text(\"\"\"\n",
    "        SELECT \n",
    "            v.ticker,\n",
    "            m.sector,\n",
    "            COUNT(v.trading_date) as trading_days,\n",
    "            AVG(v.total_value / 1e9) as adtv_bn_vnd,\n",
    "            SUM(v.total_value / 1e9) as total_turnover_bn_vnd,\n",
    "            AVG(v.market_cap / 1e9) as avg_market_cap_bn_vnd,\n",
    "            MIN(v.trading_date) as first_date,\n",
    "            MAX(v.trading_date) as last_date\n",
    "        FROM vcsc_daily_data_complete v\n",
    "        INNER JOIN master_info m ON v.ticker = m.ticker\n",
    "        WHERE v.trading_date BETWEEN :start_date AND :as_of_date\n",
    "            AND v.total_value > 0\n",
    "            AND v.market_cap > 0\n",
    "        GROUP BY v.ticker, m.sector\n",
    "        HAVING trading_days >= :min_trading_days\n",
    "            AND adtv_bn_vnd >= :min_adtv_bn\n",
    "        ORDER BY adtv_bn_vnd DESC\n",
    "        LIMIT :top_n\n",
    "    \"\"\")\n",
    "    \n",
    "    # Require at least 80% of trading days for inclusion\n",
    "    min_trading_days = int(lookback_days * 0.8)\n",
    "    \n",
    "    with engine.connect() as conn:\n",
    "        universe_df = pd.read_sql_query(\n",
    "            adtv_query,\n",
    "            conn,\n",
    "            params={\n",
    "                'start_date': start_date,\n",
    "                'as_of_date': as_of_date,\n",
    "                'min_trading_days': min_trading_days,\n",
    "                'min_adtv_bn': min_adtv_bn,\n",
    "                'top_n': top_n\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    print(f\"‚úÖ Universe calculated: {len(universe_df)} stocks qualify\")\n",
    "    print(f\"   ADTV range: {universe_df['adtv_bn_vnd'].min():.1f}B - {universe_df['adtv_bn_vnd'].max():.1f}B VND\")\n",
    "    print(f\"   Market cap range: {universe_df['avg_market_cap_bn_vnd'].min():.1f}B - {universe_df['avg_market_cap_bn_vnd'].max():.1f}B VND\")\n",
    "    \n",
    "    return universe_df\n",
    "\n",
    "# Test universe construction for Q1 2024\n",
    "test_date = '2024-03-29'  # End of Q1 2024\n",
    "liquid_universe = calculate_adtv_universe(engine, test_date)\n",
    "\n",
    "# Display top 10 most liquid stocks\n",
    "print(\"\\nüìä Top 10 Most Liquid Stocks:\")\n",
    "display(liquid_universe.head(10)[['ticker', 'sector', 'adtv_bn_vnd', 'avg_market_cap_bn_vnd', 'trading_days']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze universe composition by sector\n",
    "sector_analysis = liquid_universe.groupby('sector').agg({\n",
    "    'ticker': 'count',\n",
    "    'adtv_bn_vnd': ['mean', 'sum'],\n",
    "    'avg_market_cap_bn_vnd': ['mean', 'sum']\n",
    "}).round(2)\n",
    "\n",
    "sector_analysis.columns = ['Count', 'Avg_ADTV_Bn', 'Total_ADTV_Bn', 'Avg_MCap_Bn', 'Total_MCap_Bn']\n",
    "sector_analysis = sector_analysis.sort_values('Count', ascending=False)\n",
    "\n",
    "print(\"üè¢ Liquid Universe Composition by Sector:\")\n",
    "display(sector_analysis)\n",
    "\n",
    "# Plot sector composition\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Count by sector\n",
    "sector_analysis['Count'].plot(kind='bar', ax=ax1, color='skyblue')\n",
    "ax1.set_title('Liquid Universe: Stock Count by Sector')\n",
    "ax1.set_ylabel('Number of Stocks')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# ADTV by sector  \n",
    "sector_analysis['Total_ADTV_Bn'].plot(kind='bar', ax=ax2, color='lightcoral')\n",
    "ax2.set_title('Liquid Universe: Total ADTV by Sector (Billion VND)')\n",
    "ax2.set_ylabel('Total ADTV (Billion VND)')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìà Universe Statistics:\")\n",
    "print(f\"   Total tickers: {len(liquid_universe)}\")\n",
    "print(f\"   Sectors represented: {liquid_universe['sector'].nunique()}\")\n",
    "print(f\"   Total market cap: {liquid_universe['avg_market_cap_bn_vnd'].sum():.0f}B VND\")\n",
    "print(f\"   Total daily turnover: {liquid_universe['adtv_bn_vnd'].sum():.0f}B VND\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Factor Data Loading for Liquid Universe\n",
    "\n",
    "Load factor scores ONLY for the tickers in our liquid universe. This is the key architectural change - we filter first, then analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_factor_scores_for_universe(engine, universe_tickers, start_date: str, end_date: str, strategy_version: str = 'qvm_v2.0_enhanced'):\n",
    "    \"\"\"\n",
    "    Load factor scores ONLY for stocks in the liquid universe.\n",
    "    \n",
    "    This is the core \"liquid-universe-first\" implementation:\n",
    "    We filter the universe BEFORE loading any factor data.\n",
    "    \"\"\"\n",
    "    print(f\"üìä Loading factor scores for liquid universe\")\n",
    "    print(f\"   Universe size: {len(universe_tickers)} tickers\")\n",
    "    print(f\"   Date range: {start_date} to {end_date}\")\n",
    "    print(f\"   Strategy version: {strategy_version}\")\n",
    "    \n",
    "    # Convert universe tickers to tuple for SQL IN clause\n",
    "    ticker_tuple = tuple(universe_tickers)\n",
    "    \n",
    "    factor_query = text(\"\"\"\n",
    "        SELECT \n",
    "            ticker,\n",
    "            date,\n",
    "            Quality_Composite,\n",
    "            Value_Composite,\n",
    "            Momentum_Composite,\n",
    "            QVM_Composite\n",
    "        FROM factor_scores_qvm\n",
    "        WHERE ticker IN :tickers\n",
    "            AND date BETWEEN :start_date AND :end_date\n",
    "            AND strategy_version = :strategy_version\n",
    "            AND Quality_Composite IS NOT NULL\n",
    "            AND Value_Composite IS NOT NULL\n",
    "            AND Momentum_Composite IS NOT NULL\n",
    "        ORDER BY date, ticker\n",
    "    \"\"\")\n",
    "    \n",
    "    with engine.connect() as conn:\n",
    "        factor_df = pd.read_sql_query(\n",
    "            factor_query,\n",
    "            conn,\n",
    "            params={\n",
    "                'tickers': ticker_tuple,\n",
    "                'start_date': start_date,\n",
    "                'end_date': end_date,\n",
    "                'strategy_version': strategy_version\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    factor_df['date'] = pd.to_datetime(factor_df['date'])\n",
    "    \n",
    "    print(f\"‚úÖ Loaded {len(factor_df):,} factor observations\")\n",
    "    print(f\"   Date range: {factor_df['date'].min().date()} to {factor_df['date'].max().date()}\")\n",
    "    print(f\"   Unique tickers with data: {factor_df['ticker'].nunique()}\")\n",
    "    print(f\"   Unique dates: {factor_df['date'].nunique()}\")\n",
    "    \n",
    "    return factor_df\n",
    "\n",
    "# Load factor data for our liquid universe\n",
    "factor_data = load_factor_scores_for_universe(\n",
    "    engine=engine,\n",
    "    universe_tickers=liquid_universe['ticker'].tolist(),\n",
    "    start_date='2024-01-01',\n",
    "    end_date='2024-03-29',\n",
    "    strategy_version='qvm_v2.0_enhanced'\n",
    ")\n",
    "\n",
    "# Display sample data\n",
    "print(\"\\nüìã Sample Factor Data:\")\n",
    "display(factor_data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Critical Sanity Checks\n",
    "\n",
    "Before proceeding with any analysis, we must validate three critical conditions:\n",
    "1. **Coverage Check**: Sufficient number of stocks with factor data\n",
    "2. **Liquidity Overlap Check**: Factor universe aligns with liquid universe  \n",
    "3. **Factor Dispersion Check**: Factors show meaningful variation in liquid universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sanity_checks(factor_data, liquid_universe, min_coverage=125, min_dispersion=0.10):\n",
    "    \"\"\"\n",
    "    Run critical sanity checks before proceeding with analysis.\n",
    "    These are mandatory gates that must pass.\n",
    "    \"\"\"\n",
    "    print(\"üîç RUNNING CRITICAL SANITY CHECKS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # 1. Coverage Check\n",
    "    unique_factor_tickers = factor_data['ticker'].nunique()\n",
    "    universe_size = len(liquid_universe)\n",
    "    coverage_ratio = unique_factor_tickers / universe_size\n",
    "    \n",
    "    print(f\"\\n1Ô∏è‚É£ COVERAGE CHECK:\")\n",
    "    print(f\"   Liquid universe size: {universe_size}\")\n",
    "    print(f\"   Tickers with factor data: {unique_factor_tickers}\")\n",
    "    print(f\"   Coverage ratio: {coverage_ratio:.1%}\")\n",
    "    print(f\"   Minimum required: {min_coverage} tickers\")\n",
    "    \n",
    "    coverage_pass = unique_factor_tickers >= min_coverage\n",
    "    results['coverage'] = {\n",
    "        'pass': coverage_pass,\n",
    "        'value': unique_factor_tickers,\n",
    "        'threshold': min_coverage,\n",
    "        'ratio': coverage_ratio\n",
    "    }\n",
    "    print(f\"   Status: {'‚úÖ PASS' if coverage_pass else '‚ùå FAIL'}\")\n",
    "    \n",
    "    # 2. Liquidity Overlap Check  \n",
    "    factor_tickers = set(factor_data['ticker'].unique())\n",
    "    universe_tickers = set(liquid_universe['ticker'].unique())\n",
    "    overlap = factor_tickers.intersection(universe_tickers)\n",
    "    overlap_ratio = len(overlap) / len(universe_tickers)\n",
    "    \n",
    "    print(f\"\\n2Ô∏è‚É£ LIQUIDITY OVERLAP CHECK:\")\n",
    "    print(f\"   Universe tickers: {len(universe_tickers)}\")\n",
    "    print(f\"   Factor tickers: {len(factor_tickers)}\")\n",
    "    print(f\"   Overlap: {len(overlap)} ({overlap_ratio:.1%})\")\n",
    "    \n",
    "    # Check if any universe tickers are missing factor data\n",
    "    missing_tickers = universe_tickers - factor_tickers\n",
    "    if missing_tickers:\n",
    "        print(f\"   Missing factor data for: {sorted(list(missing_tickers))[:10]}...\")\n",
    "    \n",
    "    overlap_pass = overlap_ratio >= 0.8  # At least 80% overlap\n",
    "    results['overlap'] = {\n",
    "        'pass': overlap_pass,\n",
    "        'ratio': overlap_ratio,\n",
    "        'missing_count': len(missing_tickers)\n",
    "    }\n",
    "    print(f\"   Status: {'‚úÖ PASS' if overlap_pass else '‚ùå FAIL'}\")\n",
    "    \n",
    "    # 3. Factor Dispersion Check\n",
    "    print(f\"\\n3Ô∏è‚É£ FACTOR DISPERSION CHECK:\")\n",
    "    factors = ['Quality_Composite', 'Value_Composite', 'Momentum_Composite']\n",
    "    dispersion_results = {}\n",
    "    \n",
    "    for factor in factors:\n",
    "        # Calculate cross-sectional standard deviation for each date\n",
    "        daily_std = factor_data.groupby('date')[factor].std()\n",
    "        avg_std = daily_std.mean()\n",
    "        \n",
    "        dispersion_pass = avg_std >= min_dispersion\n",
    "        dispersion_results[factor] = {\n",
    "            'pass': dispersion_pass,\n",
    "            'avg_std': avg_std,\n",
    "            'threshold': min_dispersion\n",
    "        }\n",
    "        \n",
    "        print(f\"   {factor}: {avg_std:.3f} ({'‚úÖ PASS' if dispersion_pass else '‚ùå FAIL'})\")\n",
    "    \n",
    "    results['dispersion'] = dispersion_results\n",
    "    \n",
    "    # Overall assessment\n",
    "    all_dispersion_pass = all(r['pass'] for r in dispersion_results.values())\n",
    "    overall_pass = coverage_pass and overlap_pass and all_dispersion_pass\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"üéØ OVERALL SANITY CHECK: {'‚úÖ ALL PASS' if overall_pass else '‚ùå SOME FAILED'}\")\n",
    "    \n",
    "    if not overall_pass:\n",
    "        print(\"\\n‚ö†Ô∏è  WARNING: Some sanity checks failed!\")\n",
    "        print(\"   This indicates our factors may not be suitable for the liquid universe.\")\n",
    "        print(\"   Consider this a 'No-Go' decision for current factor definitions.\")\n",
    "    \n",
    "    results['overall_pass'] = overall_pass\n",
    "    return results\n",
    "\n",
    "# Run sanity checks\n",
    "sanity_results = run_sanity_checks(factor_data, liquid_universe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Liquid Universe Factor DNA Analysis\n",
    "\n",
    "If sanity checks pass, proceed with quintile analysis to establish the performance baseline for our factors in the investable universe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_factor_dna(factor_data, factor_name='Quality_Composite'):\n",
    "    \"\"\"\n",
    "    Analyze the \"DNA\" of a factor in the liquid universe:\n",
    "    - Distribution characteristics\n",
    "    - Temporal stability\n",
    "    - Cross-sectional dispersion\n",
    "    \"\"\"\n",
    "    print(f\"üß¨ FACTOR DNA ANALYSIS: {factor_name}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. Distribution Analysis\n",
    "    factor_values = factor_data[factor_name].dropna()\n",
    "    \n",
    "    print(f\"\\nüìä Distribution Statistics:\")\n",
    "    print(f\"   Count: {len(factor_values):,}\")\n",
    "    print(f\"   Mean: {factor_values.mean():.4f}\")\n",
    "    print(f\"   Std Dev: {factor_values.std():.4f}\")\n",
    "    print(f\"   Skewness: {factor_values.skew():.4f}\")\n",
    "    print(f\"   Min: {factor_values.min():.4f}\")\n",
    "    print(f\"   25th %ile: {factor_values.quantile(0.25):.4f}\")\n",
    "    print(f\"   Median: {factor_values.median():.4f}\")\n",
    "    print(f\"   75th %ile: {factor_values.quantile(0.75):.4f}\")\n",
    "    print(f\"   Max: {factor_values.max():.4f}\")\n",
    "    \n",
    "    # 2. Temporal Analysis\n",
    "    daily_stats = factor_data.groupby('date')[factor_name].agg([\n",
    "        'count', 'mean', 'std', 'min', 'max'\n",
    "    ]).round(4)\n",
    "    \n",
    "    print(f\"\\nüìà Temporal Stability:\")\n",
    "    print(f\"   Avg daily coverage: {daily_stats['count'].mean():.1f} stocks\")\n",
    "    print(f\"   Mean stability (std of daily means): {daily_stats['mean'].std():.4f}\")\n",
    "    print(f\"   Dispersion stability (std of daily stds): {daily_stats['std'].std():.4f}\")\n",
    "    \n",
    "    # 3. Visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Distribution histogram\n",
    "    axes[0,0].hist(factor_values, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[0,0].axvline(factor_values.mean(), color='red', linestyle='--', label=f'Mean: {factor_values.mean():.3f}')\n",
    "    axes[0,0].axvline(factor_values.median(), color='orange', linestyle='--', label=f'Median: {factor_values.median():.3f}')\n",
    "    axes[0,0].set_title(f'{factor_name} Distribution in Liquid Universe')\n",
    "    axes[0,0].set_xlabel('Factor Value')\n",
    "    axes[0,0].set_ylabel('Frequency')\n",
    "    axes[0,0].legend()\n",
    "    \n",
    "    # Box plot\n",
    "    axes[0,1].boxplot(factor_values, patch_artist=True,\n",
    "                      boxprops=dict(facecolor='lightcoral', alpha=0.7))\n",
    "    axes[0,1].set_title(f'{factor_name} Box Plot')\n",
    "    axes[0,1].set_ylabel('Factor Value')\n",
    "    \n",
    "    # Time series of daily means\n",
    "    axes[1,0].plot(daily_stats.index, daily_stats['mean'], marker='o', linewidth=2)\n",
    "    axes[1,0].set_title(f'{factor_name} Daily Mean Over Time')\n",
    "    axes[1,0].set_xlabel('Date')\n",
    "    axes[1,0].set_ylabel('Daily Mean')\n",
    "    axes[1,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Time series of daily dispersion\n",
    "    axes[1,1].plot(daily_stats.index, daily_stats['std'], marker='s', color='green', linewidth=2)\n",
    "    axes[1,1].set_title(f'{factor_name} Daily Dispersion Over Time')\n",
    "    axes[1,1].set_xlabel('Date')\n",
    "    axes[1,1].set_ylabel('Daily Std Dev')\n",
    "    axes[1,1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'distribution_stats': factor_values.describe(),\n",
    "        'temporal_stats': daily_stats,\n",
    "        'mean_stability': daily_stats['mean'].std(),\n",
    "        'dispersion_stability': daily_stats['std'].std()\n",
    "    }\n",
    "\n",
    "# Analyze each factor's DNA if sanity checks passed\n",
    "if sanity_results['overall_pass']:\n",
    "    print(\"‚úÖ Sanity checks passed - proceeding with Factor DNA analysis\\n\")\n",
    "    \n",
    "    # Analyze Quality factor\n",
    "    quality_dna = analyze_factor_dna(factor_data, 'Quality_Composite')\nelse:\n",
    "    print(\"‚ùå Sanity checks failed - Factor DNA analysis not recommended\")\n",
    "    print(\"   Current factors may not be suitable for the liquid universe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue DNA analysis for Value and Momentum if Quality passed\n",
    "if sanity_results['overall_pass']:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    value_dna = analyze_factor_dna(factor_data, 'Value_Composite')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    momentum_dna = analyze_factor_dna(factor_data, 'Momentum_Composite')\n",
    "    \n",
    "    # Summary comparison\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üéØ FACTOR DNA SUMMARY COMPARISON\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    factors = ['Quality_Composite', 'Value_Composite', 'Momentum_Composite']\n",
    "    dna_results = [quality_dna, value_dna, momentum_dna]\n",
    "    \n",
    "    summary_df = pd.DataFrame({\n",
    "        'Factor': factors,\n",
    "        'Mean': [factor_data[f].mean() for f in factors],\n",
    "        'Std_Dev': [factor_data[f].std() for f in factors],\n",
    "        'Skewness': [factor_data[f].skew() for f in factors],\n",
    "        'Mean_Stability': [dna['mean_stability'] for dna in dna_results],\n",
    "        'Dispersion_Stability': [dna['dispersion_stability'] for dna in dna_results]\n",
    "    }).round(4)\n",
    "    \n",
    "    display(summary_df)\n",
    "    \n",
    "    # Flag any concerning patterns\n",
    "    print(\"\\nüö® DNA Health Check:\")\n",
    "    for i, factor in enumerate(factors):\n",
    "        std_dev = summary_df.iloc[i]['Std_Dev']\n",
    "        stability = summary_df.iloc[i]['Mean_Stability']\n",
    "        \n",
    "        if std_dev < 0.1:\n",
    "            print(f\"   ‚ö†Ô∏è  {factor}: Low dispersion ({std_dev:.3f}) - may lack signal\")\n",
    "        if stability > 0.05:\n",
    "            print(f\"   ‚ö†Ô∏è  {factor}: High instability ({stability:.3f}) - may be noisy\")\n",
    "        if std_dev >= 0.1 and stability <= 0.05:\n",
    "            print(f\"   ‚úÖ {factor}: Healthy DNA profile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Preliminary Quintile Analysis\n",
    "\n",
    "If Factor DNA is healthy, conduct initial quintile analysis to measure factor efficacy in the liquid universe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preliminary_quintile_analysis(factor_data, price_data=None, factor_name='Quality_Composite'):\n",
    "    \"\"\"\n",
    "    Conduct preliminary quintile analysis for a single factor.\n",
    "    For now, focus on factor distribution across quintiles.\n",
    "    \n",
    "    Note: Full performance analysis requires price data loading,\n",
    "    which will be implemented in subsequent development.\n",
    "    \"\"\"\n",
    "    print(f\"üìä PRELIMINARY QUINTILE ANALYSIS: {factor_name}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Create quintile ranks for each date\n",
    "    factor_ranked = factor_data.copy()\n",
    "    factor_ranked[f'{factor_name}_quintile'] = factor_ranked.groupby('date')[factor_name].transform(\n",
    "        lambda x: pd.qcut(x, q=5, labels=[1, 2, 3, 4, 5], duplicates='drop')\n",
    "    )\n",
    "    \n",
    "    # Remove any rows where quintile assignment failed\n",
    "    factor_ranked = factor_ranked.dropna(subset=[f'{factor_name}_quintile'])\n",
    "    \n",
    "    print(f\"‚úÖ Quintile ranking complete\")\n",
    "    print(f\"   Total observations with quintiles: {len(factor_ranked):,}\")\n",
    "    \n",
    "    # Analyze quintile characteristics\n",
    "    quintile_stats = factor_ranked.groupby(f'{factor_name}_quintile')[factor_name].agg([\n",
    "        'count', 'mean', 'std', 'min', 'max'\n",
    "    ]).round(4)\n",
    "    quintile_stats.columns = ['Count', 'Mean', 'Std_Dev', 'Min', 'Max']\n",
    "    \n",
    "    print(f\"\\nüìà Quintile Characteristics:\")\n",
    "    display(quintile_stats)\n",
    "    \n",
    "    # Calculate quintile spread\n",
    "    q5_mean = quintile_stats.loc[5, 'Mean']\n",
    "    q1_mean = quintile_stats.loc[1, 'Mean']\n",
    "    quintile_spread = q5_mean - q1_mean\n",
    "    \n",
    "    print(f\"\\nüéØ Key Metrics:\")\n",
    "    print(f\"   Quintile 5 (Top) Mean: {q5_mean:.4f}\")\n",
    "    print(f\"   Quintile 1 (Bottom) Mean: {q1_mean:.4f}\")\n",
    "    print(f\"   Quintile Spread (Q5-Q1): {quintile_spread:.4f}\")\n",
    "    \n",
    "    # Assess factor efficacy\n",
    "    if quintile_spread > 0.5:\n",
    "        efficacy = \"Strong\"\n",
    "    elif quintile_spread > 0.2:\n",
    "        efficacy = \"Moderate\"\n",
    "    elif quintile_spread > 0.1:\n",
    "        efficacy = \"Weak\"\n",
    "    else:\n",
    "        efficacy = \"Very Weak\"\n",
    "    \n",
    "    print(f\"   Factor Efficacy: {efficacy}\")\n",
    "    \n",
    "    # Visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Quintile means\n",
    "    quintile_stats['Mean'].plot(kind='bar', ax=ax1, color='steelblue')\n",
    "    ax1.set_title(f'{factor_name} Mean by Quintile')\n",
    "    ax1.set_xlabel('Quintile (1=Worst, 5=Best)')\n",
    "    ax1.set_ylabel('Factor Value')\n",
    "    ax1.tick_params(axis='x', rotation=0)\n",
    "    \n",
    "    # Box plot by quintile\n",
    "    factor_ranked.boxplot(column=factor_name, by=f'{factor_name}_quintile', ax=ax2)\n",
    "    ax2.set_title(f'{factor_name} Distribution by Quintile')\n",
    "    ax2.set_xlabel('Quintile (1=Worst, 5=Best)')\n",
    "    ax2.set_ylabel('Factor Value')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'quintile_stats': quintile_stats,\n",
    "        'quintile_spread': quintile_spread,\n",
    "        'efficacy': efficacy,\n",
    "        'ranked_data': factor_ranked\n",
    "    }\n",
    "\n",
    "# Run preliminary quintile analysis if DNA is healthy\n",
    "if sanity_results['overall_pass']:\n",
    "    quality_quintiles = preliminary_quintile_analysis(factor_data, factor_name='Quality_Composite')\nelse:\n",
    "    print(\"‚ùå Skipping quintile analysis - sanity checks failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue quintile analysis for all factors\n",
    "if sanity_results['overall_pass']:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    value_quintiles = preliminary_quintile_analysis(factor_data, factor_name='Value_Composite')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    momentum_quintiles = preliminary_quintile_analysis(factor_data, factor_name='Momentum_Composite')\n",
    "    \n",
    "    # Summary comparison of all factors\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üéØ LIQUID UNIVERSE FACTOR EFFICACY SUMMARY\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    efficacy_summary = pd.DataFrame({\n",
    "        'Factor': ['Quality_Composite', 'Value_Composite', 'Momentum_Composite'],\n",
    "        'Quintile_Spread': [\n",
    "            quality_quintiles['quintile_spread'],\n",
    "            value_quintiles['quintile_spread'],\n",
    "            momentum_quintiles['quintile_spread']\n",
    "        ],\n",
    "        'Efficacy_Rating': [\n",
    "            quality_quintiles['efficacy'],\n",
    "            value_quintiles['efficacy'],\n",
    "            momentum_quintiles['efficacy']\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    display(efficacy_summary)\n",
    "    \n",
    "    # Determine go/no-go decision\n",
    "    strong_factors = sum(1 for efficacy in efficacy_summary['Efficacy_Rating'] if efficacy == 'Strong')\n",
    "    moderate_factors = sum(1 for efficacy in efficacy_summary['Efficacy_Rating'] if efficacy == 'Moderate')\n",
    "    \n",
    "    print(f\"\\nüö¶ GO/NO-GO DECISION:\")\n",
    "    print(f\"   Strong factors: {strong_factors}/3\")\n",
    "    print(f\"   Moderate+ factors: {strong_factors + moderate_factors}/3\")\n",
    "    \n",
    "    if strong_factors >= 2:\n",
    "        decision = \"‚úÖ GO - Strong factor signals in liquid universe\"\n",
    "        recommendation = \"Proceed with full backtesting pipeline development\"\n",
    "    elif strong_factors + moderate_factors >= 2:\n",
    "        decision = \"üü° CAUTIOUS GO - Moderate factor signals\"\n",
    "        recommendation = \"Proceed but consider factor enhancement\"\n",
    "    else:\n",
    "        decision = \"‚ùå NO-GO - Weak factor signals in liquid universe\"\n",
    "        recommendation = \"Pivot to Liquid Alpha Discovery phase for new factor engineering\"\n",
    "    \n",
    "    print(f\"   Decision: {decision}\")\n",
    "    print(f\"   Recommendation: {recommendation}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Cannot make go/no-go decision - preliminary analysis failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Session Summary & Next Steps\n",
    "\n",
    "Document findings and establish clear next steps based on the analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive session summary\n",
    "print(\"üìã LIQUID UNIVERSE FACTOR DNA - SESSION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüéØ Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"üìä Universe Definition: ASC-VN-Liquid-150 (Top 200 by ADTV, 10B+ VND threshold)\")\n",
    "print(f\"üìà Test Period: Q1 2024 (2024-01-01 to 2024-03-29)\")\n",
    "print(f\"üîß Strategy Version: qvm_v2.0_enhanced\")\n",
    "\n",
    "if 'liquid_universe' in locals():\n",
    "    print(f\"\\nüè¢ Universe Composition:\")\n",
    "    print(f\"   Total stocks: {len(liquid_universe)}\")\n",
    "    print(f\"   ADTV range: {liquid_universe['adtv_bn_vnd'].min():.1f}B - {liquid_universe['adtv_bn_vnd'].max():.1f}B VND\")\n",
    "    print(f\"   Sectors represented: {liquid_universe['sector'].nunique()}\")\n",
    "\n",
    "if 'sanity_results' in locals():\n",
    "    print(f\"\\nüîç Sanity Check Results:\")\n",
    "    print(f\"   Coverage: {'‚úÖ PASS' if sanity_results['coverage']['pass'] else '‚ùå FAIL'} ({sanity_results['coverage']['value']} tickers)\")\n",
    "    print(f\"   Overlap: {'‚úÖ PASS' if sanity_results['overlap']['pass'] else '‚ùå FAIL'} ({sanity_results['overlap']['ratio']:.1%} overlap)\")\n",
    "    \n",
    "    print(f\"   Factor Dispersion:\")\n",
    "    for factor, result in sanity_results['dispersion'].items():\n",
    "        print(f\"     {factor}: {'‚úÖ PASS' if result['pass'] else '‚ùå FAIL'} ({result['avg_std']:.3f})\")\n",
    "\n",
    "if 'efficacy_summary' in locals():\n",
    "    print(f\"\\nüß¨ Factor DNA Results:\")\n",
    "    for _, row in efficacy_summary.iterrows():\n",
    "        print(f\"   {row['Factor']}: {row['Efficacy_Rating']} (spread: {row['Quintile_Spread']:.3f})\")\n",
    "    \n",
    "    print(f\"\\nüö¶ Final Decision: {decision}\")\n",
    "    print(f\"üí° Recommendation: {recommendation}\")\n",
    "\n",
    "print(f\"\\nüìã Key Architectural Achievement:\")\n",
    "print(f\"   ‚úÖ Successfully implemented 'liquid-universe-first' pipeline\")\n",
    "print(f\"   ‚úÖ Universe filtering occurs BEFORE factor analysis\")\n",
    "print(f\"   ‚úÖ Eliminated risk of discovering inaccessible alpha\")\n",
    "\n",
    "print(f\"\\n‚è≠Ô∏è  Next Steps:\")\n",
    "if 'sanity_results' in locals() and sanity_results['overall_pass']:\n",
    "    if 'strong_factors' in locals() and strong_factors >= 2:\n",
    "        print(f\"   1. Load price data for liquid universe\")\n",
    "        print(f\"   2. Implement full quintile performance analysis\")\n",
    "        print(f\"   3. Calculate returns, Sharpe ratios, and turnover\")\n",
    "        print(f\"   4. Build complete liquid-universe backtesting module\")\n",
    "        print(f\"   5. Compare liquid vs unrestricted universe performance\")\n",
    "    else:\n",
    "        print(f\"   1. Investigate factor weakness in liquid universe\")\n",
    "        print(f\"   2. Consider factor enhancement or new engineering\")\n",
    "        print(f\"   3. Analyze sector-specific factor behavior\")\n",
    "        print(f\"   4. Potentially pivot to Liquid Alpha Discovery phase\")\nelse:\n",
    "    print(f\"   1. Investigate sanity check failures\")\n",
    "    print(f\"   2. Review factor generation process for liquid universe\")\n",
    "    print(f\"   3. Consider data quality issues or timing problems\")\n",
    "    print(f\"   4. Re-run analysis with different universe parameters\")\n",
    "\n",
    "print(f\"\\nüíæ Session artifacts created:\")\n",
    "print(f\"   - Liquid universe definition for Q1 2024\")\n",
    "print(f\"   - Factor DNA analysis for Quality, Value, Momentum\")\n",
    "print(f\"   - Preliminary quintile efficacy assessment\")\n",
    "print(f\"   - Go/No-Go decision framework\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(f\"‚úÖ LIQUID UNIVERSE FACTOR DNA ANALYSIS COMPLETE\")\n",
    "print(f\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}