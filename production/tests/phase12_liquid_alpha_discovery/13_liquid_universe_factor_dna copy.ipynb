{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Liquid Universe Factor DNA Analysis\n",
    "\n",
    "**Objective**: Implement the new \"liquid-universe-first\" backtesting pipeline and conduct quintile analysis for standalone Quality, Value, and Momentum factors on the ASC-VN-Liquid-150 universe.\n",
    "\n",
    "**Critical Architecture Change**: Unlike previous notebooks, this pipeline filters the universe BEFORE any factor ranking occurs, ensuring we only evaluate signals on truly investable stocks.\n",
    "\n",
    "## Strategic Context\n",
    "\n",
    "This notebook represents the pivot from our previous \"liquidity-last\" architecture to a new \"liquid-universe-first\" approach. The original strategy showed phenomenal alpha (~2.1 Sharpe) but was concentrated in untradable micro-cap stocks. This analysis will establish a realistic performance baseline for our existing factors within the investable universe.\n",
    "\n",
    "**Universe Definition**: Top 200 stocks by 63-day ADTV, refreshed quarterly, with baseline ADTV threshold of 10B VND (ASC-VN-Liquid-150).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Environment Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Environment setup complete\n",
      "Analysis date: 2025-07-28 08:22:18\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, date, timedelta\n",
    "import warnings\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"✅ Environment setup complete\")\n",
    "print(f\"Analysis date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Database connection established\n"
     ]
    }
   ],
   "source": [
    "# Database connection setup\n",
    "def create_db_connection():\n",
    "    \"\"\"Create database connection using config file\"\"\"\n",
    "    config_path = Path('../../../config/database.yml')\n",
    "    \n",
    "    with open(config_path, 'r') as f:\n",
    "        db_config = yaml.safe_load(f)\n",
    "    \n",
    "    conn_params = db_config['production']\n",
    "    connection_string = (\n",
    "        f\"mysql+pymysql://{conn_params['username']}:{conn_params['password']}\"\n",
    "        f\"@{conn_params['host']}/{conn_params['schema_name']}\"\n",
    "    )\n",
    "    \n",
    "    engine = create_engine(connection_string, pool_pre_ping=True)\n",
    "    return engine\n",
    "\n",
    "# Create database connection\n",
    "engine = create_db_connection()\n",
    "print(\"✅ Database connection established\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Liquid Universe Constructor\n",
    "\n",
    "This section implements the core \"liquid-universe-first\" logic. The universe is constructed BEFORE any factor analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Calculating ADTV universe for 2024-03-29\n",
      "   Lookback period: 2024-01-26 to 2024-03-29 (63 days)\n",
      "   Criteria: Top 200 stocks with ADTV >= 10.0B VND\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "(pymysql.err.OperationalError) (1267, \"Illegal mix of collations (utf8mb4_unicode_ci,IMPLICIT) and (utf8mb4_0900_ai_ci,IMPLICIT) for operation '='\")\n[SQL: \n        SELECT \n            v.ticker,\n            m.sector,\n            COUNT(v.trading_date) as trading_days,\n            AVG(v.total_value / 1e9) as adtv_bn_vnd,\n            SUM(v.total_value / 1e9) as total_turnover_bn_vnd,\n            AVG(v.market_cap / 1e9) as avg_market_cap_bn_vnd,\n            MIN(v.trading_date) as first_date,\n            MAX(v.trading_date) as last_date\n        FROM vcsc_daily_data_complete v\n        INNER JOIN master_info m ON v.ticker = m.ticker\n        WHERE v.trading_date BETWEEN %(start_date)s AND %(as_of_date)s\n            AND v.total_value > 0\n            AND v.market_cap > 0\n        GROUP BY v.ticker, m.sector\n        HAVING trading_days >= %(min_trading_days)s\n            AND adtv_bn_vnd >= %(min_adtv_bn)s\n        ORDER BY adtv_bn_vnd DESC\n        LIMIT %(top_n)s\n    ]\n[parameters: {'start_date': '2024-01-26', 'as_of_date': '2024-03-29', 'min_trading_days': 50, 'min_adtv_bn': 10.0, 'top_n': 200}]\n(Background on this error at: https://sqlalche.me/e/14/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOperationalError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/vn_factor_env/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1910\u001b[39m, in \u001b[36mConnection._execute_context\u001b[39m\u001b[34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[39m\n\u001b[32m   1909\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[32m-> \u001b[39m\u001b[32m1910\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1911\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1912\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1914\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine._has_events:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/vn_factor_env/lib/python3.11/site-packages/sqlalchemy/engine/default.py:736\u001b[39m, in \u001b[36mDefaultDialect.do_execute\u001b[39m\u001b[34m(self, cursor, statement, parameters, context)\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m736\u001b[39m     \u001b[43mcursor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/vn_factor_env/lib/python3.11/site-packages/pymysql/cursors.py:153\u001b[39m, in \u001b[36mCursor.execute\u001b[39m\u001b[34m(self, query, args)\u001b[39m\n\u001b[32m    151\u001b[39m query = \u001b[38;5;28mself\u001b[39m.mogrify(query, args)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[38;5;28mself\u001b[39m._executed = query\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/vn_factor_env/lib/python3.11/site-packages/pymysql/cursors.py:322\u001b[39m, in \u001b[36mCursor._query\u001b[39m\u001b[34m(self, q)\u001b[39m\n\u001b[32m    321\u001b[39m \u001b[38;5;28mself\u001b[39m._clear_result()\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[38;5;28mself\u001b[39m._do_get_result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/vn_factor_env/lib/python3.11/site-packages/pymysql/connections.py:563\u001b[39m, in \u001b[36mConnection.query\u001b[39m\u001b[34m(self, sql, unbuffered)\u001b[39m\n\u001b[32m    562\u001b[39m \u001b[38;5;28mself\u001b[39m._execute_command(COMMAND.COM_QUERY, sql)\n\u001b[32m--> \u001b[39m\u001b[32m563\u001b[39m \u001b[38;5;28mself\u001b[39m._affected_rows = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_query_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43munbuffered\u001b[49m\u001b[43m=\u001b[49m\u001b[43munbuffered\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._affected_rows\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/vn_factor_env/lib/python3.11/site-packages/pymysql/connections.py:825\u001b[39m, in \u001b[36mConnection._read_query_result\u001b[39m\u001b[34m(self, unbuffered)\u001b[39m\n\u001b[32m    824\u001b[39m     result = MySQLResult(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m     \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[38;5;28mself\u001b[39m._result = result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/vn_factor_env/lib/python3.11/site-packages/pymysql/connections.py:1199\u001b[39m, in \u001b[36mMySQLResult.read\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1198\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1199\u001b[39m     first_packet = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_read_packet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1201\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m first_packet.is_ok_packet():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/vn_factor_env/lib/python3.11/site-packages/pymysql/connections.py:775\u001b[39m, in \u001b[36mConnection._read_packet\u001b[39m\u001b[34m(self, packet_type)\u001b[39m\n\u001b[32m    774\u001b[39m         \u001b[38;5;28mself\u001b[39m._result.unbuffered_active = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m775\u001b[39m     \u001b[43mpacket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    776\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m packet\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/vn_factor_env/lib/python3.11/site-packages/pymysql/protocol.py:219\u001b[39m, in \u001b[36mMysqlPacket.raise_for_error\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    218\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33merrno =\u001b[39m\u001b[33m\"\u001b[39m, errno)\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m \u001b[43merr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_mysql_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/vn_factor_env/lib/python3.11/site-packages/pymysql/err.py:150\u001b[39m, in \u001b[36mraise_mysql_exception\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    149\u001b[39m     errorclass = InternalError \u001b[38;5;28;01mif\u001b[39;00m errno < \u001b[32m1000\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m OperationalError\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m errorclass(errno, errval)\n",
      "\u001b[31mOperationalError\u001b[39m: (1267, \"Illegal mix of collations (utf8mb4_unicode_ci,IMPLICIT) and (utf8mb4_0900_ai_ci,IMPLICIT) for operation '='\")",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOperationalError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 69\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# Test universe construction for Q1 2024\u001b[39;00m\n\u001b[32m     68\u001b[39m test_date = \u001b[33m'\u001b[39m\u001b[33m2024-03-29\u001b[39m\u001b[33m'\u001b[39m  \u001b[38;5;66;03m# End of Q1 2024\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m liquid_universe = \u001b[43mcalculate_adtv_universe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# Display top 10 most liquid stocks\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m📊 Top 10 Most Liquid Stocks:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 49\u001b[39m, in \u001b[36mcalculate_adtv_universe\u001b[39m\u001b[34m(engine, as_of_date, lookback_days, top_n, min_adtv_bn)\u001b[39m\n\u001b[32m     46\u001b[39m min_trading_days = \u001b[38;5;28mint\u001b[39m(lookback_days * \u001b[32m0.8\u001b[39m)\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m engine.connect() \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     universe_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_sql_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m        \u001b[49m\u001b[43madtv_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstart_date\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mas_of_date\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_of_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmin_trading_days\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_trading_days\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmin_adtv_bn\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_adtv_bn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtop_n\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_n\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✅ Universe calculated: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(universe_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m stocks qualify\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     62\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   ADTV range: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muniverse_df[\u001b[33m'\u001b[39m\u001b[33madtv_bn_vnd\u001b[39m\u001b[33m'\u001b[39m].min()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mB - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muniverse_df[\u001b[33m'\u001b[39m\u001b[33madtv_bn_vnd\u001b[39m\u001b[33m'\u001b[39m].max()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mB VND\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/vn_factor_env/lib/python3.11/site-packages/pandas/io/sql.py:397\u001b[39m, in \u001b[36mread_sql_query\u001b[39m\u001b[34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype)\u001b[39m\n\u001b[32m    339\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    340\u001b[39m \u001b[33;03mRead SQL query into a DataFrame.\u001b[39;00m\n\u001b[32m    341\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    394\u001b[39m \u001b[33;03mparameter will be converted to UTC.\u001b[39;00m\n\u001b[32m    395\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    396\u001b[39m pandas_sql = pandasSQL_builder(con)\n\u001b[32m--> \u001b[39m\u001b[32m397\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m    \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/vn_factor_env/lib/python3.11/site-packages/pandas/io/sql.py:1560\u001b[39m, in \u001b[36mSQLDatabase.read_query\u001b[39m\u001b[34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype)\u001b[39m\n\u001b[32m   1512\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1513\u001b[39m \u001b[33;03mRead SQL query into a DataFrame.\u001b[39;00m\n\u001b[32m   1514\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1556\u001b[39m \n\u001b[32m   1557\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1558\u001b[39m args = _convert_params(sql, params)\n\u001b[32m-> \u001b[39m\u001b[32m1560\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1561\u001b[39m columns = result.keys()\n\u001b[32m   1563\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/vn_factor_env/lib/python3.11/site-packages/pandas/io/sql.py:1405\u001b[39m, in \u001b[36mSQLDatabase.execute\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1403\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m   1404\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Simple passthrough to SQLAlchemy connectable\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1405\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnectable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/vn_factor_env/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1385\u001b[39m, in \u001b[36mConnection.execute\u001b[39m\u001b[34m(self, statement, *multiparams, **params)\u001b[39m\n\u001b[32m   1381\u001b[39m     util.raise_(\n\u001b[32m   1382\u001b[39m         exc.ObjectNotExecutableError(statement), replace_context=err\n\u001b[32m   1383\u001b[39m     )\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1385\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultiparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_EMPTY_EXECUTION_OPTS\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/vn_factor_env/lib/python3.11/site-packages/sqlalchemy/sql/elements.py:334\u001b[39m, in \u001b[36mClauseElement._execute_on_connection\u001b[39m\u001b[34m(self, connection, multiparams, params, execution_options, _force)\u001b[39m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_execute_on_connection\u001b[39m(\n\u001b[32m    331\u001b[39m     \u001b[38;5;28mself\u001b[39m, connection, multiparams, params, execution_options, _force=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    332\u001b[39m ):\n\u001b[32m    333\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _force \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.supports_execution:\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultiparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    338\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m exc.ObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/vn_factor_env/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1577\u001b[39m, in \u001b[36mConnection._execute_clauseelement\u001b[39m\u001b[34m(self, elem, multiparams, params, execution_options)\u001b[39m\n\u001b[32m   1565\u001b[39m compiled_cache = execution_options.get(\n\u001b[32m   1566\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcompiled_cache\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.engine._compiled_cache\n\u001b[32m   1567\u001b[39m )\n\u001b[32m   1569\u001b[39m compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(\n\u001b[32m   1570\u001b[39m     dialect=dialect,\n\u001b[32m   1571\u001b[39m     compiled_cache=compiled_cache,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1575\u001b[39m     linting=\u001b[38;5;28mself\u001b[39m.dialect.compiler_linting | compiler.WARN_LINTING,\n\u001b[32m   1576\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1577\u001b[39m ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1578\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1579\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_init_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1580\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1581\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1582\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1583\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1584\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1585\u001b[39m \u001b[43m    \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1586\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextracted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1587\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1588\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1589\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[32m   1590\u001b[39m     \u001b[38;5;28mself\u001b[39m.dispatch.after_execute(\n\u001b[32m   1591\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1592\u001b[39m         elem,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1596\u001b[39m         ret,\n\u001b[32m   1597\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/vn_factor_env/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1953\u001b[39m, in \u001b[36mConnection._execute_context\u001b[39m\u001b[34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[39m\n\u001b[32m   1950\u001b[39m             branched.close()\n\u001b[32m   1952\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1953\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1954\u001b[39m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1955\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1957\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/vn_factor_env/lib/python3.11/site-packages/sqlalchemy/engine/base.py:2134\u001b[39m, in \u001b[36mConnection._handle_dbapi_exception\u001b[39m\u001b[34m(self, e, statement, parameters, cursor, context)\u001b[39m\n\u001b[32m   2132\u001b[39m     util.raise_(newraise, with_traceback=exc_info[\u001b[32m2\u001b[39m], from_=e)\n\u001b[32m   2133\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[32m-> \u001b[39m\u001b[32m2134\u001b[39m     \u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2135\u001b[39m \u001b[43m        \u001b[49m\u001b[43msqlalchemy_exception\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_traceback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\n\u001b[32m   2136\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2137\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2138\u001b[39m     util.raise_(exc_info[\u001b[32m1\u001b[39m], with_traceback=exc_info[\u001b[32m2\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/vn_factor_env/lib/python3.11/site-packages/sqlalchemy/util/compat.py:211\u001b[39m, in \u001b[36mraise_\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    208\u001b[39m     exception.__cause__ = replace_context\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exception\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;66;03m# credit to\u001b[39;00m\n\u001b[32m    214\u001b[39m     \u001b[38;5;66;03m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[32m    215\u001b[39m     \u001b[38;5;66;03m# as the __traceback__ object creates a cycle\u001b[39;00m\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m exception, replace_context, from_, with_traceback\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/vn_factor_env/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1910\u001b[39m, in \u001b[36mConnection._execute_context\u001b[39m\u001b[34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[39m\n\u001b[32m   1908\u001b[39m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1909\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[32m-> \u001b[39m\u001b[32m1910\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1911\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1912\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1914\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine._has_events:\n\u001b[32m   1915\u001b[39m     \u001b[38;5;28mself\u001b[39m.dispatch.after_cursor_execute(\n\u001b[32m   1916\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1917\u001b[39m         cursor,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1921\u001b[39m         context.executemany,\n\u001b[32m   1922\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/vn_factor_env/lib/python3.11/site-packages/sqlalchemy/engine/default.py:736\u001b[39m, in \u001b[36mDefaultDialect.do_execute\u001b[39m\u001b[34m(self, cursor, statement, parameters, context)\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m736\u001b[39m     \u001b[43mcursor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/vn_factor_env/lib/python3.11/site-packages/pymysql/cursors.py:153\u001b[39m, in \u001b[36mCursor.execute\u001b[39m\u001b[34m(self, query, args)\u001b[39m\n\u001b[32m    149\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    151\u001b[39m query = \u001b[38;5;28mself\u001b[39m.mogrify(query, args)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[38;5;28mself\u001b[39m._executed = query\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/vn_factor_env/lib/python3.11/site-packages/pymysql/cursors.py:322\u001b[39m, in \u001b[36mCursor._query\u001b[39m\u001b[34m(self, q)\u001b[39m\n\u001b[32m    320\u001b[39m conn = \u001b[38;5;28mself\u001b[39m._get_db()\n\u001b[32m    321\u001b[39m \u001b[38;5;28mself\u001b[39m._clear_result()\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[38;5;28mself\u001b[39m._do_get_result()\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.rowcount\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/vn_factor_env/lib/python3.11/site-packages/pymysql/connections.py:563\u001b[39m, in \u001b[36mConnection.query\u001b[39m\u001b[34m(self, sql, unbuffered)\u001b[39m\n\u001b[32m    561\u001b[39m     sql = sql.encode(\u001b[38;5;28mself\u001b[39m.encoding, \u001b[33m\"\u001b[39m\u001b[33msurrogateescape\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    562\u001b[39m \u001b[38;5;28mself\u001b[39m._execute_command(COMMAND.COM_QUERY, sql)\n\u001b[32m--> \u001b[39m\u001b[32m563\u001b[39m \u001b[38;5;28mself\u001b[39m._affected_rows = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_query_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43munbuffered\u001b[49m\u001b[43m=\u001b[49m\u001b[43munbuffered\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._affected_rows\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/vn_factor_env/lib/python3.11/site-packages/pymysql/connections.py:825\u001b[39m, in \u001b[36mConnection._read_query_result\u001b[39m\u001b[34m(self, unbuffered)\u001b[39m\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    824\u001b[39m     result = MySQLResult(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m     \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[38;5;28mself\u001b[39m._result = result\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.server_status \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/vn_factor_env/lib/python3.11/site-packages/pymysql/connections.py:1199\u001b[39m, in \u001b[36mMySQLResult.read\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1197\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1198\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1199\u001b[39m         first_packet = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_read_packet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1201\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m first_packet.is_ok_packet():\n\u001b[32m   1202\u001b[39m             \u001b[38;5;28mself\u001b[39m._read_ok_packet(first_packet)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/vn_factor_env/lib/python3.11/site-packages/pymysql/connections.py:775\u001b[39m, in \u001b[36mConnection._read_packet\u001b[39m\u001b[34m(self, packet_type)\u001b[39m\n\u001b[32m    773\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result.unbuffered_active \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    774\u001b[39m         \u001b[38;5;28mself\u001b[39m._result.unbuffered_active = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m775\u001b[39m     \u001b[43mpacket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    776\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m packet\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/vn_factor_env/lib/python3.11/site-packages/pymysql/protocol.py:219\u001b[39m, in \u001b[36mMysqlPacket.raise_for_error\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m DEBUG:\n\u001b[32m    218\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33merrno =\u001b[39m\u001b[33m\"\u001b[39m, errno)\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m \u001b[43merr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_mysql_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/vn_factor_env/lib/python3.11/site-packages/pymysql/err.py:150\u001b[39m, in \u001b[36mraise_mysql_exception\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m errorclass \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    149\u001b[39m     errorclass = InternalError \u001b[38;5;28;01mif\u001b[39;00m errno < \u001b[32m1000\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m OperationalError\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m errorclass(errno, errval)\n",
      "\u001b[31mOperationalError\u001b[39m: (pymysql.err.OperationalError) (1267, \"Illegal mix of collations (utf8mb4_unicode_ci,IMPLICIT) and (utf8mb4_0900_ai_ci,IMPLICIT) for operation '='\")\n[SQL: \n        SELECT \n            v.ticker,\n            m.sector,\n            COUNT(v.trading_date) as trading_days,\n            AVG(v.total_value / 1e9) as adtv_bn_vnd,\n            SUM(v.total_value / 1e9) as total_turnover_bn_vnd,\n            AVG(v.market_cap / 1e9) as avg_market_cap_bn_vnd,\n            MIN(v.trading_date) as first_date,\n            MAX(v.trading_date) as last_date\n        FROM vcsc_daily_data_complete v\n        INNER JOIN master_info m ON v.ticker = m.ticker\n        WHERE v.trading_date BETWEEN %(start_date)s AND %(as_of_date)s\n            AND v.total_value > 0\n            AND v.market_cap > 0\n        GROUP BY v.ticker, m.sector\n        HAVING trading_days >= %(min_trading_days)s\n            AND adtv_bn_vnd >= %(min_adtv_bn)s\n        ORDER BY adtv_bn_vnd DESC\n        LIMIT %(top_n)s\n    ]\n[parameters: {'start_date': '2024-01-26', 'as_of_date': '2024-03-29', 'min_trading_days': 50, 'min_adtv_bn': 10.0, 'top_n': 200}]\n(Background on this error at: https://sqlalche.me/e/14/e3q8)"
     ]
    }
   ],
   "source": [
    "def calculate_adtv_universe(engine, as_of_date: str, lookback_days: int = 63, top_n: int = 200, min_adtv_bn: float = 10.0):\n",
    "    \"\"\"\n",
    "    Calculate liquid universe based on ADTV criteria.\n",
    "    \n",
    "    Parameters:\n",
    "    - as_of_date: Date for universe construction (T-2 to avoid look-ahead bias)\n",
    "    - lookback_days: Days to calculate ADTV (default 63 = ~3 months)\n",
    "    - top_n: Number of most liquid stocks to select\n",
    "    - min_adtv_bn: Minimum ADTV threshold in billion VND\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with liquid universe tickers and their ADTV metrics\n",
    "    \"\"\"\n",
    "    # Calculate lookback start date\n",
    "    as_of_dt = pd.to_datetime(as_of_date)\n",
    "    start_date = (as_of_dt - timedelta(days=lookback_days)).strftime('%Y-%m-%d')\n",
    "    \n",
    "    print(f\"🔍 Calculating ADTV universe for {as_of_date}\")\n",
    "    print(f\"   Lookback period: {start_date} to {as_of_date} ({lookback_days} days)\")\n",
    "    print(f\"   Criteria: Top {top_n} stocks with ADTV >= {min_adtv_bn}B VND\")\n",
    "    \n",
    "    # Query to calculate ADTV by ticker\n",
    "    adtv_query = text(\"\"\"\n",
    "        SELECT \n",
    "            v.ticker,\n",
    "            m.sector,\n",
    "            COUNT(v.trading_date) as trading_days,\n",
    "            AVG(v.total_value / 1e9) as adtv_bn_vnd,\n",
    "            SUM(v.total_value / 1e9) as total_turnover_bn_vnd,\n",
    "            AVG(v.market_cap / 1e9) as avg_market_cap_bn_vnd,\n",
    "            MIN(v.trading_date) as first_date,\n",
    "            MAX(v.trading_date) as last_date\n",
    "        FROM vcsc_daily_data_complete v\n",
    "        INNER JOIN master_info m ON v.ticker = m.ticker\n",
    "        WHERE v.trading_date BETWEEN :start_date AND :as_of_date\n",
    "            AND v.total_value > 0\n",
    "            AND v.market_cap > 0\n",
    "        GROUP BY v.ticker, m.sector\n",
    "        HAVING trading_days >= :min_trading_days\n",
    "            AND adtv_bn_vnd >= :min_adtv_bn\n",
    "        ORDER BY adtv_bn_vnd DESC\n",
    "        LIMIT :top_n\n",
    "    \"\"\")\n",
    "    \n",
    "    # Require at least 80% of trading days for inclusion\n",
    "    min_trading_days = int(lookback_days * 0.8)\n",
    "    \n",
    "    with engine.connect() as conn:\n",
    "        universe_df = pd.read_sql_query(\n",
    "            adtv_query,\n",
    "            conn,\n",
    "            params={\n",
    "                'start_date': start_date,\n",
    "                'as_of_date': as_of_date,\n",
    "                'min_trading_days': min_trading_days,\n",
    "                'min_adtv_bn': min_adtv_bn,\n",
    "                'top_n': top_n\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    print(f\"✅ Universe calculated: {len(universe_df)} stocks qualify\")\n",
    "    print(f\"   ADTV range: {universe_df['adtv_bn_vnd'].min():.1f}B - {universe_df['adtv_bn_vnd'].max():.1f}B VND\")\n",
    "    print(f\"   Market cap range: {universe_df['avg_market_cap_bn_vnd'].min():.1f}B - {universe_df['avg_market_cap_bn_vnd'].max():.1f}B VND\")\n",
    "    \n",
    "    return universe_df\n",
    "\n",
    "# Test universe construction for Q1 2024\n",
    "test_date = '2024-03-29'  # End of Q1 2024\n",
    "liquid_universe = calculate_adtv_universe(engine, test_date)\n",
    "\n",
    "# Display top 10 most liquid stocks\n",
    "print(\"\\n📊 Top 10 Most Liquid Stocks:\")\n",
    "display(liquid_universe.head(10)[['ticker', 'sector', 'adtv_bn_vnd', 'avg_market_cap_bn_vnd', 'trading_days']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze universe composition by sector\n",
    "sector_analysis = liquid_universe.groupby('sector').agg({\n",
    "    'ticker': 'count',\n",
    "    'adtv_bn_vnd': ['mean', 'sum'],\n",
    "    'avg_market_cap_bn_vnd': ['mean', 'sum']\n",
    "}).round(2)\n",
    "\n",
    "sector_analysis.columns = ['Count', 'Avg_ADTV_Bn', 'Total_ADTV_Bn', 'Avg_MCap_Bn', 'Total_MCap_Bn']\n",
    "sector_analysis = sector_analysis.sort_values('Count', ascending=False)\n",
    "\n",
    "print(\"🏢 Liquid Universe Composition by Sector:\")\n",
    "display(sector_analysis)\n",
    "\n",
    "# Plot sector composition\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Count by sector\n",
    "sector_analysis['Count'].plot(kind='bar', ax=ax1, color='skyblue')\n",
    "ax1.set_title('Liquid Universe: Stock Count by Sector')\n",
    "ax1.set_ylabel('Number of Stocks')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# ADTV by sector  \n",
    "sector_analysis['Total_ADTV_Bn'].plot(kind='bar', ax=ax2, color='lightcoral')\n",
    "ax2.set_title('Liquid Universe: Total ADTV by Sector (Billion VND)')\n",
    "ax2.set_ylabel('Total ADTV (Billion VND)')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n📈 Universe Statistics:\")\n",
    "print(f\"   Total tickers: {len(liquid_universe)}\")\n",
    "print(f\"   Sectors represented: {liquid_universe['sector'].nunique()}\")\n",
    "print(f\"   Total market cap: {liquid_universe['avg_market_cap_bn_vnd'].sum():.0f}B VND\")\n",
    "print(f\"   Total daily turnover: {liquid_universe['adtv_bn_vnd'].sum():.0f}B VND\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Factor Data Loading for Liquid Universe\n",
    "\n",
    "Load factor scores ONLY for the tickers in our liquid universe. This is the key architectural change - we filter first, then analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_factor_scores_for_universe(engine, universe_tickers, start_date: str, end_date: str, strategy_version: str = 'qvm_v2.0_enhanced'):\n",
    "    \"\"\"\n",
    "    Load factor scores ONLY for stocks in the liquid universe.\n",
    "    \n",
    "    This is the core \"liquid-universe-first\" implementation:\n",
    "    We filter the universe BEFORE loading any factor data.\n",
    "    \"\"\"\n",
    "    print(f\"📊 Loading factor scores for liquid universe\")\n",
    "    print(f\"   Universe size: {len(universe_tickers)} tickers\")\n",
    "    print(f\"   Date range: {start_date} to {end_date}\")\n",
    "    print(f\"   Strategy version: {strategy_version}\")\n",
    "    \n",
    "    # Convert universe tickers to tuple for SQL IN clause\n",
    "    ticker_tuple = tuple(universe_tickers)\n",
    "    \n",
    "    factor_query = text(\"\"\"\n",
    "        SELECT \n",
    "            ticker,\n",
    "            date,\n",
    "            Quality_Composite,\n",
    "            Value_Composite,\n",
    "            Momentum_Composite,\n",
    "            QVM_Composite\n",
    "        FROM factor_scores_qvm\n",
    "        WHERE ticker IN :tickers\n",
    "            AND date BETWEEN :start_date AND :end_date\n",
    "            AND strategy_version = :strategy_version\n",
    "            AND Quality_Composite IS NOT NULL\n",
    "            AND Value_Composite IS NOT NULL\n",
    "            AND Momentum_Composite IS NOT NULL\n",
    "        ORDER BY date, ticker\n",
    "    \"\"\")\n",
    "    \n",
    "    with engine.connect() as conn:\n",
    "        factor_df = pd.read_sql_query(\n",
    "            factor_query,\n",
    "            conn,\n",
    "            params={\n",
    "                'tickers': ticker_tuple,\n",
    "                'start_date': start_date,\n",
    "                'end_date': end_date,\n",
    "                'strategy_version': strategy_version\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    factor_df['date'] = pd.to_datetime(factor_df['date'])\n",
    "    \n",
    "    print(f\"✅ Loaded {len(factor_df):,} factor observations\")\n",
    "    print(f\"   Date range: {factor_df['date'].min().date()} to {factor_df['date'].max().date()}\")\n",
    "    print(f\"   Unique tickers with data: {factor_df['ticker'].nunique()}\")\n",
    "    print(f\"   Unique dates: {factor_df['date'].nunique()}\")\n",
    "    \n",
    "    return factor_df\n",
    "\n",
    "# Load factor data for our liquid universe\n",
    "factor_data = load_factor_scores_for_universe(\n",
    "    engine=engine,\n",
    "    universe_tickers=liquid_universe['ticker'].tolist(),\n",
    "    start_date='2024-01-01',\n",
    "    end_date='2024-03-29',\n",
    "    strategy_version='qvm_v2.0_enhanced'\n",
    ")\n",
    "\n",
    "# Display sample data\n",
    "print(\"\\n📋 Sample Factor Data:\")\n",
    "display(factor_data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Critical Sanity Checks\n",
    "\n",
    "Before proceeding with any analysis, we must validate three critical conditions:\n",
    "1. **Coverage Check**: Sufficient number of stocks with factor data\n",
    "2. **Liquidity Overlap Check**: Factor universe aligns with liquid universe  \n",
    "3. **Factor Dispersion Check**: Factors show meaningful variation in liquid universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sanity_checks(factor_data, liquid_universe, min_coverage=125, min_dispersion=0.10):\n",
    "    \"\"\"\n",
    "    Run critical sanity checks before proceeding with analysis.\n",
    "    These are mandatory gates that must pass.\n",
    "    \"\"\"\n",
    "    print(\"🔍 RUNNING CRITICAL SANITY CHECKS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # 1. Coverage Check\n",
    "    unique_factor_tickers = factor_data['ticker'].nunique()\n",
    "    universe_size = len(liquid_universe)\n",
    "    coverage_ratio = unique_factor_tickers / universe_size\n",
    "    \n",
    "    print(f\"\\n1️⃣ COVERAGE CHECK:\")\n",
    "    print(f\"   Liquid universe size: {universe_size}\")\n",
    "    print(f\"   Tickers with factor data: {unique_factor_tickers}\")\n",
    "    print(f\"   Coverage ratio: {coverage_ratio:.1%}\")\n",
    "    print(f\"   Minimum required: {min_coverage} tickers\")\n",
    "    \n",
    "    coverage_pass = unique_factor_tickers >= min_coverage\n",
    "    results['coverage'] = {\n",
    "        'pass': coverage_pass,\n",
    "        'value': unique_factor_tickers,\n",
    "        'threshold': min_coverage,\n",
    "        'ratio': coverage_ratio\n",
    "    }\n",
    "    print(f\"   Status: {'✅ PASS' if coverage_pass else '❌ FAIL'}\")\n",
    "    \n",
    "    # 2. Liquidity Overlap Check  \n",
    "    factor_tickers = set(factor_data['ticker'].unique())\n",
    "    universe_tickers = set(liquid_universe['ticker'].unique())\n",
    "    overlap = factor_tickers.intersection(universe_tickers)\n",
    "    overlap_ratio = len(overlap) / len(universe_tickers)\n",
    "    \n",
    "    print(f\"\\n2️⃣ LIQUIDITY OVERLAP CHECK:\")\n",
    "    print(f\"   Universe tickers: {len(universe_tickers)}\")\n",
    "    print(f\"   Factor tickers: {len(factor_tickers)}\")\n",
    "    print(f\"   Overlap: {len(overlap)} ({overlap_ratio:.1%})\")\n",
    "    \n",
    "    # Check if any universe tickers are missing factor data\n",
    "    missing_tickers = universe_tickers - factor_tickers\n",
    "    if missing_tickers:\n",
    "        print(f\"   Missing factor data for: {sorted(list(missing_tickers))[:10]}...\")\n",
    "    \n",
    "    overlap_pass = overlap_ratio >= 0.8  # At least 80% overlap\n",
    "    results['overlap'] = {\n",
    "        'pass': overlap_pass,\n",
    "        'ratio': overlap_ratio,\n",
    "        'missing_count': len(missing_tickers)\n",
    "    }\n",
    "    print(f\"   Status: {'✅ PASS' if overlap_pass else '❌ FAIL'}\")\n",
    "    \n",
    "    # 3. Factor Dispersion Check\n",
    "    print(f\"\\n3️⃣ FACTOR DISPERSION CHECK:\")\n",
    "    factors = ['Quality_Composite', 'Value_Composite', 'Momentum_Composite']\n",
    "    dispersion_results = {}\n",
    "    \n",
    "    for factor in factors:\n",
    "        # Calculate cross-sectional standard deviation for each date\n",
    "        daily_std = factor_data.groupby('date')[factor].std()\n",
    "        avg_std = daily_std.mean()\n",
    "        \n",
    "        dispersion_pass = avg_std >= min_dispersion\n",
    "        dispersion_results[factor] = {\n",
    "            'pass': dispersion_pass,\n",
    "            'avg_std': avg_std,\n",
    "            'threshold': min_dispersion\n",
    "        }\n",
    "        \n",
    "        print(f\"   {factor}: {avg_std:.3f} ({'✅ PASS' if dispersion_pass else '❌ FAIL'})\")\n",
    "    \n",
    "    results['dispersion'] = dispersion_results\n",
    "    \n",
    "    # Overall assessment\n",
    "    all_dispersion_pass = all(r['pass'] for r in dispersion_results.values())\n",
    "    overall_pass = coverage_pass and overlap_pass and all_dispersion_pass\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"🎯 OVERALL SANITY CHECK: {'✅ ALL PASS' if overall_pass else '❌ SOME FAILED'}\")\n",
    "    \n",
    "    if not overall_pass:\n",
    "        print(\"\\n⚠️  WARNING: Some sanity checks failed!\")\n",
    "        print(\"   This indicates our factors may not be suitable for the liquid universe.\")\n",
    "        print(\"   Consider this a 'No-Go' decision for current factor definitions.\")\n",
    "    \n",
    "    results['overall_pass'] = overall_pass\n",
    "    return results\n",
    "\n",
    "# Run sanity checks\n",
    "sanity_results = run_sanity_checks(factor_data, liquid_universe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Liquid Universe Factor DNA Analysis\n",
    "\n",
    "If sanity checks pass, proceed with quintile analysis to establish the performance baseline for our factors in the investable universe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_factor_dna(factor_data, factor_name='Quality_Composite'):\n",
    "    \"\"\"\n",
    "    Analyze the \"DNA\" of a factor in the liquid universe:\n",
    "    - Distribution characteristics\n",
    "    - Temporal stability\n",
    "    - Cross-sectional dispersion\n",
    "    \"\"\"\n",
    "    print(f\"🧬 FACTOR DNA ANALYSIS: {factor_name}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. Distribution Analysis\n",
    "    factor_values = factor_data[factor_name].dropna()\n",
    "    \n",
    "    print(f\"\\n📊 Distribution Statistics:\")\n",
    "    print(f\"   Count: {len(factor_values):,}\")\n",
    "    print(f\"   Mean: {factor_values.mean():.4f}\")\n",
    "    print(f\"   Std Dev: {factor_values.std():.4f}\")\n",
    "    print(f\"   Skewness: {factor_values.skew():.4f}\")\n",
    "    print(f\"   Min: {factor_values.min():.4f}\")\n",
    "    print(f\"   25th %ile: {factor_values.quantile(0.25):.4f}\")\n",
    "    print(f\"   Median: {factor_values.median():.4f}\")\n",
    "    print(f\"   75th %ile: {factor_values.quantile(0.75):.4f}\")\n",
    "    print(f\"   Max: {factor_values.max():.4f}\")\n",
    "    \n",
    "    # 2. Temporal Analysis\n",
    "    daily_stats = factor_data.groupby('date')[factor_name].agg([\n",
    "        'count', 'mean', 'std', 'min', 'max'\n",
    "    ]).round(4)\n",
    "    \n",
    "    print(f\"\\n📈 Temporal Stability:\")\n",
    "    print(f\"   Avg daily coverage: {daily_stats['count'].mean():.1f} stocks\")\n",
    "    print(f\"   Mean stability (std of daily means): {daily_stats['mean'].std():.4f}\")\n",
    "    print(f\"   Dispersion stability (std of daily stds): {daily_stats['std'].std():.4f}\")\n",
    "    \n",
    "    # 3. Visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Distribution histogram\n",
    "    axes[0,0].hist(factor_values, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[0,0].axvline(factor_values.mean(), color='red', linestyle='--', label=f'Mean: {factor_values.mean():.3f}')\n",
    "    axes[0,0].axvline(factor_values.median(), color='orange', linestyle='--', label=f'Median: {factor_values.median():.3f}')\n",
    "    axes[0,0].set_title(f'{factor_name} Distribution in Liquid Universe')\n",
    "    axes[0,0].set_xlabel('Factor Value')\n",
    "    axes[0,0].set_ylabel('Frequency')\n",
    "    axes[0,0].legend()\n",
    "    \n",
    "    # Box plot\n",
    "    axes[0,1].boxplot(factor_values, patch_artist=True,\n",
    "                      boxprops=dict(facecolor='lightcoral', alpha=0.7))\n",
    "    axes[0,1].set_title(f'{factor_name} Box Plot')\n",
    "    axes[0,1].set_ylabel('Factor Value')\n",
    "    \n",
    "    # Time series of daily means\n",
    "    axes[1,0].plot(daily_stats.index, daily_stats['mean'], marker='o', linewidth=2)\n",
    "    axes[1,0].set_title(f'{factor_name} Daily Mean Over Time')\n",
    "    axes[1,0].set_xlabel('Date')\n",
    "    axes[1,0].set_ylabel('Daily Mean')\n",
    "    axes[1,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Time series of daily dispersion\n",
    "    axes[1,1].plot(daily_stats.index, daily_stats['std'], marker='s', color='green', linewidth=2)\n",
    "    axes[1,1].set_title(f'{factor_name} Daily Dispersion Over Time')\n",
    "    axes[1,1].set_xlabel('Date')\n",
    "    axes[1,1].set_ylabel('Daily Std Dev')\n",
    "    axes[1,1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'distribution_stats': factor_values.describe(),\n",
    "        'temporal_stats': daily_stats,\n",
    "        'mean_stability': daily_stats['mean'].std(),\n",
    "        'dispersion_stability': daily_stats['std'].std()\n",
    "    }\n",
    "\n",
    "# Analyze each factor's DNA if sanity checks passed\n",
    "if sanity_results['overall_pass']:\n",
    "    print(\"✅ Sanity checks passed - proceeding with Factor DNA analysis\\n\")\n",
    "    \n",
    "    # Analyze Quality factor\n",
    "    quality_dna = analyze_factor_dna(factor_data, 'Quality_Composite')\n",
    "else:\n",
    "    print(\"❌ Sanity checks failed - Factor DNA analysis not recommended\")\n",
    "    print(\"   Current factors may not be suitable for the liquid universe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue DNA analysis for Value and Momentum if Quality passed\n",
    "if sanity_results['overall_pass']:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    value_dna = analyze_factor_dna(factor_data, 'Value_Composite')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    momentum_dna = analyze_factor_dna(factor_data, 'Momentum_Composite')\n",
    "    \n",
    "    # Summary comparison\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"🎯 FACTOR DNA SUMMARY COMPARISON\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    factors = ['Quality_Composite', 'Value_Composite', 'Momentum_Composite']\n",
    "    dna_results = [quality_dna, value_dna, momentum_dna]\n",
    "    \n",
    "    summary_df = pd.DataFrame({\n",
    "        'Factor': factors,\n",
    "        'Mean': [factor_data[f].mean() for f in factors],\n",
    "        'Std_Dev': [factor_data[f].std() for f in factors],\n",
    "        'Skewness': [factor_data[f].skew() for f in factors],\n",
    "        'Mean_Stability': [dna['mean_stability'] for dna in dna_results],\n",
    "        'Dispersion_Stability': [dna['dispersion_stability'] for dna in dna_results]\n",
    "    }).round(4)\n",
    "    \n",
    "    display(summary_df)\n",
    "    \n",
    "    # Flag any concerning patterns\n",
    "    print(\"\\n🚨 DNA Health Check:\")\n",
    "    for i, factor in enumerate(factors):\n",
    "        std_dev = summary_df.iloc[i]['Std_Dev']\n",
    "        stability = summary_df.iloc[i]['Mean_Stability']\n",
    "        \n",
    "        if std_dev < 0.1:\n",
    "            print(f\"   ⚠️  {factor}: Low dispersion ({std_dev:.3f}) - may lack signal\")\n",
    "        if stability > 0.05:\n",
    "            print(f\"   ⚠️  {factor}: High instability ({stability:.3f}) - may be noisy\")\n",
    "        if std_dev >= 0.1 and stability <= 0.05:\n",
    "            print(f\"   ✅ {factor}: Healthy DNA profile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Preliminary Quintile Analysis\n",
    "\n",
    "If Factor DNA is healthy, conduct initial quintile analysis to measure factor efficacy in the liquid universe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preliminary_quintile_analysis(factor_data, price_data=None, factor_name='Quality_Composite'):\n",
    "    \"\"\"\n",
    "    Conduct preliminary quintile analysis for a single factor.\n",
    "    For now, focus on factor distribution across quintiles.\n",
    "    \n",
    "    Note: Full performance analysis requires price data loading,\n",
    "    which will be implemented in subsequent development.\n",
    "    \"\"\"\n",
    "    print(f\"📊 PRELIMINARY QUINTILE ANALYSIS: {factor_name}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Create quintile ranks for each date\n",
    "    factor_ranked = factor_data.copy()\n",
    "    factor_ranked[f'{factor_name}_quintile'] = factor_ranked.groupby('date')[factor_name].transform(\n",
    "        lambda x: pd.qcut(x, q=5, labels=[1, 2, 3, 4, 5], duplicates='drop')\n",
    "    )\n",
    "    \n",
    "    # Remove any rows where quintile assignment failed\n",
    "    factor_ranked = factor_ranked.dropna(subset=[f'{factor_name}_quintile'])\n",
    "    \n",
    "    print(f\"✅ Quintile ranking complete\")\n",
    "    print(f\"   Total observations with quintiles: {len(factor_ranked):,}\")\n",
    "    \n",
    "    # Analyze quintile characteristics\n",
    "    quintile_stats = factor_ranked.groupby(f'{factor_name}_quintile')[factor_name].agg([\n",
    "        'count', 'mean', 'std', 'min', 'max'\n",
    "    ]).round(4)\n",
    "    quintile_stats.columns = ['Count', 'Mean', 'Std_Dev', 'Min', 'Max']\n",
    "    \n",
    "    print(f\"\\n📈 Quintile Characteristics:\")\n",
    "    display(quintile_stats)\n",
    "    \n",
    "    # Calculate quintile spread\n",
    "    q5_mean = quintile_stats.loc[5, 'Mean']\n",
    "    q1_mean = quintile_stats.loc[1, 'Mean']\n",
    "    quintile_spread = q5_mean - q1_mean\n",
    "    \n",
    "    print(f\"\\n🎯 Key Metrics:\")\n",
    "    print(f\"   Quintile 5 (Top) Mean: {q5_mean:.4f}\")\n",
    "    print(f\"   Quintile 1 (Bottom) Mean: {q1_mean:.4f}\")\n",
    "    print(f\"   Quintile Spread (Q5-Q1): {quintile_spread:.4f}\")\n",
    "    \n",
    "    # Assess factor efficacy\n",
    "    if quintile_spread > 0.5:\n",
    "        efficacy = \"Strong\"\n",
    "    elif quintile_spread > 0.2:\n",
    "        efficacy = \"Moderate\"\n",
    "    elif quintile_spread > 0.1:\n",
    "        efficacy = \"Weak\"\n",
    "    else:\n",
    "        efficacy = \"Very Weak\"\n",
    "    \n",
    "    print(f\"   Factor Efficacy: {efficacy}\")\n",
    "    \n",
    "    # Visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Quintile means\n",
    "    quintile_stats['Mean'].plot(kind='bar', ax=ax1, color='steelblue')\n",
    "    ax1.set_title(f'{factor_name} Mean by Quintile')\n",
    "    ax1.set_xlabel('Quintile (1=Worst, 5=Best)')\n",
    "    ax1.set_ylabel('Factor Value')\n",
    "    ax1.tick_params(axis='x', rotation=0)\n",
    "    \n",
    "    # Box plot by quintile\n",
    "    factor_ranked.boxplot(column=factor_name, by=f'{factor_name}_quintile', ax=ax2)\n",
    "    ax2.set_title(f'{factor_name} Distribution by Quintile')\n",
    "    ax2.set_xlabel('Quintile (1=Worst, 5=Best)')\n",
    "    ax2.set_ylabel('Factor Value')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'quintile_stats': quintile_stats,\n",
    "        'quintile_spread': quintile_spread,\n",
    "        'efficacy': efficacy,\n",
    "        'ranked_data': factor_ranked\n",
    "    }\n",
    "\n",
    "# Run preliminary quintile analysis if DNA is healthy\n",
    "if sanity_results['overall_pass']:\n",
    "    quality_quintiles = preliminary_quintile_analysis(factor_data, factor_name='Quality_Composite')\n",
    "else:\n",
    "    print(\"❌ Skipping quintile analysis - sanity checks failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue quintile analysis for all factors\n",
    "if sanity_results['overall_pass']:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    value_quintiles = preliminary_quintile_analysis(factor_data, factor_name='Value_Composite')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    momentum_quintiles = preliminary_quintile_analysis(factor_data, factor_name='Momentum_Composite')\n",
    "    \n",
    "    # Summary comparison of all factors\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"🎯 LIQUID UNIVERSE FACTOR EFFICACY SUMMARY\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    efficacy_summary = pd.DataFrame({\n",
    "        'Factor': ['Quality_Composite', 'Value_Composite', 'Momentum_Composite'],\n",
    "        'Quintile_Spread': [\n",
    "            quality_quintiles['quintile_spread'],\n",
    "            value_quintiles['quintile_spread'],\n",
    "            momentum_quintiles['quintile_spread']\n",
    "        ],\n",
    "        'Efficacy_Rating': [\n",
    "            quality_quintiles['efficacy'],\n",
    "            value_quintiles['efficacy'],\n",
    "            momentum_quintiles['efficacy']\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    display(efficacy_summary)\n",
    "    \n",
    "    # Determine go/no-go decision\n",
    "    strong_factors = sum(1 for efficacy in efficacy_summary['Efficacy_Rating'] if efficacy == 'Strong')\n",
    "    moderate_factors = sum(1 for efficacy in efficacy_summary['Efficacy_Rating'] if efficacy == 'Moderate')\n",
    "    \n",
    "    print(f\"\\n🚦 GO/NO-GO DECISION:\")\n",
    "    print(f\"   Strong factors: {strong_factors}/3\")\n",
    "    print(f\"   Moderate+ factors: {strong_factors + moderate_factors}/3\")\n",
    "    \n",
    "    if strong_factors >= 2:\n",
    "        decision = \"✅ GO - Strong factor signals in liquid universe\"\n",
    "        recommendation = \"Proceed with full backtesting pipeline development\"\n",
    "    elif strong_factors + moderate_factors >= 2:\n",
    "        decision = \"🟡 CAUTIOUS GO - Moderate factor signals\"\n",
    "        recommendation = \"Proceed but consider factor enhancement\"\n",
    "    else:\n",
    "        decision = \"❌ NO-GO - Weak factor signals in liquid universe\"\n",
    "        recommendation = \"Pivot to Liquid Alpha Discovery phase for new factor engineering\"\n",
    "    \n",
    "    print(f\"   Decision: {decision}\")\n",
    "    print(f\"   Recommendation: {recommendation}\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ Cannot make go/no-go decision - preliminary analysis failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Session Summary & Next Steps\n",
    "\n",
    "Document findings and establish clear next steps based on the analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive session summary\n",
    "print(\"📋 LIQUID UNIVERSE FACTOR DNA - SESSION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n🎯 Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"📊 Universe Definition: ASC-VN-Liquid-150 (Top 200 by ADTV, 10B+ VND threshold)\")\n",
    "print(f\"📈 Test Period: Q1 2024 (2024-01-01 to 2024-03-29)\")\n",
    "print(f\"🔧 Strategy Version: qvm_v2.0_enhanced\")\n",
    "\n",
    "if 'liquid_universe' in locals():\n",
    "    print(f\"\\n🏢 Universe Composition:\")\n",
    "    print(f\"   Total stocks: {len(liquid_universe)}\")\n",
    "    print(f\"   ADTV range: {liquid_universe['adtv_bn_vnd'].min():.1f}B - {liquid_universe['adtv_bn_vnd'].max():.1f}B VND\")\n",
    "    print(f\"   Sectors represented: {liquid_universe['sector'].nunique()}\")\n",
    "\n",
    "if 'sanity_results' in locals():\n",
    "    print(f\"\\n🔍 Sanity Check Results:\")\n",
    "    print(f\"   Coverage: {'✅ PASS' if sanity_results['coverage']['pass'] else '❌ FAIL'} ({sanity_results['coverage']['value']} tickers)\")\n",
    "    print(f\"   Overlap: {'✅ PASS' if sanity_results['overlap']['pass'] else '❌ FAIL'} ({sanity_results['overlap']['ratio']:.1%} overlap)\")\n",
    "    \n",
    "    print(f\"   Factor Dispersion:\")\n",
    "    for factor, result in sanity_results['dispersion'].items():\n",
    "        print(f\"     {factor}: {'✅ PASS' if result['pass'] else '❌ FAIL'} ({result['avg_std']:.3f})\")\n",
    "\n",
    "if 'efficacy_summary' in locals():\n",
    "    print(f\"\\n🧬 Factor DNA Results:\")\n",
    "    for _, row in efficacy_summary.iterrows():\n",
    "        print(f\"   {row['Factor']}: {row['Efficacy_Rating']} (spread: {row['Quintile_Spread']:.3f})\")\n",
    "    \n",
    "    print(f\"\\n🚦 Final Decision: {decision}\")\n",
    "    print(f\"💡 Recommendation: {recommendation}\")\n",
    "\n",
    "print(f\"\\n📋 Key Architectural Achievement:\")\n",
    "print(f\"   ✅ Successfully implemented 'liquid-universe-first' pipeline\")\n",
    "print(f\"   ✅ Universe filtering occurs BEFORE factor analysis\")\n",
    "print(f\"   ✅ Eliminated risk of discovering inaccessible alpha\")\n",
    "\n",
    "print(f\"\\n⏭️  Next Steps:\")\n",
    "if 'sanity_results' in locals() and sanity_results['overall_pass']:\n",
    "    if 'strong_factors' in locals() and strong_factors >= 2:\n",
    "        print(f\"   1. Load price data for liquid universe\")\n",
    "        print(f\"   2. Implement full quintile performance analysis\")\n",
    "        print(f\"   3. Calculate returns, Sharpe ratios, and turnover\")\n",
    "        print(f\"   4. Build complete liquid-universe backtesting module\")\n",
    "        print(f\"   5. Compare liquid vs unrestricted universe performance\")\n",
    "    else:\n",
    "        print(f\"   1. Investigate factor weakness in liquid universe\")\n",
    "        print(f\"   2. Consider factor enhancement or new engineering\")\n",
    "        print(f\"   3. Analyze sector-specific factor behavior\")\n",
    "        print(f\"   4. Potentially pivot to Liquid Alpha Discovery phase\")\n",
    "else:\n",
    "    print(f\"   1. Investigate sanity check failures\")\n",
    "    print(f\"   2. Review factor generation process for liquid universe\")\n",
    "    print(f\"   3. Consider data quality issues or timing problems\")\n",
    "    print(f\"   4. Re-run analysis with different universe parameters\")\n",
    "\n",
    "print(f\"\\n💾 Session artifacts created:\")\n",
    "print(f\"   - Liquid universe definition for Q1 2024\")\n",
    "print(f\"   - Factor DNA analysis for Quality, Value, Momentum\")\n",
    "print(f\"   - Preliminary quintile efficacy assessment\")\n",
    "print(f\"   - Go/No-Go decision framework\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(f\"✅ LIQUID UNIVERSE FACTOR DNA ANALYSIS COMPLETE\")\n",
    "print(f\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vn_factor_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
