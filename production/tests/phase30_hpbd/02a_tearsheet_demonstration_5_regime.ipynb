{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58e0a939",
   "metadata": {},
   "source": [
    "# QVM ENGINE V3J TEARSHEET DEMONSTRATION\n",
    "\n",
    "This notebook demonstrates the QVM (Quality, Value, Momentum) factor investing strategy with comprehensive performance analysis and visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79210d3",
   "metadata": {},
   "source": [
    "# IMPORTS AND SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73d2627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime, date\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61c5085",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/raymond/Documents/Projects/factor-investing-public')\n",
    "from production.database.connection import DatabaseManager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8bdad0",
   "metadata": {},
   "source": [
    "# REGIME DETECTION COMPONENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa6f74b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class EnhancedRegimeDetector:\n",
    "    \"\"\"\n",
    "    Enhanced 5-regime detection system using absolute thresholds for stability.\n",
    "    Regimes: BULL, GROWTH, SIDEWAYS, CORRECTION, CRISIS\n",
    "    \"\"\"\n",
    "    def __init__(self, lookback_period: int = 90, min_regime_duration: int = 30):\n",
    "        self.lookback_period = lookback_period\n",
    "        self.min_regime_duration = min_regime_duration\n",
    "        \n",
    "        # Absolute thresholds (more stable than percentiles) - Made more reasonable\n",
    "        self.volatility_thresholds = {\n",
    "            'low': 0.20,      # < 20% annualized volatility\n",
    "            'medium': 0.30,   # 20-30% annualized volatility  \n",
    "            'high': 0.40      # > 40% annualized volatility\n",
    "        }\n",
    "        \n",
    "        self.return_thresholds = {\n",
    "            'strong_positive': 0.15,   # > 15% annualized return\n",
    "            'moderate_positive': 0.05,  # 5-15% annualized return\n",
    "            'moderate_negative': -0.05, # -5% to 5% annualized return\n",
    "            'strong_negative': -0.15    # < -15% annualized return\n",
    "        }\n",
    "        \n",
    "        self.drawdown_thresholds = {\n",
    "            'mild': 0.10,     # < 10% drawdown\n",
    "            'moderate': 0.20,  # 10-20% drawdown\n",
    "            'severe': 0.30     # > 30% drawdown\n",
    "        }\n",
    "        \n",
    "        print(f\"âœ… EnhancedRegimeDetector initialized with 5-regime system:\")\n",
    "        print(f\"   - Lookback Period: {self.lookback_period} days\")\n",
    "        print(f\"   - Min Regime Duration: {self.min_regime_duration} days\")\n",
    "        print(f\"   - Volatility Thresholds: Low(<15%), Medium(15-25%), High(>35%)\")\n",
    "        print(f\"   - Return Thresholds: Strong+(>20%), Mod+(8-20%), Mod-(-8% to 8%), Strong-(<-20%)\")\n",
    "        print(f\"   - Drawdown Thresholds: Mild(<10%), Moderate(10-20%), Severe(>30%)\")\n",
    "    \n",
    "    def classify_regime(self, rolling_return: float, rolling_vol: float, current_drawdown: float) -> str:\n",
    "        \"\"\"\n",
    "        Enhanced 5-regime classification:\n",
    "        1. BULL: Strong positive returns, low volatility\n",
    "        2. GROWTH: Moderate positive returns, normal volatility  \n",
    "        3. SIDEWAYS: Low returns, normal volatility\n",
    "        4. CORRECTION: Moderate negative returns, elevated volatility\n",
    "        5. CRISIS: Strong negative returns, high volatility\n",
    "        \"\"\"\n",
    "        if rolling_return > self.return_thresholds['strong_positive'] and rolling_vol < self.volatility_thresholds['low']:\n",
    "            return 'bull'\n",
    "        elif rolling_return > self.return_thresholds['moderate_positive'] and rolling_vol < self.volatility_thresholds['medium']:\n",
    "            return 'growth'  \n",
    "        elif abs(rolling_return) < abs(self.return_thresholds['moderate_negative']) and rolling_vol < self.volatility_thresholds['medium']:\n",
    "            return 'sideways'\n",
    "        elif rolling_return < self.return_thresholds['moderate_negative'] and rolling_vol > self.volatility_thresholds['medium']:\n",
    "            return 'correction'\n",
    "        elif rolling_return < self.return_thresholds['strong_negative'] and rolling_vol > self.volatility_thresholds['high']:\n",
    "            return 'crisis'\n",
    "        else:\n",
    "            return 'sideways'  # default\n",
    "    \n",
    "    def detect_regime(self, benchmark_data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Detect market regime using enhanced 5-regime classification with stability controls.\"\"\"\n",
    "        print(\"ðŸ“Š Detecting market regime with enhanced 5-regime system...\")\n",
    "        \n",
    "        # Calculate rolling volatility and returns\n",
    "        benchmark_data = benchmark_data.sort_values('date').copy()\n",
    "        benchmark_data['rolling_vol'] = benchmark_data['return'].rolling(self.lookback_period).std() * np.sqrt(252)\n",
    "        benchmark_data['rolling_return'] = benchmark_data['return'].rolling(self.lookback_period).mean() * 252\n",
    "        \n",
    "        # Calculate drawdown\n",
    "        benchmark_data['cumulative_return'] = (1 + benchmark_data['return']).cumprod()\n",
    "        benchmark_data['running_max'] = benchmark_data['cumulative_return'].expanding().max()\n",
    "        benchmark_data['drawdown'] = (benchmark_data['cumulative_return'] - benchmark_data['running_max']) / benchmark_data['running_max']\n",
    "        \n",
    "        # Initial regime classification using enhanced logic\n",
    "        print(\"   ðŸ“Š Applying enhanced 5-regime classification...\")\n",
    "        benchmark_data['regime'] = 'sideways'  # default\n",
    "        \n",
    "        # Debug: Show some sample values\n",
    "        print(f\"   ðŸ“Š Sample rolling values (first 5 after lookback):\")\n",
    "        for i in range(self.lookback_period, min(self.lookback_period + 5, len(benchmark_data))):\n",
    "            rolling_return = benchmark_data.iloc[i]['rolling_return']\n",
    "            rolling_vol = benchmark_data.iloc[i]['rolling_vol']\n",
    "            current_drawdown = benchmark_data.iloc[i]['drawdown']\n",
    "            print(f\"      Date {benchmark_data.iloc[i]['date']}: Return={rolling_return:.3f}, Vol={rolling_vol:.3f}, DD={current_drawdown:.3f}\")\n",
    "        \n",
    "        for i in range(self.lookback_period, len(benchmark_data)):\n",
    "            rolling_return = benchmark_data.iloc[i]['rolling_return']\n",
    "            rolling_vol = benchmark_data.iloc[i]['rolling_vol']\n",
    "            current_drawdown = benchmark_data.iloc[i]['drawdown']\n",
    "            \n",
    "            # Classify regime using enhanced logic\n",
    "            regime = self.classify_regime(rolling_return, rolling_vol, current_drawdown)\n",
    "            benchmark_data.iloc[i, benchmark_data.columns.get_loc('regime')] = regime\n",
    "        \n",
    "        # Apply minimum regime duration filter for stability\n",
    "        print(f\"   ðŸ“Š Applying minimum regime duration filter ({self.min_regime_duration} days)...\")\n",
    "        \n",
    "        # Forward fill regimes to ensure minimum duration\n",
    "        benchmark_data['regime_stable'] = benchmark_data['regime']\n",
    "        \n",
    "        # Use rolling window to smooth regime changes\n",
    "        for i in range(self.min_regime_duration, len(benchmark_data)):\n",
    "            # Check if we have enough consecutive days in the same regime\n",
    "            recent_regimes = benchmark_data['regime'].iloc[i-self.min_regime_duration+1:i+1]\n",
    "            if len(recent_regimes.unique()) == 1:\n",
    "                # Stable regime, keep it\n",
    "                benchmark_data.iloc[i, benchmark_data.columns.get_loc('regime_stable')] = recent_regimes.iloc[0]\n",
    "            else:\n",
    "                # Unstable, keep previous stable regime\n",
    "                if i > 0:\n",
    "                    benchmark_data.iloc[i, benchmark_data.columns.get_loc('regime_stable')] = benchmark_data.iloc[i-1]['regime_stable']\n",
    "        \n",
    "        # Additional smoothing: eliminate isolated regime changes\n",
    "        print(f\"   ðŸ“Š Applying additional smoothing to eliminate isolated regime changes...\")\n",
    "        \n",
    "        # Create a copy for smoothing\n",
    "        benchmark_data['regime_smooth'] = benchmark_data['regime_stable'].copy()\n",
    "        \n",
    "        # Find isolated regime changes (regimes that only last 1-3 days)\n",
    "        for i in range(1, len(benchmark_data) - 1):\n",
    "            current_regime = benchmark_data.iloc[i]['regime_stable']\n",
    "            prev_regime = benchmark_data.iloc[i-1]['regime_stable']\n",
    "            next_regime = benchmark_data.iloc[i+1]['regime_stable']\n",
    "            \n",
    "            # If current regime is isolated (different from both previous and next)\n",
    "            if current_regime != prev_regime and current_regime != next_regime:\n",
    "                # Check if it's a very short regime (1-3 days)\n",
    "                forward_count = 0\n",
    "                backward_count = 0\n",
    "                \n",
    "                # Count forward\n",
    "                for j in range(i+1, len(benchmark_data)):\n",
    "                    if benchmark_data.iloc[j]['regime_stable'] == current_regime:\n",
    "                        forward_count += 1\n",
    "                    else:\n",
    "                        break\n",
    "                \n",
    "                # Count backward\n",
    "                for j in range(i-1, -1, -1):\n",
    "                    if benchmark_data.iloc[j]['regime_stable'] == current_regime:\n",
    "                        backward_count += 1\n",
    "                    else:\n",
    "                        break\n",
    "                \n",
    "                # If total regime duration is very short (<= 5 days), smooth it\n",
    "                total_duration = forward_count + backward_count + 1\n",
    "                if total_duration <= 5:\n",
    "                    # Use the regime that appears more frequently in the surrounding window\n",
    "                    window_start = max(0, i-10)\n",
    "                    window_end = min(len(benchmark_data), i+11)\n",
    "                    window_regimes = benchmark_data.iloc[window_start:window_end]['regime_stable']\n",
    "                    \n",
    "                    # Count regimes in the window\n",
    "                    regime_counts = window_regimes.value_counts()\n",
    "                    # Remove the current isolated regime from consideration\n",
    "                    if current_regime in regime_counts:\n",
    "                        regime_counts = regime_counts.drop(current_regime)\n",
    "                    \n",
    "                    if not regime_counts.empty:\n",
    "                        # Use the most common regime in the window\n",
    "                        most_common_regime = regime_counts.index[0]\n",
    "                        benchmark_data.iloc[i, benchmark_data.columns.get_loc('regime_smooth')] = most_common_regime\n",
    "        \n",
    "        # Use smoothed regime as final regime\n",
    "        benchmark_data['regime'] = benchmark_data['regime_smooth']\n",
    "        benchmark_data = benchmark_data.drop(['regime_stable', 'regime_smooth', 'cumulative_return', 'running_max'], axis=1)\n",
    "        \n",
    "        print(f\"   âœ… Enhanced 5-regime detection completed with stability controls\")\n",
    "        print(f\"   ðŸ“Š Regime distribution:\")\n",
    "        regime_counts = benchmark_data['regime'].value_counts()\n",
    "        for regime, count in regime_counts.items():\n",
    "            print(f\"      {regime}: {count} days ({count/len(benchmark_data)*100:.1f}%)\")\n",
    "        \n",
    "        # Calculate regime stability metrics\n",
    "        regime_changes = (benchmark_data['regime'] != benchmark_data['regime'].shift()).sum()\n",
    "        print(f\"   ðŸ“Š Regime stability: {regime_changes} changes over {len(benchmark_data)} days\")\n",
    "        \n",
    "        return benchmark_data\n",
    "    \n",
    "    def get_regime_allocation(self, regime: str) -> float:\n",
    "        \"\"\"Get target allocation based on enhanced 5-regime system.\"\"\"\n",
    "        regime_allocations = {\n",
    "            'bull': 1.0,       # 100% invested during bull periods\n",
    "            'growth': 0.9,     # 90% invested during growth periods\n",
    "            'sideways': 0.8,   # 80% invested during sideways periods\n",
    "            'correction': 0.5, # 50% invested during correction periods\n",
    "            'crisis': 0.3      # 30% invested during crisis periods\n",
    "        }\n",
    "        return regime_allocations.get(regime, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4cad51",
   "metadata": {},
   "source": [
    "# CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a047057a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'strategy_name': 'QVM_Engine_v3j_Tearsheet_Demo_v19',\n",
    "    'universe': {\n",
    "        'lookback_days': 252,\n",
    "        'top_n_stocks': 20,\n",
    "        'target_portfolio_size': 20,\n",
    "        'adtv_threshold_bn': 10,  # 10 billion VND ADTV\n",
    "    },\n",
    "    'backtest_start_date': '2016-01-01',\n",
    "    'backtest_end_date': '2025-12-31',\n",
    "    'rebalance_frequency': 'M',  # Monthly\n",
    "    'transaction_cost_bps': 10,  # 10 basis points\n",
    "    'initial_capital': 10_000_000_000,  # 10 billion VND\n",
    "    'regime_detection': {\n",
    "        'lookback_days': 90,  # 90 days lookback for regime detection\n",
    "        'min_regime_duration': 30,  # 30 days minimum for stable regimes\n",
    "    },\n",
    "    'factor_weights': {\n",
    "        'bull': {'quality': 0.15, 'value': 0.25, 'momentum': 0.6, 'allocation': 1.0},\n",
    "        'growth': {'quality': 0.20, 'value': 0.30, 'momentum': 0.5, 'allocation': 0.9},\n",
    "        'sideways': {'quality': 0.33, 'value': 0.33, 'momentum': 0.34, 'allocation': 0.8},\n",
    "        'correction': {'quality': 0.4, 'value': 0.4, 'momentum': 0.2, 'allocation': 0.5},\n",
    "        'crisis': {'quality': 0.5, 'value': 0.4, 'momentum': 0.1, 'allocation': 0.3},\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acdf733",
   "metadata": {},
   "source": [
    "# DATABASE CONNECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358896e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize database connection\n",
    "db_manager = DatabaseManager()\n",
    "engine = db_manager.get_engine()\n",
    "print(\"âœ… Database connected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5589dfc",
   "metadata": {},
   "source": [
    "# LOAD HOLDINGS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef084e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load holdings data from pre-generated file\n",
    "holdings_file = Path(\"docs/18b_complete_holdings.csv\")\n",
    "if holdings_file.exists():\n",
    "    holdings_df = pd.read_csv(holdings_file)\n",
    "    holdings_df['date'] = pd.to_datetime(holdings_df['date']).dt.date\n",
    "    print(f\"âœ… Loaded holdings: {len(holdings_df)} records\")\n",
    "else:\n",
    "    print(\"âŒ Holdings file not found, using database query...\")\n",
    "    query = \"\"\"\n",
    "    SELECT date, ticker, Quality_Composite as quality_score, Value_Composite as value_score, \n",
    "           Momentum_Composite as momentum_score, QVM_Composite as composite_score\n",
    "    FROM factor_scores_qvm \n",
    "    WHERE date BETWEEN %s AND %s\n",
    "    ORDER BY date, QVM_Composite DESC\n",
    "    \"\"\"\n",
    "    holdings_df = pd.read_sql(query, engine, params=(CONFIG['backtest_start_date'], CONFIG['backtest_end_date']))\n",
    "    holdings_df['date'] = pd.to_datetime(holdings_df['date']).dt.date\n",
    "    print(f\"âœ… Loaded holdings: {len(holdings_df)} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318b9f12",
   "metadata": {},
   "source": [
    "# LOAD PRICE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4dd555",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ“Š Loading price data...\")\n",
    "unique_tickers = holdings_df['ticker'].unique()\n",
    "ticker_list = \"', '\".join(unique_tickers)\n",
    "\n",
    "price_query = f\"\"\"\n",
    "SELECT \n",
    "    trading_date as date,\n",
    "    ticker,\n",
    "    close_price\n",
    "FROM vcsc_daily_data_complete\n",
    "WHERE ticker IN ('{ticker_list}')\n",
    "AND trading_date >= '{holdings_df['date'].min()}'\n",
    "AND trading_date <= '{holdings_df['date'].max()}'\n",
    "ORDER BY trading_date, ticker\n",
    "\"\"\"\n",
    "\n",
    "price_data = pd.read_sql(price_query, engine)\n",
    "price_data['date'] = pd.to_datetime(price_data['date']).dt.date\n",
    "print(f\"âœ… Price data: {len(price_data)} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e695d1f",
   "metadata": {},
   "source": [
    "# LOAD BENCHMARK DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d82dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ“Š Loading benchmark data...\")\n",
    "benchmark_query = f\"\"\"\n",
    "SELECT \n",
    "    date,\n",
    "    close as close_price\n",
    "FROM etf_history\n",
    "WHERE ticker = 'VNINDEX'\n",
    "AND date >= '{holdings_df['date'].min()}'\n",
    "AND date <= '{holdings_df['date'].max()}'\n",
    "ORDER BY date\n",
    "\"\"\"\n",
    "\n",
    "benchmark_data = pd.read_sql(benchmark_query, engine)\n",
    "benchmark_data['date'] = pd.to_datetime(benchmark_data['date']).dt.date\n",
    "benchmark_data['return'] = benchmark_data['close_price'].pct_change()\n",
    "print(f\"âœ… Benchmark data: {len(benchmark_data)} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a69220",
   "metadata": {},
   "source": [
    "# DETECT MARKET REGIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1196d0ab",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Initialize enhanced regime detector\n",
    "regime_detector = EnhancedRegimeDetector(\n",
    "    lookback_period=CONFIG['regime_detection']['lookback_days'],\n",
    "    min_regime_duration=CONFIG['regime_detection']['min_regime_duration']\n",
    ")\n",
    "\n",
    "# Detect market regime\n",
    "benchmark_data = regime_detector.detect_regime(benchmark_data)\n",
    "print(f\"âœ… Market regime detection completed\")\n",
    "\n",
    "# Debug: Show regime distribution\n",
    "print(\"\\nðŸ” DEBUG: Regime distribution in benchmark data:\")\n",
    "regime_counts = benchmark_data['regime'].value_counts()\n",
    "for regime, count in regime_counts.items():\n",
    "    print(f\"   {regime}: {count} days ({count/len(benchmark_data)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7efdba5",
   "metadata": {},
   "source": [
    "# CALCULATE PORTFOLIO RETURNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f135943",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def calculate_corrected_returns(holdings_df, price_data, benchmark_data, config, regime_detector):\n",
    "    \"\"\"Calculate corrected portfolio returns with regime-based allocation.\"\"\"\n",
    "    print(\"ðŸ“ˆ Calculating corrected portfolio returns with regime detection...\")\n",
    "    \n",
    "    # Convert dates to datetime\n",
    "    holdings_df['date'] = pd.to_datetime(holdings_df['date'])\n",
    "    price_data['date'] = pd.to_datetime(price_data['date'])\n",
    "    benchmark_data['date'] = pd.to_datetime(benchmark_data['date'])\n",
    "    \n",
    "    # Create price matrix with forward filling\n",
    "    print(\"   ðŸ“Š Creating price matrix with forward filling...\")\n",
    "    price_matrix = price_data.pivot(index='date', columns='ticker', values='close_price')\n",
    "    \n",
    "    # Forward fill prices (carry last known price forward)\n",
    "    price_matrix = price_matrix.fillna(method='ffill')\n",
    "    \n",
    "    # Backward fill any remaining NaN values at the beginning\n",
    "    price_matrix = price_matrix.fillna(method='bfill')\n",
    "    \n",
    "    print(f\"   âœ… Price matrix created: {price_matrix.shape}\")\n",
    "    \n",
    "    # Get unique rebalancing dates\n",
    "    unique_dates = sorted(holdings_df['date'].unique())\n",
    "    \n",
    "    portfolio_values = []\n",
    "    daily_returns = []\n",
    "    current_capital = config['initial_capital']\n",
    "    \n",
    "    for i, date in enumerate(unique_dates):\n",
    "        # Get holdings for this date\n",
    "        date_holdings = holdings_df[holdings_df['date'] == date]\n",
    "        \n",
    "        if date_holdings.empty:\n",
    "            continue\n",
    "        \n",
    "        # Get current market regime\n",
    "        regime_info = benchmark_data[benchmark_data['date'] == date]\n",
    "        if not regime_info.empty:\n",
    "            current_regime = regime_info['regime'].iloc[0]\n",
    "            regime_allocation = regime_detector.get_regime_allocation(current_regime)\n",
    "            # Debug: Show regime info for first few dates\n",
    "            if i < 5:\n",
    "                print(f\"   ðŸ” Date {date}: Regime={current_regime}, Allocation={regime_allocation:.2f}\")\n",
    "        else:\n",
    "            current_regime = 'sideways'  # Default for 5-regime system\n",
    "            regime_allocation = 0.8\n",
    "            if i < 5:\n",
    "                print(f\"   ðŸ” Date {date}: No regime found, using default={current_regime}, Allocation={regime_allocation:.2f}\")\n",
    "        \n",
    "        # Get prices for this date from the forward-filled matrix\n",
    "        if date in price_matrix.index:\n",
    "            date_prices = price_matrix.loc[date]\n",
    "        else:\n",
    "            # Find the closest available date\n",
    "            available_dates = price_matrix.index[price_matrix.index <= date]\n",
    "            if not available_dates.empty:\n",
    "                closest_date = available_dates[-1]\n",
    "                date_prices = price_matrix.loc[closest_date]\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        # Calculate portfolio value with regime-based allocation\n",
    "        portfolio_value = 0\n",
    "        valid_holdings = 0\n",
    "        \n",
    "        for _, holding in date_holdings.iterrows():\n",
    "            ticker = holding['ticker']\n",
    "            if ticker in date_prices.index:\n",
    "                price = date_prices[ticker]\n",
    "                if pd.notna(price) and price > 0:\n",
    "                    # Apply regime-based allocation\n",
    "                    position_size = (current_capital * regime_allocation) / len(date_holdings)\n",
    "                    shares = position_size / price\n",
    "                    portfolio_value += shares * price\n",
    "                    valid_holdings += 1\n",
    "        \n",
    "        if portfolio_value > 0 and valid_holdings > 0:\n",
    "            portfolio_values.append({\n",
    "                'date': date,\n",
    "                'portfolio_value': portfolio_value,\n",
    "                'capital': current_capital,\n",
    "                'valid_holdings': valid_holdings,\n",
    "                'total_holdings': len(date_holdings),\n",
    "                'regime': current_regime,\n",
    "                'regime_allocation': regime_allocation\n",
    "            })\n",
    "            \n",
    "            # Calculate daily returns for the period until next rebalancing\n",
    "            if i < len(unique_dates) - 1:\n",
    "                next_date = unique_dates[i + 1]\n",
    "                \n",
    "                # Get price data for the period (only trading days)\n",
    "                period_dates = price_matrix.index[\n",
    "                    (price_matrix.index >= date) & \n",
    "                    (price_matrix.index <= next_date)\n",
    "                ]\n",
    "                \n",
    "                if len(period_dates) > 1:\n",
    "                    # Calculate daily returns for each stock\n",
    "                    period_prices = price_matrix.loc[period_dates]\n",
    "                    \n",
    "                    # Calculate daily returns (pct_change)\n",
    "                    period_returns = period_prices.pct_change()\n",
    "                    \n",
    "                    # Calculate portfolio daily returns\n",
    "                    for daily_date in period_returns.index[1:]:  # Skip first date (no return)\n",
    "                        daily_returns_data = period_returns.loc[daily_date]\n",
    "                        \n",
    "                        # Get only the stocks in our portfolio\n",
    "                        portfolio_tickers = date_holdings['ticker'].unique()\n",
    "                        portfolio_daily_returns = daily_returns_data[daily_returns_data.index.isin(portfolio_tickers)]\n",
    "                        \n",
    "                        if not portfolio_daily_returns.empty:\n",
    "                            # Filter out extreme returns (likely data errors)\n",
    "                            portfolio_daily_returns = portfolio_daily_returns[\n",
    "                                (portfolio_daily_returns >= -0.5) & (portfolio_daily_returns <= 0.5)\n",
    "                            ]\n",
    "                            \n",
    "                            if len(portfolio_daily_returns) > 0:\n",
    "                                # Equal weight portfolio return\n",
    "                                portfolio_return = portfolio_daily_returns.mean()\n",
    "                                \n",
    "                                # Apply transaction costs on rebalancing day\n",
    "                                if daily_date == date:\n",
    "                                    transaction_cost = config['transaction_cost_bps'] / 10000\n",
    "                                    portfolio_return -= transaction_cost\n",
    "                                \n",
    "                                # Only include valid returns (not NaN or extreme)\n",
    "                                if pd.notna(portfolio_return) and abs(portfolio_return) < 0.5:\n",
    "                                    daily_returns.append({\n",
    "                                        'date': daily_date,\n",
    "                                        'portfolio_return': portfolio_return,\n",
    "                                        'rebalance_date': date,\n",
    "                                        'regime': current_regime,\n",
    "                                        'regime_allocation': regime_allocation\n",
    "                                    })\n",
    "            \n",
    "            # Update capital for next period\n",
    "            current_capital = portfolio_value\n",
    "    \n",
    "    portfolio_df = pd.DataFrame(portfolio_values)\n",
    "    daily_returns_df = pd.DataFrame(daily_returns)\n",
    "    \n",
    "    print(f\"   âœ… Portfolio values: {len(portfolio_df)} records\")\n",
    "    print(f\"   âœ… Daily returns: {len(daily_returns_df)} records\")\n",
    "    print(f\"   ðŸ“Š Regime-based allocation applied\")\n",
    "    \n",
    "    return portfolio_df, daily_returns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c70525b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def apply_regime_based_factor_weights(holdings_df, benchmark_data, config):\n",
    "    \"\"\"Apply regime-based factor weights to holdings data.\"\"\"\n",
    "    print(\"ðŸ“Š Applying regime-based factor weights...\")\n",
    "    \n",
    "    # Merge holdings with regime information\n",
    "    holdings_with_regime = holdings_df.merge(\n",
    "        benchmark_data[['date', 'regime']], \n",
    "        on='date', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Fill missing regimes with 'sideways' (default for 5-regime system)\n",
    "    holdings_with_regime['regime'] = holdings_with_regime['regime'].fillna('sideways')\n",
    "    \n",
    "    # Apply regime-based factor weights\n",
    "    holdings_with_regime['composite_score_adjusted'] = 0.0\n",
    "    \n",
    "    for regime, weights in config['factor_weights'].items():\n",
    "        mask = holdings_with_regime['regime'] == regime\n",
    "        \n",
    "        # Apply factor weights based on regime\n",
    "        holdings_with_regime.loc[mask, 'composite_score_adjusted'] = (\n",
    "            holdings_with_regime.loc[mask, 'quality_score'] * weights['quality'] +\n",
    "            holdings_with_regime.loc[mask, 'value_score'] * weights['value'] +\n",
    "            holdings_with_regime.loc[mask, 'momentum_score'] * weights['momentum']\n",
    "        )\n",
    "    \n",
    "    # Sort by adjusted composite score within each date\n",
    "    holdings_with_regime = holdings_with_regime.sort_values(['date', 'composite_score_adjusted'], ascending=[True, False])\n",
    "    \n",
    "    print(f\"   âœ… Regime-based factor weights applied\")\n",
    "    print(f\"   ðŸ“Š Regime distribution in holdings:\")\n",
    "    regime_counts = holdings_with_regime['regime'].value_counts()\n",
    "    for regime, count in regime_counts.items():\n",
    "        print(f\"      {regime}: {count} holdings ({count/len(holdings_with_regime)*100:.1f}%)\")\n",
    "    \n",
    "    # Debug: Show sample of holdings with regimes\n",
    "    print(f\"   ðŸ” Sample holdings with regimes (first 10):\")\n",
    "    sample_holdings = holdings_with_regime[['date', 'ticker', 'regime', 'composite_score_adjusted']].head(10)\n",
    "    for _, row in sample_holdings.iterrows():\n",
    "        print(f\"      {row['date']} - {row['ticker']}: {row['regime']} (score: {row['composite_score_adjusted']:.3f})\")\n",
    "    \n",
    "    return holdings_with_regime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f462706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply regime-based factor weights\n",
    "holdings_df_adjusted = apply_regime_based_factor_weights(holdings_df, benchmark_data, CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e22df69",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Calculate returns with regime-adjusted holdings\n",
    "portfolio_values, daily_returns = calculate_corrected_returns(holdings_df_adjusted, price_data, benchmark_data, CONFIG, regime_detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95f2d67",
   "metadata": {},
   "source": [
    "# CALCULATE PERFORMANCE METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8e4d37",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def calculate_performance_metrics(portfolio_values, daily_returns, benchmark_data, config):\n",
    "    \"\"\"Calculate performance metrics with proper data handling.\"\"\"\n",
    "    print(\"ðŸ“Š Calculating performance metrics...\")\n",
    "    \n",
    "    if portfolio_values.empty or daily_returns.empty:\n",
    "        print(\"   âš ï¸ No data available for performance calculation\")\n",
    "        return {}\n",
    "    \n",
    "    # Process daily returns\n",
    "    daily_returns = daily_returns.sort_values('date')\n",
    "    daily_returns = daily_returns.dropna(subset=['portfolio_return'])\n",
    "    \n",
    "    # Filter out extreme returns\n",
    "    daily_returns = daily_returns[\n",
    "        (daily_returns['portfolio_return'] >= -0.5) & \n",
    "        (daily_returns['portfolio_return'] <= 0.5)\n",
    "    ]\n",
    "    \n",
    "    if daily_returns.empty:\n",
    "        print(\"   âš ï¸ No valid daily returns\")\n",
    "        return {}\n",
    "    \n",
    "    # Merge with benchmark data\n",
    "    daily_returns = daily_returns.merge(benchmark_data, on='date', how='left')\n",
    "    daily_returns['benchmark_return'] = daily_returns['close_price'].pct_change()\n",
    "    daily_returns = daily_returns.dropna(subset=['portfolio_return', 'benchmark_return'])\n",
    "    \n",
    "    if daily_returns.empty:\n",
    "        print(\"   âš ï¸ No valid data after benchmark merge\")\n",
    "        return {}\n",
    "    \n",
    "    print(f\"   ðŸ“Š Valid daily returns: {len(daily_returns)} records\")\n",
    "    \n",
    "    # Calculate metrics with proper validation\n",
    "    total_return = (1 + daily_returns['portfolio_return']).prod() - 1\n",
    "    benchmark_total_return = (1 + daily_returns['benchmark_return']).prod() - 1\n",
    "    \n",
    "    # Annualized return\n",
    "    days = (pd.to_datetime(daily_returns['date'].iloc[-1]) - pd.to_datetime(daily_returns['date'].iloc[0])).days\n",
    "    if days > 0:\n",
    "        annualized_return = (1 + total_return) ** (365.25 / days) - 1\n",
    "        benchmark_annualized_return = (1 + benchmark_total_return) ** (365.25 / days) - 1\n",
    "    else:\n",
    "        annualized_return = 0\n",
    "        benchmark_annualized_return = 0\n",
    "    \n",
    "    # Volatility\n",
    "    volatility = daily_returns['portfolio_return'].std() * np.sqrt(252)\n",
    "    benchmark_volatility = daily_returns['benchmark_return'].std() * np.sqrt(252)\n",
    "    \n",
    "    # Sharpe ratio\n",
    "    risk_free_rate = 0.00  # 0% risk-free rate\n",
    "    sharpe_ratio = (annualized_return - risk_free_rate) / volatility if volatility > 0 else 0\n",
    "    benchmark_sharpe_ratio = (benchmark_annualized_return - risk_free_rate) / benchmark_volatility if benchmark_volatility > 0 else 0\n",
    "    \n",
    "    # Maximum drawdown\n",
    "    cumulative_returns = (1 + daily_returns['portfolio_return']).cumprod()\n",
    "    running_max = cumulative_returns.expanding().max()\n",
    "    drawdown = (cumulative_returns - running_max) / running_max\n",
    "    max_drawdown = drawdown.min()\n",
    "    \n",
    "    # Win rate\n",
    "    win_rate = (daily_returns['portfolio_return'] > 0).mean()\n",
    "    \n",
    "    # Information ratio\n",
    "    excess_returns = daily_returns['portfolio_return'] - daily_returns['benchmark_return']\n",
    "    information_ratio = excess_returns.mean() / excess_returns.std() if excess_returns.std() > 0 else 0\n",
    "    \n",
    "    # Beta and Alpha\n",
    "    covariance = np.cov(daily_returns['portfolio_return'], daily_returns['benchmark_return'])[0, 1]\n",
    "    benchmark_variance = daily_returns['benchmark_return'].var()\n",
    "    beta = covariance / benchmark_variance if benchmark_variance > 0 else 1.0\n",
    "    alpha = annualized_return - (risk_free_rate + beta * (benchmark_annualized_return - risk_free_rate))\n",
    "    \n",
    "    # Calmar ratio\n",
    "    calmar_ratio = annualized_return / abs(max_drawdown) if max_drawdown != 0 else 0\n",
    "    \n",
    "    metrics = {\n",
    "        'total_return': total_return,\n",
    "        'annualized_return': annualized_return,\n",
    "        'volatility': volatility,\n",
    "        'sharpe_ratio': sharpe_ratio,\n",
    "        'max_drawdown': max_drawdown,\n",
    "        'win_rate': win_rate,\n",
    "        'information_ratio': information_ratio,\n",
    "        'beta': beta,\n",
    "        'alpha': alpha,\n",
    "        'calmar_ratio': calmar_ratio,\n",
    "        'days': len(daily_returns),\n",
    "        'benchmark_total_return': benchmark_total_return,\n",
    "        'benchmark_annualized_return': benchmark_annualized_return,\n",
    "        'benchmark_volatility': benchmark_volatility,\n",
    "        'benchmark_sharpe_ratio': benchmark_sharpe_ratio\n",
    "    }\n",
    "    \n",
    "    print(\"   âœ… Performance metrics calculated successfully\")\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577c7195",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Calculate performance metrics\n",
    "performance_metrics = calculate_performance_metrics(portfolio_values, daily_returns, benchmark_data, CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43139106",
   "metadata": {},
   "source": [
    "# GENERATE COMPREHENSIVE TEARSHEET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c4fed5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def generate_comprehensive_tearsheet(strategy_returns: pd.Series, benchmark_returns: pd.Series, diagnostics: pd.DataFrame, title: str):\n",
    "    \"\"\"Generates comprehensive institutional tearsheet with equity curve and analysis.\"\"\"\n",
    "    \n",
    "    # Align benchmark for plotting & metrics\n",
    "    first_trade_date = strategy_returns.loc[strategy_returns.ne(0)].index.min()\n",
    "    aligned_strategy_returns = strategy_returns.loc[first_trade_date:]\n",
    "    aligned_benchmark_returns = benchmark_returns.loc[first_trade_date:]\n",
    "\n",
    "    strategy_metrics = calculate_performance_metrics(strategy_returns, benchmark_returns)\n",
    "    benchmark_metrics = calculate_performance_metrics(benchmark_returns, benchmark_returns)\n",
    "    \n",
    "    fig = plt.figure(figsize=(18, 26))\n",
    "    gs = fig.add_gridspec(5, 2, height_ratios=[1.2, 0.8, 0.8, 0.8, 1.2], hspace=0.7, wspace=0.2)\n",
    "    fig.suptitle(title, fontsize=20, fontweight='bold', color='#2C3E50')\n",
    "\n",
    "    # 1. Cumulative Performance (Equity Curve) with Regime Shading\n",
    "    ax1 = fig.add_subplot(gs[0, :])\n",
    "    \n",
    "    # Plot the main equity curves\n",
    "    (1 + aligned_strategy_returns).cumprod().plot(ax=ax1, label='QVM Engine v3j', color='#16A085', lw=2.5)\n",
    "    (1 + aligned_benchmark_returns).cumprod().plot(ax=ax1, label='VN-Index (Aligned)', color='#34495E', linestyle='--', lw=2)\n",
    "    \n",
    "    # Add regime shading if diagnostics data is available\n",
    "    if not diagnostics.empty and 'regime' in diagnostics.columns:\n",
    "        # Get regime data aligned with the returns\n",
    "        regime_data = diagnostics.reindex(aligned_strategy_returns.index, method='ffill')\n",
    "        \n",
    "        # Shade bull periods (green)\n",
    "        bull_periods = regime_data[regime_data['regime'] == 'bull']\n",
    "        if not bull_periods.empty:\n",
    "            for i, date in enumerate(bull_periods.index):\n",
    "                if i == 0 or (date - bull_periods.index[i-1]).days > 1:\n",
    "                    start_date = date\n",
    "                    end_date = date\n",
    "                    for j in range(i+1, len(bull_periods.index)):\n",
    "                        if (bull_periods.index[j] - bull_periods.index[j-1]).days == 1:\n",
    "                            end_date = bull_periods.index[j]\n",
    "                        else:\n",
    "                            break\n",
    "                    ax1.axvspan(start_date, end_date, alpha=0.1, color='green', label='Bull Period' if i == 0 else \"\")\n",
    "        \n",
    "        # Shade growth periods (light green)\n",
    "        growth_periods = regime_data[regime_data['regime'] == 'growth']\n",
    "        if not growth_periods.empty:\n",
    "            for i, date in enumerate(growth_periods.index):\n",
    "                if i == 0 or (date - growth_periods.index[i-1]).days > 1:\n",
    "                    start_date = date\n",
    "                    end_date = date\n",
    "                    for j in range(i+1, len(growth_periods.index)):\n",
    "                        if (growth_periods.index[j] - growth_periods.index[j-1]).days == 1:\n",
    "                            end_date = growth_periods.index[j]\n",
    "                        else:\n",
    "                            break\n",
    "                    ax1.axvspan(start_date, end_date, alpha=0.05, color='lightgreen', label='Growth Period' if i == 0 else \"\")\n",
    "        \n",
    "        # Shade correction periods (orange)\n",
    "        correction_periods = regime_data[regime_data['regime'] == 'correction']\n",
    "        if not correction_periods.empty:\n",
    "            for i, date in enumerate(correction_periods.index):\n",
    "                if i == 0 or (date - correction_periods.index[i-1]).days > 1:\n",
    "                    start_date = date\n",
    "                    end_date = date\n",
    "                    for j in range(i+1, len(correction_periods.index)):\n",
    "                        if (correction_periods.index[j] - correction_periods.index[j-1]).days == 1:\n",
    "                            end_date = correction_periods.index[j]\n",
    "                        else:\n",
    "                            break\n",
    "                    ax1.axvspan(start_date, end_date, alpha=0.1, color='orange', label='Correction Period' if i == 0 else \"\")\n",
    "        \n",
    "        # Shade crisis periods (red)\n",
    "        crisis_periods = regime_data[regime_data['regime'] == 'crisis']\n",
    "        if not crisis_periods.empty:\n",
    "            for i, date in enumerate(crisis_periods.index):\n",
    "                if i == 0 or (date - crisis_periods.index[i-1]).days > 1:\n",
    "                    start_date = date\n",
    "                    end_date = date\n",
    "                    for j in range(i+1, len(crisis_periods.index)):\n",
    "                        if (crisis_periods.index[j] - crisis_periods.index[j-1]).days == 1:\n",
    "                            end_date = crisis_periods.index[j]\n",
    "                        else:\n",
    "                            break\n",
    "                    ax1.axvspan(start_date, end_date, alpha=0.15, color='red', label='Crisis Period' if i == 0 else \"\")\n",
    "    \n",
    "    ax1.set_title('Cumulative Performance (Log Scale)', fontweight='bold')\n",
    "    ax1.set_ylabel('Growth of 1 VND')\n",
    "    ax1.set_yscale('log')\n",
    "    ax1.legend(loc='upper left')\n",
    "    ax1.grid(True, which='both', linestyle='--', alpha=0.5)\n",
    "\n",
    "    # 2. Drawdown Analysis\n",
    "    ax2 = fig.add_subplot(gs[1, :])\n",
    "    drawdown = ((1 + aligned_strategy_returns).cumprod() / (1 + aligned_strategy_returns).cumprod().cummax() - 1) * 100\n",
    "    drawdown.plot(ax=ax2, color='#C0392B')\n",
    "    ax2.fill_between(drawdown.index, drawdown, 0, color='#C0392B', alpha=0.1)\n",
    "    ax2.set_title('Drawdown Analysis', fontweight='bold')\n",
    "    ax2.set_ylabel('Drawdown (%)')\n",
    "    ax2.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "    # 3. Annual Returns\n",
    "    ax3 = fig.add_subplot(gs[2, 0])\n",
    "    strat_annual = aligned_strategy_returns.resample('Y').apply(lambda x: (1+x).prod()-1) * 100\n",
    "    bench_annual = aligned_benchmark_returns.resample('Y').apply(lambda x: (1+x).prod()-1) * 100\n",
    "    pd.DataFrame({'Strategy': strat_annual, 'Benchmark': bench_annual}).plot(kind='bar', ax=ax3, color=['#16A085', '#34495E'])\n",
    "    ax3.set_xticklabels([d.strftime('%Y') for d in strat_annual.index], rotation=45, ha='right')\n",
    "    ax3.set_title('Annual Returns', fontweight='bold')\n",
    "    ax3.grid(True, axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "    # 4. Rolling Sharpe Ratio\n",
    "    ax4 = fig.add_subplot(gs[2, 1])\n",
    "    rolling_sharpe = (aligned_strategy_returns.rolling(252).mean() * 252) / (aligned_strategy_returns.rolling(252).std() * np.sqrt(252))\n",
    "    rolling_sharpe.plot(ax=ax4, color='#E67E22')\n",
    "    ax4.axhline(1.0, color='#27AE60', linestyle='--')\n",
    "    ax4.set_title('1-Year Rolling Sharpe Ratio', fontweight='bold')\n",
    "    ax4.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "    # 5. Regime Analysis\n",
    "    ax5 = fig.add_subplot(gs[3, 0])\n",
    "    if not diagnostics.empty and 'regime' in diagnostics.columns:\n",
    "        regime_counts = diagnostics['regime'].value_counts()\n",
    "        regime_counts.plot(kind='bar', ax=ax5, color=['#3498DB', '#E74C3C', '#F39C12', '#9B59B6'])\n",
    "        ax5.set_title('Regime Distribution', fontweight='bold')\n",
    "        ax5.set_ylabel('Number of Rebalances')\n",
    "        ax5.grid(True, axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "    # 6. Portfolio Size Evolution\n",
    "    ax6 = fig.add_subplot(gs[3, 1])\n",
    "    if not diagnostics.empty and 'portfolio_size' in diagnostics.columns:\n",
    "        diagnostics['portfolio_size'].plot(ax=ax6, color='#2ECC71', marker='o', markersize=3)\n",
    "        ax6.set_title('Portfolio Size Evolution', fontweight='bold')\n",
    "        ax6.set_ylabel('Number of Stocks')\n",
    "        ax6.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "    # 7. Performance Metrics Table\n",
    "    ax7 = fig.add_subplot(gs[4:, :])\n",
    "    ax7.axis('off')\n",
    "    summary_data = [['Metric', 'Strategy', 'Benchmark']]\n",
    "    for key in strategy_metrics.keys():\n",
    "        summary_data.append([key, f\"{strategy_metrics[key]:.2f}\", f\"{benchmark_metrics.get(key, 0.0):.2f}\"])\n",
    "    \n",
    "    table = ax7.table(cellText=summary_data[1:], colLabels=summary_data[0], loc='center', cellLoc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(14)\n",
    "    table.scale(1, 2.5)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "    plt.show()\n",
    "\n",
    "def calculate_performance_metrics(returns: pd.Series, benchmark: pd.Series, periods_per_year: int = 252) -> dict:\n",
    "    \"\"\"Calculates comprehensive performance metrics with corrected benchmark alignment.\"\"\"\n",
    "    # Align benchmark\n",
    "    first_trade_date = returns.loc[returns.ne(0)].index.min()\n",
    "    if pd.isna(first_trade_date):\n",
    "        return {metric: 0.0 for metric in ['Annualized Return (%)', 'Annualized Volatility (%)', 'Sharpe Ratio', 'Max Drawdown (%)', 'Calmar Ratio', 'Information Ratio', 'Beta']}\n",
    "    \n",
    "    aligned_returns = returns.loc[first_trade_date:]\n",
    "    aligned_benchmark = benchmark.loc[first_trade_date:]\n",
    "\n",
    "    n_years = len(aligned_returns) / periods_per_year\n",
    "    annualized_return = ((1 + aligned_returns).prod() ** (1 / n_years) - 1) if n_years > 0 else 0\n",
    "    annualized_volatility = aligned_returns.std() * np.sqrt(periods_per_year)\n",
    "    sharpe_ratio = annualized_return / annualized_volatility if annualized_volatility != 0 else 0.0\n",
    "    \n",
    "    cumulative_returns = (1 + aligned_returns).cumprod()\n",
    "    max_drawdown = (cumulative_returns / cumulative_returns.cummax() - 1).min()\n",
    "    calmar_ratio = annualized_return / abs(max_drawdown) if max_drawdown < 0 else 0.0\n",
    "    \n",
    "    excess_returns = aligned_returns - aligned_benchmark\n",
    "    information_ratio = (excess_returns.mean() * periods_per_year) / (excess_returns.std() * np.sqrt(periods_per_year)) if excess_returns.std() > 0 else 0.0\n",
    "    beta = aligned_returns.cov(aligned_benchmark) / aligned_benchmark.var() if aligned_benchmark.var() > 0 else 0.0\n",
    "    \n",
    "    return {\n",
    "        'Annualized Return (%)': annualized_return * 100,\n",
    "        'Annualized Volatility (%)': annualized_volatility * 100,\n",
    "        'Sharpe Ratio': sharpe_ratio,\n",
    "        'Max Drawdown (%)': max_drawdown * 100,\n",
    "        'Calmar Ratio': calmar_ratio,\n",
    "        'Information Ratio': information_ratio,\n",
    "        'Beta': beta\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c3dd0e",
   "metadata": {},
   "source": [
    "# SAVE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13c6d5d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Save results\n",
    "results_dir = Path(\"docs\")\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "\n",
    "portfolio_values.to_csv(results_dir / \"19_tearsheet_portfolio_values.csv\", index=False)\n",
    "daily_returns.to_csv(results_dir / \"19_tearsheet_daily_returns.csv\", index=False)\n",
    "\n",
    "# Save performance metrics\n",
    "with open(results_dir / \"19_tearsheet_performance_metrics.txt\", 'w') as f:\n",
    "    for metric, value in performance_metrics.items():\n",
    "        f.write(f\"{metric}: {value}\\n\")\n",
    "\n",
    "print(f\"\\nðŸ“ Results saved to docs/\")\n",
    "print(f\"   - 19_tearsheet_portfolio_values.csv: {len(portfolio_values)} portfolio values\")\n",
    "print(f\"   - 19_tearsheet_daily_returns.csv: {len(daily_returns)} daily returns\")\n",
    "print(f\"   - 19_tearsheet_performance_metrics.txt: Performance metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08af6b95",
   "metadata": {},
   "source": [
    "# EQUITY CURVE VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d857f6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_equity_curve(daily_returns, benchmark_data, performance_metrics, config):\n",
    "    \"\"\"Create equity curve comparison between strategy and benchmark.\"\"\"\n",
    "    \n",
    "    # Ensure dates are datetime\n",
    "    daily_returns = daily_returns.copy()\n",
    "    daily_returns['date'] = pd.to_datetime(daily_returns['date'])\n",
    "    benchmark_data = benchmark_data.copy()\n",
    "    benchmark_data['date'] = pd.to_datetime(benchmark_data['date'])\n",
    "    \n",
    "    # Calculate cumulative returns for strategy\n",
    "    daily_returns = daily_returns.sort_values('date')\n",
    "    strategy_cumulative = (1 + daily_returns['portfolio_return']).cumprod()\n",
    "    strategy_equity = config['initial_capital'] * strategy_cumulative\n",
    "    \n",
    "    # Calculate cumulative returns for benchmark\n",
    "    benchmark_data = benchmark_data.sort_values('date')\n",
    "    benchmark_returns = benchmark_data['close_price'].pct_change().dropna()\n",
    "    benchmark_cumulative = (1 + benchmark_returns).cumprod()\n",
    "    benchmark_equity = config['initial_capital'] * benchmark_cumulative\n",
    "    \n",
    "    # Align dates for comparison\n",
    "    common_dates = strategy_equity.index.intersection(benchmark_cumulative.index)\n",
    "    if len(common_dates) == 0:\n",
    "        print(\"âš ï¸ No common dates between strategy and benchmark\")\n",
    "        return\n",
    "    \n",
    "    strategy_aligned = strategy_equity.loc[common_dates]\n",
    "    benchmark_aligned = benchmark_equity.loc[common_dates]\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Main equity curve\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(strategy_aligned.index, strategy_aligned.values, \n",
    "             label=f'QVM Strategy ({performance_metrics[\"total_return\"]:.1%})', \n",
    "             linewidth=2, color='#2E86AB')\n",
    "    plt.plot(benchmark_aligned.index, benchmark_aligned.values, \n",
    "             label=f'VNINDEX Benchmark ({performance_metrics[\"benchmark_total_return\"]:.1%})', \n",
    "             linewidth=2, color='#A23B72', alpha=0.8)\n",
    "    \n",
    "    plt.title('QVM Strategy vs VNINDEX Benchmark - Equity Curve', fontsize=16, fontweight='bold')\n",
    "    plt.ylabel('Portfolio Value (VND)', fontsize=12)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Use log scale only if values are positive and significantly different\n",
    "    if strategy_aligned.min() > 0 and benchmark_aligned.min() > 0:\n",
    "        plt.yscale('log')\n",
    "    \n",
    "    # Add performance metrics as text\n",
    "    plt.text(0.02, 0.98, f'Sharpe Ratio: {performance_metrics[\"sharpe_ratio\"]:.3f}\\n'\n",
    "                         f'Max Drawdown: {performance_metrics[\"max_drawdown\"]:.1%}\\n'\n",
    "                         f'Alpha: {performance_metrics[\"alpha\"]:.1%}\\n'\n",
    "                         f'Beta: {performance_metrics[\"beta\"]:.3f}', \n",
    "             transform=plt.gca().transAxes, verticalalignment='top',\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8), fontsize=10)\n",
    "    \n",
    "    # Drawdown subplot\n",
    "    plt.subplot(2, 1, 2)\n",
    "    running_max = strategy_aligned.expanding().max()\n",
    "    drawdown = (strategy_aligned - running_max) / running_max * 100\n",
    "    \n",
    "    plt.fill_between(drawdown.index, drawdown.values, 0, alpha=0.3, color='red')\n",
    "    plt.plot(drawdown.index, drawdown.values, color='red', linewidth=1)\n",
    "    plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    plt.axhline(y=-20, color='orange', linestyle='--', alpha=0.5, label='-20%')\n",
    "    plt.axhline(y=-35, color='red', linestyle='--', alpha=0.5, label='-35%')\n",
    "    \n",
    "    plt.title('Strategy Drawdown', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Drawdown (%)', fontsize=12)\n",
    "    plt.xlabel('Date', fontsize=12)\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    results_dir = Path(\"docs\")\n",
    "    plt.savefig(results_dir / \"19_equity_curve.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"   - 19_equity_curve.png: Equity curve visualization saved\")\n",
    "    print(f\"   ðŸ“Š Strategy data points: {len(strategy_aligned)}\")\n",
    "    print(f\"   ðŸ“Š Benchmark data points: {len(benchmark_aligned)}\")\n",
    "    print(f\"   ðŸ“Š Common dates: {len(common_dates)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994054c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive tearsheet with new format\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ“Š QVM ENGINE V3J: COMPREHENSIVE TEARSHEET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Convert daily returns to strategy returns series\n",
    "strategy_returns = daily_returns.set_index('date')['portfolio_return']\n",
    "benchmark_returns = benchmark_data.set_index('date')['close_price'].pct_change()\n",
    "\n",
    "# Create diagnostics DataFrame with regime information\n",
    "diagnostics = portfolio_values[['date', 'regime', 'regime_allocation', 'valid_holdings']].copy()\n",
    "diagnostics['portfolio_size'] = diagnostics['valid_holdings']\n",
    "diagnostics = diagnostics.set_index('date')\n",
    "\n",
    "# Generate the comprehensive tearsheet\n",
    "generate_comprehensive_tearsheet(\n",
    "    strategy_returns,\n",
    "    benchmark_returns,\n",
    "    diagnostics,\n",
    "    \"QVM Engine v3j Demonstration - Full Period Analysis\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddba458d",
   "metadata": {},
   "source": [
    "# ADDITIONAL PERIOD TEARSHEETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131aef22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. First Period Tearsheet (2016-2020)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ“Š QVM ENGINE V3J: FIRST PERIOD TEARSHEET (2016-2020)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Filter data for 2016-2020 period\n",
    "first_period_mask = (strategy_returns.index >= '2016-01-01') & (strategy_returns.index <= '2020-12-31')\n",
    "first_period_strategy_returns = strategy_returns[first_period_mask]\n",
    "first_period_benchmark_returns = benchmark_returns.reindex(first_period_strategy_returns.index).fillna(0)\n",
    "first_period_diagnostics = diagnostics.reindex(first_period_strategy_returns.index, method='ffill')\n",
    "\n",
    "# Generate first period tearsheet\n",
    "generate_comprehensive_tearsheet(\n",
    "    first_period_strategy_returns,\n",
    "    first_period_benchmark_returns,\n",
    "    first_period_diagnostics,\n",
    "    \"QVM Engine v3j Demonstration - First Period (2016-2020)\"\n",
    ")\n",
    "\n",
    "# 2. Second Period Tearsheet (2020-2025)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ“Š QVM ENGINE V3J: SECOND PERIOD TEARSHEET (2020-2025)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Filter data for 2020-2025 period\n",
    "second_period_mask = (strategy_returns.index >= '2020-01-01') & (strategy_returns.index <= '2025-12-31')\n",
    "second_period_strategy_returns = strategy_returns[second_period_mask]\n",
    "second_period_benchmark_returns = benchmark_returns.reindex(second_period_strategy_returns.index).fillna(0)\n",
    "second_period_diagnostics = diagnostics.reindex(second_period_strategy_returns.index, method='ffill')\n",
    "\n",
    "# Generate second period tearsheet\n",
    "generate_comprehensive_tearsheet(\n",
    "    second_period_strategy_returns,\n",
    "    second_period_benchmark_returns,\n",
    "    second_period_diagnostics,\n",
    "    \"QVM Engine v3j Demonstration - Second Period (2020-2025)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415c81cc",
   "metadata": {},
   "source": [
    "# SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce473a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸŽ¯ QVM STRATEGY PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"ðŸ“ˆ Total Return: {performance_metrics['total_return']:.2%}\")\n",
    "print(f\"ðŸ“Š Annualized Return: {performance_metrics['annualized_return']:.2%}\")\n",
    "print(f\"âš¡ Sharpe Ratio: {performance_metrics['sharpe_ratio']:.3f}\")\n",
    "print(f\"ðŸ“‰ Max Drawdown: {performance_metrics['max_drawdown']:.2%}\")\n",
    "print(f\"ðŸŽ¯ Alpha: {performance_metrics['alpha']:.2%}\")\n",
    "print(f\"ðŸ“Š Beta: {performance_metrics['beta']:.3f}\")\n",
    "print(f\"ðŸ† Win Rate: {performance_metrics['win_rate']:.2%}\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
