{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a3eca11",
   "metadata": {},
   "source": [
    "# QVM Engine v3d - Fixed Regime Detection\n",
    "\n",
    "**Key Fixes:**\n",
    "- Fixed RegimeDetector class to properly accept and use threshold parameters\n",
    "- Added debugging output for regime detection\n",
    "- Tested regime detection logic\n",
    "\n",
    "**Original Issue:** Regime detection was stuck at \"Sideways\" because threshold parameters weren't being passed to the RegimeDetector class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "810b62ae",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-02 17:36:17,607 - production.database.connection - INFO - Database configuration loaded from /Users/raymond/Documents/Projects/factor-investing-public/config/database.yml\n",
      "2025-08-02 17:36:17,607 - production.database.connection - INFO - DatabaseManager initialized for environment: production\n",
      "2025-08-02 17:36:17,743 - production.database.connection - INFO - SQLAlchemy engine created successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully imported production modules.\n",
      "   - Project Root set to: /Users/raymond/Documents/Projects/factor-investing-public\n",
      "\n",
      "⚙️  QVM Engine v3d Configuration Loaded:\n",
      "   - Strategy: QVM_Engine_v3_Adopted_Insights\n",
      "   - Period: 2016-01-01 to 2025-07-31\n",
      "   - Factors: ROAA + P/E + Multi-horizon Momentum\n",
      "   - Regime Detection: Simple volatility/return based\n",
      "   - Regime Thresholds: Vol=0.2659 (75th), Ret=0.2588 (75th), LowRet=0.2131 (25th)\n",
      "\n",
      "✅ Database connection established successfully.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 1: SETUP & CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "# Core scientific libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import yaml\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Database connectivity\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# --- Environment Setup ---\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.float_format', lambda x: f'{x:,.2f}')\n",
    "\n",
    "# --- Add Project Root to Python Path ---\n",
    "try:\n",
    "    current_path = Path.cwd()\n",
    "    while not (current_path / 'production').is_dir():\n",
    "        if current_path.parent == current_path:\n",
    "            raise FileNotFoundError(\"Could not find the 'production' directory.\")\n",
    "        current_path = current_path.parent\n",
    "    \n",
    "    project_root = current_path\n",
    "    \n",
    "    if str(project_root) not in sys.path:\n",
    "        sys.path.insert(0, str(project_root))\n",
    "    \n",
    "    from production.database.connection import get_database_manager\n",
    "    from production.database.mappings.financial_mapping_manager import FinancialMappingManager\n",
    "    print(f\"✅ Successfully imported production modules.\")\n",
    "    print(f\"   - Project Root set to: {project_root}\")\n",
    "\n",
    "except (ImportError, FileNotFoundError) as e:\n",
    "    print(f\"❌ ERROR: Could not import production modules. Please check your directory structure.\")\n",
    "    print(f\"   - Final Path Searched: {project_root}\")\n",
    "    print(f\"   - Error: {e}\")\n",
    "    raise\n",
    "\n",
    "# --- QVM Engine v3 Adopted Insights Configuration ---\n",
    "QVM_CONFIG = {\n",
    "    # --- Backtest Parameters ---\n",
    "    \"strategy_name\": \"QVM_Engine_v3_Adopted_Insights\",\n",
    "    \"backtest_start_date\": \"2016-01-01\",\n",
    "    \"backtest_end_date\": \"2025-07-31\",\n",
    "    \"rebalance_frequency\": \"M\", # Monthly\n",
    "    \"transaction_cost_bps\": 30, # Flat 30bps\n",
    "\n",
    "    # --- Universe Construction ---\n",
    "    \"universe\": {\n",
    "        \"lookback_days\": 63,\n",
    "        \"adtv_threshold_vnd\": 10_000_000_000,  # 10 billion VND\n",
    "        \"min_market_cap_bn\": 100.0,  # 100 billion VND\n",
    "        \"max_position_size\": 0.05,\n",
    "        \"max_sector_exposure\": 0.30,\n",
    "        \"target_portfolio_size\": 20,\n",
    "    },\n",
    "\n",
    "    # --- Factor Configuration ---\n",
    "    \"factors\": {\n",
    "        \"roaa_weight\": 0.3,\n",
    "        \"pe_weight\": 0.3,\n",
    "        \"momentum_weight\": 0.4,\n",
    "        \"momentum_horizons\": [21, 63, 126, 252], # 1M, 3M, 6M, 12M\n",
    "        \"skip_months\": 1,\n",
    "        \"fundamental_lag_days\": 45,  # 45-day lag for announcement delay\n",
    "    },\n",
    "\n",
    "    \"regime\": {\n",
    "        \"lookback_period\": 90,          # 90 days lookback period\n",
    "        \"volatility_threshold\": 0.2659, # 75th percentile volatility\n",
    "        \"return_threshold\": 0.2588,     # 75th percentile return\n",
    "        \"low_return_threshold\": 0.2131  # 25th percentile return\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n⚙️  QVM Engine v3d Configuration Loaded:\")\n",
    "print(f\"   - Strategy: {QVM_CONFIG['strategy_name']}\")\n",
    "print(f\"   - Period: {QVM_CONFIG['backtest_start_date']} to {QVM_CONFIG['backtest_end_date']}\")\n",
    "print(f\"   - Factors: ROAA + P/E + Multi-horizon Momentum\")\n",
    "print(f\"   - Regime Detection: Simple volatility/return based\")\n",
    "print(f\"   - Regime Thresholds: Vol={QVM_CONFIG['regime']['volatility_threshold']:.4f} (75th), Ret={QVM_CONFIG['regime']['return_threshold']:.4f} (75th), LowRet={QVM_CONFIG['regime']['low_return_threshold']:.4f} (25th)\")\n",
    "\n",
    "# --- Database Connection ---\n",
    "def create_db_connection():\n",
    "    \"\"\"Establishes a SQLAlchemy database engine connection.\"\"\"\n",
    "    try:\n",
    "        db_manager = get_database_manager()\n",
    "        engine = db_manager.get_engine()\n",
    "        \n",
    "        with engine.connect() as conn:\n",
    "            conn.execute(text(\"SELECT 1\"))\n",
    "        print(f\"\\n✅ Database connection established successfully.\")\n",
    "        return engine\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ FAILED to connect to the database.\")\n",
    "        print(f\"   - Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Create the engine for this session\n",
    "engine = create_db_connection()\n",
    "\n",
    "if engine is None:\n",
    "    raise ConnectionError(\"Database connection failed. Halting execution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2189a50",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 2: FIXED REGIME DETECTOR CLASS\n",
    "# ============================================================================\n",
    "\n",
    "class RegimeDetector:\n",
    "    \"\"\"\n",
    "    Simple regime detection based on volatility and return thresholds.\n",
    "    FIXED: Now properly accepts and uses threshold parameters.\n",
    "    \"\"\"\n",
    "    def __init__(self, lookback_period: int = 90, volatility_threshold: float = 0.2659, \n",
    "                 return_threshold: float = 0.2588, low_return_threshold: float = 0.2131):\n",
    "        self.lookback_period = lookback_period\n",
    "        self.volatility_threshold = volatility_threshold\n",
    "        self.return_threshold = return_threshold\n",
    "        self.low_return_threshold = low_return_threshold\n",
    "        print(f\"✅ RegimeDetector initialized with thresholds:\")\n",
    "        print(f\"   - Volatility: {self.volatility_threshold:.4f}\")\n",
    "        print(f\"   - Return: {self.return_threshold:.4f}\")\n",
    "        print(f\"   - Low Return: {self.low_return_threshold:.4f}\")\n",
    "    \n",
    "    def detect_regime(self, price_data: pd.DataFrame) -> str:\n",
    "        \"\"\"Detect market regime based on volatility and return.\"\"\"\n",
    "        if len(price_data) < self.lookback_period:\n",
    "            return 'Sideways'\n",
    "        \n",
    "        recent_data = price_data.tail(self.lookback_period)\n",
    "        returns = recent_data['close'].pct_change().dropna()\n",
    "        \n",
    "        volatility = returns.std()\n",
    "        avg_return = returns.mean()\n",
    "        \n",
    "        # Debug output\n",
    "        print(f\"   🔍 Regime Debug: Vol={volatility:.4f}, AvgRet={avg_return:.4f}\")\n",
    "        \n",
    "        if volatility > self.volatility_threshold:\n",
    "            if avg_return > self.return_threshold:\n",
    "                print(f\"   📈 Detected: Bull (Vol={volatility:.4f} > {self.volatility_threshold:.4f}, Ret={avg_return:.4f} > {self.return_threshold:.4f})\")\n",
    "                return 'Bull'\n",
    "            else:\n",
    "                print(f\"   📉 Detected: Bear (Vol={volatility:.4f} > {self.volatility_threshold:.4f}, Ret={avg_return:.4f} <= {self.return_threshold:.4f})\")\n",
    "                return 'Bear'\n",
    "        else:\n",
    "            if abs(avg_return) < self.low_return_threshold:\n",
    "                print(f\"   ↔️  Detected: Sideways (Vol={volatility:.4f} <= {self.volatility_threshold:.4f}, |Ret|={abs(avg_return):.4f} < {self.low_return_threshold:.4f})\")\n",
    "                return 'Sideways'\n",
    "            else:\n",
    "                print(f\"   ⚠️  Detected: Stress (Vol={volatility:.4f} <= {self.volatility_threshold:.4f}, |Ret|={abs(avg_return):.4f} >= {self.low_return_threshold:.4f})\")\n",
    "                return 'Stress'\n",
    "    \n",
    "    def get_regime_allocation(self, regime: str) -> float:\n",
    "        \"\"\"Get target allocation based on regime.\"\"\"\n",
    "        regime_allocations = {\n",
    "            'Bull': 1.0,      # Fully invested\n",
    "            'Bear': 0.8,      # 80% invested\n",
    "            'Sideways': 0.6,  # 60% invested\n",
    "            'Stress': 0.4     # 40% invested\n",
    "        }\n",
    "        return regime_allocations.get(regime, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec3c8510",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧪 Testing Regime Detection Logic:\n",
      "==================================================\n",
      "✅ RegimeDetector initialized with thresholds:\n",
      "   - Volatility: 0.2659\n",
      "   - Return: 0.2588\n",
      "   - Low Return: 0.2131\n",
      "\n",
      "📊 Testing: Bull Market\n",
      "   🔍 Regime Debug: Vol=0.2741, AvgRet=0.2515\n",
      "   📉 Detected: Bear (Vol=0.2741 > 0.2659, Ret=0.2515 <= 0.2588)\n",
      "   ❌ FAIL: Expected Bull, Got Bear\n",
      "\n",
      "📊 Testing: Bear Market\n",
      "   🔍 Regime Debug: Vol=0.2741, AvgRet=-0.2485\n",
      "   📉 Detected: Bear (Vol=0.2741 > 0.2659, Ret=-0.2485 <= 0.2588)\n",
      "   ✅ PASS: Expected Bear, Got Bear\n",
      "\n",
      "📊 Testing: Sideways Market\n",
      "   🔍 Regime Debug: Vol=0.1827, AvgRet=0.1176\n",
      "   ↔️  Detected: Sideways (Vol=0.1827 <= 0.2659, |Ret|=0.1176 < 0.2131)\n",
      "   ✅ PASS: Expected Sideways, Got Sideways\n",
      "\n",
      "📊 Testing: Stress Market\n",
      "   🔍 Regime Debug: Vol=0.1827, AvgRet=0.2176\n",
      "   ⚠️  Detected: Stress (Vol=0.1827 <= 0.2659, |Ret|=0.2176 >= 0.2131)\n",
      "   ✅ PASS: Expected Stress, Got Stress\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 3: TEST REGIME DETECTION\n",
    "# ============================================================================\n",
    "\n",
    "def test_regime_detection():\n",
    "    \"\"\"Test the regime detection with different scenarios.\"\"\"\n",
    "    print(\"\\n🧪 Testing Regime Detection Logic:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Create test scenarios with corrected thresholds\n",
    "    test_scenarios = [\n",
    "        {\n",
    "            'name': 'Bull Market',\n",
    "            'volatility': 0.30,   # High volatility (> 0.2659)\n",
    "            'return': 0.30,       # High positive return (> 0.2588)\n",
    "            'expected': 'Bull'\n",
    "        },\n",
    "        {\n",
    "            'name': 'Bear Market', \n",
    "            'volatility': 0.30,   # High volatility (> 0.2659)\n",
    "            'return': -0.20,      # Negative return\n",
    "            'expected': 'Bear'\n",
    "        },\n",
    "        {\n",
    "            'name': 'Sideways Market',\n",
    "            'volatility': 0.20,   # Low volatility (<= 0.2659)\n",
    "            'return': 0.15,       # Low return (<= 0.2131)\n",
    "            'expected': 'Sideways'\n",
    "        },\n",
    "        {\n",
    "            'name': 'Stress Market',\n",
    "            'volatility': 0.20,   # Low volatility (<= 0.2659)\n",
    "            'return': 0.25,       # Moderate return (> 0.2131)\n",
    "            'expected': 'Stress'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Create regime detector with config thresholds\n",
    "    regime_detector = RegimeDetector(\n",
    "        lookback_period=QVM_CONFIG['regime']['lookback_period'],\n",
    "        volatility_threshold=QVM_CONFIG['regime']['volatility_threshold'],\n",
    "        return_threshold=QVM_CONFIG['regime']['return_threshold'],\n",
    "        low_return_threshold=QVM_CONFIG['regime']['low_return_threshold']\n",
    "    )\n",
    "    \n",
    "    for scenario in test_scenarios:\n",
    "        print(f\"\\n📊 Testing: {scenario['name']}\")\n",
    "        \n",
    "        # Create synthetic price data\n",
    "        np.random.seed(42)\n",
    "        returns = np.random.normal(scenario['return'], scenario['volatility'], 100)\n",
    "        prices = (1 + pd.Series(returns)).cumprod()\n",
    "        price_data = pd.DataFrame({'close': prices})\n",
    "        \n",
    "        # Detect regime\n",
    "        detected_regime = regime_detector.detect_regime(price_data)\n",
    "        \n",
    "        # Check result\n",
    "        if detected_regime == scenario['expected']:\n",
    "            print(f\"   ✅ PASS: Expected {scenario['expected']}, Got {detected_regime}\")\n",
    "        else:\n",
    "            print(f\"   ❌ FAIL: Expected {scenario['expected']}, Got {detected_regime}\")\n",
    "\n",
    "# Run the test\n",
    "test_regime_detection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bd91628",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 4: REST OF THE ENGINE CLASSES (UNCHANGED)\n",
    "# ============================================================================\n",
    "\n",
    "class SectorAwareFactorCalculator:\n",
    "    \"\"\"\n",
    "    Sector-aware factor calculator with quality-adjusted P/E.\n",
    "    Based on insights from value_by_sector_and_quality.md.\n",
    "    \"\"\"\n",
    "    def __init__(self, engine):\n",
    "        self.engine = engine\n",
    "    \n",
    "    def calculate_sector_aware_pe(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Calculate quality-adjusted P/E by sector.\"\"\"\n",
    "        if 'roaa' not in data.columns or 'sector' not in data.columns:\n",
    "            return data\n",
    "        \n",
    "        # Create ROAA quintiles within each sector\n",
    "        def safe_qcut(x):\n",
    "            try:\n",
    "                if len(x) < 5:\n",
    "                    return pd.Series(['Q3'] * len(x), index=x.index)\n",
    "                return pd.qcut(x, 5, labels=['Q1', 'Q2', 'Q3', 'Q4', 'Q5'], duplicates='drop')\n",
    "            except ValueError:\n",
    "                return pd.Series(['Q3'] * len(x), index=x.index)\n",
    "        \n",
    "        data['roaa_quintile'] = data.groupby('sector')['roaa'].transform(safe_qcut)\n",
    "        \n",
    "        # Fill missing quintiles with Q3\n",
    "        data['roaa_quintile'] = data['roaa_quintile'].fillna('Q3')\n",
    "        \n",
    "        # Quality-adjusted P/E weights (higher quality = higher weight)\n",
    "        quality_weights = {\n",
    "            'Q1': 0.5,  # Low quality\n",
    "            'Q2': 0.7,\n",
    "            'Q3': 1.0,  # Medium quality\n",
    "            'Q4': 1.3,\n",
    "            'Q5': 1.5   # High quality\n",
    "        }\n",
    "        \n",
    "        data['quality_adjusted_pe'] = data['roaa_quintile'].map(quality_weights)\n",
    "        return data\n",
    "    \n",
    "    def calculate_momentum_score(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Calculate multi-horizon momentum score with correct signal directions.\"\"\"\n",
    "        momentum_columns = [col for col in data.columns if col.startswith('momentum_')]\n",
    "        \n",
    "        if not momentum_columns:\n",
    "            return data\n",
    "        \n",
    "        # Apply correct signal directions:\n",
    "        # - 3M and 6M: Positive signals (higher is better)\n",
    "        # - 1M and 12M: Contrarian signals (lower is better)\n",
    "        momentum_score = 0.0\n",
    "        \n",
    "        for col in momentum_columns:\n",
    "            if 'momentum_63d' in col or 'momentum_126d' in col:  # 3M and 6M - positive\n",
    "                momentum_score += data[col]\n",
    "            elif 'momentum_21d' in col or 'momentum_252d' in col:  # 1M and 12M - contrarian\n",
    "                momentum_score -= data[col]  # Negative for contrarian\n",
    "        \n",
    "        # Equal weight the components\n",
    "        data['momentum_score'] = momentum_score / len(momentum_columns)\n",
    "        return data\n",
    "\n",
    "class QVMEngineV3AdoptedInsights:\n",
    "    \"\"\"\n",
    "    QVM Engine v3 with Adopted Insights Strategy.\n",
    "    FIXED: RegimeDetector now properly receives threshold parameters.\n",
    "    \"\"\"\n",
    "    def __init__(self, config: dict, price_data: pd.DataFrame, fundamental_data: pd.DataFrame,\n",
    "                 returns_matrix: pd.DataFrame, benchmark_returns: pd.Series, db_engine):\n",
    "        \n",
    "        self.config = config\n",
    "        self.engine = db_engine\n",
    "        \n",
    "        # Slice data to the exact backtest window\n",
    "        start = pd.Timestamp(config['backtest_start_date'])\n",
    "        end = pd.Timestamp(config['backtest_end_date'])\n",
    "        \n",
    "        self.price_data_raw = price_data[price_data['date'].between(start, end)].copy()\n",
    "        self.fundamental_data_raw = fundamental_data[fundamental_data['date'].between(start, end)].copy()\n",
    "        self.daily_returns_matrix = returns_matrix.loc[start:end].copy()\n",
    "        self.benchmark_returns = benchmark_returns.loc[start:end].copy()\n",
    "        \n",
    "        # Initialize components with FIXED regime detector\n",
    "        self.regime_detector = RegimeDetector(\n",
    "            lookback_period=config['regime']['lookback_period'],\n",
    "            volatility_threshold=config['regime']['volatility_threshold'],\n",
    "            return_threshold=config['regime']['return_threshold'],\n",
    "            low_return_threshold=config['regime']['low_return_threshold']\n",
    "        )\n",
    "        self.sector_calculator = SectorAwareFactorCalculator(db_engine)\n",
    "        self.mapping_manager = FinancialMappingManager()\n",
    "        \n",
    "        print(\"✅ QVMEngineV3AdoptedInsights initialized.\")\n",
    "        print(f\"   - Strategy: {config['strategy_name']}\")\n",
    "        print(f\"   - Period: {self.daily_returns_matrix.index.min().date()} to {self.daily_returns_matrix.index.max().date()}\")\n",
    "\n",
    "    def run_backtest(self) -> (pd.Series, pd.DataFrame):\n",
    "        \"\"\"Executes the full backtesting pipeline.\"\"\"\n",
    "        print(\"\\n🚀 Starting QVM Engine v3 backtest execution...\")\n",
    "        \n",
    "        rebalance_dates = self._generate_rebalance_dates()\n",
    "        daily_holdings, diagnostics = self._run_backtesting_loop(rebalance_dates)\n",
    "        net_returns = self._calculate_net_returns(daily_holdings)\n",
    "        \n",
    "        print(\"✅ QVM Engine v3 backtest execution complete.\")\n",
    "        return net_returns, diagnostics\n",
    "\n",
    "    def _generate_rebalance_dates(self) -> list:\n",
    "        \"\"\"Generates monthly rebalance dates based on actual trading days.\"\"\"\n",
    "        all_trading_dates = self.daily_returns_matrix.index\n",
    "        rebal_dates_calendar = pd.date_range(\n",
    "            start=self.config['backtest_start_date'],\n",
    "            end=self.config['backtest_end_date'],\n",
    "            freq=self.config['rebalance_frequency']\n",
    "        )\n",
    "        actual_rebal_dates = [all_trading_dates[all_trading_dates.searchsorted(d, side='left')-1] for d in rebal_dates_calendar if d >= all_trading_dates.min()]\n",
    "        print(f\"   - Generated {len(actual_rebal_dates)} monthly rebalance dates.\")\n",
    "        return sorted(list(set(actual_rebal_dates)))\n",
    "\n",
    "    def _run_backtesting_loop(self, rebalance_dates: list) -> (pd.DataFrame, pd.DataFrame):\n",
    "        \"\"\"The core loop for portfolio construction at each rebalance date.\"\"\"\n",
    "        daily_holdings = pd.DataFrame(0.0, index=self.daily_returns_matrix.index, columns=self.daily_returns_matrix.columns)\n",
    "        diagnostics_log = []\n",
    "        \n",
    "        for i, rebal_date in enumerate(rebalance_dates):\n",
    "            print(f\"   - Processing rebalance {i+1}/{len(rebalance_dates)}: {rebal_date.date()}...\", end=\"\")\n",
    "            \n",
    "            # Get universe\n",
    "            universe = self._get_universe(rebal_date)\n",
    "            if len(universe) < 5:  # Reduced from 10 to 5\n",
    "                print(\" ⚠️ Universe too small. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            # Detect regime (FIXED: Now should work properly)\n",
    "            regime = self._detect_current_regime(rebal_date)\n",
    "            regime_allocation = self.regime_detector.get_regime_allocation(regime)\n",
    "            \n",
    "            # Calculate factors\n",
    "            factors_df = self._calculate_factors(universe, rebal_date)\n",
    "            if factors_df.empty:\n",
    "                print(\" ⚠️ No factor data. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            # Apply entry criteria\n",
    "            qualified_df = self._apply_entry_criteria(factors_df)\n",
    "            if qualified_df.empty:\n",
    "                print(\" ⚠️ No qualified stocks. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            # Construct portfolio\n",
    "            target_portfolio = self._construct_portfolio(qualified_df, regime_allocation)\n",
    "            if target_portfolio.empty:\n",
    "                print(\" ⚠️ Portfolio empty. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            # Apply holdings\n",
    "            start_period = rebal_date + pd.Timedelta(days=1)\n",
    "            end_period = rebalance_dates[i+1] if i + 1 < len(rebalance_dates) else self.daily_returns_matrix.index.max()\n",
    "            holding_dates = self.daily_returns_matrix.index[(self.daily_returns_matrix.index >= start_period) & (self.daily_returns_matrix.index <= end_period)]\n",
    "            \n",
    "            daily_holdings.loc[holding_dates] = 0.0\n",
    "            valid_tickers = target_portfolio.index.intersection(daily_holdings.columns)\n",
    "            daily_holdings.loc[holding_dates, valid_tickers] = target_portfolio[valid_tickers].values\n",
    "            \n",
    "            # Calculate turnover\n",
    "            if i > 0:\n",
    "                # Find the previous holdings using a safer method\n",
    "                try:\n",
    "                    prev_holdings_idx = self.daily_returns_matrix.index.get_loc(rebal_date) - 1\n",
    "                except KeyError:\n",
    "                    # If exact date not found, find the closest previous date\n",
    "                    prev_dates = self.daily_returns_matrix.index[self.daily_returns_matrix.index < rebal_date]\n",
    "                    if len(prev_dates) > 0:\n",
    "                        prev_holdings_idx = self.daily_returns_matrix.index.get_loc(prev_dates[-1])\n",
    "                    else:\n",
    "                        prev_holdings_idx = -1\n",
    "                \n",
    "                prev_holdings = daily_holdings.iloc[prev_holdings_idx] if prev_holdings_idx >= 0 else pd.Series(dtype='float64')\n",
    "            else:\n",
    "                prev_holdings = pd.Series(dtype='float64')\n",
    "\n",
    "            turnover = (target_portfolio - prev_holdings.reindex(target_portfolio.index).fillna(0)).abs().sum() / 2.0\n",
    "            \n",
    "            diagnostics_log.append({\n",
    "                'date': rebal_date,\n",
    "                'universe_size': len(universe),\n",
    "                'portfolio_size': len(target_portfolio),\n",
    "                'regime': regime,\n",
    "                'regime_allocation': regime_allocation,\n",
    "                'turnover': turnover\n",
    "            })\n",
    "            print(f\" ✅ Universe: {len(universe)}, Portfolio: {len(target_portfolio)}, Regime: {regime}, Turnover: {turnover:.1%}\")\n",
    "\n",
    "        if diagnostics_log:\n",
    "            return daily_holdings, pd.DataFrame(diagnostics_log).set_index('date')\n",
    "        else:\n",
    "            return daily_holdings, pd.DataFrame()\n",
    "\n",
    "    def _get_universe(self, analysis_date: pd.Timestamp) -> list:\n",
    "        \"\"\"Get liquid universe based on ADTV and market cap filters.\"\"\"\n",
    "        lookback_days = self.config['universe']['lookback_days']\n",
    "        adtv_threshold = self.config['universe']['adtv_threshold_vnd'] \n",
    "        min_market_cap = self.config['universe']['min_market_cap_bn'] * 1e9\n",
    "        \n",
    "        # Get universe data\n",
    "        universe_query = text(\"\"\"\n",
    "            SELECT \n",
    "                ticker,\n",
    "                AVG(total_volume * close_price_adjusted) as avg_adtv_vnd,\n",
    "                AVG(market_cap) as avg_market_cap\n",
    "            FROM vcsc_daily_data_complete\n",
    "            WHERE trading_date <= :analysis_date\n",
    "            AND trading_date >= DATE_SUB(:analysis_date, INTERVAL :lookback_days DAY)\n",
    "            GROUP BY ticker\n",
    "            HAVING avg_adtv_vnd >= :adtv_threshold AND avg_market_cap >= :min_market_cap\n",
    "        \"\"\")\n",
    "        \n",
    "        universe_df = pd.read_sql(universe_query, self.engine, \n",
    "                                 params={'analysis_date': analysis_date, 'lookback_days': lookback_days, 'adtv_threshold': adtv_threshold, 'min_market_cap': min_market_cap})\n",
    "        \n",
    "        return universe_df['ticker'].tolist()\n",
    "\n",
    "    def _detect_current_regime(self, analysis_date: pd.Timestamp) -> str:\n",
    "        \"\"\"Detect current market regime.\"\"\"\n",
    "        # Get recent benchmark data\n",
    "        lookback_days = self.config['regime']['lookback_period']\n",
    "        start_date = analysis_date - pd.Timedelta(days=lookback_days)\n",
    "        \n",
    "        benchmark_data = self.benchmark_returns.loc[start_date:analysis_date]\n",
    "        if len(benchmark_data) < lookback_days // 2:\n",
    "            return 'Sideways'\n",
    "        \n",
    "        # Create price series for regime detection\n",
    "        price_series = (1 + benchmark_data).cumprod()\n",
    "        price_data = pd.DataFrame({'close': price_series})\n",
    "        \n",
    "        return self.regime_detector.detect_regime(price_data)\n",
    "\n",
    "    def _calculate_factors(self, universe: list, analysis_date: pd.Timestamp) -> pd.DataFrame:\n",
    "        \"\"\"Calculate all factors for the universe using simplified approach.\"\"\"\n",
    "        try:\n",
    "            # Get fundamental data with proper lagging (45 days)\n",
    "            lag_days = self.config['factors']['fundamental_lag_days']\n",
    "            lag_date = analysis_date - pd.Timedelta(days=lag_days)\n",
    "            lag_year = lag_date.year\n",
    "            \n",
    "            # Build ticker list for IN clause with proper quoting\n",
    "            ticker_list = \"','\".join(universe)\n",
    "            \n",
    "            # Simplified query that works\n",
    "            fundamental_query = text(f\"\"\"\n",
    "                WITH netprofit_ttm AS (\n",
    "                    SELECT \n",
    "                        fv.ticker,\n",
    "                        SUM(fv.value / 1e9) as netprofit_ttm\n",
    "                    FROM fundamental_values fv\n",
    "                    WHERE fv.ticker IN ('{ticker_list}')\n",
    "                    AND fv.item_id = 1\n",
    "                    AND fv.statement_type = 'PL'\n",
    "                    AND fv.year <= {lag_year}\n",
    "                    AND fv.year >= {lag_year - 1}  -- Last 4 quarters\n",
    "                    GROUP BY fv.ticker\n",
    "                ),\n",
    "                totalassets_ttm AS (\n",
    "                    SELECT \n",
    "                        fv.ticker,\n",
    "                        SUM(fv.value / 1e9) as totalassets_ttm\n",
    "                    FROM fundamental_values fv\n",
    "                    WHERE fv.ticker IN ('{ticker_list}')\n",
    "                    AND fv.item_id = 2\n",
    "                    AND fv.statement_type = 'BS'\n",
    "                    AND fv.year <= {lag_year}\n",
    "                    AND fv.year >= {lag_year - 1}  -- Last 4 quarters\n",
    "                    GROUP BY fv.ticker\n",
    "                ),\n",
    "                revenue_ttm AS (\n",
    "                    SELECT \n",
    "                        fv.ticker,\n",
    "                        SUM(fv.value / 1e9) as revenue_ttm\n",
    "                    FROM fundamental_values fv\n",
    "                    WHERE fv.ticker IN ('{ticker_list}')\n",
    "                    AND fv.item_id = 2\n",
    "                    AND fv.statement_type = 'PL'\n",
    "                    AND fv.year <= {lag_year}\n",
    "                    AND fv.year >= {lag_year - 1}  -- Last 4 quarters\n",
    "                    GROUP BY fv.ticker\n",
    "                )\n",
    "                SELECT \n",
    "                    np.ticker,\n",
    "                    np.netprofit_ttm,\n",
    "                    ta.totalassets_ttm,\n",
    "                    rv.revenue_ttm,\n",
    "                    CASE \n",
    "                        WHEN ta.totalassets_ttm > 0 THEN np.netprofit_ttm / ta.totalassets_ttm \n",
    "                        ELSE NULL \n",
    "                    END as roaa,\n",
    "                    CASE \n",
    "                        WHEN rv.revenue_ttm > 0 THEN np.netprofit_ttm / rv.revenue_ttm\n",
    "                        ELSE NULL \n",
    "                    END as net_margin,\n",
    "                    CASE \n",
    "                        WHEN ta.totalassets_ttm > 0 THEN rv.revenue_ttm / ta.totalassets_ttm\n",
    "                        ELSE NULL \n",
    "                    END as asset_turnover\n",
    "                FROM netprofit_ttm np\n",
    "                LEFT JOIN totalassets_ttm ta ON np.ticker = ta.ticker\n",
    "                LEFT JOIN revenue_ttm rv ON np.ticker = rv.ticker\n",
    "                WHERE np.netprofit_ttm > 0 \n",
    "                AND ta.totalassets_ttm > 0\n",
    "                AND rv.revenue_ttm > 0\n",
    "            \"\"\")\n",
    "            \n",
    "            fundamental_df = pd.read_sql(fundamental_query, self.engine)\n",
    "            \n",
    "            if fundamental_df.empty:\n",
    "                return pd.DataFrame()\n",
    "            \n",
    "            # Get market data for momentum calculation\n",
    "            market_ticker_list = \"','\".join(universe)\n",
    "            \n",
    "            market_query = text(f\"\"\"\n",
    "                SELECT \n",
    "                    ticker,\n",
    "                    trading_date,\n",
    "                    close_price_adjusted as close,\n",
    "                    total_volume as volume,\n",
    "                    market_cap\n",
    "                FROM vcsc_daily_data_complete\n",
    "                WHERE trading_date <= :analysis_date\n",
    "                  AND ticker IN ('{market_ticker_list}')\n",
    "                ORDER BY ticker, trading_date DESC\n",
    "            \"\"\")\n",
    "            \n",
    "            market_df = pd.read_sql(market_query, self.engine, params={'analysis_date': analysis_date})\n",
    "            \n",
    "            if market_df.empty:\n",
    "                return pd.DataFrame()\n",
    "            \n",
    "            # Calculate momentum factors\n",
    "            momentum_data = self._calculate_momentum_factors(market_df, analysis_date)\n",
    "            \n",
    "            # Calculate P/E factors (simplified)\n",
    "            pe_data = self._calculate_pe_factors(market_df, fundamental_df)\n",
    "            \n",
    "            # Merge all data\n",
    "            factors_df = fundamental_df.merge(momentum_data, on='ticker', how='inner')\n",
    "            factors_df = factors_df.merge(pe_data, on='ticker', how='inner')\n",
    "            \n",
    "            # Apply sector-specific calculations\n",
    "            factors_df = self.sector_calculator.calculate_sector_aware_pe(factors_df)\n",
    "            factors_df = self.sector_calculator.calculate_momentum_score(factors_df)\n",
    "            \n",
    "            # Calculate composite score\n",
    "            factors_df = self._calculate_composite_score(factors_df)\n",
    "            \n",
    "            return factors_df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating factors: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def _calculate_momentum_factors(self, market_df: pd.DataFrame, analysis_date: pd.Timestamp) -> pd.DataFrame:\n",
    "        \"\"\"Calculate momentum factors with skip month.\"\"\"\n",
    "        momentum_data = []\n",
    "        skip_months = self.config['factors']['skip_months']\n",
    "        \n",
    "        for ticker in market_df['ticker'].unique():\n",
    "            ticker_data = market_df[market_df['ticker'] == ticker].sort_values('trading_date')\n",
    "            \n",
    "            if len(ticker_data) < 252 + skip_months:\n",
    "                continue\n",
    "                \n",
    "            current_price = ticker_data.iloc[skip_months]['close']\n",
    "            \n",
    "            periods = self.config['factors']['momentum_horizons']\n",
    "            momentum_factors = {'ticker': ticker}\n",
    "            \n",
    "            for period in periods:\n",
    "                if len(ticker_data) >= period + skip_months:\n",
    "                    past_price = ticker_data.iloc[period + skip_months - 1]['close']\n",
    "                    momentum_factors[f'momentum_{period}d'] = (current_price / past_price) - 1\n",
    "                else:\n",
    "                    momentum_factors[f'momentum_{period}d'] = 0\n",
    "            \n",
    "            momentum_data.append(momentum_factors)\n",
    "        \n",
    "        return pd.DataFrame(momentum_data)\n",
    "\n",
    "    def _calculate_pe_factors(self, market_df: pd.DataFrame, fundamental_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Calculate P/E factors.\"\"\"\n",
    "        pe_data = []\n",
    "        \n",
    "        for _, row in fundamental_df.iterrows():\n",
    "            ticker = row['ticker']\n",
    "            market_data = market_df[market_df['ticker'] == ticker]\n",
    "            \n",
    "            if len(market_data) == 0:\n",
    "                continue\n",
    "                \n",
    "            market_cap = market_data.iloc[0]['market_cap']\n",
    "            \n",
    "            # Simplified P/E calculation\n",
    "            pe_score = 1.0 if row['roaa'] > 0.02 else 0.5\n",
    "            \n",
    "            pe_data.append({\n",
    "                'ticker': ticker,\n",
    "                'pe_score': pe_score\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(pe_data)\n",
    "\n",
    "    def _calculate_composite_score(self, factors_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Calculate composite score combining all factors.\"\"\"\n",
    "        factors_df['composite_score'] = 0.0\n",
    "        \n",
    "        # ROAA component (positive signal)\n",
    "        if 'roaa' in factors_df.columns:\n",
    "            roaa_weight = self.config['factors']['roaa_weight']\n",
    "            factors_df['roaa_normalized'] = (factors_df['roaa'] - factors_df['roaa'].mean()) / factors_df['roaa'].std()\n",
    "            factors_df['composite_score'] += factors_df['roaa_normalized'] * roaa_weight\n",
    "        \n",
    "        # P/E component (contrarian signal - lower is better)\n",
    "        if 'pe_score' in factors_df.columns:\n",
    "            pe_weight = self.config['factors']['pe_weight']\n",
    "            factors_df['pe_normalized'] = (factors_df['pe_score'] - factors_df['pe_score'].mean()) / factors_df['pe_score'].std()\n",
    "            factors_df['composite_score'] += (-factors_df['pe_normalized']) * pe_weight  # Negative for contrarian\n",
    "        \n",
    "        # Momentum component (mixed signal - 3M/6M positive, 1M/12M contrarian)\n",
    "        if 'momentum_score' in factors_df.columns:\n",
    "            momentum_weight = self.config['factors']['momentum_weight']\n",
    "            factors_df['momentum_normalized'] = (factors_df['momentum_score'] - factors_df['momentum_score'].mean()) / factors_df['momentum_score'].std()\n",
    "            factors_df['composite_score'] += factors_df['momentum_normalized'] * momentum_weight\n",
    "        \n",
    "        return factors_df\n",
    "\n",
    "    def _apply_entry_criteria(self, factors_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Apply entry criteria to filter stocks.\"\"\"\n",
    "        # Basic quality filters\n",
    "        qualified = factors_df.copy()\n",
    "        \n",
    "        if 'roaa' in qualified.columns:\n",
    "            qualified = qualified[qualified['roaa'] > 0]  # Positive ROAA\n",
    "        \n",
    "        if 'net_margin' in qualified.columns:\n",
    "            qualified = qualified[qualified['net_margin'] > 0]  # Positive net margin\n",
    "        \n",
    "        return qualified\n",
    "\n",
    "    def _construct_portfolio(self, qualified_df: pd.DataFrame, regime_allocation: float) -> pd.Series:\n",
    "        \"\"\"Construct the portfolio using the qualified stocks.\"\"\"\n",
    "        if qualified_df.empty:\n",
    "            return pd.Series(dtype='float64')\n",
    "        \n",
    "        # Sort by composite score\n",
    "        qualified_df = qualified_df.sort_values('composite_score', ascending=False)\n",
    "        \n",
    "        # Select top stocks\n",
    "        target_size = self.config['universe']['target_portfolio_size']\n",
    "        selected_stocks = qualified_df.head(target_size)\n",
    "        \n",
    "        if selected_stocks.empty:\n",
    "            return pd.Series(dtype='float64')\n",
    "        \n",
    "        # Equal weight portfolio\n",
    "        portfolio = pd.Series(regime_allocation / len(selected_stocks), index=selected_stocks['ticker'])\n",
    "        \n",
    "        return portfolio\n",
    "\n",
    "    def _calculate_net_returns(self, daily_holdings: pd.DataFrame) -> pd.Series:\n",
    "        \"\"\"Calculate net returns with transaction costs.\"\"\"\n",
    "        holdings_shifted = daily_holdings.shift(1).fillna(0.0)\n",
    "        gross_returns = (holdings_shifted * self.daily_returns_matrix).sum(axis=1)\n",
    "        \n",
    "        # Calculate turnover and costs\n",
    "        turnover = (holdings_shifted - holdings_shifted.shift(1)).abs().sum(axis=1) / 2.0\n",
    "        costs = turnover * (self.config['transaction_cost_bps'] / 10000)\n",
    "        net_returns = (gross_returns - costs).rename(self.config['strategy_name'])\n",
    "        \n",
    "        print(\"\\n💸 Net returns calculated.\")\n",
    "        print(f\"   - Total Gross Return: {(1 + gross_returns).prod() - 1:.2%}\")\n",
    "        print(f\"   - Total Net Return: {(1 + net_returns).prod() - 1:.2%}\")\n",
    "        print(f\"   - Total Cost Drag: {gross_returns.sum() - net_returns.sum():.2%}\")\n",
    "        \n",
    "        return net_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acb35b5e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 5: DATA LOADING FUNCTION (UNCHANGED)\n",
    "# ============================================================================\n",
    "\n",
    "def load_all_data_for_backtest(config: dict, db_engine):\n",
    "    \"\"\"\n",
    "    Loads all necessary data (prices, fundamentals, sectors) for the\n",
    "    specified backtest period.\n",
    "    \"\"\"\n",
    "    start_date = config['backtest_start_date']\n",
    "    end_date = config['backtest_end_date']\n",
    "    \n",
    "    # Add a buffer to the start date for rolling calculations\n",
    "    buffer_start_date = pd.Timestamp(start_date) - pd.DateOffset(months=6)\n",
    "    \n",
    "    print(f\"📂 Loading all data for period: {buffer_start_date.date()} to {end_date}...\")\n",
    "\n",
    "    # 1. Price and Volume Data\n",
    "    print(\"   - Loading price and volume data...\")\n",
    "    price_query = text(\"\"\"\n",
    "        SELECT \n",
    "            trading_date as date,\n",
    "            ticker,\n",
    "            close_price_adjusted as close,\n",
    "            total_volume as volume,\n",
    "            market_cap\n",
    "        FROM vcsc_daily_data_complete\n",
    "        WHERE trading_date BETWEEN :start_date AND :end_date\n",
    "    \"\"\")\n",
    "    price_data = pd.read_sql(price_query, db_engine, \n",
    "                            params={'start_date': buffer_start_date, 'end_date': end_date}, \n",
    "                            parse_dates=['date'])\n",
    "    print(f\"     ✅ Loaded {len(price_data):,} price observations.\")\n",
    "\n",
    "    # 2. Fundamental Data (from fundamental_values table with simplified approach)\n",
    "    print(\"   - Loading fundamental data from fundamental_values with simplified approach...\")\n",
    "    fundamental_query = text(\"\"\"\n",
    "        WITH netprofit_ttm AS (\n",
    "            SELECT \n",
    "                fv.ticker,\n",
    "                fv.year,\n",
    "                fv.quarter,\n",
    "                SUM(fv.value / 1e9) as netprofit_ttm\n",
    "            FROM fundamental_values fv\n",
    "            WHERE fv.item_id = 1\n",
    "            AND fv.statement_type = 'PL'\n",
    "            AND fv.year BETWEEN YEAR(:start_date) AND YEAR(:end_date)\n",
    "            GROUP BY fv.ticker, fv.year, fv.quarter\n",
    "        ),\n",
    "        totalassets_ttm AS (\n",
    "            SELECT \n",
    "                fv.ticker,\n",
    "                fv.year,\n",
    "                fv.quarter,\n",
    "                SUM(fv.value / 1e9) as totalassets_ttm\n",
    "            FROM fundamental_values fv\n",
    "            WHERE fv.item_id = 2\n",
    "            AND fv.statement_type = 'BS'\n",
    "            AND fv.year BETWEEN YEAR(:start_date) AND YEAR(:end_date)\n",
    "            GROUP BY fv.ticker, fv.year, fv.quarter\n",
    "        ),\n",
    "        revenue_ttm AS (\n",
    "            SELECT \n",
    "                fv.ticker,\n",
    "                fv.year,\n",
    "                fv.quarter,\n",
    "                SUM(fv.value / 1e9) as revenue_ttm\n",
    "            FROM fundamental_values fv\n",
    "            WHERE fv.item_id = 2\n",
    "            AND fv.statement_type = 'PL'\n",
    "            AND fv.year BETWEEN YEAR(:start_date) AND YEAR(:end_date)\n",
    "            GROUP BY fv.ticker, fv.year, fv.quarter\n",
    "        )\n",
    "        SELECT \n",
    "            np.ticker,\n",
    "            mi.sector,\n",
    "            DATE(CONCAT(np.year, '-', LPAD(np.quarter * 3, 2, '0'), '-01')) as date,\n",
    "            np.netprofit_ttm,\n",
    "            ta.totalassets_ttm,\n",
    "            rv.revenue_ttm,\n",
    "            CASE \n",
    "                WHEN ta.totalassets_ttm > 0 THEN np.netprofit_ttm / ta.totalassets_ttm \n",
    "                ELSE NULL \n",
    "            END as roaa,\n",
    "            CASE \n",
    "                WHEN rv.revenue_ttm > 0 THEN np.netprofit_ttm / rv.revenue_ttm\n",
    "                ELSE NULL \n",
    "            END as net_margin,\n",
    "            CASE \n",
    "                WHEN ta.totalassets_ttm > 0 THEN rv.revenue_ttm / ta.totalassets_ttm\n",
    "                ELSE NULL \n",
    "            END as asset_turnover\n",
    "        FROM netprofit_ttm np\n",
    "        LEFT JOIN totalassets_ttm ta ON np.ticker = ta.ticker AND np.year = ta.year AND np.quarter = ta.quarter\n",
    "        LEFT JOIN revenue_ttm rv ON np.ticker = rv.ticker AND np.year = rv.year AND np.quarter = rv.quarter\n",
    "        LEFT JOIN master_info mi ON np.ticker = mi.ticker\n",
    "        WHERE np.netprofit_ttm > 0 \n",
    "        AND ta.totalassets_ttm > 0\n",
    "        AND rv.revenue_ttm > 0\n",
    "    \"\"\")\n",
    "    \n",
    "    fundamental_data = pd.read_sql(fundamental_query, db_engine, \n",
    "                                  params={'start_date': buffer_start_date, 'end_date': end_date}, \n",
    "                                  parse_dates=['date'])\n",
    "    print(f\"     ✅ Loaded {len(fundamental_data):,} fundamental observations from fundamental_values.\")\n",
    "\n",
    "    # 3. Benchmark Data (VN-Index)\n",
    "    print(\"   - Loading benchmark data (VN-Index)...\")\n",
    "    benchmark_query = text(\"\"\"\n",
    "        SELECT date, close\n",
    "        FROM etf_history\n",
    "        WHERE ticker = 'VNINDEX' AND date BETWEEN :start_date AND :end_date\n",
    "    \"\"\")\n",
    "    benchmark_data = pd.read_sql(benchmark_query, db_engine, \n",
    "                                params={'start_date': buffer_start_date, 'end_date': end_date}, \n",
    "                                parse_dates=['date'])\n",
    "    print(f\"     ✅ Loaded {len(benchmark_data):,} benchmark observations.\")\n",
    "\n",
    "    # --- Data Preparation ---\n",
    "    print(\"\\n🛠️  Preparing data structures for backtesting engine...\")\n",
    "\n",
    "    # Create returns matrix\n",
    "    price_data['return'] = price_data.groupby('ticker')['close'].pct_change()\n",
    "    daily_returns_matrix = price_data.pivot(index='date', columns='ticker', values='return')\n",
    "\n",
    "    # Create benchmark returns series\n",
    "    benchmark_returns = benchmark_data.set_index('date')['close'].pct_change().rename('VN-Index')\n",
    "\n",
    "    print(\"   ✅ Data preparation complete.\")\n",
    "    return price_data, fundamental_data, daily_returns_matrix, benchmark_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb03347b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Loading all data for period: 2015-07-01 to 2025-07-31...\n",
      "   - Loading price and volume data...\n",
      "     ✅ Loaded 1,695,229 price observations.\n",
      "   - Loading fundamental data from fundamental_values with simplified approach...\n",
      "     ✅ Loaded 11,149 fundamental observations from fundamental_values.\n",
      "   - Loading benchmark data (VN-Index)...\n",
      "     ✅ Loaded 2,519 benchmark observations.\n",
      "\n",
      "🛠️  Preparing data structures for backtesting engine...\n",
      "   ✅ Data preparation complete.\n",
      "\n",
      "✅ All data successfully loaded and prepared for the backtest.\n",
      "   - Price Data Shape: (1695229, 6)\n",
      "   - Fundamental Data Shape: (11149, 9)\n",
      "   - Returns Matrix Shape: (2520, 728)\n",
      "   - Benchmark Returns: 2519 days\n",
      "\n",
      "================================================================================\n",
      "🚀 QVM ENGINE V3D: FIXED REGIME DETECTION\n",
      "================================================================================\n",
      "✅ RegimeDetector initialized with thresholds:\n",
      "   - Volatility: 0.2659\n",
      "   - Return: 0.2588\n",
      "   - Low Return: 0.2131\n",
      "✅ QVMEngineV3AdoptedInsights initialized.\n",
      "   - Strategy: QVM_Engine_v3_Adopted_Insights\n",
      "   - Period: 2016-01-04 to 2025-07-25\n",
      "\n",
      "🚀 Starting QVM Engine v3 backtest execution...\n",
      "   - Generated 115 monthly rebalance dates.\n",
      "   - Processing rebalance 1/115: 2016-01-29... ✅ Universe: 30, Portfolio: 20, Regime: Sideways, Turnover: 30.0%\n",
      "   - Processing rebalance 2/115: 2016-02-26... ✅ Universe: 30, Portfolio: 20, Regime: Sideways, Turnover: 6.0%\n",
      "   - Processing rebalance 3/115: 2016-03-30... ✅ Universe: 32, Portfolio: 20, Regime: Sideways, Turnover: 1.5%\n",
      "   - Processing rebalance 4/115: 2016-04-29... ✅ Universe: 34, Portfolio: 20, Regime: Sideways, Turnover: 3.0%\n",
      "   - Processing rebalance 5/115: 2016-05-30... ✅ Universe: 34, Portfolio: 20, Regime: Sideways, Turnover: 6.0%\n",
      "   - Processing rebalance 6/115: 2016-06-29... ✅ Universe: 39, Portfolio: 20, Regime: Sideways, Turnover: 6.0%\n",
      "   - Processing rebalance 7/115: 2016-07-29... ✅ Universe: 46, Portfolio: 20, Regime: Sideways, Turnover: 6.0%\n",
      "   - Processing rebalance 8/115: 2016-08-30... ✅ Universe: 44, Portfolio: 20, Regime: Sideways, Turnover: 7.5%\n",
      "   - Processing rebalance 9/115: 2016-09-29... ✅ Universe: 36, Portfolio: 20, Regime: Sideways, Turnover: 7.5%\n",
      "   - Processing rebalance 10/115: 2016-10-28... ✅ Universe: 37, Portfolio: 20, Regime: Sideways, Turnover: 6.0%\n",
      "   - Processing rebalance 11/115: 2016-11-29... ✅ Universe: 29, Portfolio: 20, Regime: Sideways, Turnover: 7.5%\n",
      "   - Processing rebalance 12/115: 2016-12-30... ✅ Universe: 33, Portfolio: 20, Regime: Sideways, Turnover: 4.5%\n",
      "   - Processing rebalance 13/115: 2017-01-25... ✅ Universe: 31, Portfolio: 20, Regime: Sideways, Turnover: 1.5%\n",
      "   - Processing rebalance 14/115: 2017-02-27... ✅ Universe: 39, Portfolio: 20, Regime: Sideways, Turnover: 9.0%\n",
      "   - Processing rebalance 15/115: 2017-03-30... ✅ Universe: 51, Portfolio: 20, Regime: Sideways, Turnover: 9.0%\n",
      "   - Processing rebalance 16/115: 2017-04-28... ✅ Universe: 53, Portfolio: 20, Regime: Sideways, Turnover: 4.5%\n",
      "   - Processing rebalance 17/115: 2017-05-30... ✅ Universe: 63, Portfolio: 20, Regime: Sideways, Turnover: 1.5%\n",
      "   - Processing rebalance 18/115: 2017-06-29... ✅ Universe: 70, Portfolio: 20, Regime: Sideways, Turnover: 7.5%\n",
      "   - Processing rebalance 19/115: 2017-07-28... ✅ Universe: 69, Portfolio: 20, Regime: Sideways, Turnover: 3.0%\n",
      "   - Processing rebalance 20/115: 2017-08-30... ✅ Universe: 67, Portfolio: 20, Regime: Sideways, Turnover: 3.0%\n",
      "   - Processing rebalance 21/115: 2017-09-29... ✅ Universe: 59, Portfolio: 20, Regime: Sideways, Turnover: 4.5%\n",
      "   - Processing rebalance 22/115: 2017-10-30... ✅ Universe: 60, Portfolio: 20, Regime: Sideways, Turnover: 6.0%\n",
      "   - Processing rebalance 23/115: 2017-11-29... ✅ Universe: 70, Portfolio: 20, Regime: Sideways, Turnover: 6.0%\n",
      "   - Processing rebalance 24/115: 2017-12-29... ✅ Universe: 73, Portfolio: 20, Regime: Sideways, Turnover: 3.0%\n",
      "   - Processing rebalance 25/115: 2018-01-30... ✅ Universe: 77, Portfolio: 20, Regime: Sideways, Turnover: 3.0%\n",
      "   - Processing rebalance 26/115: 2018-02-27... ✅ Universe: 73, Portfolio: 20, Regime: Sideways, Turnover: 4.5%\n",
      "   - Processing rebalance 27/115: 2018-03-30... ✅ Universe: 72, Portfolio: 20, Regime: Sideways, Turnover: 1.5%\n",
      "   - Processing rebalance 28/115: 2018-04-27... ✅ Universe: 74, Portfolio: 20, Regime: Sideways, Turnover: 1.5%\n",
      "   - Processing rebalance 29/115: 2018-05-30... ✅ Universe: 68, Portfolio: 20, Regime: Sideways, Turnover: 1.5%\n",
      "   - Processing rebalance 30/115: 2018-06-29... ✅ Universe: 59, Portfolio: 20, Regime: Sideways, Turnover: 1.5%\n",
      "   - Processing rebalance 31/115: 2018-07-30... ✅ Universe: 56, Portfolio: 20, Regime: Sideways, Turnover: 1.5%\n",
      "   - Processing rebalance 32/115: 2018-08-30... ✅ Universe: 55, Portfolio: 20, Regime: Sideways, Turnover: 0.0%\n",
      "   - Processing rebalance 33/115: 2018-09-28... ✅ Universe: 65, Portfolio: 20, Regime: Sideways, Turnover: 1.5%\n",
      "   - Processing rebalance 34/115: 2018-10-30... ✅ Universe: 66, Portfolio: 20, Regime: Sideways, Turnover: 1.5%\n",
      "   - Processing rebalance 35/115: 2018-11-29... ✅ Universe: 64, Portfolio: 20, Regime: Sideways, Turnover: 3.0%\n",
      "   - Processing rebalance 36/115: 2018-12-28... ✅ Universe: 57, Portfolio: 20, Regime: Sideways, Turnover: 3.0%\n",
      "   - Processing rebalance 37/115: 2019-01-30... ✅ Universe: 51, Portfolio: 20, Regime: Sideways, Turnover: 4.5%\n",
      "   - Processing rebalance 38/115: 2019-02-27... ✅ Universe: 55, Portfolio: 20, Regime: Sideways, Turnover: 3.0%\n",
      "   - Processing rebalance 39/115: 2019-03-29... ✅ Universe: 64, Portfolio: 20, Regime: Sideways, Turnover: 1.5%\n",
      "   - Processing rebalance 40/115: 2019-04-26... ✅ Universe: 65, Portfolio: 20, Regime: Sideways, Turnover: 0.0%\n",
      "   - Processing rebalance 41/115: 2019-05-30... ✅ Universe: 54, Portfolio: 20, Regime: Sideways, Turnover: 4.5%\n",
      "   - Processing rebalance 42/115: 2019-06-28... ✅ Universe: 53, Portfolio: 20, Regime: Sideways, Turnover: 4.5%\n",
      "   - Processing rebalance 43/115: 2019-07-30... ✅ Universe: 56, Portfolio: 20, Regime: Sideways, Turnover: 1.5%\n",
      "   - Processing rebalance 44/115: 2019-08-30... ✅ Universe: 58, Portfolio: 20, Regime: Sideways, Turnover: 6.0%\n",
      "   - Processing rebalance 45/115: 2019-09-27... ✅ Universe: 61, Portfolio: 20, Regime: Sideways, Turnover: 4.5%\n",
      "   - Processing rebalance 46/115: 2019-10-30... ✅ Universe: 60, Portfolio: 20, Regime: Sideways, Turnover: 3.0%\n",
      "   - Processing rebalance 47/115: 2019-11-29... ✅ Universe: 59, Portfolio: 20, Regime: Sideways, Turnover: 3.0%\n",
      "   - Processing rebalance 48/115: 2019-12-30... ✅ Universe: 65, Portfolio: 20, Regime: Sideways, Turnover: 1.5%\n",
      "   - Processing rebalance 49/115: 2020-01-30... ✅ Universe: 59, Portfolio: 20, Regime: Sideways, Turnover: 3.0%\n",
      "   - Processing rebalance 50/115: 2020-02-28... ✅ Universe: 57, Portfolio: 20, Regime: Sideways, Turnover: 4.5%\n",
      "   - Processing rebalance 51/115: 2020-03-30... ✅ Universe: 57, Portfolio: 20, Regime: Sideways, Turnover: 0.0%\n",
      "   - Processing rebalance 52/115: 2020-04-29... ✅ Universe: 64, Portfolio: 20, Regime: Sideways, Turnover: 4.5%\n",
      "   - Processing rebalance 53/115: 2020-05-29... ✅ Universe: 68, Portfolio: 20, Regime: Sideways, Turnover: 1.5%\n",
      "   - Processing rebalance 54/115: 2020-06-29... ✅ Universe: 86, Portfolio: 20, Regime: Sideways, Turnover: 1.5%\n",
      "   - Processing rebalance 55/115: 2020-07-30... ✅ Universe: 85, Portfolio: 20, Regime: Sideways, Turnover: 0.0%\n",
      "   - Processing rebalance 56/115: 2020-08-28... ✅ Universe: 84, Portfolio: 20, Regime: Sideways, Turnover: 1.5%\n",
      "   - Processing rebalance 57/115: 2020-09-29... ✅ Universe: 92, Portfolio: 20, Regime: Sideways, Turnover: 1.5%\n",
      "   - Processing rebalance 58/115: 2020-10-30... ✅ Universe: 102, Portfolio: 20, Regime: Sideways, Turnover: 6.0%\n",
      "   - Processing rebalance 59/115: 2020-11-27... ✅ Universe: 107, Portfolio: 20, Regime: Sideways, Turnover: 1.5%\n",
      "   - Processing rebalance 60/115: 2020-12-30... ✅ Universe: 125, Portfolio: 20, Regime: Sideways, Turnover: 3.0%\n",
      "   - Processing rebalance 61/115: 2021-01-29... ✅ Universe: 149, Portfolio: 20, Regime: Sideways, Turnover: 3.0%\n",
      "   - Processing rebalance 62/115: 2021-02-26... ✅ Universe: 148, Portfolio: 20, Regime: Sideways, Turnover: 6.0%\n",
      "   - Processing rebalance 63/115: 2021-03-30... ✅ Universe: 147, Portfolio: 20, Regime: Sideways, Turnover: 3.0%\n",
      "   - Processing rebalance 64/115: 2021-04-29... ✅ Universe: 156, Portfolio: 20, Regime: Sideways, Turnover: 4.5%\n",
      "   - Processing rebalance 65/115: 2021-05-28... ✅ Universe: 156, Portfolio: 20, Regime: Sideways, Turnover: 3.0%\n",
      "   - Processing rebalance 66/115: 2021-06-29... ✅ Universe: 159, Portfolio: 20, Regime: Sideways, Turnover: 3.0%\n",
      "   - Processing rebalance 67/115: 2021-07-30... ✅ Universe: 162, Portfolio: 20, Regime: Sideways, Turnover: 1.5%\n",
      "   - Processing rebalance 68/115: 2021-08-30... ✅ Universe: 177, Portfolio: 20, Regime: Sideways, Turnover: 4.5%\n",
      "   - Processing rebalance 69/115: 2021-09-29... ✅ Universe: 208, Portfolio: 20, Regime: Sideways, Turnover: 3.0%\n",
      "   - Processing rebalance 70/115: 2021-10-29... ✅ Universe: 232, Portfolio: 20, Regime: Sideways, Turnover: 0.0%\n",
      "   - Processing rebalance 71/115: 2021-11-29... ✅ Universe: 254, Portfolio: 20, Regime: Sideways, Turnover: 1.5%\n",
      "   - Processing rebalance 72/115: 2021-12-30... ✅ Universe: 262, Portfolio: 20, Regime: Sideways, Turnover: 4.5%\n",
      "   - Processing rebalance 73/115: 2022-01-28... ✅ Universe: 241, Portfolio: 20, Regime: Sideways, Turnover: 1.5%\n",
      "   - Processing rebalance 74/115: 2022-02-25... ✅ Universe: 228, Portfolio: 20, Regime: Sideways, Turnover: 6.0%\n",
      "   - Processing rebalance 75/115: 2022-03-30... ✅ Universe: 233, Portfolio: 20, Regime: Sideways, Turnover: 4.5%\n",
      "   - Processing rebalance 76/115: 2022-04-29... ✅ Universe: 231, Portfolio: 20, Regime: Sideways, Turnover: 1.5%\n",
      "   - Processing rebalance 77/115: 2022-05-30... ✅ Universe: 192, Portfolio: 20, Regime: Sideways, Turnover: 1.5%\n",
      "   - Processing rebalance 78/115: 2022-06-29... ✅ Universe: 161, Portfolio: 20, Regime: Sideways, Turnover: 4.5%\n",
      "   - Processing rebalance 79/115: 2022-07-29... ✅ Universe: 154, Portfolio: 20, Regime: Sideways, Turnover: 3.0%\n",
      "   - Processing rebalance 80/115: 2022-08-30... ✅ Universe: 161, Portfolio: 20, Regime: Sideways, Turnover: 3.0%\n",
      "   - Processing rebalance 81/115: 2022-09-29... ✅ Universe: 167, Portfolio: 20, Regime: Sideways, Turnover: 1.5%\n",
      "   - Processing rebalance 82/115: 2022-10-28... ✅ Universe: 150, Portfolio: 20, Regime: Sideways, Turnover: 4.5%\n",
      "   - Processing rebalance 83/115: 2022-11-29... ✅ Universe: 135, Portfolio: 20, Regime: Sideways, Turnover: 0.0%\n",
      "   - Processing rebalance 84/115: 2022-12-30... ✅ Universe: 143, Portfolio: 20, Regime: Sideways, Turnover: 1.5%\n",
      "   - Processing rebalance 85/115: 2023-01-30... ✅ Universe: 144, Portfolio: 20, Regime: Sideways, Turnover: 0.0%\n",
      "   - Processing rebalance 86/115: 2023-02-27... ✅ Universe: 139, Portfolio: 20, Regime: Sideways, Turnover: 4.5%\n",
      "   - Processing rebalance 87/115: 2023-03-30... ✅ Universe: 131, Portfolio: 20, Regime: Sideways, Turnover: 0.0%\n",
      "   - Processing rebalance 88/115: 2023-04-28... ✅ Universe: 135, Portfolio: 20, Regime: Sideways, Turnover: 0.0%\n",
      "   - Processing rebalance 89/115: 2023-05-30... ✅ Universe: 156, Portfolio: 20, Regime: Sideways, Turnover: 3.0%\n",
      "   - Processing rebalance 90/115: 2023-06-29... ✅ Universe: 180, Portfolio: 20, Regime: Sideways, Turnover: 4.5%\n",
      "   - Processing rebalance 91/115: 2023-07-28... ✅ Universe: 188, Portfolio: 20, Regime: Sideways, Turnover: 1.5%\n",
      "   - Processing rebalance 92/115: 2023-08-30... ✅ Universe: 190, Portfolio: 20, Regime: Sideways, Turnover: 4.5%\n",
      "   - Processing rebalance 93/115: 2023-09-29... ✅ Universe: 197, Portfolio: 20, Regime: Sideways, Turnover: 0.0%\n",
      "   - Processing rebalance 94/115: 2023-10-30... ✅ Universe: 171, Portfolio: 20, Regime: Sideways, Turnover: 3.0%\n",
      "   - Processing rebalance 95/115: 2023-11-29... ✅ Universe: 149, Portfolio: 20, Regime: Sideways, Turnover: 3.0%\n",
      "   - Processing rebalance 96/115: 2023-12-29... ✅ Universe: 147, Portfolio: 20, Regime: Sideways, Turnover: 1.5%\n",
      "   - Processing rebalance 97/115: 2024-01-30... ✅ Universe: 154, Portfolio: 20, Regime: Sideways, Turnover: 0.0%\n",
      "   - Processing rebalance 98/115: 2024-02-28... ✅ Universe: 157, Portfolio: 20, Regime: Sideways, Turnover: 0.0%\n",
      "   - Processing rebalance 99/115: 2024-03-29... ✅ Universe: 166, Portfolio: 20, Regime: Sideways, Turnover: 1.5%\n",
      "   - Processing rebalance 100/115: 2024-04-26... ✅ Universe: 169, Portfolio: 20, Regime: Sideways, Turnover: 0.0%\n",
      "   - Processing rebalance 101/115: 2024-05-30... ✅ Universe: 174, Portfolio: 20, Regime: Sideways, Turnover: 0.0%\n",
      "   - Processing rebalance 102/115: 2024-06-28... ✅ Universe: 188, Portfolio: 20, Regime: Sideways, Turnover: 1.5%\n",
      "   - Processing rebalance 103/115: 2024-07-30... ✅ Universe: 182, Portfolio: 20, Regime: Sideways, Turnover: 0.0%\n",
      "   - Processing rebalance 104/115: 2024-08-30... ✅ Universe: 166, Portfolio: 20, Regime: Sideways, Turnover: 1.5%\n",
      "   - Processing rebalance 105/115: 2024-09-27... ✅ Universe: 151, Portfolio: 20, Regime: Sideways, Turnover: 0.0%\n",
      "   - Processing rebalance 106/115: 2024-10-30... ✅ Universe: 147, Portfolio: 20, Regime: Sideways, Turnover: 0.0%\n",
      "   - Processing rebalance 107/115: 2024-11-29... ✅ Universe: 144, Portfolio: 20, Regime: Sideways, Turnover: 3.0%\n",
      "   - Processing rebalance 108/115: 2024-12-30... ✅ Universe: 152, Portfolio: 20, Regime: Sideways, Turnover: 3.0%\n",
      "   - Processing rebalance 109/115: 2025-01-24... ✅ Universe: 153, Portfolio: 20, Regime: Sideways, Turnover: 0.0%\n",
      "   - Processing rebalance 110/115: 2025-02-27... ✅ Universe: 156, Portfolio: 20, Regime: Sideways, Turnover: 1.5%\n",
      "   - Processing rebalance 111/115: 2025-03-28... ✅ Universe: 163, Portfolio: 20, Regime: Sideways, Turnover: 0.0%\n",
      "   - Processing rebalance 112/115: 2025-04-29... ✅ Universe: 162, Portfolio: 20, Regime: Sideways, Turnover: 0.0%\n",
      "   - Processing rebalance 113/115: 2025-05-30... ✅ Universe: 165, Portfolio: 20, Regime: Sideways, Turnover: 1.5%\n",
      "   - Processing rebalance 114/115: 2025-06-27... ✅ Universe: 162, Portfolio: 20, Regime: Sideways, Turnover: 1.5%\n",
      "   - Processing rebalance 115/115: 2025-07-25... ✅ Universe: 174, Portfolio: 20, Regime: Sideways, Turnover: 0.0%\n",
      "\n",
      "💸 Net returns calculated.\n",
      "   - Total Gross Return: 107.19%\n",
      "   - Total Net Return: 103.06%\n",
      "   - Total Cost Drag: 2.02%\n",
      "✅ QVM Engine v3 backtest execution complete.\n",
      "\n",
      "================================================================================\n",
      "📊 QVM ENGINE V3D: RESULTS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "📈 Regime Analysis:\n",
      "   - Sideways: 115 times (100.0%)\n",
      "\n",
      "📊 Performance Summary:\n",
      "   - Total Return: 103.06%\n",
      "   - Annualized Return: 7.76%\n",
      "   - Volatility: 12.77%\n",
      "   - Sharpe Ratio: 0.61\n",
      "\n",
      "✅ QVM Engine v3d with fixed regime detection complete!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 6: EXECUTION & TESTING\n",
    "# ============================================================================\n",
    "\n",
    "# Execute the data loading\n",
    "try:\n",
    "    price_data_raw, fundamental_data_raw, daily_returns_matrix, benchmark_returns = load_all_data_for_backtest(QVM_CONFIG, engine)\n",
    "    print(\"\\n✅ All data successfully loaded and prepared for the backtest.\")\n",
    "    print(f\"   - Price Data Shape: {price_data_raw.shape}\")\n",
    "    print(f\"   - Fundamental Data Shape: {fundamental_data_raw.shape}\")\n",
    "    print(f\"   - Returns Matrix Shape: {daily_returns_matrix.shape}\")\n",
    "    print(f\"   - Benchmark Returns: {len(benchmark_returns)} days\")\n",
    "\n",
    "    # --- Instantiate and Run the QVM Engine v3d ---\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"🚀 QVM ENGINE V3D: FIXED REGIME DETECTION\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    qvm_engine = QVMEngineV3AdoptedInsights(\n",
    "        config=QVM_CONFIG,\n",
    "        price_data=price_data_raw,\n",
    "        fundamental_data=fundamental_data_raw,\n",
    "        returns_matrix=daily_returns_matrix,\n",
    "        benchmark_returns=benchmark_returns,\n",
    "        db_engine=engine\n",
    "    )\n",
    "    \n",
    "    qvm_net_returns, qvm_diagnostics = qvm_engine.run_backtest()\n",
    "\n",
    "    # --- Summary of Results ---\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"📊 QVM ENGINE V3D: RESULTS SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Regime Analysis\n",
    "    if not qvm_diagnostics.empty and 'regime' in qvm_diagnostics.columns:\n",
    "        print(\"\\n📈 Regime Analysis:\")\n",
    "        regime_summary = qvm_diagnostics['regime'].value_counts()\n",
    "        for regime, count in regime_summary.items():\n",
    "            percentage = (count / len(qvm_diagnostics)) * 100\n",
    "            print(f\"   - {regime}: {count} times ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Performance Summary\n",
    "    if not qvm_net_returns.empty:\n",
    "        total_return = (1 + qvm_net_returns).prod() - 1\n",
    "        annualized_return = (1 + total_return) ** (252 / len(qvm_net_returns)) - 1\n",
    "        volatility = qvm_net_returns.std() * np.sqrt(252)\n",
    "        sharpe_ratio = annualized_return / volatility if volatility > 0 else 0\n",
    "        \n",
    "        print(f\"\\n📊 Performance Summary:\")\n",
    "        print(f\"   - Total Return: {total_return:.2%}\")\n",
    "        print(f\"   - Annualized Return: {annualized_return:.2%}\")\n",
    "        print(f\"   - Volatility: {volatility:.2%}\")\n",
    "        print(f\"   - Sharpe Ratio: {sharpe_ratio:.2f}\")\n",
    "\n",
    "    print(\"\\n✅ QVM Engine v3d with fixed regime detection complete!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ An error occurred during execution: {e}\")\n",
    "    raise "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
