{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4198c5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Tuple, List, Dict, Any\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import jupytext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01276928",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1a2201",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_db_connection():\n",
    "    \"\"\"\n",
    "    Create database connection for the QVM engine\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from production.database.connection import get_engine\n",
    "        engine = get_engine()\n",
    "        return engine\n",
    "    except ImportError:\n",
    "        print(\"Database connection module not found. Using mock data.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207f2b5f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class RegimeDetector:\n",
    "    \"\"\"\n",
    "    Percentile-based regime detector that adapts to market conditions\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, lookback_period: int = 90, \n",
    "                 volatility_percentile_high: float = 75.0,\n",
    "                 return_percentile_high: float = 75.0,\n",
    "                 return_percentile_low: float = 25.0):\n",
    "        \"\"\"\n",
    "        Initialize regime detector with percentile-based thresholds\n",
    "        \n",
    "        Args:\n",
    "            lookback_period: Days to look back for percentile calculation\n",
    "            volatility_percentile_high: Percentile for high volatility threshold\n",
    "            return_percentile_high: Percentile for high return threshold  \n",
    "            return_percentile_low: Percentile for low return threshold\n",
    "        \"\"\"\n",
    "        self.lookback_period = lookback_period\n",
    "        self.volatility_percentile_high = volatility_percentile_high\n",
    "        self.return_percentile_high = return_percentile_high\n",
    "        self.return_percentile_low = return_percentile_low\n",
    "        \n",
    "        # Store historical data for percentile calculation\n",
    "        self.volatility_history = []\n",
    "        self.return_history = []\n",
    "        \n",
    "    def detect_regime(self, price_data: pd.DataFrame) -> str:\n",
    "        \"\"\"\n",
    "        Detect market regime using percentile-based thresholds\n",
    "        \n",
    "        Args:\n",
    "            price_data: DataFrame with 'close' column\n",
    "            \n",
    "        Returns:\n",
    "            Regime classification: 'momentum', 'stress', or 'normal'\n",
    "        \"\"\"\n",
    "        if len(price_data) < self.lookback_period:\n",
    "            return 'normal'  # Default regime for insufficient data\n",
    "            \n",
    "        # Calculate rolling volatility and returns\n",
    "        returns = price_data['close'].pct_change().dropna()\n",
    "        volatility = returns.rolling(window=20).std().dropna()\n",
    "        \n",
    "        # Update historical data\n",
    "        if len(volatility) > 0:\n",
    "            self.volatility_history.append(volatility.iloc[-1])\n",
    "        if len(returns) > 0:\n",
    "            self.return_history.append(returns.iloc[-1])\n",
    "            \n",
    "        # Keep only recent history for percentile calculation\n",
    "        if len(self.volatility_history) > self.lookback_period:\n",
    "            self.volatility_history = self.volatility_history[-self.lookback_period:]\n",
    "        if len(self.return_history) > self.lookback_period:\n",
    "            self.return_history = self.return_history[-self.lookback_period:]\n",
    "            \n",
    "        # Calculate dynamic thresholds using percentiles\n",
    "        if len(self.volatility_history) >= 10:  # Minimum data requirement\n",
    "            vol_threshold = np.percentile(self.volatility_history, self.volatility_percentile_high)\n",
    "            return_threshold_high = np.percentile(self.return_history, self.return_percentile_high)\n",
    "            return_threshold_low = np.percentile(self.return_history, self.return_percentile_low)\n",
    "        else:\n",
    "            # Fallback to reasonable defaults if insufficient data\n",
    "            vol_threshold = 0.02  # 2% daily volatility\n",
    "            return_threshold_high = 0.01  # 1% daily return\n",
    "            return_threshold_low = -0.01  # -1% daily return\n",
    "            \n",
    "        # Get current values\n",
    "        current_vol = volatility.iloc[-1] if len(volatility) > 0 else 0\n",
    "        current_return = returns.iloc[-1] if len(returns) > 0 else 0\n",
    "        \n",
    "        # Regime classification logic\n",
    "        if current_vol > vol_threshold:\n",
    "            if current_return > return_threshold_high:\n",
    "                return 'momentum'\n",
    "            elif current_return < return_threshold_low:\n",
    "                return 'stress'\n",
    "            else:\n",
    "                return 'normal'\n",
    "        else:\n",
    "            return 'normal'\n",
    "    \n",
    "    def get_regime_allocation(self, regime: str) -> float:\n",
    "        \"\"\"\n",
    "        Get portfolio allocation based on detected regime\n",
    "        \n",
    "        Args:\n",
    "            regime: Detected regime ('momentum', 'stress', 'normal')\n",
    "            \n",
    "        Returns:\n",
    "            Portfolio allocation percentage\n",
    "        \"\"\"\n",
    "        allocation_map = {\n",
    "            'momentum': 0.8,  # High allocation in momentum regime\n",
    "            'stress': 0.3,    # Low allocation in stress regime\n",
    "            'normal': 0.6     # Moderate allocation in normal regime\n",
    "        }\n",
    "        return allocation_map.get(regime, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de406a8e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class SectorAwareFactorCalculator:\n",
    "    \"\"\"\n",
    "    Enhanced factor calculator with sector-aware calculations\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, engine):\n",
    "        self.engine = engine\n",
    "        \n",
    "    def calculate_sector_aware_pe(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Calculate sector-aware PE ratios\n",
    "        \"\"\"\n",
    "        def safe_qcut(x):\n",
    "            try:\n",
    "                if len(x.dropna()) >= 4:\n",
    "                    return pd.qcut(x, q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'], duplicates='drop')\n",
    "                else:\n",
    "                    return pd.Series(['Q2'] * len(x), index=x.index)\n",
    "            except:\n",
    "                return pd.Series(['Q2'] * len(x), index=x.index)\n",
    "        \n",
    "        # Calculate PE ratios\n",
    "        data['pe_ratio'] = data['market_cap'] / data['net_income']\n",
    "        \n",
    "        # Sector-aware PE scoring\n",
    "        data['pe_score'] = data.groupby('sector')['pe_ratio'].transform(safe_qcut)\n",
    "        \n",
    "        # Convert quartiles to numerical scores\n",
    "        pe_score_map = {'Q1': 4, 'Q2': 3, 'Q3': 2, 'Q4': 1}\n",
    "        data['pe_score'] = data['pe_score'].map(pe_score_map).fillna(2)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def calculate_momentum_score(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Calculate momentum scores with sector adjustment\n",
    "        \"\"\"\n",
    "        # Calculate returns for different periods\n",
    "        for period in [20, 60, 120]:\n",
    "            data[f'return_{period}d'] = data['close'].pct_change(period)\n",
    "        \n",
    "        # Calculate momentum score as weighted average\n",
    "        data['momentum_score'] = (\n",
    "            data['return_20d'] * 0.5 + \n",
    "            data['return_60d'] * 0.3 + \n",
    "            data['return_120d'] * 0.2\n",
    "        )\n",
    "        \n",
    "        # Sector-aware momentum scoring\n",
    "        def safe_qcut(x):\n",
    "            try:\n",
    "                if len(x.dropna()) >= 4:\n",
    "                    return pd.qcut(x, q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'], duplicates='drop')\n",
    "                else:\n",
    "                    return pd.Series(['Q2'] * len(x), index=x.index)\n",
    "            except:\n",
    "                return pd.Series(['Q2'] * len(x), index=x.index)\n",
    "        \n",
    "        data['momentum_quartile'] = data.groupby('sector')['momentum_score'].transform(safe_qcut)\n",
    "        \n",
    "        # Convert quartiles to numerical scores\n",
    "        momentum_score_map = {'Q1': 1, 'Q2': 2, 'Q3': 3, 'Q4': 4}\n",
    "        data['momentum_score'] = data['momentum_quartile'].map(momentum_score_map).fillna(2)\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec3cc12",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class QVMEngineV3AdoptedInsights:\n",
    "    \"\"\"\n",
    "    QVM Engine v3e with percentile-based regime detection and adopted insights\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: dict, price_data: pd.DataFrame, fundamental_data: pd.DataFrame,\n",
    "                 returns_matrix: pd.DataFrame, benchmark_returns: pd.Series, db_engine):\n",
    "        \"\"\"\n",
    "        Initialize QVM Engine v3e\n",
    "        \n",
    "        Args:\n",
    "            config: Configuration dictionary\n",
    "            price_data: Historical price data\n",
    "            fundamental_data: Fundamental data\n",
    "            returns_matrix: Returns matrix\n",
    "            benchmark_returns: Benchmark returns series\n",
    "            db_engine: Database engine\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.price_data = price_data\n",
    "        self.fundamental_data = fundamental_data\n",
    "        self.returns_matrix = returns_matrix\n",
    "        self.benchmark_returns = benchmark_returns\n",
    "        self.db_engine = db_engine\n",
    "        \n",
    "        # Initialize regime detector with percentile-based approach\n",
    "        regime_config = config.get('regime', {})\n",
    "        self.regime_detector = RegimeDetector(\n",
    "            lookback_period=regime_config.get('lookback_period', 90),\n",
    "            volatility_percentile_high=regime_config.get('volatility_percentile_high', 75.0),\n",
    "            return_percentile_high=regime_config.get('return_percentile_high', 75.0),\n",
    "            return_percentile_low=regime_config.get('return_percentile_low', 25.0)\n",
    "        )\n",
    "        \n",
    "        # Initialize factor calculator\n",
    "        self.factor_calculator = SectorAwareFactorCalculator(self)\n",
    "        \n",
    "        # Performance tracking\n",
    "        self.portfolio_returns = []\n",
    "        self.regime_history = []\n",
    "        self.allocation_history = []\n",
    "        \n",
    "    def run_backtest(self) -> Tuple[pd.Series, pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Run the backtest with percentile-based regime detection\n",
    "        \n",
    "        Returns:\n",
    "            Tuple of (strategy_returns, diagnostics_dataframe)\n",
    "        \"\"\"\n",
    "        print(\"Starting QVM Engine v3e backtest with percentile-based regime detection...\")\n",
    "        \n",
    "        # Generate rebalance dates\n",
    "        rebalance_dates = self._generate_rebalance_dates()\n",
    "        \n",
    "        # Run backtesting loop\n",
    "        holdings_df, diagnostics_df = self._run_backtesting_loop(rebalance_dates)\n",
    "        \n",
    "        # Calculate net returns\n",
    "        strategy_returns = self._calculate_net_returns(holdings_df)\n",
    "        \n",
    "        print(f\"Backtest completed. Regime distribution: {pd.Series(self.regime_history).value_counts().to_dict()}\")\n",
    "        \n",
    "        return strategy_returns, diagnostics_df\n",
    "    \n",
    "    def _generate_rebalance_dates(self) -> List[pd.Timestamp]:\n",
    "        \"\"\"Generate rebalance dates\"\"\"\n",
    "        start_date = self.price_data.index.min()\n",
    "        end_date = self.price_data.index.max()\n",
    "        \n",
    "        rebalance_dates = []\n",
    "        current_date = start_date\n",
    "        \n",
    "        while current_date <= end_date:\n",
    "            if current_date in self.price_data.index:\n",
    "                rebalance_dates.append(current_date)\n",
    "            current_date += pd.Timedelta(days=1)\n",
    "            \n",
    "        return rebalance_dates\n",
    "    \n",
    "    def _run_backtesting_loop(self, rebalance_dates: List[pd.Timestamp]) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"Run the main backtesting loop\"\"\"\n",
    "        holdings_data = []\n",
    "        diagnostics_data = []\n",
    "        \n",
    "        for i, analysis_date in enumerate(rebalance_dates):\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Processing date {analysis_date.strftime('%Y-%m-%d')} ({i+1}/{len(rebalance_dates)})\")\n",
    "            \n",
    "            try:\n",
    "                # Get universe\n",
    "                universe = self._get_universe(analysis_date)\n",
    "                if not universe:\n",
    "                    continue\n",
    "                \n",
    "                # Detect current regime\n",
    "                regime = self._detect_current_regime(analysis_date)\n",
    "                self.regime_history.append(regime)\n",
    "                \n",
    "                # Get regime allocation\n",
    "                regime_allocation = self.regime_detector.get_regime_allocation(regime)\n",
    "                self.allocation_history.append(regime_allocation)\n",
    "                \n",
    "                # Calculate factors\n",
    "                factors_df = self._calculate_factors(universe, analysis_date)\n",
    "                \n",
    "                # Apply entry criteria\n",
    "                qualified_df = self._apply_entry_criteria(factors_df)\n",
    "                \n",
    "                # Construct portfolio\n",
    "                portfolio_weights = self._construct_portfolio(qualified_df, regime_allocation)\n",
    "                \n",
    "                # Store holdings\n",
    "                for ticker, weight in portfolio_weights.items():\n",
    "                    holdings_data.append({\n",
    "                        'date': analysis_date,\n",
    "                        'ticker': ticker,\n",
    "                        'weight': weight,\n",
    "                        'regime': regime,\n",
    "                        'allocation': regime_allocation\n",
    "                    })\n",
    "                \n",
    "                # Store diagnostics\n",
    "                diagnostics_data.append({\n",
    "                    'date': analysis_date,\n",
    "                    'regime': regime,\n",
    "                    'allocation': regime_allocation,\n",
    "                    'universe_size': len(universe),\n",
    "                    'qualified_size': len(qualified_df),\n",
    "                    'portfolio_size': len(portfolio_weights)\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {analysis_date}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        holdings_df = pd.DataFrame(holdings_data)\n",
    "        diagnostics_df = pd.DataFrame(diagnostics_data)\n",
    "        \n",
    "        return holdings_df, diagnostics_df\n",
    "    \n",
    "    def _get_universe(self, analysis_date: pd.Timestamp) -> List[str]:\n",
    "        \"\"\"Get investable universe for the given date\"\"\"\n",
    "        # Get available tickers at the analysis date\n",
    "        available_tickers = self.price_data.loc[:analysis_date].columns.tolist()\n",
    "        \n",
    "        # Filter for minimum data requirements\n",
    "        min_data_required = 120  # At least 120 days of data\n",
    "        qualified_tickers = []\n",
    "        \n",
    "        for ticker in available_tickers:\n",
    "            ticker_data = self.price_data.loc[:analysis_date, ticker].dropna()\n",
    "            if len(ticker_data) >= min_data_required:\n",
    "                qualified_tickers.append(ticker)\n",
    "        \n",
    "        return qualified_tickers\n",
    "    \n",
    "    def _detect_current_regime(self, analysis_date: pd.Timestamp) -> str:\n",
    "        \"\"\"Detect current market regime using percentile-based approach\"\"\"\n",
    "        # Get historical price data up to analysis date\n",
    "        historical_data = self.price_data.loc[:analysis_date]\n",
    "        \n",
    "        # Use VNINDEX as proxy for market data if available, otherwise use first ticker\n",
    "        if 'VNINDEX' in historical_data.columns:\n",
    "            market_data = historical_data[['VNINDEX']].copy()\n",
    "        else:\n",
    "            market_data = historical_data.iloc[:, :1].copy()\n",
    "            market_data.columns = ['close']\n",
    "        \n",
    "        # Detect regime\n",
    "        regime = self.regime_detector.detect_regime(market_data)\n",
    "        \n",
    "        return regime\n",
    "    \n",
    "    def _calculate_factors(self, universe: List[str], analysis_date: pd.Timestamp) -> pd.DataFrame:\n",
    "        \"\"\"Calculate factors for the universe\"\"\"\n",
    "        factors_data = []\n",
    "        \n",
    "        for ticker in universe:\n",
    "            try:\n",
    "                # Get price data\n",
    "                ticker_prices = self.price_data.loc[:analysis_date, ticker].dropna()\n",
    "                if len(ticker_prices) < 120:\n",
    "                    continue\n",
    "                \n",
    "                # Get fundamental data\n",
    "                ticker_fundamentals = self.fundamental_data[\n",
    "                    (self.fundamental_data['ticker'] == ticker) & \n",
    "                    (self.fundamental_data['date'] <= analysis_date)\n",
    "                ].iloc[-1] if len(self.fundamental_data[\n",
    "                    (self.fundamental_data['ticker'] == ticker) & \n",
    "                    (self.fundamental_data['date'] <= analysis_date)\n",
    "                ]) > 0 else None\n",
    "                \n",
    "                if ticker_fundamentals is None:\n",
    "                    continue\n",
    "                \n",
    "                # Create data row\n",
    "                data_row = {\n",
    "                    'ticker': ticker,\n",
    "                    'close': ticker_prices.iloc[-1],\n",
    "                    'sector': ticker_fundamentals.get('sector', 'Unknown'),\n",
    "                    'market_cap': ticker_fundamentals.get('market_cap', 0),\n",
    "                    'net_income': ticker_fundamentals.get('net_income', 0)\n",
    "                }\n",
    "                \n",
    "                # Add price data for momentum calculation\n",
    "                for i, price in enumerate(ticker_prices.tail(120)):\n",
    "                    data_row[f'price_{i}'] = price\n",
    "                \n",
    "                factors_data.append(data_row)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error calculating factors for {ticker}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        if not factors_data:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        factors_df = pd.DataFrame(factors_data)\n",
    "        \n",
    "        # Calculate momentum factors\n",
    "        factors_df = self._calculate_momentum_factors(factors_df, analysis_date)\n",
    "        \n",
    "        # Calculate PE factors\n",
    "        factors_df = self._calculate_pe_factors(factors_df, factors_df)\n",
    "        \n",
    "        # Calculate composite score\n",
    "        factors_df = self._calculate_composite_score(factors_df)\n",
    "        \n",
    "        return factors_df\n",
    "    \n",
    "    def _calculate_momentum_factors(self, market_df: pd.DataFrame, analysis_date: pd.Timestamp) -> pd.DataFrame:\n",
    "        \"\"\"Calculate momentum factors\"\"\"\n",
    "        for ticker in market_df['ticker'].unique():\n",
    "            ticker_data = market_df[market_df['ticker'] == ticker].iloc[0]\n",
    "            \n",
    "            # Extract price series\n",
    "            prices = []\n",
    "            for i in range(120):\n",
    "                price_key = f'price_{i}'\n",
    "                if price_key in ticker_data:\n",
    "                    prices.append(ticker_data[price_key])\n",
    "            \n",
    "            if len(prices) < 120:\n",
    "                continue\n",
    "            \n",
    "            prices = prices[::-1]  # Reverse to get chronological order\n",
    "            price_series = pd.Series(prices)\n",
    "            \n",
    "            # Calculate returns\n",
    "            returns_20d = price_series.pct_change(20).iloc[-1]\n",
    "            returns_60d = price_series.pct_change(60).iloc[-1]\n",
    "            returns_120d = price_series.pct_change(120).iloc[-1]\n",
    "            \n",
    "            # Update momentum scores\n",
    "            idx = market_df[market_df['ticker'] == ticker].index[0]\n",
    "            market_df.loc[idx, 'momentum_20d'] = returns_20d\n",
    "            market_df.loc[idx, 'momentum_60d'] = returns_60d\n",
    "            market_df.loc[idx, 'momentum_120d'] = returns_120d\n",
    "        \n",
    "        return market_df\n",
    "    \n",
    "    def _calculate_pe_factors(self, market_df: pd.DataFrame, fundamental_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Calculate PE factors\"\"\"\n",
    "        # Calculate PE ratio\n",
    "        market_df['pe_ratio'] = market_df['market_cap'] / market_df['net_income'].replace(0, np.nan)\n",
    "        \n",
    "        # Handle infinite and NaN values\n",
    "        market_df['pe_ratio'] = market_df['pe_ratio'].replace([np.inf, -np.inf], np.nan)\n",
    "        \n",
    "        # Calculate PE score (lower PE = higher score)\n",
    "        pe_ratio_valid = market_df['pe_ratio'].dropna()\n",
    "        if len(pe_ratio_valid) > 0:\n",
    "            pe_quantiles = pd.qcut(pe_ratio_valid, q=4, labels=[4, 3, 2, 1], duplicates='drop')\n",
    "            market_df.loc[pe_ratio_valid.index, 'pe_score'] = pe_quantiles\n",
    "        \n",
    "        return market_df\n",
    "    \n",
    "    def _calculate_composite_score(self, factors_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Calculate composite factor score\"\"\"\n",
    "        # Normalize momentum factors\n",
    "        for col in ['momentum_20d', 'momentum_60d', 'momentum_120d']:\n",
    "            if col in factors_df.columns:\n",
    "                factors_df[col] = (factors_df[col] - factors_df[col].mean()) / factors_df[col].std()\n",
    "        \n",
    "        # Calculate composite score\n",
    "        momentum_score = (\n",
    "            factors_df.get('momentum_20d', 0) * 0.5 +\n",
    "            factors_df.get('momentum_60d', 0) * 0.3 +\n",
    "            factors_df.get('momentum_120d', 0) * 0.2\n",
    "        )\n",
    "        \n",
    "        pe_score = factors_df.get('pe_score', 2)  # Default to neutral score\n",
    "        \n",
    "        # Combine scores (momentum + value)\n",
    "        factors_df['composite_score'] = momentum_score * 0.6 + pe_score * 0.4\n",
    "        \n",
    "        return factors_df\n",
    "    \n",
    "    def _apply_entry_criteria(self, factors_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Apply entry criteria to filter stocks\"\"\"\n",
    "        if len(factors_df) == 0:\n",
    "            return factors_df\n",
    "        \n",
    "        # Filter by composite score (top 50%)\n",
    "        score_threshold = factors_df['composite_score'].quantile(0.5)\n",
    "        qualified_df = factors_df[factors_df['composite_score'] >= score_threshold].copy()\n",
    "        \n",
    "        return qualified_df\n",
    "    \n",
    "    def _construct_portfolio(self, qualified_df: pd.DataFrame, regime_allocation: float) -> pd.Series:\n",
    "        \"\"\"Construct portfolio weights\"\"\"\n",
    "        if len(qualified_df) == 0:\n",
    "            return pd.Series()\n",
    "        \n",
    "        # Equal weight allocation\n",
    "        n_stocks = len(qualified_df)\n",
    "        weight_per_stock = regime_allocation / n_stocks\n",
    "        \n",
    "        portfolio_weights = pd.Series(weight_per_stock, index=qualified_df['ticker'])\n",
    "        \n",
    "        return portfolio_weights\n",
    "    \n",
    "    def _calculate_net_returns(self, daily_holdings: pd.DataFrame) -> pd.Series:\n",
    "        \"\"\"Calculate net strategy returns\"\"\"\n",
    "        if len(daily_holdings) == 0:\n",
    "            return pd.Series()\n",
    "        \n",
    "        # Group by date and calculate portfolio returns\n",
    "        portfolio_returns = []\n",
    "        \n",
    "        for date in daily_holdings['date'].unique():\n",
    "            date_holdings = daily_holdings[daily_holdings['date'] == date]\n",
    "            \n",
    "            if len(date_holdings) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Calculate weighted return for this date\n",
    "            date_return = 0\n",
    "            for _, holding in date_holdings.iterrows():\n",
    "                ticker = holding['ticker']\n",
    "                weight = holding['weight']\n",
    "                \n",
    "                if ticker in self.returns_matrix.columns and date in self.returns_matrix.index:\n",
    "                    ticker_return = self.returns_matrix.loc[date, ticker]\n",
    "                    if pd.notna(ticker_return):\n",
    "                        date_return += weight * ticker_return\n",
    "            \n",
    "            portfolio_returns.append({\n",
    "                'date': date,\n",
    "                'return': date_return\n",
    "            })\n",
    "        \n",
    "        returns_df = pd.DataFrame(portfolio_returns)\n",
    "        returns_df.set_index('date', inplace=True)\n",
    "        \n",
    "        return returns_df['return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc29a632",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_all_data_for_backtest(config: dict, db_engine):\n",
    "    \"\"\"\n",
    "    Load all required data for backtesting\n",
    "    \"\"\"\n",
    "    print(\"Loading data for backtest...\")\n",
    "    \n",
    "    # Load configuration\n",
    "    start_date = config.get('start_date', '2016-01-01')\n",
    "    end_date = config.get('end_date', '2025-01-01')\n",
    "    \n",
    "    # Mock data generation for demonstration\n",
    "    # In production, this would load from database\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "    \n",
    "    # Generate mock price data\n",
    "    n_stocks = 100\n",
    "    tickers = [f'STOCK_{i:03d}' for i in range(n_stocks)]\n",
    "    \n",
    "    # Create price data with realistic patterns\n",
    "    np.random.seed(42)\n",
    "    price_data = pd.DataFrame(index=date_range, columns=tickers)\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        # Generate random walk with trend\n",
    "        returns = np.random.normal(0.0005, 0.02, len(date_range))\n",
    "        prices = 100 * np.exp(np.cumsum(returns))\n",
    "        price_data[ticker] = prices\n",
    "    \n",
    "    # Add VNINDEX as market proxy\n",
    "    market_returns = np.random.normal(0.0003, 0.015, len(date_range))\n",
    "    market_prices = 1000 * np.exp(np.cumsum(market_returns))\n",
    "    price_data['VNINDEX'] = market_prices\n",
    "    \n",
    "    # Generate fundamental data\n",
    "    fundamental_data = []\n",
    "    for ticker in tickers:\n",
    "        for date in date_range[::90]:  # Quarterly data\n",
    "            fundamental_data.append({\n",
    "                'ticker': ticker,\n",
    "                'date': date,\n",
    "                'sector': np.random.choice(['Banking', 'Technology', 'Consumer', 'Energy']),\n",
    "                'market_cap': np.random.uniform(1000, 100000),\n",
    "                'net_income': np.random.uniform(10, 1000)\n",
    "            })\n",
    "    \n",
    "    fundamental_df = pd.DataFrame(fundamental_data)\n",
    "    \n",
    "    # Generate returns matrix\n",
    "    returns_matrix = price_data.pct_change().dropna()\n",
    "    \n",
    "    # Generate benchmark returns (VNINDEX)\n",
    "    benchmark_returns = returns_matrix['VNINDEX']\n",
    "    \n",
    "    print(f\"Data loaded: {len(price_data)} days, {len(tickers)} stocks\")\n",
    "    \n",
    "    return price_data, fundamental_df, returns_matrix, benchmark_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ee4056",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def calculate_performance_metrics(returns: pd.Series, benchmark: pd.Series, periods_per_year: int = 252) -> dict:\n",
    "    \"\"\"\n",
    "    Calculate comprehensive performance metrics\n",
    "    \"\"\"\n",
    "    if len(returns) == 0:\n",
    "        return {}\n",
    "    \n",
    "    # Basic metrics\n",
    "    total_return = (1 + returns).prod() - 1\n",
    "    annualized_return = (1 + total_return) ** (periods_per_year / len(returns)) - 1\n",
    "    volatility = returns.std() * np.sqrt(periods_per_year)\n",
    "    sharpe_ratio = annualized_return / volatility if volatility > 0 else 0\n",
    "    \n",
    "    # Drawdown analysis\n",
    "    cumulative_returns = (1 + returns).cumprod()\n",
    "    running_max = cumulative_returns.expanding().max()\n",
    "    drawdown = (cumulative_returns - running_max) / running_max\n",
    "    max_drawdown = drawdown.min()\n",
    "    \n",
    "    # Benchmark comparison\n",
    "    if len(benchmark) > 0:\n",
    "        benchmark_total_return = (1 + benchmark).prod() - 1\n",
    "        benchmark_annualized = (1 + benchmark_total_return) ** (periods_per_year / len(benchmark)) - 1\n",
    "        benchmark_volatility = benchmark.std() * np.sqrt(periods_per_year)\n",
    "        \n",
    "        excess_return = annualized_return - benchmark_annualized\n",
    "        information_ratio = excess_return / (returns - benchmark).std() * np.sqrt(periods_per_year) if (returns - benchmark).std() > 0 else 0\n",
    "    else:\n",
    "        benchmark_annualized = 0\n",
    "        benchmark_volatility = 0\n",
    "        excess_return = annualized_return\n",
    "        information_ratio = sharpe_ratio\n",
    "    \n",
    "    return {\n",
    "        'total_return': total_return,\n",
    "        'annualized_return': annualized_return,\n",
    "        'volatility': volatility,\n",
    "        'sharpe_ratio': sharpe_ratio,\n",
    "        'max_drawdown': max_drawdown,\n",
    "        'benchmark_return': benchmark_annualized,\n",
    "        'benchmark_volatility': benchmark_volatility,\n",
    "        'excess_return': excess_return,\n",
    "        'information_ratio': information_ratio\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374ad13d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def generate_comprehensive_tearsheet(strategy_returns: pd.Series, benchmark_returns: pd.Series, \n",
    "                                   diagnostics: pd.DataFrame, title: str):\n",
    "    \"\"\"\n",
    "    Generate comprehensive performance tearsheet\n",
    "    \"\"\"\n",
    "    if len(strategy_returns) == 0:\n",
    "        print(\"No strategy returns to analyze\")\n",
    "        return\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    metrics = calculate_performance_metrics(strategy_returns, benchmark_returns)\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle(f'{title} - Performance Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Cumulative returns\n",
    "    cumulative_strategy = (1 + strategy_returns).cumprod()\n",
    "    cumulative_benchmark = (1 + benchmark_returns).cumprod()\n",
    "    \n",
    "    axes[0, 0].plot(cumulative_strategy.index, cumulative_strategy.values, \n",
    "                   label='Strategy', linewidth=2, color='blue')\n",
    "    axes[0, 0].plot(cumulative_benchmark.index, cumulative_benchmark.values, \n",
    "                   label='Benchmark', linewidth=2, color='red', alpha=0.7)\n",
    "    axes[0, 0].set_title('Cumulative Returns')\n",
    "    axes[0, 0].set_ylabel('Cumulative Return')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Regime distribution\n",
    "    if len(diagnostics) > 0 and 'regime' in diagnostics.columns:\n",
    "        regime_counts = diagnostics['regime'].value_counts()\n",
    "        axes[0, 1].pie(regime_counts.values, labels=regime_counts.index, autopct='%1.1f%%')\n",
    "        axes[0, 1].set_title('Regime Distribution')\n",
    "    \n",
    "    # 3. Allocation over time\n",
    "    if len(diagnostics) > 0 and 'allocation' in diagnostics.columns:\n",
    "        axes[1, 0].plot(diagnostics['date'], diagnostics['allocation'], \n",
    "                       linewidth=2, color='green')\n",
    "        axes[1, 0].set_title('Portfolio Allocation Over Time')\n",
    "        axes[1, 0].set_ylabel('Allocation %')\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Performance metrics table\n",
    "    metrics_text = '\\n'.join([f'{k}: {v:.4f}' for k, v in metrics.items()])\n",
    "    axes[1, 1].text(0.1, 0.9, metrics_text, transform=axes[1, 1].transAxes, \n",
    "                   fontsize=10, verticalalignment='top', fontfamily='monospace')\n",
    "    axes[1, 1].set_title('Performance Metrics')\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"\\n{title} - Performance Summary:\")\n",
    "    print(\"=\" * 50)\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric.replace('_', ' ').title()}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d04996",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main execution function\n",
    "    \"\"\"\n",
    "    print(\"QVM Engine v3e - Percentile-based Regime Detection\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load configuration from config file\n",
    "    try:\n",
    "        with open('config/config_v3e_percentile_regime.yml', 'r') as f:\n",
    "            config = yaml.safe_load(f)\n",
    "        print(\"Configuration loaded from config/config_v3e_percentile_regime.yml\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Config file not found, using default configuration\")\n",
    "        # Fallback configuration with percentile-based regime detection\n",
    "        config = {\n",
    "            \"start_date\": \"2016-01-01\",\n",
    "            \"end_date\": \"2025-01-01\",\n",
    "            \"regime\": {\n",
    "                \"lookback_period\": 90,\n",
    "                \"volatility_percentile_high\": 75.0,  # 75th percentile for high volatility\n",
    "                \"return_percentile_high\": 75.0,      # 75th percentile for high return\n",
    "                \"return_percentile_low\": 25.0        # 25th percentile for low return\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    # Create database connection\n",
    "    db_engine = create_db_connection()\n",
    "    \n",
    "    # Load data\n",
    "    price_data, fundamental_data, returns_matrix, benchmark_returns = load_all_data_for_backtest(config, db_engine)\n",
    "    \n",
    "    # Initialize and run engine\n",
    "    engine = QVMEngineV3AdoptedInsights(\n",
    "        config=config,\n",
    "        price_data=price_data,\n",
    "        fundamental_data=fundamental_data,\n",
    "        returns_matrix=returns_matrix,\n",
    "        benchmark_returns=benchmark_returns,\n",
    "        db_engine=db_engine\n",
    "    )\n",
    "    \n",
    "    # Run backtest\n",
    "    strategy_returns, diagnostics = engine.run_backtest()\n",
    "    \n",
    "    # Generate tearsheet\n",
    "    generate_comprehensive_tearsheet(strategy_returns, benchmark_returns, diagnostics, \n",
    "                                   \"QVM Engine v3e - Percentile-based Regime Detection\")\n",
    "    \n",
    "    # Print regime statistics\n",
    "    if len(engine.regime_history) > 0:\n",
    "        regime_distribution = pd.Series(engine.regime_history).value_counts()\n",
    "        print(f\"\\nRegime Distribution:\")\n",
    "        print(\"=\" * 30)\n",
    "        for regime, count in regime_distribution.items():\n",
    "            percentage = (count / len(engine.regime_history)) * 100\n",
    "            print(f\"{regime}: {count} ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a47020",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
