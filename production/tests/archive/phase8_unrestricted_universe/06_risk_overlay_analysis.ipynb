{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# Aureus Sigma Capital - Risk Overlay Analysis\n",
    "# Notebook: 06_risk_overlay_analysis.ipynb\n",
    "#\n",
    "# Description:\n",
    "# Phase 8 Risk Management Implementation - Testing three distinct risk overlay\n",
    "# mechanisms to reduce maximum drawdown from -45.2% to institutional target\n",
    "# <25% while preserving validated alpha generation (Sharpe >1.2).\n",
    "#\n",
    "# Author: Duc Nguyen, Quantitative Finance Expert\n",
    "# Date: July 27, 2025\n",
    "# Version: 1.0 - Institutional Risk Management Framework\n",
    "# ============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Visualization environment configured with institutional palette.\n",
      "\n",
      "======================================================================\n",
      "üéØ Aureus Sigma: Phase 8 Risk Overlay Analysis\n",
      "   Version: 1.0 - Date: 2025-07-27 09:07:19\n",
      "======================================================================\n",
      "\n",
      "üéØ Phase 8 Mission:\n",
      "   ‚Ä¢ Reduce maximum drawdown from -45.2% to institutional target <25%\n",
      "   ‚Ä¢ Preserve validated alpha generation (maintain Sharpe >1.2)\n",
      "   ‚Ä¢ Test 3 risk overlay mechanisms on quarterly rebalancing baseline\n",
      "   ‚Ä¢ Optimize for Calmar Ratio (Annual Return / Max Drawdown)\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import warnings\n",
    "from scipy import stats\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import yaml\n",
    "from sqlalchemy import create_engine\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- INSTITUTIONAL PALETTE (Blackstone-inspired) ---\n",
    "FACTOR_COLORS = {\n",
    "    'Strategy': '#16A085',          # Blackstone Teal (primary)\n",
    "    'Benchmark': '#34495E',         # Warm charcoal (secondary)\n",
    "    'Positive': '#27AE60',         # Professional green\n",
    "    'Negative': '#C0392B',         # Sophisticated red\n",
    "    'Drawdown': '#E67E22',         # Sophisticated orange\n",
    "    'Sharpe': '#2980B9',           # Institutional blue\n",
    "    'Grid': '#BDC3C7',\n",
    "    'Text_Primary': '#2C3E50',\n",
    "    'Neutral': '#7F8C8D',\n",
    "    # Risk overlay colors\n",
    "    'Regime': '#9B59B6',           # Purple for regime overlay\n",
    "    'VolTarget': '#E74C3C',        # Red for volatility targeting\n",
    "    'DynReversal': '#F39C12',      # Orange for dynamic reversal\n",
    "    'Control': '#2C3E50'           # Dark for control baseline\n",
    "}\n",
    "\n",
    "GRADIENT_PALETTES = {\n",
    "    'performance': ['#C0392B', '#FFFFFF', '#27AE60'],  # Red-White-Green\n",
    "}\n",
    "\n",
    "# --- ENHANCED VISUALIZATION CONFIGURATION ---\n",
    "plt.style.use('default')\n",
    "plt.rcParams.update({\n",
    "    'figure.dpi': 300, 'savefig.dpi': 300, 'figure.figsize': (15, 8),\n",
    "    'figure.facecolor': 'white', 'font.size': 11,\n",
    "    'axes.facecolor': 'white', 'axes.edgecolor': FACTOR_COLORS['Text_Primary'],\n",
    "    'axes.linewidth': 1.0, 'axes.grid': True, 'axes.axisbelow': True,\n",
    "    'axes.labelcolor': FACTOR_COLORS['Text_Primary'], 'axes.titlesize': 14,\n",
    "    'axes.titleweight': 'bold', 'axes.titlecolor': FACTOR_COLORS['Text_Primary'],\n",
    "    'grid.color': FACTOR_COLORS['Grid'], 'grid.alpha': 0.3, 'grid.linewidth': 0.5,\n",
    "    'legend.frameon': False, 'legend.fontsize': 10,\n",
    "    'xtick.color': FACTOR_COLORS['Text_Primary'], 'ytick.color': FACTOR_COLORS['Text_Primary'],\n",
    "    'xtick.labelsize': 10, 'ytick.labelsize': 10,\n",
    "    'lines.linewidth': 2.0, 'lines.solid_capstyle': 'round'\n",
    "})\n",
    "\n",
    "print(\"üìä Visualization environment configured with institutional palette.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéØ Aureus Sigma: Phase 8 Risk Overlay Analysis\")\n",
    "print(f\"   Version: 1.0 - Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nüéØ Phase 8 Mission:\")\n",
    "print(\"   ‚Ä¢ Reduce maximum drawdown from -45.2% to institutional target <25%\")\n",
    "print(\"   ‚Ä¢ Preserve validated alpha generation (maintain Sharpe >1.2)\")\n",
    "print(\"   ‚Ä¢ Test 3 risk overlay mechanisms on quarterly rebalancing baseline\")\n",
    "print(\"   ‚Ä¢ Optimize for Calmar Ratio (Annual Return / Max Drawdown)\")\n",
    "print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Core Data and Establish Project Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading Phase 7 validated results and core data...\n",
      "   Phase 7 path: /Users/ducnguyen/Library/CloudStorage/GoogleDrive-duc.nguyentcb@gmail.com/My Drive/quant-world-invest/factor_investing_project/production/tests/phase7_institutional_backtesting\n",
      "   Phase 8 path: /Users/ducnguyen/Library/CloudStorage/GoogleDrive-duc.nguyentcb@gmail.com/My Drive/quant-world-invest/factor_investing_project/production/tests/phase8_risk_management\n",
      "‚úÖ Phase 7 validated results loaded:\n",
      "   Monthly strategy performance: 18.97% annual return\n",
      "   Monthly strategy Sharpe: 1.52\n",
      "   Maximum drawdown (monthly): 13.03%\n",
      "\n",
      "üèóÔ∏è Loading sector information...\n",
      "‚úÖ Loaded sector mappings for 728 tickers\n",
      "\n",
      "üîó Data aligned for Phase 8 analysis:\n",
      "   Date range: 2016-01-05 to 2025-07-25\n",
      "   Trading days: 2381\n",
      "   Universe size: 714 stocks\n",
      "   QVM scores shape: (2381, 714)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 2: LOAD PHASE 7 RESULTS AND PROJECT DATA\n",
    "# ============================================================================\n",
    "\n",
    "# Establish project paths\n",
    "project_root = Path.cwd()\n",
    "while not (project_root / 'production').exists() and not (project_root / 'config').exists():\n",
    "    if project_root.parent == project_root:\n",
    "        raise FileNotFoundError(\"Could not find project root\")\n",
    "    project_root = project_root.parent\n",
    "\n",
    "phase7_path = project_root / \"production\" / \"tests\" / \"phase7_institutional_backtesting\"\n",
    "phase8_path = project_root / \"production\" / \"tests\" / \"phase8_risk_management\"\n",
    "\n",
    "print(\"üìÇ Loading Phase 7 validated results and core data...\")\n",
    "print(f\"   Phase 7 path: {phase7_path}\")\n",
    "print(f\"   Phase 8 path: {phase8_path}\")\n",
    "\n",
    "# Load Phase 7 canonical backtest results\n",
    "with open(phase7_path / \"canonical_backtest_results.pkl\", \"rb\") as f:\n",
    "    phase7_results = pickle.load(f)\n",
    "\n",
    "# Load core data objects from Phase 7\n",
    "with open(phase7_path / \"factor_data.pkl\", \"rb\") as f:\n",
    "    factor_data_obj = pickle.load(f)\n",
    "with open(phase7_path / \"daily_returns.pkl\", \"rb\") as f:\n",
    "    returns_data_obj = pickle.load(f)\n",
    "with open(phase7_path / \"benchmark_returns.pkl\", \"rb\") as f:\n",
    "    benchmark_data_obj = pickle.load(f)\n",
    "\n",
    "# Extract data\n",
    "factor_data = factor_data_obj['data']\n",
    "daily_returns = returns_data_obj['data']\n",
    "benchmark_returns = benchmark_data_obj['data']\n",
    "\n",
    "print(\"‚úÖ Phase 7 validated results loaded:\")\n",
    "print(f\"   Monthly strategy performance: {(phase7_results['net_returns'].mean() * 252):.2%} annual return\")\n",
    "print(f\"   Monthly strategy Sharpe: {phase7_results['performance_summary']['sharpe_ratio']:.2f}\")\n",
    "print(f\"   Maximum drawdown (monthly): {phase7_results['performance_summary']['annual_vol']:.2%}\")\n",
    "\n",
    "# Load sector mappings\n",
    "print(\"\\nüèóÔ∏è Loading sector information...\")\n",
    "config_path = project_root / 'config' / 'database.yml'\n",
    "with open(config_path, 'r') as f:\n",
    "    db_config = yaml.safe_load(f)['production']\n",
    "\n",
    "engine = create_engine(\n",
    "    f\"mysql+pymysql://{db_config['username']}:{db_config['password']}@\"\n",
    "    f\"{db_config['host']}/{db_config['schema_name']}\"\n",
    ")\n",
    "\n",
    "sector_info = pd.read_sql(\"SELECT ticker, sector FROM master_info WHERE sector IS NOT NULL\", engine)\n",
    "sector_info = sector_info.drop_duplicates(subset=['ticker']).set_index('ticker')\n",
    "engine.dispose()\n",
    "\n",
    "print(f\"‚úÖ Loaded sector mappings for {len(sector_info)} tickers\")\n",
    "\n",
    "# Align data for Phase 8 analysis\n",
    "common_index = factor_data.index.intersection(daily_returns.index).intersection(benchmark_returns.index)\n",
    "common_tickers = factor_data.columns.get_level_values(1).intersection(daily_returns.columns).unique().intersection(sector_info.index)\n",
    "\n",
    "# Extract QVM scores and align all data\n",
    "qvm_scores = factor_data.loc[common_index, ('qvm_composite_score', common_tickers)]\n",
    "qvm_scores.columns = qvm_scores.columns.droplevel(0)\n",
    "daily_returns_aligned = daily_returns.loc[common_index, common_tickers]\n",
    "benchmark_returns_aligned = benchmark_returns.loc[common_index]\n",
    "\n",
    "print(\"\\nüîó Data aligned for Phase 8 analysis:\")\n",
    "print(f\"   Date range: {common_index.min().date()} to {common_index.max().date()}\")\n",
    "print(f\"   Trading days: {len(common_index)}\")\n",
    "print(f\"   Universe size: {len(common_tickers)} stocks\")\n",
    "print(f\"   QVM scores shape: {qvm_scores.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Market Regime Identification (from Phase 7)\n",
    "\n",
    "Load and validate the market regime framework that will be used for risk overlays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Identifying market regimes using Phase 7 validated methodology...\n",
      "\n",
      "üìä Regime Distribution (Phase 8 Implementation):\n",
      "   Bull      :  1004 days ( 42.2%)\n",
      "   Bear      :   768 days ( 32.3%)\n",
      "   Sideways  :   335 days ( 14.1%)\n",
      "   Stress    :   274 days ( 11.5%)\n",
      "\n",
      "üéØ Risk Overlay Coverage Analysis:\n",
      "   Bear + Stress periods: 1,042 days (43.8%)\n",
      "   Risk reduction opportunities: 43.8% of trading days\n",
      "   ‚úÖ GOOD COVERAGE: Sufficient Bear/Stress periods for risk overlay testing\n",
      "\n",
      "‚úÖ Market regime framework ready for Phase 8 implementation\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 3: MARKET REGIME FRAMEWORK (FROM PHASE 7 ATTRIBUTION ANALYSIS)\n",
    "# ============================================================================\n",
    "\n",
    "def identify_market_regimes(benchmark_returns: pd.Series, \n",
    "                          bear_threshold: float = -0.20,\n",
    "                          vol_window: int = 60,\n",
    "                          trend_window: int = 200) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Identifies market regimes using multiple criteria (from Phase 7 validation):\n",
    "    - Bear: Drawdown > 20% from peak\n",
    "    - Stress: Rolling volatility in top quartile\n",
    "    - Bull: Price above trend MA and not Bear/Stress\n",
    "    - Sideways: Everything else\n",
    "    \"\"\"\n",
    "    print(\"üîç Identifying market regimes using Phase 7 validated methodology...\")\n",
    "    \n",
    "    # Calculate cumulative returns and drawdowns\n",
    "    cumulative = (1 + benchmark_returns).cumprod()\n",
    "    drawdown = (cumulative / cumulative.cummax() - 1)\n",
    "    \n",
    "    # 1. Bear Market Regime\n",
    "    is_bear = drawdown < bear_threshold\n",
    "    \n",
    "    # 2. High-Stress Regime (rolling volatility)\n",
    "    rolling_vol = benchmark_returns.rolling(vol_window).std() * np.sqrt(252)\n",
    "    vol_75th = rolling_vol.quantile(0.75)\n",
    "    is_stress = rolling_vol > vol_75th\n",
    "    \n",
    "    # 3. Bull/Sideways (trend-based)\n",
    "    trend_ma = cumulative.rolling(trend_window).mean()\n",
    "    is_above_trend = cumulative > trend_ma\n",
    "    \n",
    "    # Combine into regime classification\n",
    "    regimes = pd.DataFrame(index=benchmark_returns.index)\n",
    "    regimes['is_bear'] = is_bear\n",
    "    regimes['is_stress'] = is_stress\n",
    "    regimes['is_bull'] = is_above_trend & ~is_bear & ~is_stress\n",
    "    regimes['is_sideways'] = ~is_above_trend & ~is_bear & ~is_stress\n",
    "    \n",
    "    # Create primary regime classification\n",
    "    regimes['regime'] = 'Undefined'\n",
    "    regimes.loc[regimes['is_bear'], 'regime'] = 'Bear'\n",
    "    regimes.loc[regimes['is_stress'] & ~regimes['is_bear'], 'regime'] = 'Stress'\n",
    "    regimes.loc[regimes['is_bull'], 'regime'] = 'Bull'\n",
    "    regimes.loc[regimes['is_sideways'], 'regime'] = 'Sideways'\n",
    "    \n",
    "    # Summary statistics\n",
    "    regime_counts = regimes['regime'].value_counts()\n",
    "    regime_pcts = (regime_counts / len(regimes)) * 100\n",
    "    \n",
    "    print(\"\\nüìä Regime Distribution (Phase 8 Implementation):\")\n",
    "    for regime, pct in regime_pcts.items():\n",
    "        days = regime_counts[regime]\n",
    "        print(f\"   {regime:10s}: {days:5d} days ({pct:5.1f}%)\")\n",
    "    \n",
    "    # Add additional metrics\n",
    "    regimes['drawdown'] = drawdown\n",
    "    regimes['rolling_vol'] = rolling_vol\n",
    "    regimes['cumulative_return'] = cumulative\n",
    "    \n",
    "    return regimes\n",
    "\n",
    "# Execute regime identification\n",
    "market_regimes = identify_market_regimes(benchmark_returns_aligned)\n",
    "\n",
    "# Validate regime signals for risk overlay implementation\n",
    "bear_stress_days = (market_regimes['regime'].isin(['Bear', 'Stress'])).sum()\n",
    "total_days = len(market_regimes)\n",
    "risk_coverage = bear_stress_days / total_days\n",
    "\n",
    "print(f\"\\nüéØ Risk Overlay Coverage Analysis:\")\n",
    "print(f\"   Bear + Stress periods: {bear_stress_days:,} days ({risk_coverage:.1%})\")\n",
    "print(f\"   Risk reduction opportunities: {risk_coverage:.1%} of trading days\")\n",
    "\n",
    "if risk_coverage > 0.35:\n",
    "    print(\"   ‚úÖ GOOD COVERAGE: Sufficient Bear/Stress periods for risk overlay testing\")\n",
    "elif risk_coverage > 0.20:\n",
    "    print(\"   ‚ö†Ô∏è MODERATE COVERAGE: Limited but adequate risk periods\")\n",
    "else:\n",
    "    print(\"   ‚ùå LOW COVERAGE: May not provide sufficient risk reduction opportunities\")\n",
    "\n",
    "print(f\"\\n‚úÖ Market regime framework ready for Phase 8 implementation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Quarterly Baseline Implementation (Control Group)\n",
    "\n",
    "Establish the quarterly rebalancing baseline that will serve as our control group for comparing risk overlay mechanisms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Implementing Quarterly Baseline (Control Group)...\n",
      "\n",
      "--- QUARTERLY BASELINE CONFIGURATION ---\n",
      "backtest_start_date      : 2016-01-01\n",
      "backtest_end_date        : 2025-07-25\n",
      "selection_percentile     : 0.2\n",
      "rebalance_freq           : Q\n",
      "long_only                : True\n",
      "max_sector_weight        : 0.4\n",
      "max_position_weight      : 0.05\n",
      "transaction_cost_bps     : 30\n",
      "üöÄ Running Quarterly Baseline Backtest (Control Group)...\n",
      "   - Identified 38 quarterly rebalance dates.\n",
      "   - Constructed quarterly holdings matrix.\n",
      "   - Shifted holdings by 1 day to prevent look-ahead bias.\n",
      "   - Calculated daily gross returns.\n",
      "   - Applied transaction costs to get net returns.\n",
      "‚úÖ Quarterly baseline backtest complete.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 4: QUARTERLY BASELINE IMPLEMENTATION (CONTROL GROUP)\n",
    "# ============================================================================\n",
    "\n",
    "# Enhanced strategy configuration for Phase 8\n",
    "QUARTERLY_BASELINE_CONFIG = {\n",
    "    \"backtest_start_date\": \"2016-01-01\",\n",
    "    \"backtest_end_date\": \"2025-07-25\",\n",
    "    \"selection_percentile\": 0.20,\n",
    "    \"rebalance_freq\": 'Q',  # QUARTERLY - Phase 8 baseline\n",
    "    \"long_only\": True,\n",
    "    \"max_sector_weight\": 0.40,\n",
    "    \"max_position_weight\": 0.05,\n",
    "    \"transaction_cost_bps\": 30\n",
    "}\n",
    "\n",
    "print(\"üöÄ Implementing Quarterly Baseline (Control Group)...\")\n",
    "print(\"\\n--- QUARTERLY BASELINE CONFIGURATION ---\")\n",
    "for key, value in QUARTERLY_BASELINE_CONFIG.items():\n",
    "    print(f\"{key:<25}: {value}\")\n",
    "\n",
    "# Load constrained portfolio construction and backtesting engine from Phase 7\n",
    "def construct_constrained_portfolio(\n",
    "    factor_scores: pd.Series, \n",
    "    sector_info: pd.DataFrame, \n",
    "    config: dict\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Constructs a single, constrained portfolio for a given rebalance date.\n",
    "    (Validated in Phase 7 - maintaining same logic)\n",
    "    \"\"\"\n",
    "    if factor_scores.empty:\n",
    "        return pd.DataFrame(columns=['weight', 'sector'])\n",
    "\n",
    "    # Select top quintile of stocks\n",
    "    top_quintile_cutoff = factor_scores.quantile(1 - config['selection_percentile'])\n",
    "    selected_stocks_df = factor_scores[factor_scores >= top_quintile_cutoff].to_frame('factor_score')\n",
    "    \n",
    "    # Merge with sector information\n",
    "    portfolio_df = selected_stocks_df.join(sector_info)\n",
    "    \n",
    "    # Handle potential missing sectors after join\n",
    "    if portfolio_df['sector'].isnull().any():\n",
    "        portfolio_df.dropna(subset=['sector'], inplace=True)\n",
    "\n",
    "    if portfolio_df.empty:\n",
    "        return pd.DataFrame(columns=['weight', 'sector'])\n",
    "\n",
    "    # Apply sector constraints\n",
    "    sector_counts = portfolio_df['sector'].value_counts()\n",
    "    max_stocks_in_portfolio = len(portfolio_df)\n",
    "    max_stocks_per_sector = int(max_stocks_in_portfolio * config['max_sector_weight'])\n",
    "    \n",
    "    final_tickers = set()\n",
    "    for sector, count in sector_counts.items():\n",
    "        sector_stocks = portfolio_df[portfolio_df['sector'] == sector]\n",
    "        if count > max_stocks_per_sector and max_stocks_per_sector > 0:\n",
    "            top_in_sector = sector_stocks.nlargest(max_stocks_per_sector, 'factor_score').index\n",
    "            final_tickers.update(top_in_sector)\n",
    "        else:\n",
    "            final_tickers.update(sector_stocks.index)\n",
    "            \n",
    "    final_portfolio = portfolio_df.loc[list(final_tickers)].copy()\n",
    "    \n",
    "    # Assign equal weights\n",
    "    num_stocks = len(final_portfolio)\n",
    "    if num_stocks > 0:\n",
    "        final_portfolio['weight'] = 1.0 / num_stocks\n",
    "    else:\n",
    "        return pd.DataFrame(columns=['weight', 'sector'])\n",
    "        \n",
    "    return final_portfolio[['weight', 'sector']]\n",
    "\n",
    "\n",
    "def run_quarterly_baseline_backtest(\n",
    "    qvm_scores: pd.DataFrame,\n",
    "    daily_returns: pd.DataFrame,\n",
    "    sector_info: pd.DataFrame,\n",
    "    config: dict\n",
    ") -> Tuple[pd.Series, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Runs the quarterly baseline backtest (Control Group for Phase 8).\n",
    "    \"\"\"\n",
    "    print(\"üöÄ Running Quarterly Baseline Backtest (Control Group)...\")\n",
    "    \n",
    "    # 1. IDENTIFY QUARTERLY REBALANCE DATES\n",
    "    ideal_rebalance_dates = pd.date_range(\n",
    "        start=qvm_scores.index.min(), \n",
    "        end=qvm_scores.index.max(), \n",
    "        freq=config['rebalance_freq']\n",
    "    )\n",
    "    print(f\"   - Identified {len(ideal_rebalance_dates)} quarterly rebalance dates.\")\n",
    "\n",
    "    # 2. Construct Daily Holdings Matrix\n",
    "    daily_holdings = pd.DataFrame(index=daily_returns.index, columns=daily_returns.columns).fillna(0.0)\n",
    "    \n",
    "    factor_scores_on_rebal_dates = qvm_scores.reindex(ideal_rebalance_dates, method='ffill')\n",
    "\n",
    "    for i in range(len(factor_scores_on_rebal_dates.index)):\n",
    "        rebal_date = factor_scores_on_rebal_dates.index[i]\n",
    "        \n",
    "        try:\n",
    "            next_rebal_date = factor_scores_on_rebal_dates.index[i+1]\n",
    "        except IndexError:\n",
    "            next_rebal_date = daily_returns.index[-1] + pd.Timedelta(days=1)\n",
    "\n",
    "        factor_scores_at_rebal = factor_scores_on_rebal_dates.loc[rebal_date].dropna()\n",
    "        \n",
    "        if len(factor_scores_at_rebal) > 20:\n",
    "            portfolio_df = construct_constrained_portfolio(factor_scores_at_rebal, sector_info, config)\n",
    "            \n",
    "            if not portfolio_df.empty:\n",
    "                # Define the holding period for this portfolio\n",
    "                relevant_days = daily_returns.index[(daily_returns.index > rebal_date) & (daily_returns.index < next_rebal_date)]\n",
    "                \n",
    "                if not relevant_days.empty:\n",
    "                    # Assign the weight Series to each relevant day\n",
    "                    for day in relevant_days:\n",
    "                        valid_tickers = portfolio_df.index.intersection(daily_holdings.columns)\n",
    "                        daily_holdings.loc[day, valid_tickers] = portfolio_df.loc[valid_tickers, 'weight']\n",
    "\n",
    "    print(\"   - Constructed quarterly holdings matrix.\")\n",
    "\n",
    "    # 3. PREVENT LOOK-AHEAD BIAS\n",
    "    daily_holdings_shifted = daily_holdings.shift(1).fillna(0)\n",
    "    print(\"   - Shifted holdings by 1 day to prevent look-ahead bias.\")\n",
    "\n",
    "    # 4. CALCULATE GROSS PORTFOLIO RETURNS\n",
    "    gross_returns = (daily_holdings_shifted * daily_returns).sum(axis=1)\n",
    "    print(\"   - Calculated daily gross returns.\")\n",
    "\n",
    "    # 5. MODEL TRANSACTION COSTS\n",
    "    turnover = (daily_holdings_shifted - daily_holdings_shifted.shift(1)).abs().sum(axis=1) / 2\n",
    "    transaction_costs = turnover * (config['transaction_cost_bps'] / 10000)\n",
    "    \n",
    "    net_returns = gross_returns - transaction_costs\n",
    "    print(\"   - Applied transaction costs to get net returns.\")\n",
    "    \n",
    "    backtest_log = pd.DataFrame({\n",
    "        'gross_return': gross_returns,\n",
    "        'net_return': net_returns,\n",
    "        'turnover': turnover,\n",
    "        'transaction_cost': transaction_costs,\n",
    "        'positions': (daily_holdings_shifted > 0).sum(axis=1)\n",
    "    })\n",
    "\n",
    "    print(\"‚úÖ Quarterly baseline backtest complete.\")\n",
    "    return net_returns, backtest_log, daily_holdings_shifted\n",
    "\n",
    "# Execute quarterly baseline backtest\n",
    "quarterly_returns, quarterly_log, quarterly_holdings = run_quarterly_baseline_backtest(\n",
    "    qvm_scores=qvm_scores,\n",
    "    daily_returns=daily_returns_aligned,\n",
    "    sector_info=sector_info,\n",
    "    config=QUARTERLY_BASELINE_CONFIG\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üìä QUARTERLY BASELINE PERFORMANCE VALIDATION (CONTROL GROUP)\n",
      "======================================================================\n",
      "Annual Return (%)        :    18.70\n",
      "Annual Volatility (%)    :    13.32\n",
      "Sharpe Ratio             :     1.40\n",
      "Max Drawdown (%)         :   -49.22\n",
      "Calmar Ratio             :     0.38\n",
      "Sortino Ratio            :     1.45\n",
      "Win Rate (%)             :    59.01\n",
      "Total Days               :  2381.00\n",
      "Information Ratio        :     0.54\n",
      "Tracking Error (%)       :    11.48\n",
      "\n",
      "üéØ Phase 8 Target Validation:\n",
      "   Sharpe Ratio Target (>1.2):  ‚úÖ PASS (1.40)\n",
      "   Drawdown Concern (<-25%):     ‚ö†Ô∏è YES (-49.2%)\n",
      "\n",
      "‚ö†Ô∏è RISK MANAGEMENT REQUIRED: Quarterly baseline exceeds -25% drawdown target\n",
      "   Risk overlays are essential for institutional deployment\n",
      "\n",
      "üìà Baseline Calmar Ratio: 0.38\n",
      "   Target: Maximize Calmar while maintaining Sharpe >1.2\n",
      "\n",
      "‚úÖ Quarterly baseline established as Control Group for Phase 8 risk overlay testing\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# QUARTERLY BASELINE PERFORMANCE VALIDATION\n",
    "# ============================================================================\n",
    "\n",
    "def calculate_performance_metrics(returns: pd.Series, \n",
    "                                  benchmark: pd.Series = None,\n",
    "                                  risk_free_rate: float = 0.0) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculate comprehensive performance metrics for Phase 8 analysis.\n",
    "    \"\"\"\n",
    "    # Basic metrics\n",
    "    total_return = (1 + returns).prod() - 1\n",
    "    n_years = len(returns) / 252\n",
    "    annual_return = (1 + total_return) ** (1 / n_years) - 1 if n_years > 0 else 0\n",
    "    annual_vol = returns.std() * np.sqrt(252)\n",
    "    sharpe_ratio = (annual_return - risk_free_rate) / annual_vol if annual_vol > 0 else 0\n",
    "    \n",
    "    # Drawdown analysis\n",
    "    cumulative = (1 + returns).cumprod()\n",
    "    drawdown = (cumulative / cumulative.cummax() - 1)\n",
    "    max_drawdown = drawdown.min()\n",
    "    \n",
    "    # Calmar Ratio (key metric for Phase 8)\n",
    "    calmar_ratio = annual_return / abs(max_drawdown) if max_drawdown < 0 else 0\n",
    "    \n",
    "    # Downside metrics\n",
    "    downside_returns = returns[returns < 0]\n",
    "    downside_vol = downside_returns.std() * np.sqrt(252) if len(downside_returns) > 0 else 0\n",
    "    sortino_ratio = (annual_return - risk_free_rate) / downside_vol if downside_vol > 0 else 0\n",
    "    \n",
    "    # Win rates\n",
    "    win_rate = (returns > 0).mean()\n",
    "    \n",
    "    metrics = {\n",
    "        'Annual Return (%)': annual_return * 100,\n",
    "        'Annual Volatility (%)': annual_vol * 100,\n",
    "        'Sharpe Ratio': sharpe_ratio,\n",
    "        'Max Drawdown (%)': max_drawdown * 100,\n",
    "        'Calmar Ratio': calmar_ratio,\n",
    "        'Sortino Ratio': sortino_ratio,\n",
    "        'Win Rate (%)': win_rate * 100,\n",
    "        'Total Days': len(returns)\n",
    "    }\n",
    "    \n",
    "    # Add benchmark comparison if provided\n",
    "    if benchmark is not None:\n",
    "        common_idx = returns.index.intersection(benchmark.index)\n",
    "        excess_returns = returns.loc[common_idx] - benchmark.loc[common_idx]\n",
    "        tracking_error = excess_returns.std() * np.sqrt(252)\n",
    "        information_ratio = (excess_returns.mean() * 252) / tracking_error if tracking_error > 0 else 0\n",
    "        \n",
    "        metrics['Information Ratio'] = information_ratio\n",
    "        metrics['Tracking Error (%)'] = tracking_error * 100\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Calculate quarterly baseline performance\n",
    "quarterly_metrics = calculate_performance_metrics(quarterly_returns, benchmark_returns_aligned)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìä QUARTERLY BASELINE PERFORMANCE VALIDATION (CONTROL GROUP)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for metric, value in quarterly_metrics.items():\n",
    "    if 'Ratio' in metric or 'Rate' in metric:\n",
    "        print(f\"{metric:<25}: {value:8.2f}\")\n",
    "    else:\n",
    "        print(f\"{metric:<25}: {value:8.2f}\")\n",
    "\n",
    "# Validate against Phase 8 targets\n",
    "print(\"\\nüéØ Phase 8 Target Validation:\")\n",
    "sharpe_target = quarterly_metrics['Sharpe Ratio'] >= 1.2\n",
    "drawdown_concern = quarterly_metrics['Max Drawdown (%)'] < -25\n",
    "\n",
    "print(f\"   Sharpe Ratio Target (>1.2):  {'‚úÖ PASS' if sharpe_target else '‚ùå FAIL'} ({quarterly_metrics['Sharpe Ratio']:.2f})\")\n",
    "print(f\"   Drawdown Concern (<-25%):     {'‚ö†Ô∏è YES' if drawdown_concern else '‚úÖ NO'} ({quarterly_metrics['Max Drawdown (%)']:.1f}%)\")\n",
    "\n",
    "if drawdown_concern:\n",
    "    print(\"\\n‚ö†Ô∏è RISK MANAGEMENT REQUIRED: Quarterly baseline exceeds -25% drawdown target\")\n",
    "    print(\"   Risk overlays are essential for institutional deployment\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ BASELINE ACCEPTABLE: Quarterly baseline meets drawdown requirements\")\n",
    "    print(\"   Risk overlays will focus on further optimization\")\n",
    "\n",
    "# Calculate improvement needed\n",
    "current_calmar = quarterly_metrics['Calmar Ratio']\n",
    "print(f\"\\nüìà Baseline Calmar Ratio: {current_calmar:.2f}\")\n",
    "print(f\"   Target: Maximize Calmar while maintaining Sharpe >1.2\")\n",
    "\n",
    "print(\"\\n‚úÖ Quarterly baseline established as Control Group for Phase 8 risk overlay testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üéØ IMPLEMENTING TEST A: MARKET REGIME OVERLAY\n",
      "======================================================================\n",
      "üîß Implementing Market Regime Overlay (Test A)...\n",
      "    Risk reduction factor: 0.5 (50% exposure during Bear/Stress)\n",
      "    Bear/Stress periods identified: 1,042 days (43.8%)\n",
      "    Applied 0.5 exposure multiplier to 1,042 trading days\n",
      "    Average exposure during normal periods: 94.5%\n",
      "    Average exposure during Bear/Stress: 49.6%\n",
      "üöÄ Running Market Regime Overlay backtest...\n",
      "‚úÖ Market Regime Overlay backtest complete.\n",
      "\n",
      "üìä MARKET REGIME OVERLAY PERFORMANCE (TEST A):\n",
      "==================================================\n",
      "Annual Return (%)        :    12.83\n",
      "Annual Volatility (%)    :    10.30\n",
      "Sharpe Ratio             :     1.25\n",
      "Max Drawdown (%)         :   -39.58\n",
      "Calmar Ratio             :     0.32\n",
      "Sortino Ratio            :     1.22\n",
      "Win Rate (%)             :    59.01\n",
      "Total Days               :  2381.00\n",
      "Information Ratio        :     0.06\n",
      "Tracking Error (%)       :    13.09\n",
      "\n",
      "üîç TEST A vs BASELINE COMPARISON:\n",
      "========================================\n",
      "Metric                    Baseline   Test A     Change    \n",
      "-------------------------------------------------------\n",
      "Annual Return (%)            18.70       12.83       -5.87\n",
      "Sharpe Ratio                  1.40        1.25       -0.16\n",
      "Max Drawdown (%)            -49.22      -39.58       +9.65\n",
      "Calmar Ratio                  0.38        0.32       -0.06\n",
      "\n",
      "üéØ TEST A RISK ASSESSMENT:\n",
      "==============================\n",
      "Sharpe Preservation (>1.2):      ‚úÖ PASS (1.25)\n",
      "Drawdown Improvement:            ‚úÖ YES (-39.6% vs -49.2%)\n",
      "Calmar Improvement:              ‚ùå NO (0.32 vs 0.38)\n",
      "Target Achieved (<-25%):         ‚ùå NO (-39.6%)\n",
      "\n",
      "‚úÖ TEST A PROGRESS: Significant improvement, may need fine-tuning\n",
      "\n",
      "‚úÖ Market Regime Overlay (Test A) analysis complete\n"
     ]
    }
   ],
   "source": [
    "# =================================================================\n",
    "# CELL 5: MARKET REGIME OVERLAY IMPLEMENTATION (TEST A)\n",
    "# =================================================================\n",
    "\n",
    "def apply_market_regime_overlay(\n",
    "    baseline_holdings: pd.DataFrame,\n",
    "    market_regimes: pd.DataFrame,\n",
    "    risk_reduction_factor: float = 0.5\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Apply market regime overlay by reducing exposure during Bear/Stress periods.\n",
    "    \n",
    "    Parameters:\n",
    "    - baseline_holdings: Daily portfolio weights from quarterly baseline\n",
    "    - market_regimes: Regime classification from Phase 7 framework\n",
    "    - risk_reduction_factor: Multiplier for Bear/Stress periods (0.5 = 50% exposure)\n",
    "    \n",
    "    Returns:\n",
    "    - risk_managed_holdings: Adjusted portfolio weights with regime overlay\n",
    "    \"\"\"\n",
    "    print(f\"üîß Implementing Market Regime Overlay (Test A)...\")\n",
    "    print(f\"    Risk reduction factor: {risk_reduction_factor} (50% exposure during Bear/Stress)\")\n",
    "\n",
    "    # Create a copy of baseline holdings\n",
    "    risk_managed_holdings = baseline_holdings.copy()\n",
    "\n",
    "    # Identify Bear and Stress periods\n",
    "    bear_stress_mask = market_regimes['regime'].isin(['Bear', 'Stress'])\n",
    "    bear_stress_dates = market_regimes[bear_stress_mask].index\n",
    "\n",
    "    print(f\"    Bear/Stress periods identified: {len(bear_stress_dates):,} days ({len(bear_stress_dates)/len(market_regimes):.1%})\")\n",
    "\n",
    "    # Apply risk reduction to Bear/Stress periods\n",
    "    common_dates = baseline_holdings.index.intersection(bear_stress_dates)\n",
    "    if len(common_dates) > 0:\n",
    "        risk_managed_holdings.loc[common_dates] *= risk_reduction_factor\n",
    "        print(f\"    Applied {risk_reduction_factor} exposure multiplier to {len(common_dates):,} trading days\")\n",
    "\n",
    "    # Calculate portfolio statistics\n",
    "    normal_exposure = baseline_holdings[~baseline_holdings.index.isin(bear_stress_dates)].sum(axis=1).mean()\n",
    "    reduced_exposure = risk_managed_holdings[risk_managed_holdings.index.isin(bear_stress_dates)].sum(axis=1).mean()\n",
    "\n",
    "    print(f\"    Average exposure during normal periods: {normal_exposure:.1%}\")\n",
    "    print(f\"    Average exposure during Bear/Stress: {reduced_exposure:.1%}\")\n",
    "\n",
    "    return risk_managed_holdings\n",
    "\n",
    "\n",
    "def run_regime_overlay_backtest(\n",
    "    regime_holdings: pd.DataFrame,\n",
    "    daily_returns: pd.DataFrame,\n",
    "    config: dict,\n",
    "    overlay_name: str = \"Regime Overlay\"\n",
    ") -> Tuple[pd.Series, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Run backtest with regime-adjusted holdings.\n",
    "    \"\"\"\n",
    "    print(f\"üöÄ Running {overlay_name} backtest...\")\n",
    "\n",
    "    # Ensure no look-ahead bias (holdings should already be shifted)\n",
    "    # But apply one more shift to be absolutely certain\n",
    "    regime_holdings_shifted = regime_holdings.shift(1).fillna(0)\n",
    "\n",
    "    # Calculate gross returns\n",
    "    gross_returns = (regime_holdings_shifted * daily_returns).sum(axis=1)\n",
    "\n",
    "    # Calculate turnover for transaction costs\n",
    "    turnover = (regime_holdings_shifted - regime_holdings_shifted.shift(1)).abs().sum(axis=1) / 2\n",
    "    transaction_costs = turnover * (config['transaction_cost_bps'] / 10000)\n",
    "\n",
    "    # Net returns\n",
    "    net_returns = gross_returns - transaction_costs\n",
    "\n",
    "    # Backtest log\n",
    "    backtest_log = pd.DataFrame({\n",
    "        'gross_return': gross_returns,\n",
    "        'net_return': net_returns,\n",
    "        'turnover': turnover,\n",
    "        'transaction_cost': transaction_costs,\n",
    "        'positions': (regime_holdings_shifted > 0).sum(axis=1),\n",
    "        'total_exposure': regime_holdings_shifted.sum(axis=1)\n",
    "    })\n",
    "\n",
    "    print(f\"‚úÖ {overlay_name} backtest complete.\")\n",
    "    return net_returns, backtest_log\n",
    "\n",
    "\n",
    "# Execute Market Regime Overlay (Test A)\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéØ IMPLEMENTING TEST A: MARKET REGIME OVERLAY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Apply regime overlay to quarterly baseline holdings\n",
    "regime_overlay_holdings = apply_market_regime_overlay(\n",
    "    baseline_holdings=quarterly_holdings,\n",
    "    market_regimes=market_regimes,\n",
    "    risk_reduction_factor=0.5  # 50% exposure during Bear/Stress\n",
    ")\n",
    "\n",
    "# Run backtest with regime overlay\n",
    "regime_overlay_returns, regime_overlay_log = run_regime_overlay_backtest(\n",
    "    regime_holdings=regime_overlay_holdings,\n",
    "    daily_returns=daily_returns_aligned,\n",
    "    config=QUARTERLY_BASELINE_CONFIG,\n",
    "    overlay_name=\"Market Regime Overlay\"\n",
    ")\n",
    "\n",
    "# Calculate performance metrics for Test A\n",
    "regime_overlay_metrics = calculate_performance_metrics(regime_overlay_returns, benchmark_returns_aligned)\n",
    "\n",
    "print(\"\\nüìä MARKET REGIME OVERLAY PERFORMANCE (TEST A):\")\n",
    "print(\"=\" * 50)\n",
    "for metric, value in regime_overlay_metrics.items():\n",
    "    if 'Ratio' in metric or 'Rate' in metric:\n",
    "        print(f\"{metric:<25}: {value:8.2f}\")\n",
    "    else:\n",
    "        print(f\"{metric:<25}: {value:8.2f}\")\n",
    "\n",
    "# Compare against baseline\n",
    "print(\"\\nüîç TEST A vs BASELINE COMPARISON:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"{'Metric':<25} {'Baseline':<10} {'Test A':<10} {'Change':<10}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "key_metrics = ['Annual Return (%)', 'Sharpe Ratio', 'Max Drawdown (%)', 'Calmar Ratio']\n",
    "for metric in key_metrics:\n",
    "    baseline_val = quarterly_metrics[metric]\n",
    "    overlay_val = regime_overlay_metrics[metric]\n",
    "    change = overlay_val - baseline_val\n",
    "    change_str = f\"{change:+.2f}\"\n",
    "    print(f\"{metric:<25} {baseline_val:8.2f}    {overlay_val:8.2f}    {change_str:>8s}\")\n",
    "\n",
    "# Risk assessment for Test A\n",
    "print(\"\\nüéØ TEST A RISK ASSESSMENT:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "sharpe_preserved = regime_overlay_metrics['Sharpe Ratio'] >= 1.2\n",
    "drawdown_improved = regime_overlay_metrics['Max Drawdown (%)'] > quarterly_metrics['Max Drawdown (%)']\n",
    "calmar_improved = regime_overlay_metrics['Calmar Ratio'] > quarterly_metrics['Calmar Ratio']\n",
    "target_achieved = regime_overlay_metrics['Max Drawdown (%)'] > -25.0\n",
    "\n",
    "print(f\"Sharpe Preservation (>1.2):      {'‚úÖ PASS' if sharpe_preserved else '‚ùå FAIL'} ({regime_overlay_metrics['Sharpe Ratio']:.2f})\")\n",
    "print(f\"Drawdown Improvement:            {'‚úÖ YES' if drawdown_improved else '‚ùå NO'} ({regime_overlay_metrics['Max Drawdown (%)']:.1f}% vs {quarterly_metrics['Max Drawdown (%)']:.1f}%)\")\n",
    "print(f\"Calmar Improvement:              {'‚úÖ YES' if calmar_improved else '‚ùå NO'} ({regime_overlay_metrics['Calmar Ratio']:.2f} vs {quarterly_metrics['Calmar Ratio']:.2f})\")\n",
    "print(f\"Target Achieved (<-25%):         {'‚úÖ YES' if target_achieved else '‚ùå NO'} ({regime_overlay_metrics['Max Drawdown (%)']:.1f}%)\")\n",
    "\n",
    "if target_achieved and sharpe_preserved:\n",
    "    print(\"\\nüéâ TEST A SUCCESS: Market Regime Overlay achieves institutional targets!\")\n",
    "elif drawdown_improved and sharpe_preserved:\n",
    "    print(\"\\n‚úÖ TEST A PROGRESS: Significant improvement, may need fine-tuning\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è TEST A MIXED: Review trade-offs between risk reduction and alpha preservation\")\n",
    "\n",
    "print(\"\\n‚úÖ Market Regime Overlay (Test A) analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXECUTIVE SUMMARY: Test A (Market Regime Overlay) shows mixed \n",
    "  results - significant drawdown improvement (+9.6%) but still\n",
    "  exceeds institutional target. Sharpe ratio preserved (1.25 > 1.2)\n",
    "  but Calmar ratio deteriorated due to return sacrifice. Need Test B\n",
    "  and C to find optimal mechanism.\n",
    "\n",
    "  DETAILED ANALYSIS:\n",
    "\n",
    "  Test A Results Assessment:\n",
    "\n",
    "  ‚úÖ Positive Outcomes:\n",
    "  - Drawdown Reduction: -39.6% vs -49.2% baseline (+9.6% improvement)\n",
    "  - Sharpe Preservation: 1.25 > 1.2 institutional requirement ‚úÖ\n",
    "  - Volatility Control: 10.30% vs 13.32% baseline (significant risk\n",
    "  reduction)\n",
    "  - Operational Success: Applied 50% exposure reduction to 43.8% of\n",
    "  trading days\n",
    "\n",
    "  ‚ö†Ô∏è Areas of Concern:\n",
    "  - Target Miss: -39.6% still exceeds -25% institutional target by\n",
    "  14.6%\n",
    "  - Return Sacrifice: 12.83% vs 18.70% baseline (-5.87% annual return\n",
    "   loss)\n",
    "  - Calmar Deterioration: 0.32 vs 0.38 baseline (net risk-adjusted\n",
    "  performance decline)\n",
    "\n",
    "  üìä Key Insights:\n",
    "  - Risk Coverage: 43.8% Bear/Stress periods provide substantial\n",
    "  intervention opportunities\n",
    "  - Mechanism Effectiveness: 50% exposure reduction during risk\n",
    "  periods works but may be too conservative\n",
    "  - Trade-off Balance: Substantial risk reduction comes at\n",
    "  significant return cost\n",
    "\n",
    "  IMPLEMENTATION NOTES:\n",
    "\n",
    "  Test A validates the regime overlay approach but suggests\n",
    "  calibration needs:\n",
    "  1. Fine-tuning Opportunity: 50% reduction may be excessive - could\n",
    "  test 60-70% exposure\n",
    "  2. Institutional Gap: 14.6% gap to -25% target requires additional\n",
    "  risk management\n",
    "  3. Return Preservation: Need mechanism that maintains more alpha\n",
    "  while reducing risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üéØ IMPLEMENTING TEST B: VOLATILITY TARGETING OVERLAY\n",
      "======================================================================\n",
      "üîß Implementing Volatility Targeting Overlay (Test B)...\n",
      "    Target volatility: 15.0%\n",
      "    Volatility window: 60 days\n",
      "    Exposure range: 20.0% to 100.0%\n",
      "    Average volatility scaling: 0.94\n",
      "    Scaling volatility: 0.12\n",
      "    High volatility days (>80% reduction): 341\n",
      "    Low volatility days (>100% exposure): 0\n",
      "üöÄ Running Volatility Targeting Overlay backtest...\n",
      "‚úÖ Volatility Targeting Overlay backtest complete.\n",
      "\n",
      "üìä VOLATILITY TARGETING OVERLAY PERFORMANCE (TEST B):\n",
      "==================================================\n",
      "Annual Return (%)        :    17.62\n",
      "Annual Volatility (%)    :    11.84\n",
      "Sharpe Ratio             :     1.49\n",
      "Max Drawdown (%)         :   -41.71\n",
      "Calmar Ratio             :     0.42\n",
      "Sortino Ratio            :     1.54\n",
      "Win Rate (%)             :    59.18\n",
      "Total Days               :  2381.00\n",
      "Information Ratio        :     0.44\n",
      "Tracking Error (%)       :    11.58\n",
      "\n",
      "üîç TEST B vs BASELINE COMPARISON:\n",
      "========================================\n",
      "Metric                    Baseline   Test B     Change    \n",
      "-------------------------------------------------------\n",
      "Annual Return (%)            18.70       17.62       -1.08\n",
      "Sharpe Ratio                  1.40        1.49       +0.08\n",
      "Max Drawdown (%)            -49.22      -41.71       +7.51\n",
      "Calmar Ratio                  0.38        0.42       +0.04\n",
      "\n",
      "üéØ TEST B RISK ASSESSMENT:\n",
      "==============================\n",
      "Sharpe Preservation (>1.2):      ‚úÖ PASS (1.49)\n",
      "Drawdown Improvement:            ‚úÖ YES (-41.7% vs -49.2%)\n",
      "Calmar Improvement:              ‚úÖ YES (0.42 vs 0.38)\n",
      "Target Achieved (<-25%):         ‚ùå NO (-41.7%)\n",
      "\n",
      "‚úÖ TEST B PROGRESS: Significant improvement, may need fine-tuning\n",
      "\n",
      "‚úÖ Volatility Targeting Overlay (Test B) analysis complete\n"
     ]
    }
   ],
   "source": [
    "# =================================================================\n",
    "# CELL 6: VOLATILITY TARGETING OVERLAY IMPLEMENTATION (TEST B)\n",
    "# =================================================================\n",
    "\n",
    "def calculate_portfolio_volatility(\n",
    "    portfolio_returns: pd.Series,\n",
    "    window: int = 60\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Calculate rolling portfolio volatility (annualized).\n",
    "    \"\"\"\n",
    "    rolling_vol = portfolio_returns.rolling(window).std() * np.sqrt(252)\n",
    "    return rolling_vol\n",
    "\n",
    "\n",
    "def apply_volatility_targeting_overlay(\n",
    "    baseline_holdings: pd.DataFrame,\n",
    "    baseline_returns: pd.Series,\n",
    "    target_volatility: float = 0.15,\n",
    "    vol_window: int = 60,\n",
    "    max_leverage: float = 1.0,\n",
    "    min_exposure: float = 0.2\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Apply volatility targeting overlay by scaling exposure based on realized volatility.\n",
    "    \n",
    "    Parameters:\n",
    "    - baseline_holdings: Daily portfolio weights from quarterly baseline\n",
    "    - baseline_returns: Portfolio returns to calculate volatility\n",
    "    - target_volatility: Target portfolio volatility (15%)\n",
    "    - vol_window: Rolling window for volatility calculation (60 days)\n",
    "    - max_leverage: Maximum exposure multiplier (1.0 = no leverage)\n",
    "    - min_exposure: Minimum exposure multiplier (0.2 = 20% minimum)\n",
    "    \n",
    "    Returns:\n",
    "    - vol_targeted_holdings: Adjusted portfolio weights with volatility targeting\n",
    "    \"\"\"\n",
    "    print(f\"üîß Implementing Volatility Targeting Overlay (Test B)...\")\n",
    "    print(f\"    Target volatility: {target_volatility:.1%}\")\n",
    "    print(f\"    Volatility window: {vol_window} days\")\n",
    "    print(f\"    Exposure range: {min_exposure:.1%} to {max_leverage:.1%}\")\n",
    "\n",
    "    # Calculate rolling portfolio volatility\n",
    "    rolling_vol = calculate_portfolio_volatility(baseline_returns, window=vol_window)\n",
    "\n",
    "    # Calculate volatility scaling factor\n",
    "    vol_scaling = target_volatility / rolling_vol\n",
    "\n",
    "    # Apply constraints\n",
    "    vol_scaling = np.clip(vol_scaling, min_exposure, max_leverage)\n",
    "\n",
    "    # Handle NaN values (early periods without enough data)\n",
    "    vol_scaling = vol_scaling.fillna(1.0)\n",
    "\n",
    "    # Apply scaling to holdings\n",
    "    vol_targeted_holdings = baseline_holdings.copy()\n",
    "\n",
    "    for date in vol_targeted_holdings.index:\n",
    "        if date in vol_scaling.index:\n",
    "            scaling_factor = vol_scaling[date]\n",
    "            vol_targeted_holdings.loc[date] *= scaling_factor\n",
    "\n",
    "    # Calculate statistics\n",
    "    avg_scaling = vol_scaling[vol_scaling.notna()].mean()\n",
    "    scaling_std = vol_scaling[vol_scaling.notna()].std()\n",
    "    high_vol_days = (vol_scaling < 0.8).sum()  # Days with >80% reduction\n",
    "    low_vol_days = (vol_scaling > 1.0).sum()    # Days with leverage (if any)\n",
    "\n",
    "    print(f\"    Average volatility scaling: {avg_scaling:.2f}\")\n",
    "    print(f\"    Scaling volatility: {scaling_std:.2f}\")\n",
    "    print(f\"    High volatility days (>80% reduction): {high_vol_days:,}\")\n",
    "    print(f\"    Low volatility days (>100% exposure): {low_vol_days:,}\")\n",
    "\n",
    "    return vol_targeted_holdings, vol_scaling\n",
    "\n",
    "\n",
    "# Execute Volatility Targeting Overlay (Test B)\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéØ IMPLEMENTING TEST B: VOLATILITY TARGETING OVERLAY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Apply volatility targeting to quarterly baseline holdings\n",
    "vol_target_holdings, vol_scaling_factors = apply_volatility_targeting_overlay(\n",
    "    baseline_holdings=quarterly_holdings,\n",
    "    baseline_returns=quarterly_returns,\n",
    "    target_volatility=0.15,  # 15% target volatility\n",
    "    vol_window=60,\n",
    "    max_leverage=1.0,\n",
    "    min_exposure=0.2\n",
    ")\n",
    "\n",
    "# Run backtest with volatility targeting\n",
    "vol_target_returns, vol_target_log = run_regime_overlay_backtest(\n",
    "    regime_holdings=vol_target_holdings,\n",
    "    daily_returns=daily_returns_aligned,\n",
    "    config=QUARTERLY_BASELINE_CONFIG,\n",
    "    overlay_name=\"Volatility Targeting Overlay\"\n",
    ")\n",
    "\n",
    "# Calculate performance metrics for Test B\n",
    "vol_target_metrics = calculate_performance_metrics(vol_target_returns, benchmark_returns_aligned)\n",
    "\n",
    "print(\"\\nüìä VOLATILITY TARGETING OVERLAY PERFORMANCE (TEST B):\")\n",
    "print(\"=\" * 50)\n",
    "for metric, value in vol_target_metrics.items():\n",
    "    if 'Ratio' in metric or 'Rate' in metric:\n",
    "        print(f\"{metric:<25}: {value:8.2f}\")\n",
    "    else:\n",
    "        print(f\"{metric:<25}: {value:8.2f}\")\n",
    "\n",
    "# Compare against baseline\n",
    "print(\"\\nüîç TEST B vs BASELINE COMPARISON:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"{'Metric':<25} {'Baseline':<10} {'Test B':<10} {'Change':<10}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for metric in key_metrics:\n",
    "    baseline_val = quarterly_metrics[metric]\n",
    "    overlay_val = vol_target_metrics[metric]\n",
    "    change = overlay_val - baseline_val\n",
    "    change_str = f\"{change:+.2f}\"\n",
    "    print(f\"{metric:<25} {baseline_val:8.2f}    {overlay_val:8.2f}    {change_str:>8s}\")\n",
    "\n",
    "# Risk assessment for Test B\n",
    "print(\"\\nüéØ TEST B RISK ASSESSMENT:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "sharpe_preserved_b = vol_target_metrics['Sharpe Ratio'] >= 1.2\n",
    "drawdown_improved_b = vol_target_metrics['Max Drawdown (%)'] > quarterly_metrics['Max Drawdown (%)']\n",
    "calmar_improved_b = vol_target_metrics['Calmar Ratio'] > quarterly_metrics['Calmar Ratio']\n",
    "target_achieved_b = vol_target_metrics['Max Drawdown (%)'] > -25.0\n",
    "\n",
    "print(f\"Sharpe Preservation (>1.2):      {'‚úÖ PASS' if sharpe_preserved_b else '‚ùå FAIL'} ({vol_target_metrics['Sharpe Ratio']:.2f})\")\n",
    "print(f\"Drawdown Improvement:            {'‚úÖ YES' if drawdown_improved_b else '‚ùå NO'} ({vol_target_metrics['Max Drawdown (%)']:.1f}% vs {quarterly_metrics['Max Drawdown (%)']:.1f}%)\")\n",
    "print(f\"Calmar Improvement:              {'‚úÖ YES' if calmar_improved_b else '‚ùå NO'} ({vol_target_metrics['Calmar Ratio']:.2f} vs {quarterly_metrics['Calmar Ratio']:.2f})\")\n",
    "print(f\"Target Achieved (<-25%):         {'‚úÖ YES' if target_achieved_b else '‚ùå NO'} ({vol_target_metrics['Max Drawdown (%)']:.1f}%)\")\n",
    "\n",
    "if target_achieved_b and sharpe_preserved_b:\n",
    "    print(\"\\nüéâ TEST B SUCCESS: Volatility Targeting achieves institutional targets!\")\n",
    "elif drawdown_improved_b and sharpe_preserved_b:\n",
    "    print(\"\\n‚úÖ TEST B PROGRESS: Significant improvement, may need fine-tuning\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è TEST B MIXED: Review trade-offs between volatility control and alpha preservation\")\n",
    "\n",
    "print(\"\\n‚úÖ Volatility Targeting Overlay (Test B) analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXECUTIVE SUMMARY: Test B (Volatility Targeting) delivers superior \n",
    "  performance - best Calmar ratio (0.42), improved Sharpe (1.49),\n",
    "  minimal return sacrifice (-1.08%), and +7.5% drawdown improvement.\n",
    "  Currently the leading risk management mechanism, though still 16.7%\n",
    "   from institutional target.\n",
    "\n",
    "  DETAILED ANALYSIS:\n",
    "\n",
    "  Test B Results Assessment:\n",
    "\n",
    "  ‚úÖ Excellent Performance:\n",
    "  - Calmar Ratio Leader: 0.42 vs 0.38 baseline (+0.04 improvement) üèÜ\n",
    "  - Sharpe Enhancement: 1.49 vs 1.40 baseline (+0.08 improvement)\n",
    "  - Return Preservation: 17.62% vs 18.70% baseline (only -1.08%\n",
    "  sacrifice)\n",
    "  - Risk Reduction: -41.7% vs -49.2% baseline (+7.51% improvement)\n",
    "  - Volatility Control: 11.84% vs 13.32% baseline (effective\n",
    "  targeting)\n",
    "\n",
    "  üìä Mechanism Effectiveness:\n",
    "  - Dynamic Scaling: Average 0.94 scaling factor (6% average\n",
    "  reduction)\n",
    "  - Precision Targeting: 341 high-volatility days (14.3%) received\n",
    "  >80% exposure reduction\n",
    "  - Conservative Approach: Zero leverage days (respects 100% maximum\n",
    "  exposure)\n",
    "\n",
    "  ‚ö†Ô∏è Remaining Challenge:\n",
    "  - Institutional Gap: -41.7% vs -25% target (16.7% gap remaining)\n",
    "\n",
    "  üèÜ Test B vs Test A Comparison:\n",
    "\n",
    "  | Metric              | Test A         | Test B         | Winner |\n",
    "  |---------------------|----------------|----------------|--------|\n",
    "  | Return Preservation | 12.83% (-5.87) | 17.62% (-1.08) | Test B |\n",
    "  | Sharpe Ratio        | 1.25           | 1.49           | Test B |\n",
    "  | Max Drawdown        | -39.6%         | -41.7%         | Test A |\n",
    "  | Calmar Ratio        | 0.32           | 0.42           | Test B |\n",
    "\n",
    "  Key Insight: Volatility targeting provides more nuanced risk\n",
    "  management than blunt regime-based exposure cuts.\n",
    "\n",
    "  IMPLEMENTATION NOTES:\n",
    "\n",
    "  Test B validates dynamic volatility targeting as superior to static\n",
    "   regime overlays:\n",
    "  1. Precision Approach: Responds to actual portfolio risk rather\n",
    "  than market regimes\n",
    "  2. Return Efficiency: Minimal alpha sacrifice for substantial risk\n",
    "  reduction\n",
    "  3. Institutional Quality: Best risk-adjusted performance (Calmar\n",
    "  ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vn_factor_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
