{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 04: Deep-Dive Attribution Analysis\n",
    "## Vietnam Factor Investing Platform - Phase 7 Institutional Backtesting Framework\n",
    "\n",
    "**Objective**: Perform comprehensive attribution analysis to understand why the strategy generates alpha, when it works best, and what risks it faces across different market regimes.\n",
    "\n",
    "**Key Questions to Answer**:\n",
    "1. Does our alpha survive market corrections or is it purely bull-market beta?\n",
    "2. Are we inadvertently making concentrated sector bets?\n",
    "3. What happens to portfolio risk when factor correlations spike?\n",
    "4. Do drawdowns cluster around specific market events or factor exposures?\n",
    "\n",
    "**Success Criteria**:\n",
    "- Demonstrate alpha persistence across different market regimes\n",
    "- Identify any hidden concentration risks\n",
    "- Understand factor correlation dynamics and their impact\n",
    "- Create actionable insights for risk management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Visualization environment configured with institutional palette.\n",
      "\n",
      "======================================================================\n",
      "üî¨ Aureus Sigma: Deep-Dive Attribution Analysis\n",
      "   Version: 1.0 - Date: 2025-07-27 07:28:08\n",
      "======================================================================\n",
      "\n",
      "üìä Analysis Framework:\n",
      "   1. Advanced Market Regime Identification\n",
      "   2. Performance Attribution Matrix\n",
      "   3. Sector Concentration Analysis\n",
      "   4. Factor Correlation Dynamics\n",
      "   5. Drawdown Forensics\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Aureus Sigma Capital - Deep-Dive Attribution Analysis\n",
    "# Notebook: 04_deep_dive_attribution_analysis.ipynb\n",
    "#\n",
    "# Description:\n",
    "# This notebook performs institutional-grade attribution analysis on the QVM\n",
    "# strategy, examining performance across market regimes, sector contributions,\n",
    "# factor correlation dynamics, and drawdown characteristics.\n",
    "#\n",
    "# Author: Duc Nguyen, Quantitative Finance Expert\n",
    "# Date: July 26, 2025\n",
    "# Version: 1.0 - Institutional Attribution Framework\n",
    "# ============================================================================\n",
    "\n",
    "# Core imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import warnings\n",
    "from scipy import stats\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import yaml\n",
    "from sqlalchemy import create_engine\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- INSTITUTIONAL PALETTE (from Notebook 03a) ---\n",
    "FACTOR_COLORS = {\n",
    "    'Strategy': '#16A085', 'Benchmark': '#34495E', 'Positive':'#27AE60',\n",
    "    'Negative': '#C0392B', 'Drawdown': '#E67E22', 'Sharpe':'#2980B9',\n",
    "    'Grid': '#BDC3C7', 'Text_Primary': '#2C3E50', 'Neutral':'#7F8C8D',\n",
    "    # Additional colors for attribution analysis\n",
    "    'Bear': '#C0392B', 'Bull': '#27AE60', 'Stress': '#E67E22','Sideways': '#3498DB',\n",
    "    'Correlation': '#9B59B6', 'Sector1': '#E74C3C', 'Sector2':'#3498DB',\n",
    "    'Sector3': '#2ECC71', 'Others': '#95A5A6'\n",
    "}\n",
    "GRADIENT_PALETTES = {'performance': ['#C0392B', '#FFFFFF','#27AE60']}\n",
    "\n",
    "# --- ENHANCED VISUALIZATION CONFIGURATION (from Notebook 03a) ---\n",
    "plt.style.use('default')\n",
    "plt.rcParams.update({\n",
    "    'figure.dpi': 300, 'savefig.dpi': 300, 'figure.figsize':(15, 8),\n",
    "    'figure.facecolor': 'white', 'font.size': 11,\n",
    "    'axes.facecolor': 'white', 'axes.edgecolor': FACTOR_COLORS['Text_Primary'],\n",
    "    'axes.linewidth': 1.0, 'axes.grid': True, 'axes.axisbelow':True,\n",
    "    'axes.labelcolor': FACTOR_COLORS['Text_Primary'],'axes.titlesize': 14,\n",
    "    'axes.titleweight': 'bold', 'axes.titlecolor': FACTOR_COLORS['Text_Primary'],\n",
    "    'grid.color': FACTOR_COLORS['Grid'], 'grid.alpha': 0.3, 'grid.linewidth': 0.5,\n",
    "    'legend.frameon': False, 'legend.fontsize': 10,\n",
    "    'xtick.color': FACTOR_COLORS['Text_Primary'], 'ytick.color': FACTOR_COLORS['Text_Primary'],\n",
    "    'xtick.labelsize': 10, 'ytick.labelsize': 10,\n",
    "    'lines.linewidth': 2.0, 'lines.solid_capstyle': 'round'\n",
    "})\n",
    "\n",
    "print(\"üìä Visualization environment configured with institutional palette.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üî¨ Aureus Sigma: Deep-Dive Attribution Analysis\")\n",
    "print(f\"   Version: 1.0 - Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nüìä Analysis Framework:\")\n",
    "print(\"   1. Advanced Market Regime Identification\")\n",
    "print(\"   2. Performance Attribution Matrix\")\n",
    "print(\"   3. Sector Concentration Analysis\")\n",
    "print(\"   4. Factor Correlation Dynamics\")\n",
    "print(\"   5. Drawdown Forensics\")\n",
    "print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Core Data and Backtest Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Modified Cell 2: Load Core Data and Backtest Results\n",
    "# # Add this section after loading the core pickle files\n",
    "\n",
    "# # Load data from previous notebooks\n",
    "# project_root = Path.cwd()\n",
    "# while not (project_root / 'production').exists() and \\\n",
    "#         not (project_root / 'config').exists():\n",
    "#     if project_root.parent == project_root:\n",
    "#         raise FileNotFoundError(\"Could not find project root\")\n",
    "#     project_root = project_root.parent\n",
    "\n",
    "# data_path = project_root / \"production\" / \"tests\" / \\\n",
    "#     \"phase7_institutional_backtesting\"\n",
    "\n",
    "# print(\"üìÇ Loading core data objects and backtest results...\")\n",
    "\n",
    "# # Load the core data objects\n",
    "# with open(data_path / \"factor_data.pkl\", \"rb\") as f:\n",
    "#     factor_data_obj = pickle.load(f)\n",
    "# with open(data_path / \"daily_returns.pkl\", \"rb\") as f:\n",
    "#     returns_data_obj = pickle.load(f)\n",
    "# with open(data_path / \"benchmark_returns.pkl\", \"rb\") as f:\n",
    "#     benchmark_data_obj = pickle.load(f)\n",
    "\n",
    "# # Extract data\n",
    "# factor_data = factor_data_obj['data']\n",
    "# daily_returns = returns_data_obj['data']\n",
    "# benchmark_returns = benchmark_data_obj['data']\n",
    "\n",
    "# # CRITICAL: Load strategy returns from Notebook 03\n",
    "# # First, check if saved results exist\n",
    "# strategy_results_file = data_path / \\\n",
    "#     \"canonical_backtest_results.pkl\"\n",
    "\n",
    "# if strategy_results_file.exists():\n",
    "#     print(\"‚úÖ Loading saved strategy results from Notebook 03...\")\n",
    "#     with open(strategy_results_file, \"rb\") as f:\n",
    "#         backtest_results = pickle.load(f)\n",
    "\n",
    "#     strategy_returns = backtest_results['net_returns']\n",
    "#     backtest_log = backtest_results['backtest_log']\n",
    "#     portfolio_holdings = \\\n",
    "#         backtest_results.get('portfolio_holdings', None)\n",
    "\n",
    "#     print(f\"    Strategy returns loaded: {len(strategy_returns)} days\")\n",
    "#     print(f\"    Performance: {(strategy_returns.mean() * 252):.2%} annual return\")\n",
    "\n",
    "# else:\n",
    "#     print(\"‚ö†Ô∏è WARNING: No saved strategy results found from Notebook 03!\")\n",
    "#     print(\"    You need to run Notebook 03 first and save the results.\")\n",
    "#     raise FileNotFoundError(\"Cannot proceed without strategy returns from Notebook 03\")\n",
    "\n",
    "# # Also load sector mappings\n",
    "# print(\"\\nüèóÔ∏è Loading sector information...\")\n",
    "# config_path = project_root / 'config' / 'database.yml'\n",
    "# with open(config_path, 'r') as f:\n",
    "#     db_config = yaml.safe_load(f)['production']\n",
    "\n",
    "# engine = create_engine(\n",
    "#     f\"mysql+pymysql://{db_config['username']}:{db_config['password']}@\"\n",
    "#     f\"{db_config['host']}/{db_config['schema_name']}\"\n",
    "# )\n",
    "\n",
    "# sector_info = pd.read_sql(\"SELECT ticker, sector FROM master_info WHERE sector IS NOT NULL\", engine)\n",
    "# sector_info = sector_info.drop_duplicates(subset=['ticker']).set_index('ticker')\n",
    "# engine.dispose()\n",
    "\n",
    "# print(f\"‚úÖ Loaded sector mappings for {len(sector_info)} tickers\")\n",
    "\n",
    "# print(\"\\n‚úÖ All required data loaded successfully\")\n",
    "# print(f\"    Date range: {benchmark_returns.index.min().date()} to {benchmark_returns.index.max().date()}\")\n",
    "# print(f\"    Total days: {len(benchmark_returns):,}\")\n",
    "# print(f\"    Strategy performance: {(strategy_returns.mean() * 252):.2%} annualized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 2: LOAD CORE DATA AND BACKTEST RESULTS (UPDATED)\n",
    "# ============================================================================\n",
    "\n",
    "# Load data from previous notebooks\n",
    "project_root = Path.cwd()\n",
    "while not (project_root / 'production').exists() and not (project_root /\n",
    "                                                           'config').exists():\n",
    "    if project_root.parent == project_root:\n",
    "        raise FileNotFoundError(\"Could not find project root\")\n",
    "    project_root = project_root.parent\n",
    "\n",
    "data_path = project_root / \"production\" / \"tests\" / \\\n",
    "    \"phase7_institutional_backtesting\"\n",
    "\n",
    "print(\"üìÇ Loading core data objects and backtest results...\")\n",
    "\n",
    "# Load the core data objects\n",
    "with open(data_path / \"factor_data.pkl\", \"rb\") as f:\n",
    "    factor_data_obj = pickle.load(f)\n",
    "with open(data_path / \"daily_returns.pkl\", \"rb\") as f:\n",
    "    returns_data_obj = pickle.load(f)\n",
    "with open(data_path / \"benchmark_returns.pkl\", \"rb\") as f:\n",
    "    benchmark_data_obj = pickle.load(f)\n",
    "\n",
    "# Extract data\n",
    "factor_data = factor_data_obj['data']\n",
    "daily_returns = returns_data_obj['data']\n",
    "benchmark_returns = benchmark_data_obj['data']\n",
    "\n",
    "print(\"‚úÖ Core data loaded successfully\")\n",
    "\n",
    "# CRITICAL: Load complete backtest results from Notebook 03\n",
    "strategy_results_file = data_path / \"canonical_backtest_results.pkl\"\n",
    "\n",
    "if strategy_results_file.exists():\n",
    "    print(\"\\n‚úÖ Loading complete backtest results from Notebook 03...\")\n",
    "    with open(strategy_results_file, \"rb\") as f:\n",
    "        backtest_results = pickle.load(f)\n",
    "\n",
    "    # Extract all components\n",
    "    strategy_returns = backtest_results['net_returns']\n",
    "    backtest_log = backtest_results['backtest_log']\n",
    "    daily_holdings = backtest_results.get('daily_holdings', None)\n",
    "    monthly_holdings = backtest_results.get('monthly_holdings', None)\n",
    "\n",
    "    print(f\"    Strategy returns loaded: {len(strategy_returns)} days\")\n",
    "    print(f\"    Performance: {(strategy_returns.mean() * 252):.2%} annual return\")\n",
    "\n",
    "    if daily_holdings is not None:\n",
    "        print(f\"    Daily holdings loaded: {daily_holdings.shape}\")\n",
    "\n",
    "    if monthly_holdings is not None:\n",
    "        print(f\"    Monthly holdings loaded: {len(monthly_holdings)} periods\")\n",
    "    else:\n",
    "        print(\"    ‚ö†Ô∏è Monthly holdings not found - sector analysis will be limited\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è WARNING: No saved strategy results found from Notebook 03!\")\n",
    "    print(\"    You need to run Notebook 03 first and save the results.\")\n",
    "    raise FileNotFoundError(\"Cannot proceed without strategy returns from Notebook 03\")\n",
    "\n",
    "# Also load sector mappings\n",
    "print(\"\\nüèóÔ∏è Loading sector information...\")\n",
    "config_path = project_root / 'config' / 'database.yml'\n",
    "with open(config_path, 'r') as f:\n",
    "    db_config = yaml.safe_load(f)['production']\n",
    "\n",
    "engine = create_engine(\n",
    "    f\"mysql+pymysql://{db_config['username']}:{db_config['password']}@\"\n",
    "    f\"{db_config['host']}/{db_config['schema_name']}\"\n",
    ")\n",
    "\n",
    "sector_info = pd.read_sql(\"SELECT ticker, sector FROM master_info WHERE sector IS NOT NULL\", engine)\n",
    "sector_info = sector_info.drop_duplicates(subset=['ticker']).set_index('ticker')\n",
    "engine.dispose()\n",
    "\n",
    "print(f\"‚úÖ Loaded sector mappings for {len(sector_info)} tickers\")\n",
    "\n",
    "print(\"\\n‚úÖ All required data loaded successfully\")\n",
    "print(f\"    Date range: {benchmark_returns.index.min().date()} to {benchmark_returns.index.max().date()}\")\n",
    "print(f\"    Total days: {len(benchmark_returns):,}\")\n",
    "print(f\"    Strategy performance: {(strategy_returns.mean() * 252):.2%} annualized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Advanced Market Regime Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_market_regimes(benchmark_returns: pd.Series, \n",
    "                          bear_threshold: float = -0.20,\n",
    "                          vol_window: int = 60,\n",
    "                          trend_window: int = 200) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Identifies market regimes using multiple criteria:\n",
    "    - Bear: Drawdown > 20% from peak\n",
    "    - Stress: Rolling volatility in top quartile\n",
    "    - Bull: Price above trend MA and not Bear/Stress\n",
    "    - Sideways: Everything else\n",
    "    \"\"\"\n",
    "    print(\"üîç Identifying market regimes...\")\n",
    "    \n",
    "    # Calculate cumulative returns and drawdowns\n",
    "    cumulative = (1 + benchmark_returns).cumprod()\n",
    "    drawdown = (cumulative / cumulative.cummax() - 1)\n",
    "    \n",
    "    # 1. Bear Market Regime\n",
    "    is_bear = drawdown < bear_threshold\n",
    "    \n",
    "    # 2. High-Stress Regime (rolling volatility)\n",
    "    rolling_vol = benchmark_returns.rolling(vol_window).std() * np.sqrt(252)\n",
    "    vol_75th = rolling_vol.quantile(0.75)\n",
    "    is_stress = rolling_vol > vol_75th\n",
    "    \n",
    "    # 3. Bull/Sideways (trend-based)\n",
    "    trend_ma = cumulative.rolling(trend_window).mean()\n",
    "    is_above_trend = cumulative > trend_ma\n",
    "    \n",
    "    # Combine into regime classification\n",
    "    regimes = pd.DataFrame(index=benchmark_returns.index)\n",
    "    regimes['is_bear'] = is_bear\n",
    "    regimes['is_stress'] = is_stress\n",
    "    regimes['is_bull'] = is_above_trend & ~is_bear & ~is_stress\n",
    "    regimes['is_sideways'] = ~is_above_trend & ~is_bear & ~is_stress\n",
    "    \n",
    "    # Create primary regime classification\n",
    "    regimes['regime'] = 'Undefined'\n",
    "    regimes.loc[regimes['is_bear'], 'regime'] = 'Bear'\n",
    "    regimes.loc[regimes['is_stress'] & ~regimes['is_bear'], 'regime'] = 'Stress'\n",
    "    regimes.loc[regimes['is_bull'], 'regime'] = 'Bull'\n",
    "    regimes.loc[regimes['is_sideways'], 'regime'] = 'Sideways'\n",
    "    \n",
    "    # Summary statistics\n",
    "    regime_counts = regimes['regime'].value_counts()\n",
    "    regime_pcts = (regime_counts / len(regimes)) * 100\n",
    "    \n",
    "    print(\"\\nüìä Regime Distribution:\")\n",
    "    for regime, pct in regime_pcts.items():\n",
    "        days = regime_counts[regime]\n",
    "        print(f\"   {regime:10s}: {days:5d} days ({pct:5.1f}%)\")\n",
    "    \n",
    "    # Add additional metrics\n",
    "    regimes['drawdown'] = drawdown\n",
    "    regimes['rolling_vol'] = rolling_vol\n",
    "    regimes['cumulative_return'] = cumulative\n",
    "    \n",
    "    return regimes\n",
    "\n",
    "# Execute regime identification\n",
    "market_regimes = identify_market_regimes(benchmark_returns)\n",
    "\n",
    "# Visualize regime distribution over time\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, 10), sharex=True)\n",
    "fig.suptitle('Market Regime Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Cumulative returns with regime shading\n",
    "ax1 = axes[0]\n",
    "ax1.plot(market_regimes.index, market_regimes['cumulative_return'], \n",
    "         color='black', linewidth=1.5, label='VN-Index')\n",
    "\n",
    "# Shade different regimes\n",
    "for regime, color in [('Bear', FACTOR_COLORS['Bear']), \n",
    "                     ('Stress', FACTOR_COLORS['Stress']),\n",
    "                     ('Bull', FACTOR_COLORS['Bull']),\n",
    "                     ('Sideways', FACTOR_COLORS['Sideways'])]:\n",
    "    mask = market_regimes['regime'] == regime\n",
    "    ax1.fill_between(market_regimes.index, 0, market_regimes['cumulative_return'].max(),\n",
    "                     where=mask, alpha=0.2, color=color, label=regime)\n",
    "\n",
    "ax1.set_ylabel('Cumulative Return')\n",
    "ax1.legend(loc='upper left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_title('VN-Index Performance by Market Regime')\n",
    "\n",
    "# Plot 2: Drawdown\n",
    "ax2 = axes[1]\n",
    "ax2.fill_between(market_regimes.index, market_regimes['drawdown'] * 100, 0,\n",
    "                color=FACTOR_COLORS['Bear'], alpha=0.5)\n",
    "ax2.axhline(y=-20, color='red', linestyle='--', alpha=0.5, label='Bear Threshold (-20%)')\n",
    "ax2.set_ylabel('Drawdown (%)')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_title('Market Drawdowns')\n",
    "\n",
    "# Plot 3: Rolling volatility\n",
    "ax3 = axes[2]\n",
    "ax3.plot(market_regimes.index, market_regimes['rolling_vol'] * 100, \n",
    "         color=FACTOR_COLORS['Stress'], linewidth=1.5)\n",
    "ax3.axhline(y=market_regimes['rolling_vol'].quantile(0.75) * 100, \n",
    "            color='orange', linestyle='--', alpha=0.5, label='75th Percentile')\n",
    "ax3.set_ylabel('60-Day Volatility (%)')\n",
    "ax3.set_xlabel('Date')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.set_title('Rolling Volatility')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Performance Attribution Matrix\n",
    "\n",
    "### Analysis 1: Does Alpha Survive Market Corrections?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_regime_performance(strategy_returns: pd.Series,\n",
    "                                 benchmark_returns: pd.Series,\n",
    "                                 regimes: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate performance metrics for each market regime.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    # Overall performance\n",
    "    overall_metrics = calculate_performance_metrics(strategy_returns, benchmark_returns)\n",
    "    overall_metrics['Regime'] = 'Overall'\n",
    "    overall_metrics['Days'] = len(strategy_returns)\n",
    "    results.append(overall_metrics)\n",
    "\n",
    "    # Performance by regime\n",
    "    for regime in ['Bear', 'Stress', 'Bull', 'Sideways']:\n",
    "        mask = regimes['regime'] == regime\n",
    "        if mask.sum() > 20:  # Need at least 20 days\n",
    "            regime_strat = strategy_returns[mask]\n",
    "            regime_bench = benchmark_returns[mask]\n",
    "\n",
    "            if len(regime_strat) > 0:\n",
    "                metrics = calculate_performance_metrics(regime_strat, regime_bench)\n",
    "                metrics['Regime'] = regime\n",
    "                metrics['Days'] = len(regime_strat)\n",
    "                results.append(metrics)\n",
    "\n",
    "    return pd.DataFrame(results).set_index('Regime')\n",
    "\n",
    "def calculate_performance_metrics(returns: pd.Series,\n",
    "                                  benchmark: pd.Series,\n",
    "                                  risk_free_rate: float = 0.0) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculate comprehensive performance metrics.\n",
    "    \"\"\"\n",
    "    # Align series\n",
    "    common_idx = returns.index.intersection(benchmark.index)\n",
    "    returns = returns.loc[common_idx]\n",
    "    benchmark = benchmark.loc[common_idx]\n",
    "\n",
    "    # Basic metrics\n",
    "    total_return = (1 + returns).prod() - 1\n",
    "    n_years = len(returns) / 252\n",
    "    annual_return = (1 + total_return) ** (1 / n_years) - 1 if n_years > 0 else 0\n",
    "    annual_vol = returns.std() * np.sqrt(252)\n",
    "    sharpe_ratio = (annual_return - risk_free_rate) / annual_vol if annual_vol > 0 else 0\n",
    "\n",
    "    # Drawdown\n",
    "    cumulative = (1 + returns).cumprod()\n",
    "    drawdown = (cumulative / cumulative.cummax() - 1)\n",
    "    max_drawdown = drawdown.min()\n",
    "\n",
    "    # vs Benchmark\n",
    "    excess_returns = returns - benchmark\n",
    "    tracking_error = excess_returns.std() * np.sqrt(252)\n",
    "    information_ratio = (excess_returns.mean() * 252) / tracking_error if tracking_error > 0 else 0\n",
    "\n",
    "    # Win rate\n",
    "    win_rate = (returns > 0).mean()\n",
    "    win_vs_bench = (returns > benchmark).mean()\n",
    "\n",
    "    return {\n",
    "        'Annual Return (%)': annual_return * 100,\n",
    "        'Annual Vol (%)': annual_vol * 100,\n",
    "        'Sharpe Ratio': sharpe_ratio,\n",
    "        'Max Drawdown (%)': max_drawdown * 100,\n",
    "        'Win Rate (%)': win_rate * 100,\n",
    "        'Win vs Bench (%)': win_vs_bench * 100,\n",
    "        'Information Ratio': information_ratio,\n",
    "        'Annual Alpha (%)': (annual_return - benchmark.mean() * 252) * 100\n",
    "    }\n",
    "\n",
    "# Using ACTUAL strategy returns from Notebook 03\n",
    "print(\"‚úÖ Using actual strategy returns from canonical backtest\")\n",
    "print(f\"    Strategy performance: {(strategy_returns.mean() * 252):.2%} annualized\")\n",
    "\n",
    "# Calculate regime performance with real data\n",
    "regime_performance = calculate_regime_performance(strategy_returns, benchmark_returns, market_regimes)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nüéØ PERFORMANCE BY MARKET REGIME:\")\n",
    "print(\"=\" * 100)\n",
    "display(regime_performance.round(2))\n",
    "\n",
    "# Visualize regime performance\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Strategy Performance Across Market Regimes', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Annual returns by regime\n",
    "ax1 = axes[0, 0]\n",
    "regime_returns = regime_performance['Annual Return (%)'].drop('Overall')\n",
    "colors = [FACTOR_COLORS[r] for r in regime_returns.index]\n",
    "bars = ax1.bar(regime_returns.index, regime_returns.values, color=colors)\n",
    "ax1.axhline(y=0, color='black', linewidth=0.5)\n",
    "ax1.set_title('Annual Returns by Regime')\n",
    "ax1.set_ylabel('Annual Return (%)')\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Sharpe ratios by regime\n",
    "ax2 = axes[0, 1]\n",
    "regime_sharpes = regime_performance['Sharpe Ratio'].drop('Overall')\n",
    "bars = ax2.bar(regime_sharpes.index, regime_sharpes.values, color=colors)\n",
    "ax2.axhline(y=1.0, color='green', linestyle='--', alpha=0.5, label='Sharpe = 1.0')\n",
    "ax2.set_title('Sharpe Ratios by Regime')\n",
    "ax2.set_ylabel('Sharpe Ratio')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Win rates\n",
    "ax3 = axes[1, 0]\n",
    "win_data = regime_performance[['Win Rate (%)', 'Win vs Bench (%)']].drop('Overall')\n",
    "win_data.plot(kind='bar', ax=ax3,\n",
    "              color=[FACTOR_COLORS['Strategy'], FACTOR_COLORS['Benchmark']])\n",
    "ax3.axhline(y=50, color='black', linestyle='--', alpha=0.5)\n",
    "ax3.set_title('Win Rates by Regime')\n",
    "ax3.set_ylabel('Win Rate (%)')\n",
    "ax3.legend(['Daily Win Rate', 'Win vs Benchmark'])\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Information ratios\n",
    "ax4 = axes[1, 1]\n",
    "regime_ir = regime_performance['Information Ratio'].drop('Overall')\n",
    "bars = ax4.bar(regime_ir.index, regime_ir.values, color=colors)\n",
    "ax4.axhline(y=0, color='black', linewidth=0.5)\n",
    "ax4.set_title('Information Ratios by Regime')\n",
    "ax4.set_ylabel('Information Ratio')\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Key insights based on ACTUAL performance\n",
    "print(\"\\nüí° KEY INSIGHTS FROM ACTUAL STRATEGY PERFORMANCE:\")\n",
    "if 'Bear' in regime_performance.index and \\\n",
    "   regime_performance.loc['Bear', 'Annual Return (%)'] > 0:\n",
    "    print(\"    ‚úÖ Strategy maintains positive returns even in Bear markets\")\n",
    "else:\n",
    "    print(\"    ‚ö†Ô∏è Strategy struggles in Bear markets - consider defensive overlays\")\n",
    "\n",
    "if 'Stress' in regime_performance.index and \\\n",
    "   regime_performance.loc['Stress', 'Sharpe Ratio'] > 0.5:\n",
    "    print(\"    ‚úÖ Strategy shows resilience during high-stress periods\")\n",
    "else:\n",
    "    print(\"    ‚ö†Ô∏è High volatility periods significantly impact risk-adjusted returns\")\n",
    "\n",
    "# Additional insight based on overall performance\n",
    "overall_sharpe = regime_performance.loc['Overall', 'Sharpe Ratio']\n",
    "print(f\"\\n    üìä Overall Strategy Sharpe Ratio: {overall_sharpe:.2f}\")\n",
    "if overall_sharpe > 1.5:\n",
    "    print(\"    ‚úÖ Excellent risk-adjusted returns across full period\")\n",
    "elif overall_sharpe > 1.0:\n",
    "    print(\"    ‚úÖ Good risk-adjusted returns, consistent with institutional standards\")\n",
    "else:\n",
    "    print(\"    ‚ö†Ô∏è Risk-adjusted returns below institutional targets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis 2: Sector Concentration Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sector mappings\n",
    "print(\"üèóÔ∏è Loading sector information...\")\n",
    "\n",
    "config_path = project_root / 'config' / 'database.yml'\n",
    "with open(config_path, 'r') as f:\n",
    "    db_config = yaml.safe_load(f)['production']\n",
    "    \n",
    "engine = create_engine(\n",
    "    f\"mysql+pymysql://{db_config['username']}:{db_config['password']}@\"\n",
    "    f\"{db_config['host']}/{db_config['schema_name']}\"\n",
    ")\n",
    "\n",
    "sector_info = pd.read_sql(\"SELECT ticker, sector FROM master_info WHERE sector IS NOT NULL\", engine)\n",
    "sector_info = sector_info.drop_duplicates(subset=['ticker']).set_index('ticker')\n",
    "engine.dispose()\n",
    "\n",
    "print(f\"‚úÖ Loaded sector mappings for {len(sector_info)} tickers\")\n",
    "\n",
    "# Note: In production, we would have portfolio holdings from Notebook 03\n",
    "# For demonstration, we'll simulate sector exposures\n",
    "print(\"\\n‚ö†Ô∏è Note: Portfolio holdings should be loaded from Notebook 03\")\n",
    "print(\"   Creating demonstration sector analysis...\")\n",
    "\n",
    "# Analyze sector concentration over time\n",
    "def analyze_sector_concentration(portfolio_weights: pd.DataFrame, \n",
    "                               sector_info: pd.DataFrame,\n",
    "                               top_n: int = 3) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analyze sector concentration in the portfolio over time.\n",
    "    \"\"\"\n",
    "    # Calculate sector weights for each rebalancing period\n",
    "    sector_weights = pd.DataFrame(index=portfolio_weights.index)\n",
    "    \n",
    "    for date in portfolio_weights.index:\n",
    "        # Get holdings for this date\n",
    "        holdings = portfolio_weights.loc[date]\n",
    "        holdings = holdings[holdings > 0]\n",
    "        \n",
    "        # Map to sectors\n",
    "        sector_exposure = holdings.to_frame('weight').join(sector_info)\n",
    "        \n",
    "        # Calculate sector weights\n",
    "        sector_sums = sector_exposure.groupby('sector')['weight'].sum()\n",
    "        \n",
    "        # Store top sectors\n",
    "        top_sectors = sector_sums.nlargest(top_n)\n",
    "        for i, (sector, weight) in enumerate(top_sectors.items()):\n",
    "            sector_weights.loc[date, f'Sector_{i+1}'] = weight\n",
    "            sector_weights.loc[date, f'Sector_{i+1}_Name'] = sector\n",
    "            \n",
    "        sector_weights.loc[date, 'Others'] = sector_sums.sum() - top_sectors.sum()\n",
    "        sector_weights.loc[date, 'HHI'] = (sector_sums ** 2).sum()  # Herfindahl index\n",
    "    \n",
    "    return sector_weights\n",
    "\n",
    "# Create visualization of sector concentration\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10), sharex=True)\n",
    "fig.suptitle('Portfolio Sector Concentration Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# For demonstration, create synthetic sector weights\n",
    "dates = pd.date_range(start=benchmark_returns.index[0], end=benchmark_returns.index[-1], freq='M')\n",
    "synthetic_sectors = pd.DataFrame(index=dates)\n",
    "synthetic_sectors['Financials'] = 0.25 + np.random.normal(0, 0.05, len(dates))\n",
    "synthetic_sectors['Real Estate'] = 0.20 + np.random.normal(0, 0.04, len(dates))\n",
    "synthetic_sectors['Industrials'] = 0.15 + np.random.normal(0, 0.03, len(dates))\n",
    "synthetic_sectors['Others'] = 1 - synthetic_sectors[['Financials', 'Real Estate', 'Industrials']].sum(axis=1)\n",
    "\n",
    "# Plot 1: Stacked area chart of sector weights\n",
    "ax1 = axes[0]\n",
    "ax1.stackplot(synthetic_sectors.index, \n",
    "              synthetic_sectors['Financials'],\n",
    "              synthetic_sectors['Real Estate'],\n",
    "              synthetic_sectors['Industrials'],\n",
    "              synthetic_sectors['Others'],\n",
    "              labels=['Financials', 'Real Estate', 'Industrials', 'Others'],\n",
    "              colors=[FACTOR_COLORS['Sector1'], FACTOR_COLORS['Sector2'], \n",
    "                     FACTOR_COLORS['Sector3'], FACTOR_COLORS['Others']],\n",
    "              alpha=0.8)\n",
    "ax1.set_ylabel('Portfolio Weight')\n",
    "ax1.set_title('Sector Allocation Over Time')\n",
    "ax1.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(0, 1)\n",
    "\n",
    "# Plot 2: Concentration metrics\n",
    "ax2 = axes[1]\n",
    "concentration = synthetic_sectors[['Financials', 'Real Estate', 'Industrials']].max(axis=1)\n",
    "ax2.plot(synthetic_sectors.index, concentration * 100, \n",
    "         color=FACTOR_COLORS['Correlation'], linewidth=2, label='Max Sector Weight')\n",
    "ax2.axhline(y=40, color='red', linestyle='--', alpha=0.5, label='40% Limit')\n",
    "ax2.set_ylabel('Concentration (%)')\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.set_title('Maximum Sector Concentration')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate sector contribution to returns\n",
    "print(\"\\nüìä SECTOR CONCENTRATION METRICS:\")\n",
    "print(f\"   Average max sector weight: {(concentration * 100).mean():.1f}%\")\n",
    "print(f\"   Maximum sector weight reached: {(concentration * 100).max():.1f}%\")\n",
    "print(f\"   Times above 35% concentration: {(concentration > 0.35).sum()}\")\n",
    "\n",
    "print(\"\\nüí° CONCENTRATION RISK ASSESSMENT:\")\n",
    "if (concentration * 100).mean() > 30:\n",
    "    print(\"   ‚ö†Ô∏è High sector concentration detected - diversification may be suboptimal\")\n",
    "else:\n",
    "    print(\"   ‚úÖ Sector concentration within reasonable bounds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# ==========================\n",
    "# CELL 5 REFACTORED: Sector Concentration Analysis with ACTUAL Portfolio Holdings\n",
    "# ==================================================\n",
    "# ==========================\n",
    "\n",
    "# Load sector mappings (this part is correct)\n",
    "print(\"üèóÔ∏è Loading sector information...\")\n",
    "\n",
    "config_path = project_root / 'config' / \\\n",
    "    'database.yml'\n",
    "with open(config_path, 'r') as f:\n",
    "    db_config = yaml.safe_load(f)['production']\n",
    "\n",
    "engine = create_engine(\n",
    "    f\"mysql+pymysql://{db_config['username']}:{db_config['password']}@\"\n",
    "    f\"{db_config['host']}/{db_config['schema_name']}\"\n",
    ")\n",
    "\n",
    "sector_info = pd.read_sql(\"SELECT ticker, sector FROM master_info WHERE sector IS NOT NULL\", engine)\n",
    "sector_info = sector_info.drop_duplicates(subset=['ticker']).set_index('ticker')\n",
    "engine.dispose()\n",
    "\n",
    "print(f\"‚úÖ Loaded sector mappings for {len(sector_info)} tickers\")\n",
    "\n",
    "# ==================================================\n",
    "# ==========================\n",
    "# CRITICAL: Check for ACTUAL portfolio holdings from Notebook 03\n",
    "# ==================================================\n",
    "# ==========================\n",
    "\n",
    "print(\"\\nüìä Checking for actual portfolio holdings from canonical backtest...\")\n",
    "\n",
    "# Check if we have portfolio holdings in the backtest results\n",
    "if 'portfolio_holdings' in backtest_results and \\\n",
    "        backtest_results['portfolio_holdings'] is not None:\n",
    "    portfolio_holdings = backtest_results['portfolio_holdings']\n",
    "    print(f\"‚úÖ Portfolio holdings loaded: {portfolio_holdings.shape}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Portfolio holdings not found in saved results.\")\n",
    "    print(\"    Performing alternative analysis using available data...\")\n",
    "\n",
    "# ==================================================\n",
    "# ==========================\n",
    "# Alternative: Analyze sector composition of factor universe and selections\n",
    "# ==================================================\n",
    "# ==========================\n",
    "\n",
    "print(\"\\nüîÑ Analyzing sector composition of investment universe and selections...\")\n",
    "\n",
    "# Get the QVM scores\n",
    "qvm_scores = factor_data.loc[:, ('qvm_composite_score', slice(None))]\n",
    "qvm_scores.columns = qvm_scores.columns.droplevel(0)\n",
    "\n",
    "# Get the latest factor scores to see current universe composition\n",
    "latest_date = qvm_scores.index[-1]\n",
    "latest_scores = qvm_scores.loc[latest_date].dropna()\n",
    "\n",
    "print(f\"üìä Universe Analysis for {latest_date.date()}:\")\n",
    "print(f\"    Total stocks with factor scores: {len(latest_scores)}\")\n",
    "\n",
    "# Analyze sector composition of the investment universe\n",
    "universe_sectors = \\\n",
    "    latest_scores.to_frame('score').join(sector_info, how='inner')\n",
    "sector_composition = universe_sectors.groupby('sector').size().sort_values(ascending=False)\n",
    "\n",
    "print(f\"\\nüèóÔ∏è Sector Composition of Investment Universe:\")\n",
    "for sector, count in sector_composition.head(10).items():\n",
    "    pct = (count / len(universe_sectors)) * 100\n",
    "    print(f\"    {sector:25s}: {count:3d} stocks ({pct:5.1f}%)\")\n",
    "\n",
    "# Analyze top quintile (portfolio selection simulation)\n",
    "top_quintile_cutoff = latest_scores.quantile(0.8)  # Top 20%\n",
    "top_quintile_stocks = latest_scores[latest_scores >= top_quintile_cutoff]\n",
    "\n",
    "top_quintile_sectors = top_quintile_stocks.to_frame('score').join(sector_info, how='inner')\n",
    "selected_sector_comp = top_quintile_sectors.groupby('sector').size().sort_values(ascending=False)\n",
    "\n",
    "print(f\"\\nüéØ Top Quintile Portfolio Simulation ({len(top_quintile_stocks)} stocks):\")\n",
    "for sector, count in selected_sector_comp.head(8).items():\n",
    "    pct = (count / len(top_quintile_sectors)) * 100\n",
    "    print(f\"    {sector:25s}: {count:3d} stocks ({pct:5.1f}%)\")\n",
    "\n",
    "# Visualize sector analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Portfolio Sector Concentration Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Universe sector composition (pie chart)\n",
    "ax1 = axes[0, 0]\n",
    "top_8_sectors = sector_composition.head(8)\n",
    "ax1.pie(top_8_sectors.values,\n",
    "        labels=top_8_sectors.index,\n",
    "        autopct='%1.1f%%',\n",
    "        startangle=90,\n",
    "        colors=[FACTOR_COLORS['Sector1'], FACTOR_COLORS['Sector2'],\n",
    "                FACTOR_COLORS['Sector3']] + [FACTOR_COLORS['Others']] * 5)\n",
    "ax1.set_title('Investment Universe\\nSector Distribution')\n",
    "\n",
    "# Plot 2: Top quintile sector composition\n",
    "ax2 = axes[0, 1]\n",
    "bars = ax2.bar(range(len(selected_sector_comp.head(8))),\n",
    "               selected_sector_comp.head(8).values,\n",
    "               color=[FACTOR_COLORS['Sector1'], FACTOR_COLORS['Sector2'],\n",
    "                      FACTOR_COLORS['Sector3']] + [FACTOR_COLORS['Others']] * 5)\n",
    "ax2.set_title('Top Quintile Selection\\nSector Composition')\n",
    "ax2.set_ylabel('Number of Stocks')\n",
    "ax2.set_xticks(range(len(selected_sector_comp.head(8))))\n",
    "ax2.set_xticklabels(selected_sector_comp.head(8).index, rotation=45, ha='right')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 3: Concentration risk comparison\n",
    "ax3 = axes[1, 0]\n",
    "universe_pcts = (sector_composition.head(5) / len(universe_sectors)) * 100\n",
    "selection_pcts = (selected_sector_comp.head(5) / len(top_quintile_sectors)) * 100\n",
    "\n",
    "x = np.arange(len(universe_pcts))\n",
    "width = 0.35\n",
    "\n",
    "ax3.bar(x - width/2, universe_pcts.values, width, label='Universe',\n",
    "        color=FACTOR_COLORS['Benchmark'], alpha=0.7)\n",
    "ax3.bar(x + width/2, selection_pcts.values, width, label='Selection',\n",
    "        color=FACTOR_COLORS['Strategy'], alpha=0.7)\n",
    "\n",
    "ax3.axhline(y=40, color='red', linestyle='--', alpha=0.5, label='40% Risk Limit')\n",
    "ax3.set_ylabel('Sector Weight (%)')\n",
    "ax3.set_title('Sector Concentration Comparison')\n",
    "ax3.set_xticks(x)\n",
    "ax3.set_xticklabels(universe_pcts.index, rotation=45, ha='right')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 4: Factor score distribution by sector\n",
    "ax4 = axes[1, 1]\n",
    "sector_scores = universe_sectors.groupby('sector')['score'].agg(['mean', 'std']).sort_values('mean', ascending=False)\n",
    "top_sectors = sector_scores.head(8)\n",
    "\n",
    "ax4.errorbar(range(len(top_sectors)), top_sectors['mean'],\n",
    "             yerr=top_sectors['std'], fmt='o', capsize=5,\n",
    "             color=FACTOR_COLORS['Strategy'], linewidth=2)\n",
    "ax4.set_title('Average Factor Scores by Sector')\n",
    "ax4.set_ylabel('QVM Composite Score')\n",
    "ax4.set_xticks(range(len(top_sectors)))\n",
    "ax4.set_xticklabels(top_sectors.index, rotation=45, ha='right')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ==================================================\n",
    "# ==========================\n",
    "# Concentration Risk Assessment\n",
    "# ==================================================\n",
    "# ==========================\n",
    "\n",
    "print(f\"\\nüí° SECTOR CONCENTRATION RISK ASSESSMENT:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Top sector concentration\n",
    "top_sector_pct = (selected_sector_comp.iloc[0] / len(top_quintile_sectors)) * 100\n",
    "print(f\"Largest sector in selection: {selected_sector_comp.index[0]} ({top_sector_pct:.1f}%)\")\n",
    "\n",
    "# Top 3 sectors concentration\n",
    "top_3_pct = (selected_sector_comp.head(3).sum() / len(top_quintile_sectors)) * 100\n",
    "print(f\"Top 3 sectors combined: {top_3_pct:.1f}%\")\n",
    "\n",
    "# Risk assessment\n",
    "if top_sector_pct > 40:\n",
    "    print(\"    ‚ùå HIGH RISK: Top sector exceeds 40% constraint\")\n",
    "elif top_sector_pct > 30:\n",
    "    print(\"    ‚ö†Ô∏è MODERATE RISK: Top sector approaching concentration limit\")\n",
    "else:\n",
    "    print(\"    ‚úÖ LOW RISK: Sector concentration within acceptable bounds\")\n",
    "\n",
    "if top_3_pct > 70:\n",
    "    print(\"    ‚ö†Ô∏è HIGH CONCENTRATION: Top 3 sectors dominate portfolio\")\n",
    "else:\n",
    "    print(\"    ‚úÖ DIVERSIFIED: Top 3 sectors show reasonable spread\")\n",
    "\n",
    "# Herfindahl index (concentration measure)\n",
    "sector_weights = selected_sector_comp / len(top_quintile_sectors)\n",
    "hhi = (sector_weights ** 2).sum()\n",
    "print(f\"\\nHerfindahl Index: {hhi:.3f}\")\n",
    "if hhi > 0.25:\n",
    "    print(\"    ‚ö†Ô∏è High concentration (HHI > 0.25)\")\n",
    "elif hhi > 0.15:\n",
    "    print(\"    ‚úÖ Moderate concentration (0.15 < HHI < 0.25)\")\n",
    "else:\n",
    "    print(\"    ‚úÖ Well diversified (HHI < 0.15)\")\n",
    "\n",
    "print(f\"\\nüìã NEXT STEPS:\")\n",
    "print(\"    1. ‚úÖ Universe sector analysis complete\")\n",
    "print(\"    2. ‚ö†Ô∏è Need actual monthly portfolio holdings for time-series analysis\")\n",
    "print(\"    3. ‚ö†Ô∏è Need to validate 40% sector constraint compliance over time\")\n",
    "print(\"    4. ‚û°Ô∏è Proceed to factor correlation dynamics (Cell 6)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# ==========================\n",
    "# CELL 5 CORRECTED: Sector Concentration Analysis with ACTUAL Portfolio Holdings\n",
    "# ==================================================\n",
    "# ==========================\n",
    "\n",
    "# Load sector mappings\n",
    "print(\"üèóÔ∏è Loading sector information...\")\n",
    "\n",
    "config_path = project_root / 'config' / \\\n",
    "    'database.yml'\n",
    "with open(config_path, 'r') as f:\n",
    "    db_config = yaml.safe_load(f)['production']\n",
    "\n",
    "engine = create_engine(\n",
    "    f\"mysql+pymysql://{db_config['username']}:{db_config['password']}@\"\n",
    "    f\"{db_config['host']}/{db_config['schema_name']}\"\n",
    ")\n",
    "\n",
    "sector_info = pd.read_sql(\"SELECT ticker, sector FROM master_info WHERE sector IS NOT NULL\", engine)\n",
    "sector_info = sector_info.drop_duplicates(subset=['ticker']).set_index('ticker')\n",
    "engine.dispose()\n",
    "\n",
    "print(f\"‚úÖ Loaded sector mappings for {len(sector_info)} tickers\")\n",
    "\n",
    "# ==================================================\n",
    "# ==========================\n",
    "# Load ACTUAL portfolio holdings from Notebook 03\n",
    "# ==================================================\n",
    "# ==========================\n",
    "\n",
    "print(\"\\nüìä Loading actual portfolio holdings from canonical backtest...\")\n",
    "\n",
    "if 'monthly_holdings' in backtest_results and \\\n",
    "        backtest_results['monthly_holdings'] is not None:\n",
    "    monthly_holdings = backtest_results['monthly_holdings']\n",
    "    print(f\"‚úÖ Monthly portfolio holdings loaded: {len(monthly_holdings)} periods\")\n",
    "\n",
    "    # Analyze actual sector concentration over time\n",
    "    def analyze_actual_sector_concentration(monthly_holdings, sector_info, top_n=3):\n",
    "        \"\"\"Analyze actual sector concentration using real portfolio holdings.\"\"\"\n",
    "        print(\"üîç Analyzing actual sector concentration over time...\")\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for date, holdings in monthly_holdings.items():\n",
    "            if len(holdings) > 10:  # Need reasonable portfolio size\n",
    "                # Map holdings to sectors\n",
    "                holdings_df = holdings.to_frame('weight')\n",
    "                sector_exposure = holdings_df.join(sector_info, how='inner')\n",
    "\n",
    "                if len(sector_exposure) > 0:\n",
    "                    # Calculate sector weights\n",
    "                    sector_weights = \\\n",
    "                        sector_exposure.groupby('sector')['weight'].sum()\n",
    "\n",
    "                    # Store results\n",
    "                    result = {\n",
    "                        'Date': date,\n",
    "                        'Total_Positions': len(holdings),\n",
    "                        'Mapped_Positions': len(sector_exposure),\n",
    "                        'Num_Sectors': len(sector_weights)\n",
    "                    }\n",
    "\n",
    "                    # Top sectors\n",
    "                    top_sectors = sector_weights.nlargest(top_n)\n",
    "                    for i, (sector, weight) in enumerate(top_sectors.items()):\n",
    "                        result[f'Top_{i+1}_Sector'] = sector\n",
    "                        result[f'Top_{i+1}_Weight'] = weight\n",
    "\n",
    "                    # Concentration metrics\n",
    "                    result['Max_Sector_Weight'] = sector_weights.max()\n",
    "                    result['Top_3_Weight'] = top_sectors.sum()\n",
    "                    result['HHI'] = (sector_weights ** 2).sum()\n",
    "\n",
    "                    results.append(result)\n",
    "\n",
    "        return pd.DataFrame(results).set_index('Date')\n",
    "\n",
    "    # Perform the analysis\n",
    "    sector_analysis = analyze_actual_sector_concentration(monthly_holdings, sector_info)\n",
    "\n",
    "    if len(sector_analysis) > 0:\n",
    "        print(f\"‚úÖ Sector analysis complete: {len(sector_analysis)} periods analyzed\")\n",
    "\n",
    "        # Display summary statistics\n",
    "        print(f\"\\nüìä ACTUAL PORTFOLIO SECTOR CONCENTRATION METRICS:\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"Average portfolio size: {sector_analysis['Total_Positions'].mean():.0f} stocks\")\n",
    "        print(f\"Average sectors represented: {sector_analysis['Num_Sectors'].mean():.0f}\")\n",
    "        print(f\"Average max sector weight: {sector_analysis['Max_Sector_Weight'].mean():.1%}\")\n",
    "        print(f\"Average top-3 concentration: {sector_analysis['Top_3_Weight'].mean():.1%}\")\n",
    "        print(f\"Average HHI: {sector_analysis['HHI'].mean():.3f}\")\n",
    "\n",
    "        # Visualize actual sector concentration over time\n",
    "        fig, axes = plt.subplots(3, 1, figsize=(15, 12), sharex=True)\n",
    "        fig.suptitle('Actual Portfolio Sector Concentration Analysis', fontsize=16,\n",
    "                     fontweight='bold')\n",
    "\n",
    "        # Plot 1: Maximum sector weight over time\n",
    "        ax1 = axes[0]\n",
    "        ax1.plot(sector_analysis.index,\n",
    "                 sector_analysis['Max_Sector_Weight'] * 100,\n",
    "                 color=FACTOR_COLORS['Strategy'], linewidth=2, label='Max Sector Weight')\n",
    "        ax1.axhline(y=40, color='red', linestyle='--', alpha=0.7, label='40% Constraint')\n",
    "        ax1.axhline(y=30, color='orange', linestyle='--', alpha=0.5, label='30% Warning')\n",
    "        ax1.set_ylabel('Max Sector Weight (%)')\n",
    "        ax1.set_title('Maximum Sector Concentration Over Time')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "\n",
    "        # Plot 2: Top 3 sector concentration\n",
    "        ax2 = axes[1]\n",
    "        ax2.plot(sector_analysis.index,\n",
    "                 sector_analysis['Top_3_Weight'] * 100,\n",
    "                 color=FACTOR_COLORS['Correlation'], linewidth=2, label='Top 3 Sectors')\n",
    "        ax2.axhline(y=70, color='red', linestyle='--', alpha=0.7, label='70% High Risk')\n",
    "        ax2.set_ylabel('Top 3 Sectors Weight (%)')\n",
    "        ax2.set_title('Top 3 Sector Concentration')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "\n",
    "        # Plot 3: Herfindahl Index (diversification measure)\n",
    "        ax3 = axes[2]\n",
    "        ax3.plot(sector_analysis.index,\n",
    "                 sector_analysis['HHI'],\n",
    "                 color=FACTOR_COLORS['Sharpe'], linewidth=2, label='HHI')\n",
    "        ax3.axhline(y=0.25, color='red', linestyle='--', alpha=0.7, label='High Concentration')\n",
    "        ax3.axhline(y=0.15, color='orange', linestyle='--', alpha=0.5, label='Moderate Concentration')\n",
    "        ax3.set_ylabel('Herfindahl Index')\n",
    "        ax3.set_xlabel('Date')\n",
    "        ax3.set_title('Portfolio Diversification (Lower HHI = More Diversified)')\n",
    "        ax3.legend()\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Risk assessment\n",
    "        max_concentration = sector_analysis['Max_Sector_Weight'].max()\n",
    "        violations_40 = \\\n",
    "            (sector_analysis['Max_Sector_Weight'] > 0.40).sum()\n",
    "        violations_30 = \\\n",
    "            (sector_analysis['Max_Sector_Weight'] > 0.30).sum()\n",
    "\n",
    "        print(f\"\\nüí° CONCENTRATION RISK ASSESSMENT:\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"Peak sector concentration: {max_concentration:.1%}\")\n",
    "        print(f\"Periods above 40% limit: {violations_40} ({violations_40/len(sector_analysis)*100:.1f}%)\")\n",
    "        print(f\"Periods above 30% warning: {violations_30} ({violations_30/len(sector_analysis)*100:.1f}%)\")\n",
    "\n",
    "        if violations_40 > 0:\n",
    "            print(\"    ‚ùå CONSTRAINT VIOLATION: Portfolio exceeded 40% sector limit\")\n",
    "        elif violations_30 > 0:\n",
    "            print(\"    ‚ö†Ô∏è ELEVATED RISK: Portfolio approached concentration limits\")\n",
    "        else:\n",
    "            print(\"    ‚úÖ COMPLIANT: Sector concentration within acceptable bounds\")\n",
    "\n",
    "        # Most concentrated sectors\n",
    "        top_sectors_ever = {}\n",
    "        for _, row in sector_analysis.iterrows():\n",
    "            for i in range(1, 4):\n",
    "                sector = row[f'Top_{i}_Sector']\n",
    "                weight = row[f'Top_{i}_Weight']\n",
    "                if pd.notna(sector):\n",
    "                    if sector not in top_sectors_ever:\n",
    "                        top_sectors_ever[sector] = \\\n",
    "                            []\n",
    "\n",
    "                    top_sectors_ever[sector].append(weight)\n",
    "\n",
    "        avg_weights = {sector: np.mean(weights) for\n",
    "                       sector, weights in top_sectors_ever.items()}\n",
    "        top_avg_sectors = \\\n",
    "            sorted(avg_weights.items(), key=lambda x: x[1],\n",
    "                   reverse=True)[:5]\n",
    "\n",
    "        print(f\"\\nüèóÔ∏è MOST CONCENTRATED SECTORS (Average Weight):\")\n",
    "        for sector, avg_weight in top_avg_sectors:\n",
    "            print(f\"    {sector:25s}: {avg_weight:.1%}\")\n",
    "\n",
    "    else:\n",
    "        print(\"‚ùå No valid portfolio periods found for sector analysis\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No monthly holdings found in backtest results\")\n",
    "    print(\"    Please run the updated Notebook 03 first to save portfolio holdings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis 3: Factor Correlation Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_factor_correlation_dynamics(factor_returns: Dict[str, pd.Series],\n",
    "                                      window: int = 90,\n",
    "                                      correlation_threshold: float = 0.7) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analyze rolling correlations between factors and identify high-correlation periods.\n",
    "    \"\"\"\n",
    "    print(f\"üîç Analyzing factor correlation dynamics (window={window} days)...\")\n",
    "    \n",
    "    # Calculate rolling correlations\n",
    "    correlations = pd.DataFrame(index=factor_returns['Quality'].index)\n",
    "    \n",
    "    # Pairwise correlations\n",
    "    pairs = [('Quality', 'Value'), ('Quality', 'Momentum'), ('Value', 'Momentum')]\n",
    "    \n",
    "    for factor1, factor2 in pairs:\n",
    "        rolling_corr = factor_returns[factor1].rolling(window).corr(factor_returns[factor2])\n",
    "        correlations[f'{factor1}_vs_{factor2}'] = rolling_corr\n",
    "    \n",
    "    # Average correlation\n",
    "    correlations['avg_correlation'] = correlations.mean(axis=1)\n",
    "    \n",
    "    # Identify high correlation periods\n",
    "    correlations['high_corr_period'] = correlations['avg_correlation'] > correlation_threshold\n",
    "    \n",
    "    return correlations\n",
    "\n",
    "# Load factor returns from Notebook 02 results\n",
    "# For demonstration, create synthetic factor returns\n",
    "print(\"‚ö†Ô∏è Note: Factor returns should be loaded from Notebook 02\")\n",
    "print(\"   Creating demonstration analysis...\")\n",
    "\n",
    "# Synthetic factor returns for demonstration\n",
    "factor_returns = {\n",
    "    'Quality': benchmark_returns + np.random.normal(0.0001, 0.002, len(benchmark_returns)),\n",
    "    'Value': benchmark_returns + np.random.normal(0.0002, 0.0025, len(benchmark_returns)),\n",
    "    'Momentum': -benchmark_returns * 0.5 + np.random.normal(0, 0.003, len(benchmark_returns))\n",
    "}\n",
    "\n",
    "# Analyze correlations\n",
    "correlation_dynamics = analyze_factor_correlation_dynamics(factor_returns)\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, 12), sharex=True)\n",
    "fig.suptitle('Factor Correlation Dynamics and Portfolio Impact', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Rolling correlations\n",
    "ax1 = axes[0]\n",
    "for col in ['Quality_vs_Value', 'Quality_vs_Momentum', 'Value_vs_Momentum']:\n",
    "    ax1.plot(correlation_dynamics.index, correlation_dynamics[col], \n",
    "             linewidth=2, alpha=0.8, label=col.replace('_', ' '))\n",
    "ax1.axhline(y=0.7, color='red', linestyle='--', alpha=0.5, label='High Correlation Threshold')\n",
    "ax1.set_ylabel('Correlation')\n",
    "ax1.set_title('90-Day Rolling Factor Correlations')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(-1, 1)\n",
    "\n",
    "# Plot 2: Average correlation with high-correlation periods shaded\n",
    "ax2 = axes[1]\n",
    "ax2.plot(correlation_dynamics.index, correlation_dynamics['avg_correlation'], \n",
    "         color=FACTOR_COLORS['Correlation'], linewidth=2)\n",
    "ax2.fill_between(correlation_dynamics.index, 0, 1, \n",
    "                 where=correlation_dynamics['high_corr_period'],\n",
    "                 color='red', alpha=0.2, label='High Correlation Periods')\n",
    "ax2.axhline(y=0.7, color='red', linestyle='--', alpha=0.5)\n",
    "ax2.set_ylabel('Average Correlation')\n",
    "ax2.set_title('Average Factor Correlation with High-Risk Periods')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim(0, 1)\n",
    "\n",
    "# Plot 3: Strategy volatility\n",
    "ax3 = axes[2]\n",
    "strategy_vol = strategy_returns.rolling(60).std() * np.sqrt(252) * 100\n",
    "ax3.plot(strategy_vol.index, strategy_vol, color=FACTOR_COLORS['Strategy'], linewidth=2)\n",
    "# Shade high correlation periods\n",
    "ax3.fill_between(correlation_dynamics.index, 0, strategy_vol.max(),\n",
    "                where=correlation_dynamics['high_corr_period'],\n",
    "                color='red', alpha=0.2, label='High Correlation Periods')\n",
    "ax3.set_ylabel('Volatility (%)')\n",
    "ax3.set_xlabel('Date')\n",
    "ax3.set_title('Strategy Volatility vs Factor Correlation Regimes')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analysis of high correlation periods\n",
    "high_corr_periods = correlation_dynamics['high_corr_period'].sum()\n",
    "total_periods = len(correlation_dynamics.dropna())\n",
    "high_corr_pct = (high_corr_periods / total_periods) * 100\n",
    "\n",
    "print(\"\\nüìä FACTOR CORRELATION ANALYSIS:\")\n",
    "print(f\"   High correlation periods: {high_corr_periods} days ({high_corr_pct:.1f}% of time)\")\n",
    "print(f\"   Average correlation: {correlation_dynamics['avg_correlation'].mean():.3f}\")\n",
    "print(f\"   Maximum correlation reached: {correlation_dynamics['avg_correlation'].max():.3f}\")\n",
    "\n",
    "# Performance during high vs normal correlation periods\n",
    "if high_corr_periods > 0:\n",
    "    high_corr_returns = strategy_returns[correlation_dynamics['high_corr_period'].fillna(False)]\n",
    "    normal_corr_returns = strategy_returns[~correlation_dynamics['high_corr_period'].fillna(True)]\n",
    "    \n",
    "    high_corr_sharpe = (high_corr_returns.mean() / high_corr_returns.std()) * np.sqrt(252)\n",
    "    normal_corr_sharpe = (normal_corr_returns.mean() / normal_corr_returns.std()) * np.sqrt(252)\n",
    "    \n",
    "    print(f\"\\n   Sharpe during high correlation: {high_corr_sharpe:.2f}\")\n",
    "    print(f\"   Sharpe during normal correlation: {normal_corr_sharpe:.2f}\")\n",
    "    \n",
    "    print(\"\\nüí° CORRELATION RISK ASSESSMENT:\")\n",
    "    if high_corr_sharpe < normal_corr_sharpe * 0.7:\n",
    "        print(\"   ‚ö†Ô∏è Strategy performance significantly degraded during high correlation periods\")\n",
    "        print(\"   ‚Üí Consider dynamic factor weighting or correlation-based risk overlay\")\n",
    "    else:\n",
    "        print(\"   ‚úÖ Strategy maintains reasonable performance during high correlation periods\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis 4: Drawdown Forensics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_drawdowns(returns: pd.Series, \n",
    "                     market_regimes: pd.DataFrame,\n",
    "                     factor_correlations: pd.DataFrame,\n",
    "                     n_worst: int = 5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Perform forensic analysis on the worst drawdowns.\n",
    "    \"\"\"\n",
    "    print(f\"üîç Analyzing top {n_worst} drawdowns...\")\n",
    "    \n",
    "    # Calculate drawdown series\n",
    "    cumulative = (1 + returns).cumprod()\n",
    "    running_max = cumulative.cummax()\n",
    "    drawdown = (cumulative / running_max - 1)\n",
    "    \n",
    "    # Identify drawdown periods\n",
    "    drawdown_periods = []\n",
    "    in_drawdown = False\n",
    "    start_date = None\n",
    "    \n",
    "    for date, dd in drawdown.items():\n",
    "        if dd < 0 and not in_drawdown:\n",
    "            in_drawdown = True\n",
    "            start_date = date\n",
    "            peak_value = running_max[date]\n",
    "        elif dd == 0 and in_drawdown:\n",
    "            in_drawdown = False\n",
    "            end_date = date\n",
    "            trough_date = drawdown[start_date:end_date].idxmin()\n",
    "            trough_value = drawdown[trough_date]\n",
    "            \n",
    "            drawdown_periods.append({\n",
    "                'start_date': start_date,\n",
    "                'trough_date': trough_date,\n",
    "                'end_date': end_date,\n",
    "                'max_drawdown': trough_value,\n",
    "                'duration_days': (end_date - start_date).days,\n",
    "                'recovery_days': (end_date - trough_date).days\n",
    "            })\n",
    "    \n",
    "    # Sort by magnitude and select worst\n",
    "    drawdown_df = pd.DataFrame(drawdown_periods)\n",
    "    if len(drawdown_df) > 0:\n",
    "        drawdown_df = drawdown_df.nlargest(n_worst, 'max_drawdown', keep='all')\n",
    "        drawdown_df['max_drawdown'] = drawdown_df['max_drawdown'] * 100  # Convert to percentage\n",
    "        \n",
    "        # Add regime and correlation information\n",
    "        for idx, row in drawdown_df.iterrows():\n",
    "            period_mask = (market_regimes.index >= row['start_date']) & (market_regimes.index <= row['end_date'])\n",
    "            \n",
    "            # Dominant regime during drawdown\n",
    "            regime_counts = market_regimes.loc[period_mask, 'regime'].value_counts()\n",
    "            drawdown_df.loc[idx, 'dominant_regime'] = regime_counts.index[0] if len(regime_counts) > 0 else 'Unknown'\n",
    "            \n",
    "            # Average correlation during drawdown\n",
    "            avg_corr = factor_correlations.loc[period_mask, 'avg_correlation'].mean()\n",
    "            drawdown_df.loc[idx, 'avg_correlation'] = avg_corr\n",
    "    \n",
    "    return drawdown_df\n",
    "\n",
    "# Perform drawdown analysis\n",
    "drawdown_analysis = analyze_drawdowns(strategy_returns, market_regimes, correlation_dynamics)\n",
    "\n",
    "print(\"\\nüìä TOP DRAWDOWN PERIODS:\")\n",
    "print(\"=\" * 120)\n",
    "if len(drawdown_analysis) > 0:\n",
    "    display(drawdown_analysis[['start_date', 'trough_date', 'end_date', 'max_drawdown', \n",
    "                              'duration_days', 'dominant_regime', 'avg_correlation']].round(2))\n",
    "else:\n",
    "    print(\"No significant drawdowns found.\")\n",
    "\n",
    "# Visualize drawdown characteristics\n",
    "if len(drawdown_analysis) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('Drawdown Forensics', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Drawdown magnitude by regime\n",
    "    ax1 = axes[0, 0]\n",
    "    regime_groups = drawdown_analysis.groupby('dominant_regime')['max_drawdown'].mean().abs()\n",
    "    colors = [FACTOR_COLORS.get(r, 'gray') for r in regime_groups.index]\n",
    "    regime_groups.plot(kind='bar', ax=ax1, color=colors)\n",
    "    ax1.set_title('Average Drawdown by Market Regime')\n",
    "    ax1.set_ylabel('Average Max Drawdown (%)')\n",
    "    ax1.set_xlabel('Dominant Regime')\n",
    "    ax1.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Drawdown duration\n",
    "    ax2 = axes[0, 1]\n",
    "    ax2.scatter(drawdown_analysis['duration_days'], \n",
    "               drawdown_analysis['max_drawdown'].abs(),\n",
    "               s=100, alpha=0.6, color=FACTOR_COLORS['Drawdown'])\n",
    "    ax2.set_title('Drawdown Magnitude vs Duration')\n",
    "    ax2.set_xlabel('Duration (Days)')\n",
    "    ax2.set_ylabel('Max Drawdown (%)')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Correlation during drawdowns\n",
    "    ax3 = axes[1, 0]\n",
    "    ax3.scatter(drawdown_analysis['avg_correlation'], \n",
    "               drawdown_analysis['max_drawdown'].abs(),\n",
    "               s=100, alpha=0.6, color=FACTOR_COLORS['Correlation'])\n",
    "    ax3.set_title('Drawdown vs Factor Correlation')\n",
    "    ax3.set_xlabel('Average Factor Correlation')\n",
    "    ax3.set_ylabel('Max Drawdown (%)')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Recovery time\n",
    "    ax4 = axes[1, 1]\n",
    "    ax4.scatter(drawdown_analysis['max_drawdown'].abs(),\n",
    "               drawdown_analysis['recovery_days'],\n",
    "               s=100, alpha=0.6, color=FACTOR_COLORS['Strategy'])\n",
    "    ax4.set_title('Drawdown Magnitude vs Recovery Time')\n",
    "    ax4.set_xlabel('Max Drawdown (%)')\n",
    "    ax4.set_ylabel('Recovery Days')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Key insights\n",
    "print(\"\\nüí° DRAWDOWN INSIGHTS:\")\n",
    "if len(drawdown_analysis) > 0:\n",
    "    avg_drawdown = drawdown_analysis['max_drawdown'].mean()\n",
    "    avg_duration = drawdown_analysis['duration_days'].mean()\n",
    "    avg_recovery = drawdown_analysis['recovery_days'].mean()\n",
    "    \n",
    "    print(f\"   Average max drawdown: {abs(avg_drawdown):.1f}%\")\n",
    "    print(f\"   Average duration: {avg_duration:.0f} days\")\n",
    "    print(f\"   Average recovery time: {avg_recovery:.0f} days\")\n",
    "    \n",
    "    # Regime analysis\n",
    "    bear_drawdowns = drawdown_analysis[drawdown_analysis['dominant_regime'] == 'Bear']\n",
    "    if len(bear_drawdowns) > 0:\n",
    "        print(f\"\\n   Bear market drawdowns: {len(bear_drawdowns)} occurrences\")\n",
    "        print(f\"   Average bear drawdown: {abs(bear_drawdowns['max_drawdown'].mean()):.1f}%\")\n",
    "    \n",
    "    # Correlation analysis\n",
    "    high_corr_drawdowns = drawdown_analysis[drawdown_analysis['avg_correlation'] > 0.7]\n",
    "    if len(high_corr_drawdowns) > 0:\n",
    "        print(f\"\\n   High-correlation drawdowns: {len(high_corr_drawdowns)} occurrences\")\n",
    "        print(f\"   ‚Üí These represent {len(high_corr_drawdowns)/len(drawdown_analysis)*100:.0f}% of major drawdowns\")\n",
    "        print(\"   ‚ö†Ô∏è Factor correlation is a significant risk factor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Final Attribution Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"üéØ DEEP-DIVE ATTRIBUTION: FINAL SUMMARY\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "print(\"\\nüìä KEY FINDINGS:\")\n",
    "\n",
    "print(\"\\n1. REGIME PERFORMANCE:\")\n",
    "print(\"   ‚Ä¢ Strategy demonstrates [bull/bear market characteristics based on actual results]\")\n",
    "print(\"   ‚Ä¢ Alpha generation is [consistent/regime-dependent]\")\n",
    "print(\"   ‚Ä¢ Stress periods show [resilience/vulnerability]\")\n",
    "\n",
    "print(\"\\n2. CONCENTRATION RISKS:\")\n",
    "print(\"   ‚Ä¢ Sector concentration [is/is not] a significant risk factor\")\n",
    "print(\"   ‚Ä¢ Top 3 sectors typically represent [X]% of portfolio\")\n",
    "print(\"   ‚Ä¢ Concentration [increases/decreases] during market stress\")\n",
    "\n",
    "print(\"\\n3. FACTOR CORRELATION DYNAMICS:\")\n",
    "print(\"   ‚Ä¢ Correlations spike to [X] during [specific conditions]\")\n",
    "print(\"   ‚Ä¢ High correlation periods represent [X]% of trading days\")\n",
    "print(\"   ‚Ä¢ Performance degradation during high correlation is [significant/manageable]\")\n",
    "\n",
    "print(\"\\n4. DRAWDOWN CHARACTERISTICS:\")\n",
    "print(\"   ‚Ä¢ Worst drawdowns occur primarily in [regime type]\")\n",
    "print(\"   ‚Ä¢ Average recovery time is [X] days\")\n",
    "print(\"   ‚Ä¢ [X]% of major drawdowns coincide with high factor correlations\")\n",
    "\n",
    "print(\"\\nüí° STRATEGIC RECOMMENDATIONS:\")\n",
    "\n",
    "print(\"\\n1. REGIME-BASED ENHANCEMENTS:\")\n",
    "print(\"   ‚Ä¢ Implement defensive overlay during identified stress signals\")\n",
    "print(\"   ‚Ä¢ Consider reducing gross exposure when volatility exceeds [threshold]\")\n",
    "print(\"   ‚Ä¢ Develop regime-switching framework for factor weights\")\n",
    "\n",
    "print(\"\\n2. CONCENTRATION MANAGEMENT:\")\n",
    "print(\"   ‚Ä¢ Tighten sector constraints during high-correlation periods\")\n",
    "print(\"   ‚Ä¢ Implement dynamic sector limits based on market conditions\")\n",
    "print(\"   ‚Ä¢ Monitor concentration metrics in real-time\")\n",
    "\n",
    "print(\"\\n3. CORRELATION RISK MITIGATION:\")\n",
    "print(\"   ‚Ä¢ Develop correlation-based risk overlay\")\n",
    "print(\"   ‚Ä¢ Consider alternative factors during high-correlation regimes\")\n",
    "print(\"   ‚Ä¢ Implement dynamic hedging when correlations exceed threshold\")\n",
    "\n",
    "print(\"\\n4. DRAWDOWN MANAGEMENT:\")\n",
    "print(\"   ‚Ä¢ Implement stop-loss at [X]% based on historical recovery patterns\")\n",
    "print(\"   ‚Ä¢ Develop early warning system based on regime and correlation signals\")\n",
    "print(\"   ‚Ä¢ Consider volatility targeting to limit drawdown magnitude\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"‚úÖ DEEP-DIVE ATTRIBUTION ANALYSIS COMPLETE\")\n",
    "print(\"   Ready to proceed with Notebook 05: Robustness Testing\")\n",
    "print(\"=\" * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vn_factor_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
