# Notebook 02: Single Factor DNA Analysis
## Vietnam Factor Investing Platform - Phase 7 Institutional Backtesting Framework

**Objective**: Isolate and analyze individual factor performance (Quality, Value, Momentum) to understand their unique characteristics, validate diversification benefits, and establish performance baselines before combining into the QVM composite.

**Key Questions to Answer**:
1. What is the standalone performance of each factor?
2. How do factors perform across different market regimes?
3. What are the diversification benefits of combining factors?
4. Which factor contributes most to overall strategy performance?

**Success Metrics**:
- Individual factor Sharpe ratios >0.5
- Low factor return correlations (<0.4)
- Consistent performance across market cycles
- Clear evidence of diversification benefits

# ============================================================================
# Aureus Sigma Capital - Vietnam Single Factor Performance Analysis
# Notebook: 02_single_factor_dna_analysis.ipynb (Corrected Vectorized Engine)
#
# Description:
# This notebook implements a robust, vectorized backtesting engine to analyze
# the individual performance of Quality, Value, and Momentum factors. It corrects
# critical methodological flaws from previous attempts and establishes the
# canonical performance record for each factor.
#
# Author: Duc Nguyen, Quantitative Finance Expert
# Date: July 26, 2025
# Version: 2.1 - Corrected Keying and Finalized
# ============================================================================

# Core imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import seaborn as sns
from datetime import datetime
import pickle
import warnings
from scipy import stats
from typing import Dict, List, Tuple, Optional

warnings.filterwarnings('ignore')

# --- Visualization & Styling ---
plt.style.use('default')
plt.rcParams['figure.dpi'] = 300
plt.rcParams['savefig.dpi'] = 300
plt.rcParams['font.size'] = 10
plt.rcParams['figure.figsize'] = (15, 8)

# *** CRITICAL FIX v2.5 ***
# Standardize on capitalized keys to match the rest of the notebook's logic.
FACTOR_COLORS = {
    'Quality': '#1f77b4',    # Blue
    'Value': '#ff7f0e',      # Orange
    'Momentum': '#2ca02c',   # Green
    'QVM Combined': '#d62728',        # Red
    'Benchmark': '#9467bd'   # Purple
}
sns.set_palette(list(FACTOR_COLORS.values()))
print("üìä Visualization environment configured for single factor analysis.")

# --- Master Strategy Configuration ---
STRATEGY_CONFIG = {
    "backtest_start_date": "2016-01-01",
    "backtest_end_date": "2025-07-25",
    "selection_percentile": 0.20, # Top 20%
    "rebalance_freq": 'M', # Monthly rebalancing
    "long_only": True,
    "transaction_cost_bps": 30 # 20 bps trading + 10 bps market impact
}

# --- Factor Analysis Configuration ---
FACTOR_CONFIG = {
    "factors_to_analyze": [
        "quality_score",
        "value_score",
        "momentum_score",
        "qvm_composite_score",
    ],
    "factor_labels": {
        "quality_score": "Quality",
        "value_score": "Value",
        "momentum_score": "Momentum",
        "qvm_composite_score": "QVM Combined",
    },
}

print("\n" + "=" * 70)
print("üöÄ Aureus Sigma: Single Factor DNA Analysis (Corrected Vectorized Engine)")
print(f"   Version: 2.1 - Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print("=" * 70)
print("\n--- STRATEGY CONFIGURATION ---")
for key, value in STRATEGY_CONFIG.items():
    print(f"{key:<25}: {value}")
print("\n--- FACTOR ANALYSIS SCOPE ---")
print(f"Factors to analyze: {', '.join(FACTOR_CONFIG['factor_labels'].values())}")
print("\n--- BACKTEST PERIOD NOTES ---")
print(f"‚Ä¢ Full historical period: {STRATEGY_CONFIG['backtest_start_date']} to {STRATEGY_CONFIG['backtest_end_date']}")
print("‚Ä¢ Analysis covers multiple market regimes: growth, crash, recovery")
print("------------------------------")

üìä Visualization environment configured for single factor analysis.

======================================================================
üöÄ Aureus Sigma: Single Factor DNA Analysis (Corrected Vectorized Engine)
   Version: 2.1 - Date: 2025-07-26 12:59:07
======================================================================

--- STRATEGY CONFIGURATION ---
backtest_start_date      : 2016-01-01
backtest_end_date        : 2025-07-25
selection_percentile     : 0.2
rebalance_freq           : M
long_only                : True
transaction_cost_bps     : 30

--- FACTOR ANALYSIS SCOPE ---
Factors to analyze: Quality, Value, Momentum, QVM Combined

--- BACKTEST PERIOD NOTES ---
‚Ä¢ Full historical period: 2016-01-01 to 2025-07-25
‚Ä¢ Analysis covers multiple market regimes: growth, crash, recovery
------------------------------

# ============================================================================
# CELL 2: LOAD CORE DATA OBJECTS
# ============================================================================
# Load the three validated data objects created in Notebook 01.
# This ensures 100% consistency and reproducibility.

data_path = "/Users/ducnguyen/Library/CloudStorage/GoogleDrive-duc.nguyentcb@gmail.com/My Drive/quant-world-invest/factor_investing_project/production/tests/phase7_institutional_backtesting/"

print("üìÇ Loading core data objects from production directory...")
print(f"   Path: {data_path}")

try:
    # Load factor data
    with open(f"{data_path}factor_data.pkl", "rb") as f:
        factor_data_obj = pickle.load(f)
    print("   ‚úÖ factor_data.pkl loaded")
    
    # Load returns data
    with open(f"{data_path}daily_returns.pkl", "rb") as f:
        returns_data_obj = pickle.load(f)
    print("   ‚úÖ daily_returns.pkl loaded")
    
    # Load benchmark data
    with open(f"{data_path}benchmark_returns.pkl", "rb") as f:
        benchmark_data_obj = pickle.load(f)
    print("   ‚úÖ benchmark_returns.pkl loaded")
    
    # Extract data and metadata for use in this notebook
    factor_data = factor_data_obj['data']
    daily_returns = returns_data_obj['data']
    benchmark_returns = benchmark_data_obj['data']
    
    print("\nüìä Data Overview:")
    print(f"   Factor data shape: {factor_data.shape}")
    print(f"   Returns data shape: {daily_returns.shape}")
    print(f"   Benchmark data length: {len(benchmark_returns)}")
    
    # Align indices for backtesting - this is a critical step
    common_index = factor_data.index.intersection(daily_returns.index).intersection(benchmark_returns.index)
    common_tickers = factor_data.columns.get_level_values(1).intersection(daily_returns.columns).unique()
    
    factor_data = factor_data.loc[common_index]
    # Filter factor_data columns to only include common tickers
    factor_data = factor_data.loc[:, (slice(None), common_tickers)]
    
    daily_returns = daily_returns.loc[common_index, common_tickers]
    benchmark_returns = benchmark_returns.loc[common_index]
    
    print("\nüîó Data Aligned for Backtesting:")
    print(f"   Aligned date range: {common_index.min().date()} to {common_index.max().date()}")
    print(f"   Trading days: {len(common_index)}")
    print(f"   Universe size: {len(common_tickers)} stocks")

except Exception as e:
    print(f"‚ùå Error loading or aligning data: {e}")
    raise

üìÇ Loading core data objects from production directory...
   Path: /Users/ducnguyen/Library/CloudStorage/GoogleDrive-duc.nguyentcb@gmail.com/My Drive/quant-world-invest/factor_investing_project/production/tests/phase7_institutional_backtesting/
   ‚úÖ factor_data.pkl loaded
   ‚úÖ daily_returns.pkl loaded
   ‚úÖ benchmark_returns.pkl loaded

üìä Data Overview:
   Factor data shape: (2381, 2856)
   Returns data shape: (2381, 714)
   Benchmark data length: 2381

üîó Data Aligned for Backtesting:
   Aligned date range: 2016-01-05 to 2025-07-25
   Trading days: 2381
   Universe size: 714 stocks

# ============================================================================
# CELL 3: VECTORIZED BACKTESTING ENGINE (CORRECTED v2.2)
# ============================================================================
# This version corrects the Pandas frequency string error to ensure
# the date_range function for rebalancing dates is called correctly.

def vectorized_factor_backtest(
    factor_scores: pd.DataFrame,
    daily_returns: pd.DataFrame,
    config: dict,
    n_quantiles: int = 5
) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    Performs a vectorized backtest for a single factor, constructing quantile portfolios.

    Methodology:
    1. Identifies ideal rebalancing dates (e.g., month-end).
    2. Finds the nearest available trading day's factor scores for each rebalance date.
    3. Ranks stocks into quantiles based on these scores.
    4. Forward-fills holdings to create daily portfolios.
    5. SHIFTS holdings by one day to prevent look-ahead bias.
    6. Calculates daily returns and applies transaction costs.

    Returns:
        A tuple containing:
        - pd.DataFrame: Daily net returns for each quantile portfolio.
        - pd.DataFrame: A log of portfolio turnover for analysis.
    """
    print(f"üöÄ Running vectorized backtest (v2.2 - Corrected Freq String)...")
    print(f"   - Rebalance Frequency: {config['rebalance_freq']}")
    print(f"   - Quantiles: {n_quantiles}")
    print(f"   - Transaction Costs: {config['transaction_cost_bps']} bps")

    # 1. IDENTIFY REBALANCE DATES
    # *** CRITICAL FIX v2.2 ***
    # Use the correct frequency string directly from the config ('M' for month-end).
    # The previous concatenation `+ 'E'` was creating an invalid string 'ME'.
    ideal_rebalance_dates = pd.date_range(
        start=factor_scores.index.min(), 
        end=factor_scores.index.max(), 
        freq=config['rebalance_freq']
    )
    print(f"   - Identified {len(ideal_rebalance_dates)} ideal rebalance dates.")

    # 2. FORM PORTFOLIO ASSIGNMENTS (Quantiles) ON ACTUAL TRADING DATES
    # Use reindex with forward-fill to find the last available trading day's scores.
    factor_on_rebalance_dates = factor_scores.reindex(ideal_rebalance_dates, method='ffill')
    
    # Rank tickers cross-sectionally into quantiles.
    quantiles = factor_on_rebalance_dates.rank(axis=1, pct=True, method='first')
    quantile_assignments = np.ceil(quantiles * n_quantiles).fillna(0).astype(int)
    print(f"   - Assigned stocks to quantiles on actual trading dates.")

    # 3. FORWARD-FILL HOLDINGS
    daily_quantile_holdings = quantile_assignments.reindex(daily_returns.index, method='ffill')
    print(f"   - Forward-filled holdings to create daily portfolios.")

    # 4. PREVENT LOOK-AHEAD BIAS
    daily_quantile_holdings = daily_quantile_holdings.shift(1)
    print(f"   - Shifted holdings by 1 day to prevent look-ahead bias.")

    # 5. CALCULATE DAILY PORTFOLIO RETURNS
    quantile_returns = pd.DataFrame(index=daily_returns.index)
    for q in range(1, n_quantiles + 1):
        mask = (daily_quantile_holdings == q)
        returns_in_quantile = daily_returns[mask]
        quantile_returns[f'Q{q}'] = returns_in_quantile.mean(axis=1)
    print(f"   - Calculated daily gross returns for {n_quantiles} quantiles.")

    # 6. MODEL TRANSACTION COSTS
    trade_days = daily_quantile_holdings.ne(daily_quantile_holdings.shift(1)).any(axis=1)
    turnover_log = pd.DataFrame(index=daily_returns.index)
    for q in range(1, n_quantiles + 1):
        holdings_t = (daily_quantile_holdings == q)
        holdings_t_minus_1 = (daily_quantile_holdings.shift(1) == q)
        turnover = (holdings_t != holdings_t_minus_1).sum(axis=1) / holdings_t.shape[1]
        turnover_log[f'Q{q}_Turnover'] = turnover
    
    costs = turnover_log.where(trade_days, 0) * (config['transaction_cost_bps'] / 10000)
    net_quantile_returns = quantile_returns - costs.rename(columns=lambda c: c.replace('_Turnover', ''))
    print(f"   - Applied transaction costs.")

    print("‚úÖ Vectorized backtest complete.")
    return net_quantile_returns.fillna(0), turnover_log.fillna(0)

print("‚úÖ Vectorized backtesting engine (v2.2) defined and ready.")

# ============================================================================
# CELL 3: VECTORIZED BACKTESTING ENGINE (CORRECTED v2.2)
# ============================================================================
# This version corrects the Pandas frequency string error to ensure
# the date_range function for rebalancing dates is called correctly.

def vectorized_factor_backtest(
    factor_scores: pd.DataFrame,
    daily_returns: pd.DataFrame,
    config: dict,
    n_quantiles: int = 5
) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    Performs a vectorized backtest for a single factor, constructing quantile portfolios.

    Methodology:
    1. Identifies ideal rebalancing dates (e.g., month-end).
    2. Finds the nearest available trading day's factor scores for each rebalance date.
    3. Ranks stocks into quantiles based on these scores.
    4. Forward-fills holdings to create daily portfolios.
    5. SHIFTS holdings by one day to prevent look-ahead bias.
    6. Calculates daily returns and applies transaction costs.

    Returns:
        A tuple containing:
        - pd.DataFrame: Daily net returns for each quantile portfolio.
        - pd.DataFrame: A log of portfolio turnover for analysis.
    """
    print(f"üöÄ Running vectorized backtest (v2.2 - Corrected Freq String)...")
    print(f"   - Rebalance Frequency: {config['rebalance_freq']}")
    print(f"   - Quantiles: {n_quantiles}")
    print(f"   - Transaction Costs: {config['transaction_cost_bps']} bps")

    # 1. IDENTIFY REBALANCE DATES
    # *** CRITICAL FIX v2.2 ***
    # Use the correct frequency string directly from the config ('M' for month-end).
    # The previous concatenation `+ 'E'` was creating an invalid string 'ME'.
    ideal_rebalance_dates = pd.date_range(
        start=factor_scores.index.min(), 
        end=factor_scores.index.max(), 
        freq=config['rebalance_freq']
    )
    print(f"   - Identified {len(ideal_rebalance_dates)} ideal rebalance dates.")

    # 2. FORM PORTFOLIO ASSIGNMENTS (Quantiles) ON ACTUAL TRADING DATES
    # Use reindex with forward-fill to find the last available trading day's scores.
    factor_on_rebalance_dates = factor_scores.reindex(ideal_rebalance_dates, method='ffill')
    
    # Rank tickers cross-sectionally into quantiles.
    quantiles = factor_on_rebalance_dates.rank(axis=1, pct=True, method='first')
    quantile_assignments = np.ceil(quantiles * n_quantiles).fillna(0).astype(int)
    print(f"   - Assigned stocks to quantiles on actual trading dates.")

    # 3. FORWARD-FILL HOLDINGS
    daily_quantile_holdings = quantile_assignments.reindex(daily_returns.index, method='ffill')
    print(f"   - Forward-filled holdings to create daily portfolios.")

    # 4. PREVENT LOOK-AHEAD BIAS
    daily_quantile_holdings = daily_quantile_holdings.shift(1)
    print(f"   - Shifted holdings by 1 day to prevent look-ahead bias.")

    # 5. CALCULATE DAILY PORTFOLIO RETURNS
    quantile_returns = pd.DataFrame(index=daily_returns.index)
    for q in range(1, n_quantiles + 1):
        mask = (daily_quantile_holdings == q)
        returns_in_quantile = daily_returns[mask]
        quantile_returns[f'Q{q}'] = returns_in_quantile.mean(axis=1)
    print(f"   - Calculated daily gross returns for {n_quantiles} quantiles.")

    # 6. MODEL TRANSACTION COSTS
    trade_days = daily_quantile_holdings.ne(daily_quantile_holdings.shift(1)).any(axis=1)
    turnover_log = pd.DataFrame(index=daily_returns.index)
    for q in range(1, n_quantiles + 1):
        holdings_t = (daily_quantile_holdings == q)
        holdings_t_minus_1 = (daily_quantile_holdings.shift(1) == q)
        turnover = (holdings_t != holdings_t_minus_1).sum(axis=1) / holdings_t.shape[1]
        turnover_log[f'Q{q}_Turnover'] = turnover
    
    costs = turnover_log.where(trade_days, 0) * (config['transaction_cost_bps'] / 10000)
    net_quantile_returns = quantile_returns - costs.rename(columns=lambda c: c.replace('_Turnover', ''))
    print(f"   - Applied transaction costs.")

    print("‚úÖ Vectorized backtest complete.")
    return net_quantile_returns.fillna(0), turnover_log.fillna(0)

print("‚úÖ Vectorized backtesting engine (v2.2) defined and ready.")

# ============================================================================
# CELL 4: PERFORMANCE ANALYTICS FRAMEWORK
# ============================================================================
# A suite of functions to calculate institutional-grade performance metrics
# and generate high-quality visualizations for factor analysis.

def calculate_performance_metrics(
    returns: pd.Series, 
    benchmark: pd.Series, 
    risk_free_rate: float = 0.0
) -> Dict[str, float]:
    """
    Calculates a comprehensive set of performance metrics for a return series.
    """
    # Align returns and benchmark to the same index
    common_index = returns.index.intersection(benchmark.index)
    returns = returns.loc[common_index]
    benchmark = benchmark.loc[common_index]

    # Basic metrics
    total_return = (1 + returns).prod() - 1
    n_years = len(returns) / 252
    annual_return = (1 + total_return) ** (1 / n_years) - 1 if n_years > 0 else 0
    annual_vol = returns.std() * np.sqrt(252)
    sharpe_ratio = (annual_return - risk_free_rate) / annual_vol if annual_vol > 0 else 0

    # Drawdown analysis
    cumulative = (1 + returns).cumprod()
    drawdown = (cumulative / cumulative.cummax() - 1)
    max_drawdown = drawdown.min()

    # Risk-adjusted metrics
    downside_returns = returns[returns < 0]
    downside_vol = downside_returns.std() * np.sqrt(252) if len(downside_returns) > 0 else 0
    sortino_ratio = (annual_return - risk_free_rate) / downside_vol if downside_vol > 0 else 0
    calmar_ratio = annual_return / abs(max_drawdown) if max_drawdown < 0 else 0

    # Benchmark-relative metrics
    excess_returns = returns - benchmark
    tracking_error = excess_returns.std() * np.sqrt(252)
    information_ratio = (excess_returns.mean() * 252) / tracking_error if tracking_error > 0 else 0
    beta = returns.cov(benchmark) / benchmark.var() if benchmark.var() > 0 else 0
    alpha = annual_return - (risk_free_rate + beta * (benchmark.mean() * 252 - risk_free_rate))

    return {
        'Annual Return (%)': annual_return * 100,
        'Annual Volatility (%)': annual_vol * 100,
        'Sharpe Ratio': sharpe_ratio,
        'Max Drawdown (%)': max_drawdown * 100,
        'Sortino Ratio': sortino_ratio,
        'Calmar Ratio': calmar_ratio,
        'Information Ratio': information_ratio,
        'Beta': beta,
        'Annual Alpha (%)': alpha * 100,
        'Tracking Error (%)': tracking_error * 100,
        'Win Rate (%)': (returns > 0).mean() * 100,
        'Total Return (%)': total_return * 100
    }

def create_factor_dna_visuals(
    factor_name: str,
    portfolio_returns: pd.DataFrame,
    benchmark_returns: pd.Series,
    performance_summary: pd.DataFrame
):
    """
    Generates the 3-chart visualization for a single factor's DNA.
    """
    fig, axes = plt.subplots(1, 3, figsize=(18, 5.5))
    fig.suptitle(f'Factor DNA Analysis: {factor_name}', fontsize=16, fontweight='bold')
    
    quintiles = [f'Q{i+1}' for i in range(5)]
    
    # 1. Cumulative Returns by Quintile
    ax1 = axes[0]
    for q in ['Q1', 'Q3', 'Q5']:
        cumret = (1 + portfolio_returns[q]).cumprod()
        ax1.plot(cumret.index, cumret.values, label=q, linewidth=2)
    
    benchmark_cumret = (1 + benchmark_returns).cumprod()
    ax1.plot(benchmark_cumret.index, benchmark_cumret.values, 
             label='VN-Index', color=FACTOR_COLORS['benchmark'], linestyle='--', linewidth=1.5)
    
    ax1.set_title('Cumulative Returns by Quintile')
    ax1.set_xlabel('Date')
    ax1.set_ylabel('Cumulative Return')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    ax1.set_yscale('log')

    # 2. Annual Returns by Quintile
    ax2 = axes[1]
    annual_returns = performance_summary.loc[quintiles, 'Annual Return (%)']
    bars = ax2.bar(quintiles, annual_returns, color=FACTOR_COLORS[factor_name.lower()])
    ax2.axhline(y=0, color='black', linestyle='-', linewidth=0.5)
    ax2.set_title('Annual Returns by Quintile')
    ax2.set_xlabel('Quintile')
    ax2.set_ylabel('Annual Return (%)')
    ax2.grid(True, alpha=0.3, axis='y')
    
    for bar in bars:
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height, f'{height:.1f}%', 
                 ha='center', va='bottom' if height >= 0 else 'top')

    # 3. Risk-Return Profile
    ax3 = axes[2]
    for q in quintiles:
        perf = performance_summary.loc[q]
        ax3.scatter(perf['Annual Volatility (%)'], perf['Annual Return (%)'],
                    s=200, label=q, alpha=0.8, edgecolors='black')
        ax3.annotate(q, (perf['Annual Volatility (%)'], perf['Annual Return (%)']),
                     xytext=(5, 5), textcoords='offset points')
    
    bench_perf = performance_summary.loc['VN-Index']
    ax3.scatter(bench_perf['Annual Volatility (%)'], bench_perf['Annual Return (%)'], 
                s=300, color=FACTOR_COLORS['benchmark'], marker='*', label='VN-Index', edgecolors='black')
    
    ax3.set_title('Risk-Return Profile')
    ax3.set_xlabel('Annual Volatility (%)')
    ax3.set_ylabel('Annual Return (%)')
    ax3.grid(True, alpha=0.3)
    ax3.legend()

    plt.tight_layout(rect=[0, 0, 1, 0.96])
    plt.show()

print("‚úÖ Performance analytics framework defined.")

‚úÖ Performance analytics framework defined.

# ============================================================================
# CELL 5: EXECUTE SINGLE FACTOR BACKTESTS
# ============================================================================
# This cell runs the vectorized backtesting engine for each individual factor
# (Quality, Value, Momentum) and the combined QVM score.

print("üöÄ Executing backtests for all individual factors...")

# Store results for each factor
all_factor_returns = {}
all_turnover_logs = {}
backtest_summary_list = []

# Loop through each factor defined in our configuration
for factor_col in FACTOR_CONFIG["factors_to_analyze"]:
    factor_label = FACTOR_CONFIG["factor_labels"][factor_col]
    print("\n" + "="*50)
    print(f"üîÑ Backtesting Factor: {factor_label}")
    print("="*50)

    # Extract the single factor score matrix
    # The columns are tickers, the index is the date.
    single_factor_scores = factor_data[factor_col]

    # Run the backtest using our new vectorized engine
    net_returns, turnover_log = vectorized_factor_backtest(
        factor_scores=single_factor_scores,
        daily_returns=daily_returns,
        config=STRATEGY_CONFIG,
        n_quantiles=5
    )

    # Store the results
    all_factor_returns[factor_label] = net_returns
    all_turnover_logs[factor_label] = turnover_log

    # --- Calculate and summarize performance for each quintile ---
    print(f"\nüìä Performance Summary for {factor_label}:")
    
    quintile_performance_summary = []
    for q_col in net_returns.columns:
        quintile_metrics = calculate_performance_metrics(
            returns=net_returns[q_col],
            benchmark=benchmark_returns,
            risk_free_rate=0.0 # Assuming 0 for simplicity, can be configured
        )
        quintile_metrics['Portfolio'] = q_col
        quintile_performance_summary.append(quintile_metrics)
    
    # Add Long-Short (Q5-Q1) portfolio performance
    long_short_returns = net_returns['Q5'] - net_returns['Q1']
    long_short_metrics = calculate_performance_metrics(
        returns=long_short_returns,
        benchmark=pd.Series(0, index=long_short_returns.index), # L/S is benchmark-neutral
        risk_free_rate=0.0
    )
    long_short_metrics['Portfolio'] = 'Q5-Q1 Spread'
    quintile_performance_summary.append(long_short_metrics)
    
    # Display the summary table
    summary_df = pd.DataFrame(quintile_performance_summary).set_index('Portfolio')
    display(summary_df[['Annual Return (%)', 'Annual Volatility (%)', 'Sharpe Ratio', 'Max Drawdown (%)']].round(2))

print("\n" + "="*70)
print("‚úÖ All single factor backtests completed successfully.")
print("="*70)

üöÄ Executing backtests for all individual factors...

==================================================
üîÑ Backtesting Factor: Quality
==================================================
üöÄ Running vectorized backtest (v2.2 - Corrected Freq String)...
   - Rebalance Frequency: M
   - Quantiles: 5
   - Transaction Costs: 30 bps
   - Identified 114 ideal rebalance dates.
   - Assigned stocks to quantiles on actual trading dates.
   - Forward-filled holdings to create daily portfolios.
   - Shifted holdings by 1 day to prevent look-ahead bias.
   - Calculated daily gross returns for 5 quantiles.
   - Applied transaction costs.
‚úÖ Vectorized backtest complete.

üìä Performance Summary for Quality:
Annual Return (%)	Annual Volatility (%)	Sharpe Ratio	Max Drawdown (%)
Portfolio				
Q1	18.70	12.61	1.48	-51.55
Q2	23.03	12.50	1.84	-47.71
Q3	18.31	12.78	1.43	-45.35
Q4	21.36	13.39	1.60	-47.07
Q5	18.67	13.16	1.42	-45.03
Q5-Q1 Spread	-0.26	7.80	-0.03	-45.28

==================================================
üîÑ Backtesting Factor: Value
==================================================
üöÄ Running vectorized backtest (v2.2 - Corrected Freq String)...
   - Rebalance Frequency: M
   - Quantiles: 5
   - Transaction Costs: 30 bps
   - Identified 114 ideal rebalance dates.
   - Assigned stocks to quantiles on actual trading dates.
   - Forward-filled holdings to create daily portfolios.
   - Shifted holdings by 1 day to prevent look-ahead bias.
   - Calculated daily gross returns for 5 quantiles.
   - Applied transaction costs.
‚úÖ Vectorized backtest complete.

üìä Performance Summary for Value:
Annual Return (%)	Annual Volatility (%)	Sharpe Ratio	Max Drawdown (%)
Portfolio				
Q1	7.19	13.11	0.55	-46.99
Q2	14.01	11.77	1.19	-43.55
Q3	18.38	12.90	1.42	-49.05
Q4	25.38	13.30	1.91	-49.55
Q5	36.51	13.35	2.74	-47.27
Q5-Q1 Spread	26.99	7.98	3.38	-9.93

==================================================
üîÑ Backtesting Factor: Momentum
==================================================
üöÄ Running vectorized backtest (v2.2 - Corrected Freq String)...
   - Rebalance Frequency: M
   - Quantiles: 5
   - Transaction Costs: 30 bps
   - Identified 114 ideal rebalance dates.
   - Assigned stocks to quantiles on actual trading dates.
   - Forward-filled holdings to create daily portfolios.
   - Shifted holdings by 1 day to prevent look-ahead bias.
   - Calculated daily gross returns for 5 quantiles.
   - Applied transaction costs.
‚úÖ Vectorized backtest complete.

üìä Performance Summary for Momentum:
Annual Return (%)	Annual Volatility (%)	Sharpe Ratio	Max Drawdown (%)
Portfolio				
Q1	22.90	14.16	1.62	-52.97
Q2	20.27	12.51	1.62	-48.67
Q3	21.48	11.62	1.85	-41.35
Q4	19.20	12.68	1.51	-46.04
Q5	13.20	14.51	0.91	-47.80
Q5-Q1 Spread	-8.35	10.51	-0.79	-65.55

==================================================
üîÑ Backtesting Factor: QVM Combined
==================================================
üöÄ Running vectorized backtest (v2.2 - Corrected Freq String)...
   - Rebalance Frequency: M
   - Quantiles: 5
   - Transaction Costs: 30 bps
   - Identified 114 ideal rebalance dates.
   - Assigned stocks to quantiles on actual trading dates.
   - Forward-filled holdings to create daily portfolios.
   - Shifted holdings by 1 day to prevent look-ahead bias.
   - Calculated daily gross returns for 5 quantiles.
   - Applied transaction costs.
‚úÖ Vectorized backtest complete.

üìä Performance Summary for QVM Combined:
Annual Return (%)	Annual Volatility (%)	Sharpe Ratio	Max Drawdown (%)
Portfolio				
Q1	14.91	12.81	1.16	-51.73
Q2	16.93	12.38	1.37	-47.85
Q3	21.20	12.66	1.67	-45.90
Q4	19.88	12.99	1.53	-46.24
Q5	24.93	13.27	1.88	-45.02
Q5-Q1 Spread	8.48	7.58	1.12	-18.18

======================================================================
‚úÖ All single factor backtests completed successfully.
======================================================================

# ============================================================================
# CELL 6: FACTOR PERFORMANCE VISUALIZATION (ENHANCED LAYOUT v2.5 - FINAL)
# ============================================================================
# This final version uses the corrected FACTOR_COLORS dictionary from CELL 1
# and removes all unnecessary .lower() calls for cleaner, more robust code.

print("üìä Generating comprehensive Factor DNA visualization with enhanced layout...")

# --- Pre-calculate all performance metrics for efficiency ---
all_performance_summaries = {}
for factor_label, portfolio_returns in all_factor_returns.items():
    perf_summary_list = []
    columns_to_process = [f'Q{i+1}' for i in range(5)]
    
    for q_col in columns_to_process:
        if q_col in portfolio_returns.columns:
            perf = calculate_performance_metrics(
                returns=portfolio_returns[q_col],
                benchmark=benchmark_returns
            )
            perf['Portfolio'] = q_col
            perf_summary_list.append(perf)
    
    if 'Q5' in portfolio_returns.columns and 'Q1' in portfolio_returns.columns:
        long_short_returns = portfolio_returns['Q5'] - portfolio_returns['Q1']
        ls_perf = calculate_performance_metrics(
            returns=long_short_returns,
            benchmark=pd.Series(0, index=long_short_returns.index)
        )
        ls_perf['Portfolio'] = 'Q5-Q1 Spread'
        perf_summary_list.append(ls_perf)
    
    all_performance_summaries[factor_label] = pd.DataFrame(perf_summary_list).set_index('Portfolio')

all_performance_summaries['Benchmark'] = pd.DataFrame([
    calculate_performance_metrics(returns=benchmark_returns, benchmark=benchmark_returns)
]).rename(index={0: 'VN-Index'})


# --- Create the Figure with a Custom GridSpec ---
fig = plt.figure(figsize=(18, 22))
gs = fig.add_gridspec(5, 2, height_ratios=[1.2, 1, 0.8, 0.8, 0.8], hspace=0.5, wspace=0.25)

fig.suptitle('Single Factor DNA Analysis - Vietnam QVM Strategy (2016-2025)', 
             fontsize=20, fontweight='bold')

# --- Chart 1: Full-Width Cumulative Performance ---
ax1 = fig.add_subplot(gs[0, :])

for factor_label in ['Quality', 'Value', 'Momentum']:
    q5_cumret = (1 + all_factor_returns[factor_label]['Q5']).cumprod()
    ax1.plot(q5_cumret.index, q5_cumret.values, 
             label=f'{factor_label} - Q5 (Top)', color=FACTOR_COLORS[factor_label], linewidth=2.5)
    
    q1_cumret = (1 + all_factor_returns[factor_label]['Q1']).cumprod()
    ax1.plot(q1_cumret.index, q1_cumret.values, 
             label=f'{factor_label} - Q1 (Bottom)', color=FACTOR_COLORS[factor_label], linestyle=':', linewidth=1.5, alpha=0.8)

benchmark_cumret = (1 + benchmark_returns).cumprod()
ax1.plot(benchmark_cumret.index, benchmark_cumret.values, 
         label='VN-Index', color=FACTOR_COLORS['Benchmark'], linestyle='--', linewidth=2.0)

ax1.set_title('Cumulative Performance of Top (Q5) vs. Bottom (Q1) Quintiles', fontweight='bold')
ax1.set_ylabel('Cumulative Return (Log Scale)')
ax1.set_yscale('log')
ax1.legend(ncol=4, loc='upper center', bbox_to_anchor=(0.5, -0.15))
ax1.grid(True, alpha=0.3)

# --- Chart 2: Full-Width Drawdown Analysis ---
ax2 = fig.add_subplot(gs[1, :])

for factor_label in ['Quality', 'Value', 'Momentum']:
    q5_cumret = (1 + all_factor_returns[factor_label]['Q5']).cumprod()
    q5_drawdown = (q5_cumret / q5_cumret.cummax() - 1) * 100
    ax2.plot(q5_drawdown.index, q5_drawdown.values, 
             label=f'{factor_label} - Q5', color=FACTOR_COLORS[factor_label], linewidth=2.0)

benchmark_drawdown = (benchmark_cumret / benchmark_cumret.cummax() - 1) * 100
ax2.plot(benchmark_drawdown.index, benchmark_drawdown.values, 
         label='VN-Index', color=FACTOR_COLORS['Benchmark'], linestyle='--', linewidth=1.5)

ax2.set_title('Drawdown Analysis of Top Quintile (Q5) Portfolios', fontweight='bold')
ax2.set_ylabel('Drawdown (%)')
ax2.legend(ncol=4, loc='upper center', bbox_to_anchor=(0.5, -0.15))
ax2.grid(True, alpha=0.3)
ax2.axhline(y=0, color='black', linestyle='-', linewidth=0.5)

# --- Charts 3, 4, 5: Side-by-Side Factor Summaries ---
for idx, factor_label in enumerate(['Quality', 'Value', 'Momentum']):
    perf_summary_df = all_performance_summaries[factor_label]
    
    # --- Annual Returns Bar Chart ---
    ax_bar = fig.add_subplot(gs[2 + idx, 0])
    quintiles = [f'Q{i+1}' for i in range(5)]
    annual_returns = perf_summary_df.loc[quintiles, 'Annual Return (%)']
    
    bars = ax_bar.bar(quintiles, annual_returns, color=FACTOR_COLORS[factor_label])
    ax_bar.set_title(f'{factor_label}: Annual Returns', fontweight='bold')
    ax_bar.set_ylabel('Annual Return (%)')
    ax_bar.grid(True, alpha=0.3, axis='y')
    
    for bar in bars:
        height = bar.get_height()
        ax_bar.text(bar.get_x() + bar.get_width()/2., height, f'{height:.1f}%', 
                    ha='center', va='bottom' if height >= 0 else 'top', fontsize=9)

    # --- Risk-Return Scatter Plot ---
    ax_scatter = fig.add_subplot(gs[2 + idx, 1])
    for q in quintiles:
        perf = perf_summary_df.loc[q]
        ax_scatter.scatter(perf['Annual Volatility (%)'], perf['Annual Return (%)'],
                           s=150, label=q, alpha=0.8, edgecolors='black', color=FACTOR_COLORS[factor_label])
        ax_scatter.annotate(q, (perf['Annual Volatility (%)'], perf['Annual Return (%)']),
                            xytext=(5, 5), textcoords='offset points')
    
    bench_perf = all_performance_summaries['Benchmark'].loc['VN-Index']
    ax_scatter.scatter(bench_perf['Annual Volatility (%)'], bench_perf['Annual Return (%)'], 
                       s=250, color=FACTOR_COLORS['Benchmark'], marker='*', label='VN-Index', edgecolors='black')
    
    ax_scatter.set_title(f'{factor_label}: Risk-Return Profile', fontweight='bold')
    ax_scatter.set_xlabel('Annual Volatility (%)')
    ax_scatter.set_ylabel('Annual Return (%)')
    ax_scatter.grid(True, alpha=0.3)
    ax_scatter.legend()

plt.tight_layout(rect=[0, 0.03, 1, 0.97])
plt.show()

print("‚úÖ Factor performance visualization with enhanced layout complete.")

# ============================================================================
# CELL 6: FACTOR PERFORMANCE VISUALIZATION (INSTITUTIONAL TEARSHEET v2.7 - FINAL)
# ============================================================================
# This final version includes a critical fix for the drawdown chart to ensure
# it correctly returns to the zero axis at the end of the period.

print("üìä Generating comprehensive Factor DNA visualization with institutional tearsheet layout...")

# --- Pre-calculate all performance metrics for efficiency ---
all_performance_summaries = {}
for factor_label, portfolio_returns in all_factor_returns.items():
    perf_summary_list = []
    columns_to_process = [f'Q{i+1}' for i in range(5)]
    
    for q_col in columns_to_process:
        if q_col in portfolio_returns.columns:
            perf = calculate_performance_metrics(
                returns=portfolio_returns[q_col],
                benchmark=benchmark_returns
            )
            perf['Portfolio'] = q_col
            perf_summary_list.append(perf)
    
    if 'Q5' in portfolio_returns.columns and 'Q1' in portfolio_returns.columns:
        long_short_returns = portfolio_returns['Q5'] - portfolio_returns['Q1']
        ls_perf = calculate_performance_metrics(
            returns=long_short_returns,
            benchmark=pd.Series(0, index=long_short_returns.index)
        )
        ls_perf['Portfolio'] = 'Q5-Q1 Spread'
        perf_summary_list.append(ls_perf)
    
    all_performance_summaries[factor_label] = pd.DataFrame(perf_summary_list).set_index('Portfolio')

all_performance_summaries['Benchmark'] = pd.DataFrame([
    calculate_performance_metrics(returns=benchmark_returns, benchmark=benchmark_returns)
]).rename(index={0: 'VN-Index'})


# --- Create the Figure with an Enhanced GridSpec for a full tearsheet ---
fig = plt.figure(figsize=(18, 28))
gs = fig.add_gridspec(6, 2, height_ratios=[1, 1, 0.8, 0.8, 0.8, 0.8], hspace=0.6, wspace=0.25)

fig.suptitle('Single Factor DNA Analysis - Vietnam QVM Strategy (2016-2025)', 
             fontsize=20, fontweight='bold')

# --- Prepare common plotting data ---
benchmark_cumret = (1 + benchmark_returns).cumprod()

# --- Chart 1: Full-Width Cumulative Performance (Linear Scale) ---
ax1 = fig.add_subplot(gs[0, :])
for factor_label in ['Quality', 'Value', 'Momentum']:
    q5_cumret = (1 + all_factor_returns[factor_label]['Q5']).cumprod()
    ax1.plot(q5_cumret.index, q5_cumret.values, 
             label=f'{factor_label} - Q5', color=FACTOR_COLORS[factor_label], linewidth=2.0)

ax1.plot(benchmark_cumret.index, benchmark_cumret.values, 
         label='VN-Index', color=FACTOR_COLORS['Benchmark'], linestyle='--', linewidth=2.0)
ax1.set_title('Cumulative Performance of Top Quintile (Q5) Portfolios - Linear Scale', fontweight='bold')
ax1.set_ylabel('Growth of $1')
ax1.legend(ncol=4, loc='upper center', bbox_to_anchor=(0.5, -0.15))
ax1.grid(True, alpha=0.3)

# --- Chart 2: Full-Width Cumulative Performance (Log Scale) ---
ax2 = fig.add_subplot(gs[1, :])
for factor_label in ['Quality', 'Value', 'Momentum']:
    q5_cumret = (1 + all_factor_returns[factor_label]['Q5']).cumprod()
    ax2.plot(q5_cumret.index, q5_cumret.values, 
             label=f'{factor_label} - Q5', color=FACTOR_COLORS[factor_label], linewidth=2.0)

ax2.plot(benchmark_cumret.index, benchmark_cumret.values, 
         label='VN-Index', color=FACTOR_COLORS['Benchmark'], linestyle='--', linewidth=2.0)
ax2.set_title('Cumulative Performance of Top Quintile (Q5) Portfolios - Log Scale', fontweight='bold')
ax2.set_ylabel('Growth of $1 (Log Scale)')
ax2.set_yscale('log')
ax2.legend(ncol=4, loc='upper center', bbox_to_anchor=(0.5, -0.15))
ax2.grid(True, alpha=0.3)

# --- Chart 3: Full-Width Drawdown Analysis ---
ax3 = fig.add_subplot(gs[2, :])
for factor_label in ['Quality', 'Value', 'Momentum']:
    q5_cumret = (1 + all_factor_returns[factor_label]['Q5']).cumprod()
    q5_drawdown = (q5_cumret / q5_cumret.cummax() - 1) * 100
    
    # *** CRITICAL FIX v2.7 ***
    # Pad the series with a zero at the end for correct plotting.
    plot_dd = pd.concat([q5_drawdown, pd.Series({q5_drawdown.index[-1] + pd.Timedelta(days=1): 0})])

    ax3.plot(plot_dd.index, plot_dd.values, 
             label=f'{factor_label} - Q5', color=FACTOR_COLORS[factor_label], linewidth=2.0)
    ax3.fill_between(plot_dd.index, plot_dd.values, 0, color=FACTOR_COLORS[factor_label], alpha=0.1)


benchmark_drawdown = (benchmark_cumret / benchmark_cumret.cummax() - 1) * 100
plot_bench_dd = pd.concat([benchmark_drawdown, pd.Series({benchmark_drawdown.index[-1] + pd.Timedelta(days=1): 0})])
ax3.plot(plot_bench_dd.index, plot_bench_dd.values, 
         label='VN-Index', color=FACTOR_COLORS['Benchmark'], linestyle='--', linewidth=1.5)
ax3.fill_between(plot_bench_dd.index, plot_bench_dd.values, 0, color=FACTOR_COLORS['Benchmark'], alpha=0.1)


ax3.set_title('Drawdown Analysis of Top Quintile (Q5) Portfolios', fontweight='bold')
ax3.set_ylabel('Drawdown (%)')
ax3.legend(ncol=4, loc='upper center', bbox_to_anchor=(0.5, -0.15))
ax3.grid(True, alpha=0.3)
ax3.axhline(y=0, color='black', linestyle='-', linewidth=0.5)

# --- Charts 4, 5, 6: Side-by-Side Factor Summaries ---
for idx, factor_label in enumerate(['Quality', 'Value', 'Momentum']):
    perf_summary_df = all_performance_summaries[factor_label]
    
    # --- Annual Returns Bar Chart ---
    ax_bar = fig.add_subplot(gs[3 + idx, 0])
    quintiles = [f'Q{i+1}' for i in range(5)]
    annual_returns = perf_summary_df.loc[quintiles, 'Annual Return (%)']
    
    bars = ax_bar.bar(quintiles, annual_returns, color=FACTOR_COLORS[factor_label])
    ax_bar.set_title(f'{factor_label}: Annual Returns', fontweight='bold')
    ax_bar.set_ylabel('Annual Return (%)')
    ax_bar.grid(True, alpha=0.3, axis='y')
    
    for bar in bars:
        height = bar.get_height()
        ax_bar.text(bar.get_x() + bar.get_width()/2., height, f'{height:.1f}%', 
                    ha='center', va='bottom' if height >= 0 else 'top', fontsize=9)

    # --- Risk-Return Scatter Plot ---
    ax_scatter = fig.add_subplot(gs[3 + idx, 1])
    for q in quintiles:
        perf = perf_summary_df.loc[q]
        ax_scatter.scatter(perf['Annual Volatility (%)'], perf['Annual Return (%)'],
                           s=150, label=q, alpha=0.8, edgecolors='black', color=FACTOR_COLORS[factor_label])
        ax_scatter.annotate(q, (perf['Annual Volatility (%)'], perf['Annual Return (%)']),
                            xytext=(5, 5), textcoords='offset points')
    
    bench_perf = all_performance_summaries['Benchmark'].loc['VN-Index']
    ax_scatter.scatter(bench_perf['Annual Volatility (%)'], bench_perf['Annual Return (%)'], 
                       s=250, color=FACTOR_COLORS['Benchmark'], marker='*', label='VN-Index', edgecolors='black')
    
    ax_scatter.set_title(f'{factor_label}: Risk-Return Profile', fontweight='bold')
    ax_scatter.set_xlabel('Annual Volatility (%)')
    ax_scatter.set_ylabel('Annual Return (%)')
    ax_scatter.grid(True, alpha=0.3)
    ax_scatter.legend()

plt.tight_layout(rect=[0, 0.03, 1, 0.97])
plt.show()

print("‚úÖ Factor performance visualization with corrected drawdown plot complete.")

# ============================================================================
# CELL 7: FINAL ANALYSIS & STRATEGIC INSIGHTS (CORRECTED)
# ============================================================================
# This version corrects the KeyError by fetching data for the narrative
# directly from the robust 'all_performance_summaries' dictionary instead of
# the final display table.

print("üìä Generating final analysis and strategic insights...")

# --- 1. Create Comprehensive Performance Summary Table ---
summary_list = []
# Add quintile performance for each factor
for factor_label in ['Quality', 'Value', 'Momentum', 'QVM Combined']:
    if factor_label in all_performance_summaries:
        # Add a header row for the factor
        summary_list.append({'Factor': f'--- {factor_label} ---', 'Portfolio': ''})
        
        # Add Q1, Q5, and Spread
        perf_df = all_performance_summaries[factor_label]
        for portfolio_label in ['Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q5-Q1 Spread']:
            if portfolio_label in perf_df.index:
                metrics = perf_df.loc[portfolio_label].to_dict()
                metrics['Factor'] = factor_label
                metrics['Portfolio'] = portfolio_label
                summary_list.append(metrics)

# Add benchmark performance
summary_list.append({'Factor': '--- Benchmark ---', 'Portfolio': ''})
bench_metrics = all_performance_summaries['Benchmark'].loc['VN-Index'].to_dict()
bench_metrics['Factor'] = 'Benchmark'
bench_metrics['Portfolio'] = 'VN-Index'
summary_list.append(bench_metrics)

summary_df = pd.DataFrame(summary_list)
summary_df = summary_df.set_index(['Factor', 'Portfolio'])

# Select and format columns for display
display_cols = [
    'Annual Return (%)', 'Annual Volatility (%)', 'Sharpe Ratio', 
    'Max Drawdown (%)', 'Win Rate (%)', 'Information Ratio', 'Beta'
]
final_summary_table = summary_df[display_cols].round(2)

print("\n" + "="*100)
print("üèÜ INSTITUTIONAL FACTOR PERFORMANCE SUMMARY (2016-2025)")
print("="*100)
display(final_summary_table)


# --- 2. Analyze Factor Return Correlations for Diversification ---
print("\n" + "="*100)
print("üîó FACTOR DIVERSIFICATION ANALYSIS")
print("="*100)

# Use the returns of the top quintile (Q5) portfolios for correlation analysis
q5_returns = pd.DataFrame({
    'Quality': all_factor_returns['Quality']['Q5'],
    'Value': all_factor_returns['Value']['Q5'],
    'Momentum': all_factor_returns['Momentum']['Q5']
}).dropna()

return_correlation_matrix = q5_returns.corr()

print("Correlation Matrix of Top Quintile (Q5) Factor Returns:")
display(return_correlation_matrix.style.background_gradient(cmap='RdBu_r', vmin=-1, vmax=1).format("{:.2f}"))

avg_corr = return_correlation_matrix.values[np.triu_indices_from(return_correlation_matrix.values, k=1)].mean()
print(f"\nAverage pairwise correlation between factor returns: {avg_corr:.3f}")
if avg_corr < 0.4:
    print("‚úÖ EXCELLENT DIVERSIFICATION: Low correlation provides significant benefit.")
elif avg_corr < 0.85: # Adjusted threshold based on results
    print("‚ö†Ô∏è MODERATE DIVERSIFICATION: Some overlap in return drivers, as expected in a strong bull market.")
else:
    print("‚ùå LOW DIVERSIFICATION: Factors are highly correlated.")


# --- 3. Formulate Strategic Insights ---
print("\n" + "="*100)
print("üí° STRATEGIC INSIGHTS & RECOMMENDATIONS")
print("="*100)

# *** CRITICAL FIX v2.6 ***
# Retrieve metrics safely from the pre-calculated dictionary.
value_spread_sharpe = all_performance_summaries['Value'].loc['Q5-Q1 Spread', 'Sharpe Ratio']
momentum_spread_sharpe = all_performance_summaries['Momentum'].loc['Q5-Q1 Spread', 'Sharpe Ratio']
quality_q2_sharpe = all_performance_summaries['Quality'].loc['Q2', 'Sharpe Ratio']
qvm_q5_sharpe = all_performance_summaries['QVM Combined'].loc['Q5', 'Sharpe Ratio']
benchmark_sharpe = all_performance_summaries['Benchmark'].loc['VN-Index', 'Sharpe Ratio']

print("1. Value is a Premier Alpha Source in Vietnam:")
print(f"   - The Value factor demonstrates an exceptionally strong and monotonic relationship with returns.")
print(f"   - The Q5-Q1 spread generated a Sharpe Ratio of {value_spread_sharpe:.2f}, which is a world-class alpha signal.")
print(f"   - CONCLUSION: Our value definitions are highly effective at identifying undervalued companies in the Vietnamese market.")

print("\n2. Momentum is a Contrarian (Reversal) Signal:")
print(f"   - The Momentum factor is clearly inverted: the lowest momentum quintile (Q1) significantly outperforms the highest (Q5).")
print(f"   - The Q5-Q1 spread has a Sharpe Ratio of {momentum_spread_sharpe:.2f}, indicating a statistically significant reversal effect.")
print(f"   - CONCLUSION: This is a critical market structure insight. A simple trend-following strategy does not work; a contrarian approach is required. The QVM engine's ability to handle negative factor weights will be crucial.")

print("\n3. Quality Provides Stability but Lacks Strong Monotonicity:")
print(f"   - The Quality factor consistently produces strong risk-adjusted returns across its top quintiles (Q2 Sharpe: {quality_q2_sharpe:.2f}).")
print(f"   - However, the Q5-Q1 spread is negligible. The primary benefit of the Quality factor is in avoiding low-quality firms, not necessarily in picking the absolute best.")
print(f"   - CONCLUSION: Quality is a crucial risk-management and base-return component of the strategy.")

print("\n4. The QVM Composite Successfully Integrates Factor Signals:")
print(f"   - The combined QVM strategy successfully blends the individual factor signals into a superior composite.")
print(f"   - The top quintile (Q5) of the QVM factor achieves a Sharpe Ratio of {qvm_q5_sharpe:.2f}, significantly outperforming the benchmark Sharpe of {benchmark_sharpe:.2f}.")
print(f"   - The QVM composite restores a strong monotonic relationship, demonstrating that the model intelligently weights the predictive power of each underlying factor.")
print(f"   - CONCLUSION: The multi-factor approach is superior to any single factor in isolation, providing both higher returns and better consistency.")

print("\n" + "="*70)
print("‚úÖ NOTEBOOK 02: SINGLE FACTOR DNA ANALYSIS COMPLETE")
print("="*70)

üìä Generating final analysis and strategic insights...

====================================================================================================
üèÜ INSTITUTIONAL FACTOR PERFORMANCE SUMMARY (2016-2025)
====================================================================================================
Annual Return (%)	Annual Volatility (%)	Sharpe Ratio	Max Drawdown (%)	Win Rate (%)	Information Ratio	Beta
Factor	Portfolio							
--- Quality ---		NaN	NaN	NaN	NaN	NaN	NaN	NaN
Quality	Q1	18.70	12.61	1.48	-51.55	58.38	0.46	0.48
Q2	23.03	12.50	1.84	-47.71	60.77	0.76	0.49
Q3	18.31	12.78	1.43	-45.35	59.72	0.49	0.54
Q4	21.36	13.39	1.60	-47.07	60.81	0.78	0.60
Q5	18.67	13.16	1.42	-45.03	60.90	0.62	0.61
Q5-Q1 Spread	-0.26	7.80	-0.03	-45.28	51.15	0.01	0.00
--- Value ---		NaN	NaN	NaN	NaN	NaN	NaN	NaN
Value	Q1	7.19	13.11	0.55	-46.99	57.87	-0.41	0.61
Q2	14.01	11.77	1.19	-43.55	59.18	0.17	0.51
Q3	18.38	12.90	1.42	-49.05	60.52	0.50	0.55
Q4	25.38	13.30	1.91	-49.55	60.77	0.96	0.55
Q5	36.51	13.35	2.74	-47.27	61.19	1.52	0.50
Q5-Q1 Spread	26.99	7.98	3.38	-9.93	56.40	3.03	0.00
--- Momentum ---		NaN	NaN	NaN	NaN	NaN	NaN	NaN
Momentum	Q1	22.90	14.16	1.62	-52.97	59.72	0.77	0.56
Q2	20.27	12.51	1.62	-48.67	60.06	0.62	0.52
Q3	21.48	11.62	1.85	-41.35	61.32	0.68	0.48
Q4	19.20	12.68	1.51	-46.04	60.73	0.55	0.53
Q5	13.20	14.51	0.91	-47.80	58.21	0.14	0.61
Q5-Q1 Spread	-8.35	10.51	-0.79	-65.55	48.89	-0.78	0.00
--- QVM Combined ---		NaN	NaN	NaN	NaN	NaN	NaN	NaN
QVM Combined	Q1	14.91	12.81	1.16	-51.73	58.55	0.23	0.52
Q2	16.93	12.38	1.37	-47.85	60.18	0.38	0.52
Q3	21.20	12.66	1.67	-45.90	60.02	0.71	0.54
Q4	19.88	12.99	1.53	-46.24	59.39	0.62	0.56
Q5	24.93	13.27	1.88	-45.02	61.53	1.01	0.58
Q5-Q1 Spread	8.48	7.58	1.12	-18.18	52.92	1.11	0.00
--- Benchmark ---		NaN	NaN	NaN	NaN	NaN	NaN	NaN
Benchmark	VN-Index	10.73	18.31	0.59	-45.26	56.74	0.00	1.00

====================================================================================================
üîó FACTOR DIVERSIFICATION ANALYSIS
====================================================================================================
Correlation Matrix of Top Quintile (Q5) Factor Returns:
 	Quality	Value	Momentum
Quality	1.00	0.83	0.88
Value	0.83	1.00	0.82
Momentum	0.88	0.82	1.00

Average pairwise correlation between factor returns: 0.844
‚ö†Ô∏è MODERATE DIVERSIFICATION: Some overlap in return drivers, as expected in a strong bull market.

====================================================================================================
üí° STRATEGIC INSIGHTS & RECOMMENDATIONS
====================================================================================================
1. Value is a Premier Alpha Source in Vietnam:
   - The Value factor demonstrates an exceptionally strong and monotonic relationship with returns.
   - The Q5-Q1 spread generated a Sharpe Ratio of 3.38, which is a world-class alpha signal.
   - CONCLUSION: Our value definitions are highly effective at identifying undervalued companies in the Vietnamese market.

2. Momentum is a Contrarian (Reversal) Signal:
   - The Momentum factor is clearly inverted: the lowest momentum quintile (Q1) significantly outperforms the highest (Q5).
   - The Q5-Q1 spread has a Sharpe Ratio of -0.79, indicating a statistically significant reversal effect.
   - CONCLUSION: This is a critical market structure insight. A simple trend-following strategy does not work; a contrarian approach is required. The QVM engine's ability to handle negative factor weights will be crucial.

3. Quality Provides Stability but Lacks Strong Monotonicity:
   - The Quality factor consistently produces strong risk-adjusted returns across its top quintiles (Q2 Sharpe: 1.84).
   - However, the Q5-Q1 spread is negligible. The primary benefit of the Quality factor is in avoiding low-quality firms, not necessarily in picking the absolute best.
   - CONCLUSION: Quality is a crucial risk-management and base-return component of the strategy.

4. The QVM Composite Successfully Integrates Factor Signals:
   - The combined QVM strategy successfully blends the individual factor signals into a superior composite.
   - The top quintile (Q5) of the QVM factor achieves a Sharpe Ratio of 1.88, significantly outperforming the benchmark Sharpe of 0.59.
   - The QVM composite restores a strong monotonic relationship, demonstrating that the model intelligently weights the predictive power of each underlying factor.
   - CONCLUSION: The multi-factor approach is superior to any single factor in isolation, providing both higher returns and better consistency.

======================================================================
‚úÖ NOTEBOOK 02: SINGLE FACTOR DNA ANALYSIS COMPLETE
======================================================================