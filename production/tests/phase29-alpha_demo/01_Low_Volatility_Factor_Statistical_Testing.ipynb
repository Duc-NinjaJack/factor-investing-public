{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0922ab3a",
   "metadata": {},
   "source": [
    "# Low-Volatility Factor Statistical Significance Testing\n",
    "\n",
    "**Objective:** Test the statistical significance of the Low-Volatility factor as a defensive overlay in the QVM v2.1 Alpha strategy.\n",
    "\n",
    "**Factor Description:** \n",
    "- Calculates 252-day rolling volatility for each stock\n",
    "- Converts to low-volatility scores (lower volatility = higher score)\n",
    "- Normalized to 0-1 range for defensive positioning\n",
    "\n",
    "**Testing Period:** 2018-2025 (excluding 2016-2017 OOS period)\n",
    "**Target Metrics:** Information Coefficient (IC), Factor Returns, Rank Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3d0116",
   "metadata": {},
   "source": [
    "# IMPORTS AND SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1071b6fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/raymond/anaconda3/envs/py310_env/lib/python3.10/site-packages/scipy/spatial/_qhull.cpython-310-darwin.so, 0x0002): Library not loaded: @rpath/libgfortran.5.dylib\n  Referenced from: <D37BED4E-7F75-3467-A281-7E7E316989C9> /Users/raymond/anaconda3/envs/py310_env/lib/libopenblas.0.dylib\n  Reason: tried: '/Users/raymond/anaconda3/envs/py310_env/lib/libgfortran.5.dylib' (duplicate LC_RPATH '@loader_path'), '/Users/raymond/anaconda3/envs/py310_env/lib/libgfortran.5.dylib' (duplicate LC_RPATH '@loader_path'), '/Users/raymond/anaconda3/envs/py310_env/lib/python3.10/site-packages/scipy/spatial/../../../../libgfortran.5.dylib' (duplicate LC_RPATH '@loader_path'), '/Users/raymond/anaconda3/envs/py310_env/lib/python3.10/site-packages/scipy/spatial/../../../../libgfortran.5.dylib' (duplicate LC_RPATH '@loader_path'), '/Users/raymond/anaconda3/envs/py310_env/bin/../lib/libgfortran.5.dylib' (duplicate LC_RPATH '@loader_path'), '/Users/raymond/anaconda3/envs/py310_env/bin/../lib/libgfortran.5.dylib' (duplicate LC_RPATH '@loader_path'), '/usr/local/lib/libgfortran.5.dylib' (no such file), '/usr/lib/libgfortran.5.dylib' (no such file, not in dyld cache)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m stats\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m     10\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310_env/lib/python3.10/site-packages/scipy/stats/__init__.py:453\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m.. _statsrefmanual:\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    450\u001b[0m \n\u001b[1;32m    451\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats_py\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_variation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m variation\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/py310_env/lib/python3.10/site-packages/scipy/stats/_stats_py.py:38\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m array, asarray, ma\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NumpyVersion\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistance\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cdist\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mndimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _measurements\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_util\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (check_random_state, MapWrapper,\n\u001b[1;32m     41\u001b[0m                               rng_integers, float_factorial)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310_env/lib/python3.10/site-packages/scipy/spatial/__init__.py:104\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_kdtree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ckdtree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m--> 104\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_qhull\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_spherical_voronoi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SphericalVoronoi\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_plotutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/raymond/anaconda3/envs/py310_env/lib/python3.10/site-packages/scipy/spatial/_qhull.cpython-310-darwin.so, 0x0002): Library not loaded: @rpath/libgfortran.5.dylib\n  Referenced from: <D37BED4E-7F75-3467-A281-7E7E316989C9> /Users/raymond/anaconda3/envs/py310_env/lib/libopenblas.0.dylib\n  Reason: tried: '/Users/raymond/anaconda3/envs/py310_env/lib/libgfortran.5.dylib' (duplicate LC_RPATH '@loader_path'), '/Users/raymond/anaconda3/envs/py310_env/lib/libgfortran.5.dylib' (duplicate LC_RPATH '@loader_path'), '/Users/raymond/anaconda3/envs/py310_env/lib/python3.10/site-packages/scipy/spatial/../../../../libgfortran.5.dylib' (duplicate LC_RPATH '@loader_path'), '/Users/raymond/anaconda3/envs/py310_env/lib/python3.10/site-packages/scipy/spatial/../../../../libgfortran.5.dylib' (duplicate LC_RPATH '@loader_path'), '/Users/raymond/anaconda3/envs/py310_env/bin/../lib/libgfortran.5.dylib' (duplicate LC_RPATH '@loader_path'), '/Users/raymond/anaconda3/envs/py310_env/bin/../lib/libgfortran.5.dylib' (duplicate LC_RPATH '@loader_path'), '/usr/local/lib/libgfortran.5.dylib' (no such file), '/usr/lib/libgfortran.5.dylib' (no such file, not in dyld cache)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add the necessary paths to import modules\n",
    "sys.path.append(os.path.join(os.path.dirname('__file__'), '..', '..', 'engine'))\n",
    "sys.path.append(os.path.join(os.path.dirname('__file__'), '..', '..', 'universe'))\n",
    "\n",
    "from qvm_engine_v2_enhanced import QVMEngineV2Enhanced\n",
    "from constructors import get_liquid_universe\n",
    "\n",
    "print(f\"Low-Volatility Factor Testing Started: {datetime.now()}\")\n",
    "print(\"QVM Engine v2 Enhanced - Low-Volatility Statistical Analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525b81c2",
   "metadata": {},
   "source": [
    "# DATABASE CONNECTION AND ENGINE SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a91bca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the QVM engine\n",
    "engine = QVMEngineV2Enhanced()\n",
    "\n",
    "print(\"‚úÖ QVM Engine v2 Enhanced initialized successfully\")\n",
    "print(f\"   - Engine class: {engine.__class__.__name__}\")\n",
    "print(f\"   - Database connection: {'‚úÖ Connected' if hasattr(engine, 'engine') and engine.engine else '‚ùå Failed'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a57e3f7",
   "metadata": {},
   "source": [
    "# UNIVERSE CONSTRUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4312d78",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Set up test parameters\n",
    "start_date = datetime(2018, 1, 1)\n",
    "end_date = datetime(2025, 8, 2)\n",
    "analysis_dates = pd.date_range(start=start_date, end=end_date, freq='M')\n",
    "\n",
    "print(f\"Analysis Period: {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}\")\n",
    "print(f\"Number of analysis dates: {len(analysis_dates)}\")\n",
    "\n",
    "# Get universe for testing (using sample tickers for demonstration)\n",
    "SAMPLE_TICKERS = ['TCB', 'VCB', 'OCB', 'NLG', 'SSI', 'FPT', 'HPG', 'MWG', 'VIC', 'VHM', 'GAS', 'VJC']\n",
    "print(f\"Testing with {len(SAMPLE_TICKERS)} sample tickers: {SAMPLE_TICKERS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b94802b",
   "metadata": {},
   "source": [
    "# LOW-VOLATILITY FACTOR CALCULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f4985a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def calculate_low_volatility_factor(engine, analysis_date, universe_tickers):\n",
    "    \"\"\"\n",
    "    Calculate low-volatility factor scores for defensive overlay.\n",
    "    \n",
    "    Parameters:\n",
    "    - engine: QVMEngineV2Enhanced instance\n",
    "    - analysis_date: datetime for analysis\n",
    "    - universe_tickers: list of ticker symbols\n",
    "    \n",
    "    Returns:\n",
    "    - dict: {ticker: low_vol_score}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        low_vol_scores = {}\n",
    "        \n",
    "        # Get price data for volatility calculation\n",
    "        ticker_str = \"', '\".join(universe_tickers)\n",
    "        start_date = analysis_date - pd.DateOffset(months=12)  # 12 months for volatility calculation\n",
    "        \n",
    "        price_query = f\"\"\"\n",
    "        SELECT \n",
    "            date,\n",
    "            ticker,\n",
    "            close as adj_close\n",
    "        FROM equity_history\n",
    "        WHERE ticker IN ('{ticker_str}')\n",
    "          AND date BETWEEN '{start_date.date()}' AND '{analysis_date.date()}'\n",
    "        ORDER BY ticker, date\n",
    "        \"\"\"\n",
    "        \n",
    "        price_data = pd.read_sql(price_query, engine.engine, parse_dates=['date'])\n",
    "        \n",
    "        if price_data.empty:\n",
    "            print(f\"No price data available for {analysis_date.strftime('%Y-%m-%d')}\")\n",
    "            return low_vol_scores\n",
    "        \n",
    "        # Calculate daily returns\n",
    "        price_data['return'] = price_data.groupby('ticker')['adj_close'].pct_change()\n",
    "        \n",
    "        # Calculate rolling volatility (252-day annualized)\n",
    "        volatility_data = price_data.groupby('ticker')['return'].rolling(\n",
    "            window=252, min_periods=126\n",
    "        ).std().reset_index()\n",
    "        \n",
    "        # Annualize volatility\n",
    "        volatility_data['volatility_annualized'] = volatility_data['return'] * np.sqrt(252)\n",
    "        \n",
    "        # Get latest volatility for each ticker\n",
    "        latest_volatility = volatility_data.groupby('ticker')['volatility_annualized'].last()\n",
    "        \n",
    "        # Convert to low-volatility scores (lower volatility = higher score)\n",
    "        if not latest_volatility.empty:\n",
    "            max_vol = latest_volatility.max()\n",
    "            min_vol = latest_volatility.min()\n",
    "            \n",
    "            if max_vol > min_vol:\n",
    "                # Normalize to 0-1 range (lower volatility = higher score)\n",
    "                low_vol_scores = {\n",
    "                    ticker: 1.0 - ((vol - min_vol) / (max_vol - min_vol))\n",
    "                    for ticker, vol in latest_volatility.items()\n",
    "                }\n",
    "            else:\n",
    "                # All volatilities are the same, assign equal scores\n",
    "                low_vol_scores = {ticker: 0.5 for ticker in latest_volatility.index}\n",
    "        \n",
    "        return low_vol_scores\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to calculate low-volatility factor for {analysis_date.strftime('%Y-%m-%d')}: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33398b28",
   "metadata": {},
   "source": [
    "# HISTORICAL FACTOR GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da478af0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Generate historical low-volatility scores\n",
    "historical_low_vol = {}\n",
    "\n",
    "for date in analysis_dates:\n",
    "    print(f\"Processing {date.strftime('%Y-%m-%d')}...\", end=' ')\n",
    "    scores = calculate_low_volatility_factor(engine, date, SAMPLE_TICKERS)\n",
    "    if scores:\n",
    "        historical_low_vol[date] = scores\n",
    "        print(f\"‚úÖ {len(scores)} scores calculated\")\n",
    "    else:\n",
    "        print(\"‚ùå No scores\")\n",
    "\n",
    "print(f\"\\n‚úÖ Historical low-volatility scores generated for {len(historical_low_vol)} dates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c777e07",
   "metadata": {},
   "source": [
    "# FORWARD RETURNS CALCULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762f9b39",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def calculate_forward_returns(engine, analysis_date, universe_tickers, forward_periods=[1, 3, 6, 12]):\n",
    "    \"\"\"\n",
    "    Calculate forward returns for statistical testing.\n",
    "    \n",
    "    Parameters:\n",
    "    - engine: QVMEngineV2Enhanced instance\n",
    "    - analysis_date: datetime for analysis\n",
    "    - universe_tickers: list of ticker symbols\n",
    "    - forward_periods: list of months for forward returns\n",
    "    \n",
    "    Returns:\n",
    "    - dict: {ticker: {period: return}}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        forward_returns = {}\n",
    "        \n",
    "        # Get price data for forward return calculation\n",
    "        ticker_str = \"', '\".join(universe_tickers)\n",
    "        max_forward = max(forward_periods)\n",
    "        end_date = analysis_date + pd.DateOffset(months=max_forward)\n",
    "        \n",
    "        price_query = f\"\"\"\n",
    "        SELECT \n",
    "            date,\n",
    "            ticker,\n",
    "            close as adj_close\n",
    "        FROM equity_history\n",
    "        WHERE ticker IN ('{ticker_str}')\n",
    "          AND date BETWEEN '{analysis_date.date()}' AND '{end_date.date()}'\n",
    "        ORDER BY ticker, date\n",
    "        \"\"\"\n",
    "        \n",
    "        price_data = pd.read_sql(price_query, engine.engine, parse_dates=['date'])\n",
    "        \n",
    "        if price_data.empty:\n",
    "            return forward_returns\n",
    "        \n",
    "        # Calculate forward returns for each period\n",
    "        for ticker in universe_tickers:\n",
    "            ticker_data = price_data[price_data['ticker'] == ticker].sort_values('date')\n",
    "            if ticker_data.empty:\n",
    "                continue\n",
    "                \n",
    "            start_price = ticker_data.iloc[0]['adj_close']\n",
    "            forward_returns[ticker] = {}\n",
    "            \n",
    "            for period in forward_periods:\n",
    "                # Find price at period months later\n",
    "                period_date = analysis_date + pd.DateOffset(months=period)\n",
    "                period_data = ticker_data[ticker_data['date'] >= period_date]\n",
    "                \n",
    "                if not period_data.empty:\n",
    "                    end_price = period_data.iloc[0]['adj_close']\n",
    "                    forward_return = (end_price - start_price) / start_price\n",
    "                    forward_returns[ticker][period] = forward_return\n",
    "        \n",
    "        return forward_returns\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to calculate forward returns for {analysis_date.strftime('%Y-%m-%d')}: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a24daa",
   "metadata": {},
   "source": [
    "# STATISTICAL SIGNIFICANCE TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5d5aa0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def calculate_information_coefficient(factor_scores, forward_returns, period):\n",
    "    \"\"\"\n",
    "    Calculate Information Coefficient (IC) for a given forward period.\n",
    "    \n",
    "    Parameters:\n",
    "    - factor_scores: dict of {ticker: score}\n",
    "    - forward_returns: dict of {ticker: {period: return}}\n",
    "    - period: forward period in months\n",
    "    \n",
    "    Returns:\n",
    "    - float: Information Coefficient\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    returns = []\n",
    "    \n",
    "    for ticker in factor_scores:\n",
    "        if ticker in forward_returns and period in forward_returns[ticker]:\n",
    "            scores.append(factor_scores[ticker])\n",
    "            returns.append(forward_returns[ticker][period])\n",
    "    \n",
    "    if len(scores) < 3:  # Need at least 3 observations\n",
    "        return np.nan\n",
    "    \n",
    "    # Calculate rank correlation (Spearman's rho)\n",
    "    ic = stats.spearmanr(scores, returns)[0]\n",
    "    return ic\n",
    "\n",
    "def calculate_factor_returns(factor_scores, forward_returns, period, n_quintiles=5):\n",
    "    \"\"\"\n",
    "    Calculate factor returns using quintile analysis.\n",
    "    \n",
    "    Parameters:\n",
    "    - factor_scores: dict of {ticker: score}\n",
    "    - forward_returns: dict of {ticker: {period: return}}\n",
    "    - period: forward period in months\n",
    "    - n_quintiles: number of quintiles for analysis\n",
    "    \n",
    "    Returns:\n",
    "    - dict: quintile returns and spread\n",
    "    \"\"\"\n",
    "    # Create DataFrame for analysis\n",
    "    data = []\n",
    "    for ticker in factor_scores:\n",
    "        if ticker in forward_returns and period in forward_returns[ticker]:\n",
    "            data.append({\n",
    "                'ticker': ticker,\n",
    "                'factor_score': factor_scores[ticker],\n",
    "                'forward_return': forward_returns[ticker][period]\n",
    "            })\n",
    "    \n",
    "    if len(data) < n_quintiles:\n",
    "        return {}\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Create quintiles\n",
    "    df['quintile'] = pd.qcut(df['factor_score'], n_quintiles, labels=False)\n",
    "    \n",
    "    # Calculate returns by quintile\n",
    "    quintile_returns = df.groupby('quintile')['forward_return'].mean()\n",
    "    \n",
    "    # Calculate spread (Q5 - Q1)\n",
    "    spread = quintile_returns.iloc[-1] - quintile_returns.iloc[0]\n",
    "    \n",
    "    return {\n",
    "        'quintile_returns': quintile_returns,\n",
    "        'spread': spread,\n",
    "        'high_low_spread': spread\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93769386",
   "metadata": {},
   "source": [
    "# COMPREHENSIVE STATISTICAL ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3446fdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate forward returns for all dates\n",
    "print(\"Calculating forward returns...\")\n",
    "historical_forward_returns = {}\n",
    "\n",
    "for date in list(historical_low_vol.keys()):\n",
    "    forward_returns = calculate_forward_returns(engine, date, SAMPLE_TICKERS, [1, 3, 6, 12])\n",
    "    if forward_returns:\n",
    "        historical_forward_returns[date] = forward_returns\n",
    "\n",
    "print(f\"‚úÖ Forward returns calculated for {len(historical_forward_returns)} dates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89031937",
   "metadata": {},
   "source": [
    "# INFORMATION COEFFICIENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455fbe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate IC for different forward periods\n",
    "forward_periods = [1, 3, 6, 12]\n",
    "ic_results = {period: [] for period in forward_periods}\n",
    "\n",
    "for date in historical_low_vol:\n",
    "    if date in historical_forward_returns:\n",
    "        for period in forward_periods:\n",
    "            ic = calculate_information_coefficient(\n",
    "                historical_low_vol[date], \n",
    "                historical_forward_returns[date], \n",
    "                period\n",
    "            )\n",
    "            if not np.isnan(ic):\n",
    "                ic_results[period].append(ic)\n",
    "\n",
    "# Calculate IC statistics\n",
    "ic_stats = {}\n",
    "for period in forward_periods:\n",
    "    if ic_results[period]:\n",
    "        ic_values = ic_results[period]\n",
    "        ic_stats[period] = {\n",
    "            'mean': np.mean(ic_values),\n",
    "            'std': np.std(ic_values),\n",
    "            't_stat': np.mean(ic_values) / (np.std(ic_values) / np.sqrt(len(ic_values))),\n",
    "            'p_value': stats.ttest_1samp(ic_values, 0)[1],\n",
    "            'count': len(ic_values)\n",
    "        }\n",
    "\n",
    "print(\"Information Coefficient Analysis Results:\")\n",
    "print(\"=\" * 60)\n",
    "for period, stats in ic_stats.items():\n",
    "    print(f\"{period}M Forward Period:\")\n",
    "    print(f\"  Mean IC: {stats['mean']:.4f}\")\n",
    "    print(f\"  Std IC:  {stats['std']:.4f}\")\n",
    "    print(f\"  t-stat:  {stats['t_stat']:.4f}\")\n",
    "    print(f\"  p-value: {stats['p_value']:.4f}\")\n",
    "    print(f\"  N:       {stats['count']}\")\n",
    "    print(f\"  Significant: {'‚úÖ' if stats['p_value'] < 0.05 else '‚ùå'}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373527ef",
   "metadata": {},
   "source": [
    "# FACTOR RETURNS ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f05685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate factor returns for different periods\n",
    "factor_returns_results = {}\n",
    "\n",
    "for period in forward_periods:\n",
    "    period_returns = []\n",
    "    \n",
    "    for date in historical_low_vol:\n",
    "        if date in historical_forward_returns:\n",
    "            returns = calculate_factor_returns(\n",
    "                historical_low_vol[date],\n",
    "                historical_forward_returns[date],\n",
    "                period\n",
    "            )\n",
    "            if returns and 'spread' in returns:\n",
    "                period_returns.append(returns['spread'])\n",
    "    \n",
    "    if period_returns:\n",
    "        factor_returns_results[period] = {\n",
    "            'mean_return': np.mean(period_returns),\n",
    "            'std_return': np.std(period_returns),\n",
    "            't_stat': np.mean(period_returns) / (np.std(period_returns) / np.sqrt(len(period_returns))),\n",
    "            'p_value': stats.ttest_1samp(period_returns, 0)[1],\n",
    "            'count': len(period_returns),\n",
    "            'returns': period_returns\n",
    "        }\n",
    "\n",
    "print(\"Factor Returns Analysis Results:\")\n",
    "print(\"=\" * 60)\n",
    "for period, results in factor_returns_results.items():\n",
    "    print(f\"{period}M Forward Period:\")\n",
    "    print(f\"  Mean Spread: {results['mean_return']:.4f}\")\n",
    "    print(f\"  Std Spread:  {results['std_return']:.4f}\")\n",
    "    print(f\"  t-stat:      {results['t_stat']:.4f}\")\n",
    "    print(f\"  p-value:     {results['p_value']:.4f}\")\n",
    "    print(f\"  N:           {results['count']}\")\n",
    "    print(f\"  Significant: {'‚úÖ' if results['p_value'] < 0.05 else '‚ùå'}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f8e0d3",
   "metadata": {},
   "source": [
    "# VISUALIZATION OF RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6b6c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Low-Volatility Factor Statistical Analysis Results', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: IC Distribution\n",
    "ax1 = axes[0, 0]\n",
    "for period in [1, 3, 6, 12]:\n",
    "    if ic_results[period]:\n",
    "        ax1.hist(ic_results[period], alpha=0.6, label=f'{period}M', bins=20)\n",
    "ax1.axvline(0, color='red', linestyle='--', alpha=0.7)\n",
    "ax1.set_xlabel('Information Coefficient')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('IC Distribution by Forward Period')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: IC Time Series\n",
    "ax2 = axes[0, 1]\n",
    "for period in [1, 3, 6, 12]:\n",
    "    if ic_results[period]:\n",
    "        dates = list(historical_low_vol.keys())[:len(ic_results[period])]\n",
    "        ax2.plot(dates, ic_results[period], label=f'{period}M', alpha=0.7)\n",
    "ax2.axhline(0, color='red', linestyle='--', alpha=0.7)\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.set_ylabel('Information Coefficient')\n",
    "ax2.set_title('IC Time Series')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Factor Returns Distribution\n",
    "ax3 = axes[1, 0]\n",
    "for period in [1, 3, 6, 12]:\n",
    "    if period in factor_returns_results:\n",
    "        ax3.hist(factor_returns_results[period]['returns'], alpha=0.6, label=f'{period}M', bins=20)\n",
    "ax3.axvline(0, color='red', linestyle='--', alpha=0.7)\n",
    "ax3.set_xlabel('Factor Return Spread')\n",
    "ax3.set_ylabel('Frequency')\n",
    "ax3.set_title('Factor Returns Distribution')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Factor Returns Summary\n",
    "ax4 = axes[1, 1]\n",
    "periods = list(factor_returns_results.keys())\n",
    "means = [factor_returns_results[p]['mean_return'] for p in periods]\n",
    "stds = [factor_returns_results[p]['std_return'] for p in periods]\n",
    "colors = ['green' if factor_returns_results[p]['p_value'] < 0.05 else 'red' for p in periods]\n",
    "\n",
    "bars = ax4.bar([str(p) + 'M' for p in periods], means, yerr=stds, capsize=5, color=colors, alpha=0.7)\n",
    "ax4.axhline(0, color='black', linestyle='-', alpha=0.5)\n",
    "ax4.set_xlabel('Forward Period')\n",
    "ax4.set_ylabel('Mean Factor Return Spread')\n",
    "ax4.set_title('Factor Returns by Forward Period')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# Add significance annotations\n",
    "for i, (period, results) in enumerate(factor_returns_results.items()):\n",
    "    if results['p_value'] < 0.05:\n",
    "        ax4.text(i, means[i] + stds[i] + 0.001, '*', ha='center', va='bottom', fontsize=16, color='green')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb41e88",
   "metadata": {},
   "source": [
    "# SUMMARY AND CONCLUSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9807210",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"LOW-VOLATILITY FACTOR STATISTICAL SIGNIFICANCE SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nüìä KEY FINDINGS:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# IC Analysis Summary\n",
    "print(\"\\n1. INFORMATION COEFFICIENT ANALYSIS:\")\n",
    "for period in [1, 3, 6, 12]:\n",
    "    if period in ic_stats:\n",
    "        stats = ic_stats[period]\n",
    "        significance = \"‚úÖ STATISTICALLY SIGNIFICANT\" if stats['p_value'] < 0.05 else \"‚ùå NOT SIGNIFICANT\"\n",
    "        print(f\"   {period}M Forward: IC = {stats['mean']:.4f} (p = {stats['p_value']:.4f}) - {significance}\")\n",
    "\n",
    "# Factor Returns Summary\n",
    "print(\"\\n2. FACTOR RETURNS ANALYSIS:\")\n",
    "for period in [1, 3, 6, 12]:\n",
    "    if period in factor_returns_results:\n",
    "        results = factor_returns_results[period]\n",
    "        significance = \"‚úÖ STATISTICALLY SIGNIFICANT\" if results['p_value'] < 0.05 else \"‚ùå NOT SIGNIFICANT\"\n",
    "        print(f\"   {period}M Forward: Spread = {results['mean_return']:.4f} (p = {results['p_value']:.4f}) - {significance}\")\n",
    "\n",
    "# Overall Assessment\n",
    "print(\"\\n3. OVERALL ASSESSMENT:\")\n",
    "significant_ic = sum(1 for period in [1, 3, 6, 12] if period in ic_stats and ic_stats[period]['p_value'] < 0.05)\n",
    "significant_returns = sum(1 for period in [1, 3, 6, 12] if period in factor_returns_results and factor_returns_results[period]['p_value'] < 0.05)\n",
    "\n",
    "print(f\"   - IC Significance: {significant_ic}/4 periods significant\")\n",
    "print(f\"   - Returns Significance: {significant_returns}/4 periods significant\")\n",
    "\n",
    "if significant_ic >= 2 and significant_returns >= 2:\n",
    "    print(\"   üéØ CONCLUSION: Low-Volatility factor shows strong statistical significance\")\n",
    "    print(\"   ‚úÖ RECOMMENDATION: Include in QVM v2.1 Alpha strategy\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è CONCLUSION: Low-Volatility factor shows mixed statistical significance\")\n",
    "    print(\"   üîç RECOMMENDATION: Further analysis needed before inclusion\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80) "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "py310_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
