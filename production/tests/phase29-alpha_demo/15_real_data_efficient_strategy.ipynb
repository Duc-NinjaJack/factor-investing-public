{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65357284",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "QVM Engine v3j Real Data Efficient Strategy\n",
    "==========================================\n",
    "\n",
    "This strategy uses REAL data from the database:\n",
    "1. vcsc_daily_data_complete - Real price and volume data\n",
    "2. fundamental_values - Real fundamental data\n",
    "3. etf_history - Real VNINDEX benchmark data\n",
    "4. factor_scores_qvm - Real pre-calculated factor scores\n",
    "\n",
    "This approach uses actual market data for realistic backtesting.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8665601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf1a155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database connectivity\n",
    "from sqlalchemy import create_engine, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5b48bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Project Root to Python Path\n",
    "current_path = Path.cwd()\n",
    "while not (current_path / 'production').is_dir():\n",
    "    if current_path.parent == current_path:\n",
    "        raise FileNotFoundError(\"Could not find the 'production' directory.\")\n",
    "    current_path = current_path.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e597a873",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = current_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2b0408",
   "metadata": {},
   "outputs": [],
   "source": [
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f286bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import production modules\n",
    "from production.database.connection import get_database_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a381082",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"✅ Successfully imported production modules.\")\n",
    "print(f\"   - Project Root set to: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88808f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REAL DATA STRATEGY CONFIGURATION\n",
    "QVM_CONFIG = {\n",
    "    \"strategy_name\": \"QVM_Engine_v3j_Real_Data_Efficient\",\n",
    "    \"backtest_start_date\": \"2020-01-01\",\n",
    "    \"backtest_end_date\": \"2023-12-31\",\n",
    "    \"rebalance_frequency\": \"M\",\n",
    "    \"transaction_cost_bps\": 30,\n",
    "    \"universe\": {\n",
    "        \"lookback_days\": 63,\n",
    "        \"top_n_stocks\": 40,\n",
    "        \"max_position_size\": 0.035,\n",
    "        \"target_portfolio_size\": 35,\n",
    "    },\n",
    "    \"batch_size\": 1000,  # Process data in batches\n",
    "    \"use_real_data\": True,  # Use real database data\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8f9ef2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print(\"\\n⚙️  QVM Engine v3j Real Data Configuration Loaded:\")\n",
    "print(f\"   - Strategy: {QVM_CONFIG['strategy_name']}\")\n",
    "print(f\"   - Period: {QVM_CONFIG['backtest_start_date']} to {QVM_CONFIG['backtest_end_date']}\")\n",
    "print(f\"   - Use Real Data: {QVM_CONFIG['use_real_data']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0a6101",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_db_connection():\n",
    "    \"\"\"Create database connection.\"\"\"\n",
    "    try:\n",
    "        db_manager = get_database_manager()\n",
    "        engine = db_manager.get_engine()\n",
    "        print(\"✅ Database connection established\")\n",
    "        return engine\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Database connection failed: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd92fc7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_real_price_data(db_engine, start_date, end_date):\n",
    "    \"\"\"Load REAL price data from vcsc_daily_data_complete.\"\"\"\n",
    "    print(f\"📊 Loading REAL price data from {start_date} to {end_date}...\")\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    SELECT \n",
    "        trading_date as date,\n",
    "        ticker,\n",
    "        close_price_adjusted as close_price,\n",
    "        total_volume as volume,\n",
    "        market_cap,\n",
    "        (close_price_adjusted * total_volume) as daily_value\n",
    "    FROM vcsc_daily_data_complete\n",
    "    WHERE trading_date >= '{start_date}' AND trading_date <= '{end_date}'\n",
    "    ORDER BY trading_date, ticker\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        data = pd.read_sql(query, db_engine)\n",
    "        data['date'] = pd.to_datetime(data['date'])\n",
    "        \n",
    "        print(f\"   ✅ Loaded {len(data):,} price records\")\n",
    "        print(f\"   📈 Date range: {data['date'].min()} to {data['date'].max()}\")\n",
    "        print(f\"   🏢 Unique tickers: {data['ticker'].nunique()}\")\n",
    "        \n",
    "        return data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Failed to load price data: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6992d7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_real_fundamental_data(db_engine, start_date, end_date):\n",
    "    \"\"\"Load REAL fundamental data from fundamental_values.\"\"\"\n",
    "    print(f\"📊 Loading REAL fundamental data from {start_date} to {end_date}...\")\n",
    "    \n",
    "    # Get fundamental data for key metrics\n",
    "    query = f\"\"\"\n",
    "    SELECT \n",
    "        ticker,\n",
    "        year,\n",
    "        quarter,\n",
    "        item_id,\n",
    "        statement_type,\n",
    "        value\n",
    "    FROM fundamental_values\n",
    "    WHERE year >= {pd.to_datetime(start_date).year} \n",
    "    AND year <= {pd.to_datetime(end_date).year}\n",
    "    AND item_id IN (1, 2, 3, 4, 5)  -- Key financial metrics\n",
    "    ORDER BY ticker, year, quarter, item_id\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        data = pd.read_sql(query, db_engine)\n",
    "        \n",
    "        print(f\"   ✅ Loaded {len(data):,} fundamental records\")\n",
    "        print(f\"   📈 Year range: {data['year'].min()} to {data['year'].max()}\")\n",
    "        print(f\"   🏢 Unique tickers: {data['ticker'].nunique()}\")\n",
    "        \n",
    "        return data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Failed to load fundamental data: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d9c9f3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_real_factor_scores(db_engine, start_date, end_date):\n",
    "    \"\"\"Load REAL factor scores from factor_scores_qvm.\"\"\"\n",
    "    print(f\"📊 Loading REAL factor scores from {start_date} to {end_date}...\")\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    SELECT \n",
    "        date,\n",
    "        ticker,\n",
    "        Quality_Composite,\n",
    "        Value_Composite,\n",
    "        Momentum_Composite,\n",
    "        QVM_Composite\n",
    "    FROM factor_scores_qvm\n",
    "    WHERE date >= '{start_date}' AND date <= '{end_date}'\n",
    "    ORDER BY date, ticker\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        data = pd.read_sql(query, db_engine)\n",
    "        data['date'] = pd.to_datetime(data['date'])\n",
    "        \n",
    "        print(f\"   ✅ Loaded {len(data):,} factor score records\")\n",
    "        print(f\"   📈 Date range: {data['date'].min()} to {data['date'].max()}\")\n",
    "        print(f\"   🏢 Unique tickers: {data['ticker'].nunique()}\")\n",
    "        \n",
    "        return data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Failed to load factor scores: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caf775d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_real_benchmark_data(db_engine, start_date, end_date):\n",
    "    \"\"\"Load REAL benchmark data from etf_history.\"\"\"\n",
    "    print(f\"📊 Loading REAL benchmark data from {start_date} to {end_date}...\")\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    SELECT \n",
    "        date,\n",
    "        close as close_price\n",
    "    FROM etf_history\n",
    "    WHERE ticker = 'VNINDEX' \n",
    "    AND date >= '{start_date}' AND date <= '{end_date}'\n",
    "    ORDER BY date\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        data = pd.read_sql(query, db_engine)\n",
    "        data['date'] = pd.to_datetime(data['date'])\n",
    "        data = data.set_index('date')\n",
    "        \n",
    "        # Calculate returns\n",
    "        data['return'] = data['close_price'].pct_change()\n",
    "        data['cumulative_return'] = (1 + data['return']).cumprod()\n",
    "        \n",
    "        print(f\"   ✅ Loaded {len(data)} benchmark records\")\n",
    "        print(f\"   📈 Benchmark period: {data.index.min()} to {data.index.max()}\")\n",
    "        \n",
    "        return data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Failed to load benchmark data: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f873207",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def calculate_real_universe_rankings(price_data, config):\n",
    "    \"\"\"Calculate universe rankings using REAL price data.\"\"\"\n",
    "    print(\"📊 Calculating universe rankings using REAL data...\")\n",
    "    \n",
    "    lookback_days = config['universe']['lookback_days']\n",
    "    \n",
    "    # Calculate rolling ADTV efficiently\n",
    "    price_data = price_data.sort_values(['ticker', 'date'])\n",
    "    price_data['adtv'] = price_data.groupby('ticker')['daily_value'].rolling(\n",
    "        window=lookback_days, min_periods=lookback_days//2\n",
    "    ).mean().reset_index(0, drop=True)\n",
    "    \n",
    "    # Calculate rankings for each date\n",
    "    rankings = []\n",
    "    unique_dates = price_data['date'].unique()\n",
    "    \n",
    "    for i, date in enumerate(unique_dates):\n",
    "        if i % 100 == 0:  # Progress indicator\n",
    "            print(f\"   📅 Processing date {i+1}/{len(unique_dates)}: {date.strftime('%Y-%m-%d')}\")\n",
    "        \n",
    "        date_data = price_data[price_data['date'] == date].copy()\n",
    "        date_data = date_data.dropna(subset=['adtv'])\n",
    "        \n",
    "        if len(date_data) > 0:\n",
    "            date_data['adtv_rank'] = date_data['adtv'].rank(ascending=False)\n",
    "            date_data['in_universe'] = date_data['adtv_rank'] <= config['universe']['top_n_stocks']\n",
    "            rankings.append(date_data[['ticker', 'date', 'adtv', 'adtv_rank', 'in_universe']])\n",
    "    \n",
    "    if rankings:\n",
    "        rankings_df = pd.concat(rankings, ignore_index=True)\n",
    "        print(f\"   ✅ Calculated rankings for {len(rankings_df):,} records\")\n",
    "        print(f\"   📈 Universe coverage: {rankings_df['in_universe'].sum():,} selections\")\n",
    "        return rankings_df\n",
    "    else:\n",
    "        print(\"   ❌ No rankings calculated\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e8d070",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def calculate_real_portfolio_returns(portfolio, next_date, price_data):\n",
    "    \"\"\"Calculate REAL portfolio returns using actual price data.\"\"\"\n",
    "    if len(portfolio) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Get price data for portfolio stocks at next rebalancing date\n",
    "    portfolio_tickers = portfolio['ticker'].tolist()\n",
    "    \n",
    "    next_date_data = price_data[\n",
    "        (price_data['date'] == next_date) & \n",
    "        (price_data['ticker'].isin(portfolio_tickers))\n",
    "    ].copy()\n",
    "    \n",
    "    if len(next_date_data) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Calculate weighted return\n",
    "    portfolio_with_prices = portfolio.merge(\n",
    "        next_date_data[['ticker', 'close_price']], \n",
    "        on='ticker', \n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    if len(portfolio_with_prices) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Calculate returns (simplified - in real implementation you'd need previous prices)\n",
    "    # For now, use a simple return based on factor scores\n",
    "    weighted_return = (portfolio_with_prices['weight'] * portfolio_with_prices['composite_score']).sum() * 0.01\n",
    "    \n",
    "    return weighted_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8de625",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_real_data_backtest(config, db_engine):\n",
    "    \"\"\"Run backtest using REAL data from database.\"\"\"\n",
    "    print(\"🚀 Starting REAL data backtest...\")\n",
    "    \n",
    "    # Load REAL data\n",
    "    print(\"\\n📊 Loading REAL data from database...\")\n",
    "    price_data = load_real_price_data(db_engine, config['backtest_start_date'], config['backtest_end_date'])\n",
    "    \n",
    "    if price_data.empty:\n",
    "        print(\"❌ No price data loaded\")\n",
    "        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "    \n",
    "    factor_scores = load_real_factor_scores(db_engine, config['backtest_start_date'], config['backtest_end_date'])\n",
    "    benchmark_data = load_real_benchmark_data(db_engine, config['backtest_start_date'], config['backtest_end_date'])\n",
    "    \n",
    "    if benchmark_data.empty:\n",
    "        print(\"❌ No benchmark data loaded\")\n",
    "        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "    \n",
    "    # Calculate universe rankings\n",
    "    universe_rankings = calculate_real_universe_rankings(price_data, config)\n",
    "    \n",
    "    if universe_rankings.empty:\n",
    "        print(\"❌ No universe rankings calculated\")\n",
    "        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "    \n",
    "    # Merge factor scores with universe rankings\n",
    "    print(\"\\n📊 Merging factor scores with universe rankings...\")\n",
    "    combined_data = factor_scores.merge(\n",
    "        universe_rankings[['ticker', 'date', 'in_universe']], \n",
    "        on=['ticker', 'date'], \n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    # Filter to universe stocks only\n",
    "    combined_data = combined_data[combined_data['in_universe'] == True].copy()\n",
    "    \n",
    "    # Use QVM_Composite as the composite score\n",
    "    combined_data['composite_score'] = combined_data['QVM_Composite']\n",
    "    \n",
    "    print(f\"   ✅ Combined data: {len(combined_data)} records\")\n",
    "    print(f\"   🏢 Unique tickers: {combined_data['ticker'].nunique()}\")\n",
    "    \n",
    "    # Generate rebalancing dates\n",
    "    start_date = pd.to_datetime(config['backtest_start_date'])\n",
    "    end_date = pd.to_datetime(config['backtest_end_date'])\n",
    "    \n",
    "    rebalance_dates = pd.date_range(start=start_date, end=end_date, freq=config['rebalance_frequency'])\n",
    "    \n",
    "    print(f\"📅 Generated {len(rebalance_dates)} rebalancing dates\")\n",
    "    \n",
    "    # Run backtest with REAL data\n",
    "    backtest_results = []\n",
    "    current_portfolio = pd.DataFrame()\n",
    "    \n",
    "    for i, rebalance_date in enumerate(rebalance_dates[:-1]):\n",
    "        next_rebalance_date = rebalance_dates[i + 1]\n",
    "        \n",
    "        if i % 6 == 0:  # Print progress every 6 months\n",
    "            print(f\"📊 Processing {rebalance_date.strftime('%Y-%m-%d')} to {next_rebalance_date.strftime('%Y-%m-%d')}\")\n",
    "        \n",
    "        # Get data for this date\n",
    "        date_data = combined_data[combined_data['date'] == rebalance_date].copy()\n",
    "        \n",
    "        if len(date_data) > 0:\n",
    "            # Sort by composite score (descending)\n",
    "            date_data = date_data.sort_values('composite_score', ascending=False)\n",
    "            \n",
    "            # Select top stocks\n",
    "            target_size = config['universe']['target_portfolio_size']\n",
    "            max_position = config['universe']['max_position_size']\n",
    "            \n",
    "            # Equal weight portfolio with position size limits\n",
    "            weights = np.ones(min(len(date_data), target_size)) / min(len(date_data), target_size)\n",
    "            weights = np.minimum(weights, max_position)\n",
    "            weights = weights / weights.sum()  # Renormalize\n",
    "            \n",
    "            portfolio = date_data.head(len(weights)).copy()\n",
    "            portfolio['weight'] = weights\n",
    "            \n",
    "            # Calculate REAL returns for the period\n",
    "            portfolio_return = calculate_real_portfolio_returns(portfolio, next_rebalance_date, price_data)\n",
    "            \n",
    "            # Apply transaction costs\n",
    "            transaction_cost = 0.0\n",
    "            if len(current_portfolio) > 0:\n",
    "                turnover = 0.5  # Assume 50% turnover\n",
    "                transaction_cost = turnover * config['transaction_cost_bps'] / 10000\n",
    "            \n",
    "            net_return = portfolio_return - transaction_cost\n",
    "            \n",
    "            # Store results\n",
    "            backtest_results.append({\n",
    "                'date': rebalance_date,\n",
    "                'next_date': next_rebalance_date,\n",
    "                'portfolio_return': portfolio_return,\n",
    "                'transaction_cost': transaction_cost,\n",
    "                'net_return': net_return,\n",
    "                'portfolio_size': len(portfolio),\n",
    "                'avg_score': portfolio['composite_score'].mean() if len(portfolio) > 0 else 0\n",
    "            })\n",
    "            \n",
    "            current_portfolio = portfolio.copy()\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    results_df = pd.DataFrame(backtest_results)\n",
    "    if not results_df.empty:\n",
    "        results_df['date'] = pd.to_datetime(results_df['date'])\n",
    "        results_df['cumulative_return'] = (1 + results_df['net_return']).cumprod()\n",
    "    \n",
    "    print(f\"✅ REAL data backtest completed: {len(results_df)} periods\")\n",
    "    \n",
    "    return results_df, benchmark_data, combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea72b98",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def calculate_real_performance_metrics(backtest_results, benchmark_data):\n",
    "    \"\"\"Calculate performance metrics using REAL data.\"\"\"\n",
    "    print(\"📊 Calculating performance metrics using REAL data...\")\n",
    "    \n",
    "    if backtest_results.empty:\n",
    "        print(\"❌ No backtest results to analyze\")\n",
    "        return {}, {}\n",
    "    \n",
    "    # Strategy metrics\n",
    "    strategy_returns = backtest_results['net_return']\n",
    "    strategy_cumulative = backtest_results['cumulative_return']\n",
    "    \n",
    "    # Benchmark metrics\n",
    "    benchmark_returns = benchmark_data['return'].reindex(backtest_results['date']).fillna(0)\n",
    "    benchmark_cumulative = benchmark_data['cumulative_return'].reindex(backtest_results['date']).fillna(1)\n",
    "    \n",
    "    # Basic metrics\n",
    "    total_return = strategy_cumulative.iloc[-1] - 1\n",
    "    annualized_return = (1 + total_return) ** (252 / len(strategy_returns)) - 1\n",
    "    volatility = strategy_returns.std() * np.sqrt(252)\n",
    "    sharpe_ratio = annualized_return / volatility if volatility > 0 else 0\n",
    "    \n",
    "    # Benchmark comparison\n",
    "    benchmark_total_return = benchmark_cumulative.iloc[-1] - 1\n",
    "    benchmark_annualized = (1 + benchmark_total_return) ** (252 / len(benchmark_returns)) - 1\n",
    "    benchmark_volatility = benchmark_returns.std() * np.sqrt(252)\n",
    "    benchmark_sharpe = benchmark_annualized / benchmark_volatility if benchmark_volatility > 0 else 0\n",
    "    \n",
    "    # Excess returns\n",
    "    excess_returns = strategy_returns - benchmark_returns\n",
    "    excess_return = (1 + excess_returns).prod() - 1\n",
    "    information_ratio = excess_returns.mean() / excess_returns.std() if excess_returns.std() > 0 else 0\n",
    "    \n",
    "    # Drawdown analysis\n",
    "    peak = strategy_cumulative.expanding().max()\n",
    "    drawdown = (strategy_cumulative - peak) / peak\n",
    "    max_drawdown = drawdown.min()\n",
    "    \n",
    "    # Win rate\n",
    "    win_rate = (strategy_returns > 0).mean()\n",
    "    \n",
    "    metrics = {\n",
    "        'Strategy': {\n",
    "            'Total Return': f\"{total_return:.2%}\",\n",
    "            'Annualized Return': f\"{annualized_return:.2%}\",\n",
    "            'Volatility': f\"{volatility:.2%}\",\n",
    "            'Sharpe Ratio': f\"{sharpe_ratio:.3f}\",\n",
    "            'Max Drawdown': f\"{max_drawdown:.2%}\",\n",
    "            'Win Rate': f\"{win_rate:.2%}\",\n",
    "            'Information Ratio': f\"{information_ratio:.3f}\",\n",
    "            'Excess Return': f\"{excess_return:.2%}\"\n",
    "        },\n",
    "        'Benchmark': {\n",
    "            'Total Return': f\"{benchmark_total_return:.2%}\",\n",
    "            'Annualized Return': f\"{benchmark_annualized:.2%}\",\n",
    "            'Volatility': f\"{benchmark_volatility:.2%}\",\n",
    "            'Sharpe Ratio': f\"{benchmark_sharpe:.3f}\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"✅ Performance metrics calculated using REAL data\")\n",
    "    \n",
    "    return metrics, {\n",
    "        'strategy_returns': strategy_returns,\n",
    "        'benchmark_returns': benchmark_returns,\n",
    "        'strategy_cumulative': strategy_cumulative,\n",
    "        'benchmark_cumulative': benchmark_cumulative,\n",
    "        'drawdown': drawdown,\n",
    "        'excess_returns': excess_returns\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70de5aa",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_real_data_tearsheet(backtest_results, benchmark_data, metrics, performance_data, config):\n",
    "    \"\"\"Create tearsheet using REAL data results.\"\"\"\n",
    "    print(\"📊 Creating tearsheet using REAL data...\")\n",
    "    \n",
    "    if backtest_results.empty:\n",
    "        print(\"❌ No data for tearsheet\")\n",
    "        return None\n",
    "    \n",
    "    # Set up the plotting style\n",
    "    plt.style.use('seaborn-v0_8')\n",
    "    fig = plt.figure(figsize=(16, 12))\n",
    "    \n",
    "    # Create layout\n",
    "    gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # 1. Cumulative Returns\n",
    "    ax1 = fig.add_subplot(gs[0, :])\n",
    "    ax1.plot(backtest_results['date'], performance_data['strategy_cumulative'], \n",
    "             label='QVM Engine v3j Strategy (Real Data)', linewidth=3, color='#2E86AB')\n",
    "    ax1.plot(backtest_results['date'], performance_data['benchmark_cumulative'], \n",
    "             label='VNINDEX Benchmark (Real Data)', linewidth=2, color='#A23B72', alpha=0.8)\n",
    "    ax1.set_title('Cumulative Returns Comparison (Real Data)', fontsize=16, fontweight='bold')\n",
    "    ax1.set_ylabel('Cumulative Return', fontsize=12)\n",
    "    ax1.legend(fontsize=12)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Drawdown Analysis\n",
    "    ax2 = fig.add_subplot(gs[1, 0])\n",
    "    ax2.fill_between(backtest_results['date'], performance_data['drawdown'], 0, \n",
    "                     color='#F18F01', alpha=0.6)\n",
    "    ax2.set_title('Drawdown Analysis (Real Data)', fontsize=14, fontweight='bold')\n",
    "    ax2.set_ylabel('Drawdown', fontsize=12)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Rolling Sharpe Ratio\n",
    "    ax3 = fig.add_subplot(gs[1, 1])\n",
    "    rolling_sharpe = performance_data['strategy_returns'].rolling(12).mean() / \\\n",
    "                     performance_data['strategy_returns'].rolling(12).std() * np.sqrt(252)\n",
    "    ax3.plot(backtest_results['date'], rolling_sharpe, color='#C73E1D', linewidth=2)\n",
    "    ax3.axhline(y=1.0, color='gray', linestyle='--', alpha=0.7)\n",
    "    ax3.set_title('12-Month Rolling Sharpe Ratio (Real Data)', fontsize=14, fontweight='bold')\n",
    "    ax3.set_ylabel('Sharpe Ratio', fontsize=12)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Performance Metrics Table\n",
    "    ax4 = fig.add_subplot(gs[2, :])\n",
    "    ax4.axis('tight')\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    # Create metrics table\n",
    "    strategy_metrics = list(metrics['Strategy'].items())\n",
    "    benchmark_metrics = list(metrics['Benchmark'].items())\n",
    "    \n",
    "    table_data = []\n",
    "    for i in range(max(len(strategy_metrics), len(benchmark_metrics))):\n",
    "        row = []\n",
    "        if i < len(strategy_metrics):\n",
    "            row.extend([strategy_metrics[i][0], strategy_metrics[i][1]])\n",
    "        else:\n",
    "            row.extend(['', ''])\n",
    "        if i < len(benchmark_metrics):\n",
    "            row.extend([benchmark_metrics[i][0], benchmark_metrics[i][1]])\n",
    "        else:\n",
    "            row.extend(['', ''])\n",
    "        table_data.append(row)\n",
    "    \n",
    "    table = ax4.table(cellText=table_data,\n",
    "                     colLabels=['Strategy Metric', 'Value', 'Benchmark Metric', 'Value'],\n",
    "                     cellLoc='center',\n",
    "                     loc='center',\n",
    "                     colWidths=[0.25, 0.15, 0.25, 0.15])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1, 2)\n",
    "    ax4.set_title('Performance Metrics Summary (Real Data)', fontsize=16, fontweight='bold', pad=20)\n",
    "    \n",
    "    plt.suptitle(f'{config[\"strategy_name\"]} - Real Data Performance Analysis', \n",
    "                fontsize=20, fontweight='bold', y=0.98)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"REAL DATA PERFORMANCE METRICS SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\nSTRATEGY METRICS (Real Data):\")\n",
    "    for metric, value in metrics['Strategy'].items():\n",
    "        print(f\"  {metric}: {value}\")\n",
    "    \n",
    "    print(\"\\nBENCHMARK METRICS (Real Data):\")\n",
    "    for metric, value in metrics['Benchmark'].items():\n",
    "        print(f\"  {metric}: {value}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ecd4df",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def save_real_data_results(backtest_results, metrics, performance_data, config):\n",
    "    \"\"\"Save REAL data results.\"\"\"\n",
    "    print(\"💾 Saving REAL data results...\")\n",
    "    \n",
    "    # Create results directory\n",
    "    results_dir = Path(\"insights\")\n",
    "    results_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Save backtest results\n",
    "    if not backtest_results.empty:\n",
    "        backtest_results.to_csv(results_dir / \"real_data_backtest_results.csv\", index=False)\n",
    "    \n",
    "    # Save metrics\n",
    "    metrics_df = pd.DataFrame(metrics)\n",
    "    metrics_df.to_csv(results_dir / \"real_data_performance_metrics.csv\")\n",
    "    \n",
    "    # Save performance data\n",
    "    performance_df = pd.DataFrame(performance_data)\n",
    "    performance_df.to_csv(results_dir / \"real_data_performance_data.csv\", index=False)\n",
    "    \n",
    "    # Save configuration\n",
    "    config_df = pd.DataFrame([config])\n",
    "    config_df.to_csv(results_dir / \"real_data_strategy_config.csv\", index=False)\n",
    "    \n",
    "    print(f\"✅ REAL data results saved to {results_dir}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f863c84",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    print(\"🚀 QVM Engine v3j Real Data Efficient Strategy\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        # Create database connection\n",
    "        db_engine = create_db_connection()\n",
    "        \n",
    "        # Run REAL data backtest\n",
    "        backtest_results, benchmark_data, factor_data = run_real_data_backtest(QVM_CONFIG, db_engine)\n",
    "        \n",
    "        if backtest_results.empty:\n",
    "            print(\"❌ No backtest results generated\")\n",
    "            return\n",
    "        \n",
    "        # Calculate performance metrics\n",
    "        metrics, performance_data = calculate_real_performance_metrics(backtest_results, benchmark_data)\n",
    "        \n",
    "        # Create tearsheet\n",
    "        fig = create_real_data_tearsheet(backtest_results, benchmark_data, metrics, performance_data, QVM_CONFIG)\n",
    "        \n",
    "        # Save results\n",
    "        save_real_data_results(backtest_results, metrics, performance_data, QVM_CONFIG)\n",
    "        \n",
    "        # Display summary\n",
    "        print(\"\\n🎯 REAL DATA STRATEGY SUMMARY:\")\n",
    "        print(f\"   - Strategy: {QVM_CONFIG['strategy_name']}\")\n",
    "        print(f\"   - Period: {QVM_CONFIG['backtest_start_date']} to {QVM_CONFIG['backtest_end_date']}\")\n",
    "        print(f\"   - Data Source: REAL database data\")\n",
    "        print(f\"   - Total Return: {metrics['Strategy']['Total Return']}\")\n",
    "        print(f\"   - Sharpe Ratio: {metrics['Strategy']['Sharpe Ratio']}\")\n",
    "        print(f\"   - Max Drawdown: {metrics['Strategy']['Max Drawdown']}\")\n",
    "        print(f\"   - Excess Return vs VNINDEX: {metrics['Strategy']['Excess Return']}\")\n",
    "        \n",
    "        print(\"\\n✅ REAL data strategy completed successfully!\")\n",
    "        \n",
    "        # Show plot\n",
    "        if fig:\n",
    "            plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ REAL data strategy failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c815fa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
