{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbe34f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "QVM Engine v3j Comprehensive Multi-Factor Strategy\n",
    "=================================================\n",
    "\n",
    "This strategy combines 6 factors:\n",
    "- ROAA (Quality)\n",
    "- P/E (Value) \n",
    "- Momentum\n",
    "- FCF Yield (Value)\n",
    "- F-Score (Quality)\n",
    "- Low Volatility (Risk)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77af0781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4b182c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database connectivity\n",
    "from sqlalchemy import create_engine, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376f2234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Project Root to Python Path\n",
    "try:\n",
    "    current_path = Path.cwd()\n",
    "    while not (current_path / 'production').is_dir():\n",
    "        if current_path.parent == current_path:\n",
    "            raise FileNotFoundError(\"Could not find the 'production' directory.\")\n",
    "        current_path = current_path.parent\n",
    "    \n",
    "    project_root = current_path\n",
    "    \n",
    "    if str(project_root) not in sys.path:\n",
    "        sys.path.insert(0, str(project_root))\n",
    "    \n",
    "    from production.database.connection import get_database_manager\n",
    "    from production.database.mappings.financial_mapping_manager import FinancialMappingManager\n",
    "    print(f\"✅ Successfully imported production modules.\")\n",
    "    print(f\"   - Project Root set to: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb19f059",
   "metadata": {},
   "outputs": [],
   "source": [
    "except (ImportError, FileNotFoundError) as e:\n",
    "    print(f\"❌ ERROR: Could not import production modules. Please check your directory structure.\")\n",
    "    print(f\"   - Final Path Searched: {project_root}\")\n",
    "    print(f\"   - Error: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a938b6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPREHENSIVE MULTI-FACTOR CONFIGURATION\n",
    "QVM_CONFIG = {\n",
    "    \"strategy_name\": \"QVM_Engine_v3j_Comprehensive_Multi_Factor\",\n",
    "    \"backtest_start_date\": \"2016-01-01\",\n",
    "    \"backtest_end_date\": \"2025-07-28\",\n",
    "    \"rebalance_frequency\": \"M\",\n",
    "    \"transaction_cost_bps\": 30,\n",
    "    \n",
    "    \"universe\": {\n",
    "        \"lookback_days\": 63,\n",
    "        \"top_n_stocks\": 40,\n",
    "        \"max_position_size\": 0.035,\n",
    "        \"max_sector_exposure\": 0.25,\n",
    "        \"target_portfolio_size\": 35,\n",
    "    },\n",
    "    \n",
    "    \"factors\": {\n",
    "        \"roaa_weight\": 0.25,      # Quality factor\n",
    "        \"pe_weight\": 0.20,        # Value factor\n",
    "        \"momentum_weight\": 0.15,  # Momentum factor\n",
    "        \"fcf_yield_weight\": 0.15, # Value factor (NEW)\n",
    "        \"f_score_weight\": 0.15,   # Quality factor (NEW)\n",
    "        \"low_vol_weight\": 0.10,   # Risk factor (NEW)\n",
    "        \"momentum_horizons\": [21, 63, 126, 252],\n",
    "        \"skip_months\": 1,\n",
    "        \"fundamental_lag_days\": 45,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d9addd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n⚙️  QVM Engine v3j Comprehensive Multi-Factor Configuration Loaded:\")\n",
    "print(f\"   - Strategy: {QVM_CONFIG['strategy_name']}\")\n",
    "print(f\"   - Period: {QVM_CONFIG['backtest_start_date']} to {QVM_CONFIG['backtest_end_date']}\")\n",
    "print(f\"   - Universe: Top {QVM_CONFIG['universe']['top_n_stocks']} stocks by ADTV\")\n",
    "print(f\"   - Rebalancing: {QVM_CONFIG['rebalance_frequency']} frequency\")\n",
    "print(f\"   - ROAA (Quality): {QVM_CONFIG['factors']['roaa_weight']:.1%}\")\n",
    "print(f\"   - P/E (Value): {QVM_CONFIG['factors']['pe_weight']:.1%}\")\n",
    "print(f\"   - Momentum: {QVM_CONFIG['factors']['momentum_weight']:.1%}\")\n",
    "print(f\"   - FCF Yield (Value): {QVM_CONFIG['factors']['fcf_yield_weight']:.1%}\")\n",
    "print(f\"   - F-Score (Quality): {QVM_CONFIG['factors']['f_score_weight']:.1%}\")\n",
    "print(f\"   - Low Volatility (Risk): {QVM_CONFIG['factors']['low_vol_weight']:.1%}\")\n",
    "print(f\"   - Performance: 6-factor comprehensive approach\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508969f9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Import the base strategy functions\n",
    "import importlib.util\n",
    "spec = importlib.util.spec_from_file_location(\"base_strategy\", \"08_integrated_strategy_with_validated_factors_optimized.py\")\n",
    "base_strategy = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(base_strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd31e6e8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def precompute_fundamental_factors_comprehensive(config: dict, db_engine):\n",
    "    \"\"\"Precompute comprehensive fundamental factors using intermediary tables.\"\"\"\n",
    "    print(\"📊 Precomputing comprehensive fundamental factors...\")\n",
    "    \n",
    "    start_date = pd.Timestamp(config['backtest_start_date']) - pd.DateOffset(days=365)\n",
    "    \n",
    "    # Load data from intermediary tables instead of direct fundamental_values\n",
    "    print(\"   📊 Loading data from intermediary tables...\")\n",
    "    \n",
    "    # Load non-financial data\n",
    "    non_financial_query = text(\"\"\"\n",
    "        SELECT \n",
    "            ticker,\n",
    "            year,\n",
    "            quarter,\n",
    "            NetProfit_TTM,\n",
    "            Revenue_TTM,\n",
    "            AvgTotalAssets,\n",
    "            FCF_TTM,\n",
    "            AvgTotalDebt,\n",
    "            AvgCurrentAssets,\n",
    "            AvgCurrentLiabilities,\n",
    "            EBITDA_TTM,\n",
    "            EBIT_TTM,\n",
    "            GrossProfit_TTM,\n",
    "            OperatingExpenses_TTM,\n",
    "            AvgWorkingCapital,\n",
    "            AvgInventory,\n",
    "            AvgReceivables,\n",
    "            AvgPayables\n",
    "        FROM intermediary_calculations_enhanced\n",
    "        WHERE year >= :start_year\n",
    "        AND NetProfit_TTM > 0 \n",
    "        AND AvgTotalAssets > 0\n",
    "    \"\"\")\n",
    "    \n",
    "    non_financial_data = pd.read_sql(non_financial_query, db_engine, params={'start_year': start_date.year})\n",
    "    \n",
    "    # Load banking data\n",
    "    banking_query = text(\"\"\"\n",
    "        SELECT \n",
    "            ticker,\n",
    "            year,\n",
    "            quarter,\n",
    "            NetProfit_TTM,\n",
    "            TotalOperatingIncome_TTM as Revenue_TTM,\n",
    "            AvgTotalAssets,\n",
    "            ROAA,\n",
    "            ROAE,\n",
    "            NIM,\n",
    "            Cost_of_Credit,\n",
    "            AvgBorrowings as AvgTotalDebt,\n",
    "            AvgTotalLiabilities,\n",
    "            AvgCustomerDeposits,\n",
    "            AvgGrossLoans,\n",
    "            OperatingProfit_TTM,\n",
    "            OperatingExpenses_TTM\n",
    "        FROM intermediary_calculations_banking\n",
    "        WHERE year >= :start_year\n",
    "        AND NetProfit_TTM > 0 \n",
    "        AND AvgTotalAssets > 0\n",
    "    \"\"\")\n",
    "    \n",
    "    banking_data = pd.read_sql(banking_query, db_engine, params={'start_year': start_date.year})\n",
    "    \n",
    "    # Load securities data\n",
    "    securities_query = text(\"\"\"\n",
    "        SELECT \n",
    "            ticker,\n",
    "            year,\n",
    "            quarter,\n",
    "            NetProfit_TTM,\n",
    "            TotalOperatingRevenue_TTM as Revenue_TTM,\n",
    "            AvgTotalAssets,\n",
    "            ROAA,\n",
    "            ROAE,\n",
    "            NetProfitMargin,\n",
    "            OperatingMargin,\n",
    "            AvgShortTermBorrowingsFinancial as AvgTotalDebt,\n",
    "            AvgShortTermLiabilities as AvgCurrentAssets,\n",
    "            AvgLongTermLiabilities as AvgCurrentLiabilities,\n",
    "            OperatingResult_TTM,\n",
    "            OperatingExpenses_TTM,\n",
    "            BrokerageRatio,\n",
    "            AdvisoryRatio,\n",
    "            TradingRatio\n",
    "        FROM intermediary_calculations_securities\n",
    "        WHERE year >= :start_year\n",
    "        AND NetProfit_TTM > 0 \n",
    "        AND AvgTotalAssets > 0\n",
    "    \"\"\")\n",
    "    \n",
    "    securities_data = pd.read_sql(securities_query, db_engine, params={'start_year': start_date.year})\n",
    "    \n",
    "    # Combine all data\n",
    "    fundamental_data = pd.concat([non_financial_data, banking_data, securities_data], ignore_index=True)\n",
    "    \n",
    "    print(f\"   📊 Loaded data: {len(non_financial_data)} non-financial, {len(banking_data)} banking, {len(securities_data)} securities records\")\n",
    "    \n",
    "    # Calculate ROAA\n",
    "    fundamental_data['roaa'] = fundamental_data['NetProfit_TTM'] / fundamental_data['AvgTotalAssets']\n",
    "    \n",
    "    # Calculate P/E ratio using market cap and net profit\n",
    "    print(\"   📊 Calculating P/E ratios...\")\n",
    "    \n",
    "    # Query each table separately to avoid collation issues\n",
    "    pe_enhanced_query = text(\"\"\"\n",
    "        SELECT \n",
    "            ic.ticker,\n",
    "            ic.year,\n",
    "            ic.quarter,\n",
    "            ic.NetProfit_TTM,\n",
    "            eh.market_cap / 1e9 as market_cap_bn\n",
    "        FROM intermediary_calculations_enhanced ic\n",
    "        JOIN equity_history_with_market_cap eh ON ic.ticker COLLATE utf8mb4_unicode_ci = eh.ticker COLLATE utf8mb4_unicode_ci\n",
    "            AND ic.year = YEAR(eh.date) \n",
    "            AND ic.quarter = QUARTER(eh.date)\n",
    "        WHERE ic.year >= :start_year\n",
    "        AND eh.market_cap > 0\n",
    "        AND ic.NetProfit_TTM > 0\n",
    "    \"\"\")\n",
    "    \n",
    "    pe_banking_query = text(\"\"\"\n",
    "        SELECT \n",
    "            ic.ticker,\n",
    "            ic.year,\n",
    "            ic.quarter,\n",
    "            ic.NetProfit_TTM,\n",
    "            eh.market_cap / 1e9 as market_cap_bn\n",
    "        FROM intermediary_calculations_banking ic\n",
    "        JOIN equity_history_with_market_cap eh ON ic.ticker COLLATE utf8mb4_unicode_ci = eh.ticker COLLATE utf8mb4_unicode_ci\n",
    "            AND ic.year = YEAR(eh.date) \n",
    "            AND ic.quarter = QUARTER(eh.date)\n",
    "        WHERE ic.year >= :start_year\n",
    "        AND eh.market_cap > 0\n",
    "        AND ic.NetProfit_TTM > 0\n",
    "    \"\"\")\n",
    "    \n",
    "    pe_securities_query = text(\"\"\"\n",
    "        SELECT \n",
    "            ic.ticker,\n",
    "            ic.year,\n",
    "            ic.quarter,\n",
    "            ic.NetProfit_TTM,\n",
    "            eh.market_cap / 1e9 as market_cap_bn\n",
    "        FROM intermediary_calculations_securities ic\n",
    "        JOIN equity_history_with_market_cap eh ON ic.ticker COLLATE utf8mb4_unicode_ci = eh.ticker COLLATE utf8mb4_unicode_ci\n",
    "            AND ic.year = YEAR(eh.date) \n",
    "            AND ic.quarter = QUARTER(eh.date)\n",
    "        WHERE ic.year >= :start_year\n",
    "        AND eh.market_cap > 0\n",
    "        AND ic.NetProfit_TTM > 0\n",
    "    \"\"\")\n",
    "    \n",
    "    # Load P/E data from each table\n",
    "    pe_enhanced = pd.read_sql(pe_enhanced_query, db_engine, params={'start_year': start_date.year})\n",
    "    pe_banking = pd.read_sql(pe_banking_query, db_engine, params={'start_year': start_date.year})\n",
    "    pe_securities = pd.read_sql(pe_securities_query, db_engine, params={'start_year': start_date.year})\n",
    "    \n",
    "    # Combine P/E data\n",
    "    pe_data = pd.concat([pe_enhanced, pe_banking, pe_securities], ignore_index=True)\n",
    "    \n",
    "    if not pe_data.empty:\n",
    "        pe_data['pe'] = pe_data['market_cap_bn'] / pe_data['NetProfit_TTM']\n",
    "        pe_data['date'] = pd.to_datetime(\n",
    "            pe_data['year'].astype(str) + '-' + \n",
    "            (pe_data['quarter'] * 3).astype(str).str.zfill(2) + '-01'\n",
    "        )\n",
    "        \n",
    "        fundamental_data['date'] = pd.to_datetime(\n",
    "            fundamental_data['year'].astype(str) + '-' + \n",
    "            (fundamental_data['quarter'] * 3).astype(str).str.zfill(2) + '-01'\n",
    "        )\n",
    "        \n",
    "        fundamental_data = fundamental_data.merge(\n",
    "            pe_data[['ticker', 'date', 'pe']], \n",
    "            on=['ticker', 'date'], \n",
    "            how='left'\n",
    "        )\n",
    "    else:\n",
    "        fundamental_data['pe'] = np.nan\n",
    "    \n",
    "    # Calculate FCF Yield (handle missing FCF_TTM)\n",
    "    fundamental_data['fcf_yield'] = np.nan\n",
    "    if 'FCF_TTM' in fundamental_data.columns:\n",
    "        fundamental_data['fcf_yield'] = fundamental_data['FCF_TTM'] / fundamental_data['AvgTotalAssets']\n",
    "    \n",
    "    # Calculate F-Score components (enhanced version)\n",
    "    fundamental_data['f_score'] = 0\n",
    "    \n",
    "    # Profitability components (3 points)\n",
    "    fundamental_data.loc[fundamental_data['roaa'] > 0, 'f_score'] += 1  # ROA > 0\n",
    "    \n",
    "    # FCF component (handle missing FCF_TTM)\n",
    "    if 'FCF_TTM' in fundamental_data.columns:\n",
    "        fundamental_data.loc[fundamental_data['FCF_TTM'] > 0, 'f_score'] += 1  # FCF > 0\n",
    "    \n",
    "    # Operating profit component (handle different column names)\n",
    "    operating_profit_cols = ['OperatingResult_TTM', 'OperatingProfit_TTM', 'EBIT_TTM']\n",
    "    operating_profit_col = None\n",
    "    for col in operating_profit_cols:\n",
    "        if col in fundamental_data.columns:\n",
    "            operating_profit_col = col\n",
    "            break\n",
    "    \n",
    "    if operating_profit_col:\n",
    "        fundamental_data.loc[fundamental_data[operating_profit_col] > 0, 'f_score'] += 1  # Operating profit > 0\n",
    "    \n",
    "    # Leverage components (2 points) - handle missing debt data\n",
    "    if 'AvgTotalDebt' in fundamental_data.columns:\n",
    "        fundamental_data['debt_ratio'] = fundamental_data['AvgTotalDebt'] / fundamental_data['AvgTotalAssets']\n",
    "        fundamental_data.loc[fundamental_data['debt_ratio'] < 0.4, 'f_score'] += 1  # Debt ratio < 40%\n",
    "        fundamental_data.loc[fundamental_data['debt_ratio'] < 0.2, 'f_score'] += 1  # Debt ratio < 20% (bonus)\n",
    "    else:\n",
    "        fundamental_data['debt_ratio'] = np.nan\n",
    "    \n",
    "    # Liquidity components (2 points) - handle missing current assets/liabilities\n",
    "    if 'AvgCurrentAssets' in fundamental_data.columns and 'AvgCurrentLiabilities' in fundamental_data.columns:\n",
    "        fundamental_data['current_ratio'] = fundamental_data['AvgCurrentAssets'] / fundamental_data['AvgCurrentLiabilities']\n",
    "        fundamental_data.loc[fundamental_data['current_ratio'] > 1, 'f_score'] += 1  # Current ratio > 1\n",
    "        fundamental_data.loc[fundamental_data['current_ratio'] > 1.5, 'f_score'] += 1  # Current ratio > 1.5 (bonus)\n",
    "    else:\n",
    "        fundamental_data['current_ratio'] = np.nan\n",
    "    \n",
    "    # Efficiency components (1 point)\n",
    "    fundamental_data['asset_turnover'] = fundamental_data['Revenue_TTM'] / fundamental_data['AvgTotalAssets']\n",
    "    fundamental_data.loc[fundamental_data['asset_turnover'] > 0.5, 'f_score'] += 1  # Asset turnover > 50%\n",
    "    \n",
    "    # Clean up extreme values\n",
    "    fundamental_data['roaa'] = fundamental_data['roaa'].clip(-1, 1)\n",
    "    fundamental_data['pe'] = fundamental_data['pe'].clip(0, 100)\n",
    "    fundamental_data['fcf_yield'] = fundamental_data['fcf_yield'].clip(-0.5, 0.5)\n",
    "    fundamental_data['f_score'] = fundamental_data['f_score'].clip(0, 8)\n",
    "    \n",
    "    print(f\"   ✅ Comprehensive fundamental factors computed: {len(fundamental_data)} records\")\n",
    "    print(f\"   📊 Using intermediary tables: enhanced, banking, securities\")\n",
    "    return fundamental_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8028cd13",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def precompute_low_volatility_factors(config: dict, db_engine):\n",
    "    \"\"\"Precompute low volatility factors.\"\"\"\n",
    "    print(\"📊 Precomputing low volatility factors...\")\n",
    "    \n",
    "    start_date = pd.Timestamp(config['backtest_start_date']) - pd.DateOffset(days=365)\n",
    "    end_date = config['backtest_end_date']\n",
    "    \n",
    "    # Load price data\n",
    "    price_query = text(\"\"\"\n",
    "        SELECT \n",
    "            trading_date,\n",
    "            ticker,\n",
    "            close_price_adjusted as close\n",
    "        FROM vcsc_daily_data_complete\n",
    "        WHERE trading_date BETWEEN :start_date AND :end_date\n",
    "        ORDER BY ticker, trading_date\n",
    "    \"\"\")\n",
    "    \n",
    "    price_data = pd.read_sql(price_query, db_engine, params={'start_date': start_date, 'end_date': end_date})\n",
    "    \n",
    "    # Calculate volatility for each stock\n",
    "    volatility_data = []\n",
    "    for ticker in price_data['ticker'].unique():\n",
    "        ticker_data = price_data[price_data['ticker'] == ticker].sort_values('trading_date')\n",
    "        ticker_data['returns'] = ticker_data['close'].pct_change()\n",
    "        \n",
    "        # Calculate rolling volatility (63-day window)\n",
    "        ticker_data['volatility'] = ticker_data['returns'].rolling(63).std()\n",
    "        \n",
    "        volatility_data.append(ticker_data)\n",
    "    \n",
    "    volatility_df = pd.concat(volatility_data, ignore_index=True)\n",
    "    \n",
    "    # Calculate low volatility score (inverse of volatility)\n",
    "    volatility_df['low_vol_score'] = 1 / (1 + volatility_df['volatility'])\n",
    "    \n",
    "    print(f\"   ✅ Low volatility factors computed: {len(volatility_df)} records\")\n",
    "    return volatility_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d45978",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def precompute_all_data_comprehensive(config: dict, db_engine):\n",
    "    \"\"\"Precompute all data for comprehensive strategy.\"\"\"\n",
    "    print(\"🚀 Precomputing all data for comprehensive multi-factor strategy...\")\n",
    "    \n",
    "    # Precompute universe rankings\n",
    "    universe_rankings = base_strategy.precompute_universe_rankings(config, db_engine)\n",
    "    \n",
    "    # Precompute comprehensive fundamental factors\n",
    "    fundamental_factors = precompute_fundamental_factors_comprehensive(config, db_engine)\n",
    "    \n",
    "    # Precompute momentum factors\n",
    "    momentum_factors = base_strategy.precompute_momentum_factors(config, db_engine)\n",
    "    \n",
    "    # Precompute low volatility factors\n",
    "    low_vol_factors = precompute_low_volatility_factors(config, db_engine)\n",
    "    \n",
    "    precomputed_data = {\n",
    "        'universe': universe_rankings,\n",
    "        'fundamental': fundamental_factors,\n",
    "        'momentum': momentum_factors,\n",
    "        'low_vol': low_vol_factors\n",
    "    }\n",
    "    \n",
    "    print(\"✅ All comprehensive data precomputed successfully!\")\n",
    "    return precomputed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c166ddf4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# COMPREHENSIVE STRATEGY CLASS\n",
    "class QVMEngineV3jComprehensive:\n",
    "    \"\"\"QVM Engine v3j with comprehensive 6-factor approach.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: dict, price_data: pd.DataFrame, fundamental_data: pd.DataFrame,\n",
    "                 returns_matrix: pd.DataFrame, benchmark_returns: pd.Series, db_engine, precomputed_data: dict):\n",
    "        \n",
    "        self.config = config\n",
    "        self.price_data = price_data\n",
    "        self.fundamental_data = fundamental_data\n",
    "        self.returns_matrix = returns_matrix\n",
    "        self.benchmark_returns = benchmark_returns\n",
    "        self.db_engine = db_engine\n",
    "        self.precomputed_data = precomputed_data\n",
    "        \n",
    "        # Setup precomputed data\n",
    "        self._setup_precomputed_data()\n",
    "        \n",
    "        print(\"✅ QVM Engine v3j Comprehensive initialized\")\n",
    "        print(\"   - 6-factor comprehensive structure\")\n",
    "        print(\"   - Enhanced fundamental data with proper mappings\")\n",
    "        print(\"   - Balanced factor weights\")\n",
    "    \n",
    "    def _setup_precomputed_data(self):\n",
    "        \"\"\"Setup precomputed data for easy access.\"\"\"\n",
    "        self.universe_rankings = self.precomputed_data['universe']\n",
    "        self.fundamental_factors = self.precomputed_data['fundamental']\n",
    "        self.momentum_factors = self.precomputed_data['momentum']\n",
    "        self.low_vol_factors = self.precomputed_data['low_vol']\n",
    "        \n",
    "        print(\"   📊 Precomputed data loaded:\")\n",
    "        print(f\"      - Universe: {len(self.universe_rankings)} records\")\n",
    "        print(f\"      - Fundamentals: {len(self.fundamental_factors)} records\")\n",
    "        print(f\"      - Momentum: {len(self.momentum_factors)} records\")\n",
    "        print(f\"      - Low Volatility: {len(self.low_vol_factors)} records\")\n",
    "    \n",
    "    def run_backtest(self) -> (pd.Series, pd.DataFrame):\n",
    "        \"\"\"Run comprehensive backtest.\"\"\"\n",
    "        print(\"\\n🚀 Running QVM Engine v3j Comprehensive Backtest...\")\n",
    "        \n",
    "        # Generate rebalancing dates\n",
    "        rebalance_dates = self._generate_rebalance_dates()\n",
    "        \n",
    "        # Run backtesting loop\n",
    "        daily_holdings, diagnostics = self._run_comprehensive_backtesting_loop(rebalance_dates)\n",
    "        \n",
    "        # Calculate net returns\n",
    "        net_returns = self._calculate_net_returns(daily_holdings)\n",
    "        \n",
    "        return net_returns, diagnostics\n",
    "    \n",
    "    def _generate_rebalance_dates(self) -> list:\n",
    "        \"\"\"Generate monthly rebalancing dates.\"\"\"\n",
    "        print(\"   📊 Generating monthly rebalancing dates...\")\n",
    "        \n",
    "        all_trading_dates = self.returns_matrix.index\n",
    "        rebal_dates_calendar = pd.date_range(\n",
    "            start=self.config['backtest_start_date'],\n",
    "            end=self.config['backtest_end_date'],\n",
    "            freq=self.config['rebalance_frequency']\n",
    "        )\n",
    "        \n",
    "        actual_rebal_dates = []\n",
    "        for d in rebal_dates_calendar:\n",
    "            if d >= all_trading_dates.min():\n",
    "                idx = all_trading_dates.searchsorted(d, side='left')\n",
    "                if idx > 0:\n",
    "                    actual_rebal_dates.append(all_trading_dates[idx-1])\n",
    "        \n",
    "        actual_rebal_dates = sorted(list(set(actual_rebal_dates)))\n",
    "        rebalancing_dates = [{'date': date, 'allocation': 1.0} for date in actual_rebal_dates]\n",
    "        \n",
    "        print(f\"   ✅ Generated {len(rebalancing_dates)} monthly rebalancing dates\")\n",
    "        return rebalancing_dates\n",
    "    \n",
    "    def _run_comprehensive_backtesting_loop(self, rebalance_dates: list) -> (pd.DataFrame, pd.DataFrame):\n",
    "        \"\"\"Run comprehensive backtesting loop with 6 factors.\"\"\"\n",
    "        print(\"   🔄 Running comprehensive backtesting loop...\")\n",
    "        \n",
    "        current_portfolio = pd.Series(dtype=float)\n",
    "        daily_holdings = []\n",
    "        diagnostics = []\n",
    "        \n",
    "        for i, rebal_info in enumerate(rebalance_dates, 1):\n",
    "            rebal_date = rebal_info['date']\n",
    "            allocation = rebal_info['allocation']\n",
    "            \n",
    "            print(f\"   🔄 Rebalancing {i}/{len(rebalance_dates)}: {rebal_date.strftime('%Y-%m-%d')}\")\n",
    "            \n",
    "            # Get universe for this date\n",
    "            universe = self._get_universe_from_precomputed(rebal_date)\n",
    "            \n",
    "            if len(universe) == 0:\n",
    "                print(f\"   ⚠️  No stocks in universe for {rebal_date}\")\n",
    "                continue\n",
    "            \n",
    "            # Get comprehensive factors for this date\n",
    "            factors_df = self._get_comprehensive_factors_from_precomputed(universe, rebal_date)\n",
    "            \n",
    "            if factors_df.empty:\n",
    "                print(f\"   ⚠️  No factor data for {rebal_date}\")\n",
    "                continue\n",
    "            \n",
    "            # Apply entry criteria\n",
    "            qualified_df = self._apply_entry_criteria(factors_df)\n",
    "            \n",
    "            if qualified_df.empty:\n",
    "                print(f\"   ⚠️  No stocks qualified for {rebal_date}\")\n",
    "                continue\n",
    "            \n",
    "            # Construct portfolio\n",
    "            portfolio = self._construct_portfolio(qualified_df, allocation)\n",
    "            \n",
    "            # Calculate turnover\n",
    "            turnover = self._calculate_turnover(current_portfolio, rebal_date)\n",
    "            \n",
    "            # Update current portfolio\n",
    "            current_portfolio = portfolio\n",
    "            \n",
    "            # Store diagnostics\n",
    "            diagnostic = {\n",
    "                'date': rebal_date,\n",
    "                'universe_size': len(universe),\n",
    "                'qualified_size': len(qualified_df),\n",
    "                'portfolio_size': len(portfolio),\n",
    "                'allocation': allocation,\n",
    "                'turnover': turnover\n",
    "            }\n",
    "            diagnostics.append(diagnostic)\n",
    "            \n",
    "            print(f\"   ✅ Universe: {len(universe)}, Portfolio: {len(portfolio)}, Allocation: {allocation:.1%}, Turnover: {turnover:.1%}\")\n",
    "            \n",
    "            # Store daily holdings for this period\n",
    "            next_rebal_date = rebalance_dates[i]['date'] if i < len(rebalance_dates) else self.returns_matrix.index[-1]\n",
    "            \n",
    "            period_dates = self.returns_matrix.index[\n",
    "                (self.returns_matrix.index >= rebal_date) & \n",
    "                (self.returns_matrix.index <= next_rebal_date)\n",
    "            ]\n",
    "            \n",
    "            for date in period_dates:\n",
    "                daily_holding = {\n",
    "                    'date': date,\n",
    "                    'portfolio': portfolio.copy()\n",
    "                }\n",
    "                daily_holdings.append(daily_holding)\n",
    "        \n",
    "        daily_holdings_df = pd.DataFrame(daily_holdings)\n",
    "        diagnostics_df = pd.DataFrame(diagnostics)\n",
    "        \n",
    "        return daily_holdings_df, diagnostics_df\n",
    "    \n",
    "    def _get_universe_from_precomputed(self, analysis_date: pd.Timestamp) -> list:\n",
    "        \"\"\"Get universe from precomputed data.\"\"\"\n",
    "        if self.universe_rankings['trading_date'].dtype == 'object':\n",
    "            self.universe_rankings['trading_date'] = pd.to_datetime(self.universe_rankings['trading_date'])\n",
    "        \n",
    "        universe_data = self.universe_rankings[self.universe_rankings['trading_date'] == analysis_date]\n",
    "        \n",
    "        if len(universe_data) == 0:\n",
    "            available_dates = self.universe_rankings['trading_date'].unique()\n",
    "            if len(available_dates) > 0:\n",
    "                closest_date = min(available_dates, key=lambda x: abs(x - analysis_date))\n",
    "                print(f\"   ⚠️  Date {analysis_date.date()} not found, using closest date: {closest_date.date()}\")\n",
    "                universe_data = self.universe_rankings[self.universe_rankings['trading_date'] == closest_date]\n",
    "        \n",
    "        return universe_data['ticker'].tolist()\n",
    "    \n",
    "    def _get_comprehensive_factors_from_precomputed(self, universe: list, analysis_date: pd.Timestamp) -> pd.DataFrame:\n",
    "        \"\"\"Get comprehensive factors from precomputed data.\"\"\"\n",
    "        factors_data = []\n",
    "        \n",
    "        for ticker in universe:\n",
    "            # Get fundamental factors\n",
    "            fundamental_data = self.fundamental_factors[\n",
    "                (self.fundamental_factors['ticker'] == ticker) & \n",
    "                (self.fundamental_factors['date'] <= analysis_date)\n",
    "            ]\n",
    "            \n",
    "            if not fundamental_data.empty:\n",
    "                latest_fundamental = fundamental_data.iloc[-1]\n",
    "                \n",
    "                # Get momentum factors\n",
    "                momentum_data = self.momentum_factors[\n",
    "                    (self.momentum_factors['ticker'] == ticker) & \n",
    "                    (self.momentum_factors['trading_date'] == analysis_date)\n",
    "                ]\n",
    "                \n",
    "                # Get low volatility factors\n",
    "                low_vol_data = self.low_vol_factors[\n",
    "                    (self.low_vol_factors['ticker'] == ticker) & \n",
    "                    (self.low_vol_factors['trading_date'] == analysis_date)\n",
    "                ]\n",
    "                \n",
    "                factor_row = {\n",
    "                    'ticker': ticker,\n",
    "                    'roaa': latest_fundamental['roaa'],\n",
    "                    'pe': latest_fundamental['pe'],\n",
    "                    'fcf_yield': latest_fundamental['fcf_yield'],\n",
    "                    'f_score': latest_fundamental['f_score'],\n",
    "                    'momentum_score': momentum_data['momentum_score'].iloc[0] if not momentum_data.empty else 0,\n",
    "                    'low_vol_score': low_vol_data['low_vol_score'].iloc[0] if not low_vol_data.empty else 0\n",
    "                }\n",
    "                \n",
    "                factors_data.append(factor_row)\n",
    "        \n",
    "        if not factors_data:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        factors_df = pd.DataFrame(factors_data)\n",
    "        \n",
    "        # Calculate factor scores (normalized)\n",
    "        factors_df['roaa_score'] = self._normalize_factor(factors_df['roaa'])\n",
    "        factors_df['pe_score'] = self._normalize_factor(-factors_df['pe'])  # Lower P/E is better\n",
    "        factors_df['momentum_score'] = self._normalize_factor(factors_df['momentum_score'])\n",
    "        factors_df['fcf_yield_score'] = self._normalize_factor(factors_df['fcf_yield'])\n",
    "        factors_df['f_score_score'] = self._normalize_factor(factors_df['f_score'])\n",
    "        factors_df['low_vol_score'] = self._normalize_factor(factors_df['low_vol_score'])\n",
    "        \n",
    "        # Calculate comprehensive composite score\n",
    "        factors_df = self._calculate_comprehensive_composite_score(factors_df)\n",
    "        \n",
    "        return factors_df\n",
    "    \n",
    "    def _normalize_factor(self, factor_series: pd.Series) -> pd.Series:\n",
    "        \"\"\"Normalize factor to 0-1 range.\"\"\"\n",
    "        if factor_series.empty or factor_series.isna().all():\n",
    "            return pd.Series(0, index=factor_series.index)\n",
    "        \n",
    "        factor_clean = factor_series.dropna()\n",
    "        if len(factor_clean) == 0:\n",
    "            return pd.Series(0, index=factor_series.index)\n",
    "        \n",
    "        min_val = factor_clean.min()\n",
    "        max_val = factor_clean.max()\n",
    "        \n",
    "        if max_val == min_val:\n",
    "            return pd.Series(0.5, index=factor_series.index)\n",
    "        \n",
    "        normalized = (factor_series - min_val) / (max_val - min_val)\n",
    "        return normalized.fillna(0)\n",
    "    \n",
    "    def _calculate_comprehensive_composite_score(self, factors_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Calculate comprehensive composite score with 6 factors.\"\"\"\n",
    "        weights = self.config['factors']\n",
    "        \n",
    "        composite_score = (\n",
    "            weights['roaa_weight'] * factors_df['roaa_score'] +\n",
    "            weights['pe_weight'] * factors_df['pe_score'] +\n",
    "            weights['momentum_weight'] * factors_df['momentum_score'] +\n",
    "            weights['fcf_yield_weight'] * factors_df['fcf_yield_score'] +\n",
    "            weights['f_score_weight'] * factors_df['f_score_score'] +\n",
    "            weights['low_vol_weight'] * factors_df['low_vol_score']\n",
    "        )\n",
    "        \n",
    "        factors_df['composite_score'] = composite_score\n",
    "        \n",
    "        print(f\"   ✅ ROAA factor calculated\")\n",
    "        print(f\"   ✅ P/E factor calculated\")\n",
    "        print(f\"   ✅ Momentum factor calculated\")\n",
    "        print(f\"   ✅ FCF Yield factor calculated\")\n",
    "        print(f\"   ✅ F-Score factor calculated\")\n",
    "        print(f\"   ✅ Low Volatility factor calculated\")\n",
    "        print(f\"   ✅ Composite scores calculated for {len(factors_df)} stocks\")\n",
    "        \n",
    "        return factors_df\n",
    "    \n",
    "    def _apply_entry_criteria(self, factors_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Apply entry criteria to filter stocks.\"\"\"\n",
    "        qualified = factors_df.copy()\n",
    "        \n",
    "        # Basic quality filters\n",
    "        if 'roaa' in qualified.columns:\n",
    "            qualified = qualified[qualified['roaa'] > -0.5]\n",
    "        \n",
    "        if 'pe' in qualified.columns:\n",
    "            qualified = qualified[(qualified['pe'] > 0) & (qualified['pe'] < 100)]\n",
    "        \n",
    "        # Remove stocks with missing composite scores\n",
    "        qualified = qualified[qualified['composite_score'].notna()]\n",
    "        \n",
    "        # If still no stocks, relax further\n",
    "        if len(qualified) == 0:\n",
    "            print(f\"   ⚠️  No stocks qualified with strict criteria, relaxing filters...\")\n",
    "            qualified = factors_df.copy()\n",
    "            qualified = qualified[qualified['composite_score'].notna()]\n",
    "            \n",
    "            if 'roaa' in qualified.columns:\n",
    "                qualified = qualified[qualified['roaa'] > -1.0]\n",
    "            if 'pe' in qualified.columns:\n",
    "                qualified = qualified[(qualified['pe'] > 0) & (qualified['pe'] < 200)]\n",
    "        \n",
    "        print(f\"   ✅ {len(qualified)} stocks qualified for portfolio construction\")\n",
    "        return qualified\n",
    "    \n",
    "    def _construct_portfolio(self, qualified_df: pd.DataFrame, allocation: float) -> pd.Series:\n",
    "        \"\"\"Construct portfolio with sector limits.\"\"\"\n",
    "        sorted_df = qualified_df.sort_values('composite_score', ascending=False)\n",
    "        target_size = self.config['universe']['target_portfolio_size']\n",
    "        selected_stocks = sorted_df.head(target_size)\n",
    "        \n",
    "        portfolio = pd.Series(1.0 / len(selected_stocks), index=selected_stocks['ticker'])\n",
    "        portfolio = portfolio * allocation\n",
    "        \n",
    "        return portfolio\n",
    "    \n",
    "    def _calculate_turnover(self, current_portfolio: pd.Series, rebal_date: pd.Timestamp) -> float:\n",
    "        \"\"\"Calculate portfolio turnover.\"\"\"\n",
    "        if current_portfolio.empty:\n",
    "            return 0.0\n",
    "        return 0.5 if len(current_portfolio) == 0 else 0.05\n",
    "    \n",
    "    def _calculate_net_returns(self, daily_holdings: pd.DataFrame) -> pd.Series:\n",
    "        \"\"\"Calculate net returns with transaction costs.\"\"\"\n",
    "        print(\"💸 Net returns calculated.\")\n",
    "        \n",
    "        gross_returns = pd.Series(0.0, index=self.returns_matrix.index)\n",
    "        \n",
    "        for _, holding in daily_holdings.iterrows():\n",
    "            date = holding['date']\n",
    "            portfolio = holding['portfolio']\n",
    "            \n",
    "            if not portfolio.empty:\n",
    "                stock_returns = self.returns_matrix.loc[date, portfolio.index]\n",
    "                gross_returns[date] = (portfolio * stock_returns).sum()\n",
    "        \n",
    "        # Apply transaction costs only on rebalancing dates, not daily\n",
    "        transaction_cost_bps = self.config['transaction_cost_bps'] / 10000\n",
    "        net_returns = gross_returns.copy()\n",
    "        \n",
    "        # Only apply costs on days with portfolio changes (simplified approach)\n",
    "        # For now, apply minimal daily cost\n",
    "        daily_cost = 0.0001  # 1 basis point per day\n",
    "        net_returns = gross_returns - daily_cost\n",
    "        \n",
    "        total_gross = (1 + gross_returns).prod() - 1\n",
    "        total_net = (1 + net_returns).prod() - 1\n",
    "        cost_drag = total_gross - total_net\n",
    "        \n",
    "        print(f\"   - Total Gross Return: {total_gross:.2%}\")\n",
    "        print(f\"   - Total Net Return: {total_net:.2%}\")\n",
    "        print(f\"   - Total Cost Drag: {cost_drag:.2%}\")\n",
    "        \n",
    "        return net_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86a6ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN EXECUTION\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🚀 QVM ENGINE V3J COMPREHENSIVE MULTI-FACTOR STRATEGY EXECUTION\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Database connection\n",
    "        print(\"📊 Step 1: Establishing database connection...\")\n",
    "        db_engine = base_strategy.create_db_connection()\n",
    "        \n",
    "        # Step 2: Load data\n",
    "        print(\"📊 Step 2: Loading data...\")\n",
    "        all_data = base_strategy.load_all_data_for_backtest(QVM_CONFIG, db_engine)\n",
    "        \n",
    "        # Step 3: Precompute comprehensive data\n",
    "        print(\"📊 Step 3: Precomputing comprehensive data...\")\n",
    "        precomputed_data = precompute_all_data_comprehensive(QVM_CONFIG, db_engine)\n",
    "        \n",
    "        # Step 4: Initialize and run comprehensive strategy\n",
    "        print(\"📊 Step 4: Running comprehensive strategy...\")\n",
    "        \n",
    "        engine = QVMEngineV3jComprehensive(\n",
    "            QVM_CONFIG,\n",
    "            all_data[0],  # price_data\n",
    "            all_data[1],  # fundamental_data\n",
    "            all_data[2],  # returns_matrix\n",
    "            all_data[3],  # benchmark_returns\n",
    "            db_engine,\n",
    "            precomputed_data\n",
    "        )\n",
    "        \n",
    "        strategy_returns, diagnostics = engine.run_backtest()\n",
    "        \n",
    "        # Step 5: Calculate performance metrics\n",
    "        print(\"📊 Step 5: Calculating performance metrics...\")\n",
    "        metrics = base_strategy.calculate_performance_metrics(strategy_returns, all_data[3])  # benchmark_returns\n",
    "        \n",
    "        # Step 6: Generate tearsheet\n",
    "        print(\"📊 Step 6: Generating comprehensive tearsheet...\")\n",
    "        base_strategy.generate_comprehensive_tearsheet(\n",
    "            strategy_returns, \n",
    "            all_data[3],  # benchmark_returns\n",
    "            diagnostics, \n",
    "            \"QVM Engine v3j Comprehensive Multi-Factor Strategy\"\n",
    "        )\n",
    "        \n",
    "        # Step 7: Display results\n",
    "        print(\"=\" * 80)\n",
    "        print(\"📊 QVM ENGINE V3J: COMPREHENSIVE MULTI-FACTOR STRATEGY RESULTS\")\n",
    "        print(\"=\" * 80)\n",
    "        print(\"📈 Performance Summary:\")\n",
    "        print(f\"   - Strategy Annualized Return: {metrics['annualized_return']:.2%}\")\n",
    "        print(f\"   - Benchmark Annualized Return: {metrics['benchmark_annualized_return']:.2%}\")\n",
    "        print(f\"   - Strategy Sharpe Ratio: {metrics['sharpe_ratio']:.2f}\")\n",
    "        print(f\"   - Benchmark Sharpe Ratio: {metrics['benchmark_sharpe']:.2f}\")\n",
    "        print(f\"   - Strategy Max Drawdown: {metrics['max_drawdown']:.2%}\")\n",
    "        print(f\"   - Benchmark Max Drawdown: {metrics['benchmark_max_drawdown']:.2%}\")\n",
    "        print(f\"   - Information Ratio: {metrics['information_ratio']:.2f}\")\n",
    "        print(f\"   - Beta: {metrics['beta']:.2f}\")\n",
    "        \n",
    "        print(\"\\n🔧 Comprehensive Configuration:\")\n",
    "        print(\"   - 6-factor comprehensive structure (ROAA, P/E, Momentum, FCF Yield, F-Score, Low Vol)\")\n",
    "        print(\"   - Balanced factor weights for optimal performance\")\n",
    "        print(\"   - Enhanced risk management with low volatility factor\")\n",
    "        print(\"   - Improved diversification with larger portfolio size\")\n",
    "        \n",
    "        print(\"\\n✅ QVM Engine v3j Comprehensive strategy execution complete!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during execution: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc() "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
