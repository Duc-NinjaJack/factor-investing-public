{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c93d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "QVM Engine v3j Comprehensive Multi-Factor Strategy v2\n",
    "====================================================\n",
    "\n",
    "This strategy combines 6 factors using VNSC data for maximum coverage:\n",
    "- ROAA (Quality) - from raw fundamental data\n",
    "- P/E (Value) - from raw fundamental data + market data\n",
    "- Momentum (4-horizon) - from VNSC daily data\n",
    "- FCF Yield (Value) - from raw fundamental data\n",
    "- F-Score (Quality) - from raw fundamental data\n",
    "- Low Volatility (Risk) - from VNSC daily data\n",
    "\n",
    "The strategy uses VNSC daily data and raw fundamental data for maximum\n",
    "historical coverage and precise financial calculations.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac04bb2f",
   "metadata": {},
   "source": [
    "# IMPORTS AND SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d95c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Database connectivity\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Add Project Root to Python Path\n",
    "try:\n",
    "    current_path = Path.cwd()\n",
    "    while not (current_path / 'production').is_dir():\n",
    "        if current_path.parent == current_path:\n",
    "            raise FileNotFoundError(\"Could not find the 'production' directory.\")\n",
    "        current_path = current_path.parent\n",
    "    \n",
    "    project_root = current_path\n",
    "    \n",
    "    if str(project_root) not in sys.path:\n",
    "        sys.path.insert(0, str(project_root))\n",
    "    \n",
    "    from production.database.connection import get_database_manager\n",
    "    \n",
    "    # Import our custom components\n",
    "    sys.path.append(str(project_root / 'production' / 'tests' / 'phase29-alpha_demo' / 'components'))\n",
    "    from components.02_fundamental_factor_calculator import FundamentalFactorCalculator\n",
    "    from components.03_momentum_volatility_calculator import MomentumVolatilityCalculator\n",
    "    \n",
    "    print(f\"✅ Successfully imported production modules.\")\n",
    "    print(f\"   - Project Root set to: {project_root}\")\n",
    "\n",
    "except (ImportError, FileNotFoundError) as e:\n",
    "    print(f\"❌ ERROR: Could not import production modules. Please check your directory structure.\")\n",
    "    print(f\"   - Final Path Searched: {project_root}\")\n",
    "    print(f\"   - Error: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee1e8a3",
   "metadata": {},
   "source": [
    "# COMPREHENSIVE MULTI-FACTOR CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a96a71",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "QVM_CONFIG = {\n",
    "    \"strategy_name\": \"QVM_Engine_v3j_Comprehensive_Multi_Factor_v2\",\n",
    "    \"backtest_start_date\": \"2016-01-01\",\n",
    "    \"backtest_end_date\": \"2025-07-28\",\n",
    "    \"rebalance_frequency\": \"M\",\n",
    "    \"transaction_cost_bps\": 30,\n",
    "    \"universe\": {\n",
    "        \"lookback_days\": 63,\n",
    "        \"top_n_stocks\": 40,\n",
    "        \"max_position_size\": 0.035,\n",
    "        \"max_sector_exposure\": 0.25,\n",
    "        \"target_portfolio_size\": 35,\n",
    "    },\n",
    "    \"factors\": {\n",
    "        # Quality factors (1/3 total weight)\n",
    "        \"roaa_weight\": 0.167,  # 0.5 * 1/3 = 0.167\n",
    "        \"f_score_weight\": 0.167,  # 0.5 * 1/3 = 0.167\n",
    "        \n",
    "        # Value factors (1/3 total weight)\n",
    "        \"pe_weight\": 0.167,  # 0.5 * 1/3 = 0.167\n",
    "        \"fcf_yield_weight\": 0.167,  # 0.5 * 1/3 = 0.167\n",
    "        \n",
    "        # Momentum factors (1/3 total weight)\n",
    "        \"momentum_weight\": 0.167,  # 0.5 * 1/3 = 0.167\n",
    "        \"low_vol_weight\": 0.167,  # 0.5 * 1/3 = 0.167\n",
    "        \n",
    "        \"momentum_horizons\": [21, 63, 126, 252],\n",
    "        \"skip_months\": 1,\n",
    "        \"fundamental_lag_days\": 45,\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n⚙️  QVM Engine v3j Comprehensive Multi-Factor v2 Configuration Loaded:\")\n",
    "print(f\"   - Strategy: {QVM_CONFIG['strategy_name']}\")\n",
    "print(f\"   - Period: {QVM_CONFIG['backtest_start_date']} to {QVM_CONFIG['backtest_end_date']}\")\n",
    "print(f\"   - Universe: Top {QVM_CONFIG['universe']['top_n_stocks']} stocks by ADTV\")\n",
    "print(f\"   - Rebalancing: {QVM_CONFIG['rebalance_frequency']} frequency\")\n",
    "print(f\"   - Quality (1/3): ROAA 50% + F-Score 50%\")\n",
    "print(f\"   - Value (1/3): P/E 50% + FCF Yield 50%\")\n",
    "print(f\"   - Momentum (1/3): 4-Horizon 50% + Low Vol 50%\")\n",
    "print(f\"   - Data Source: VNSC daily data + Raw fundamental data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a52a70",
   "metadata": {},
   "source": [
    "# DATA LOADING AND PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abe94ef",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_db_connection():\n",
    "    \"\"\"Create database connection.\"\"\"\n",
    "    try:\n",
    "        db_manager = get_database_manager()\n",
    "        engine = db_manager.get_engine()\n",
    "        print(\"✅ Database connection established\")\n",
    "        return engine\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Database connection failed: {e}\")\n",
    "        raise\n",
    "\n",
    "def load_universe_data(config: dict, db_engine):\n",
    "    \"\"\"Load universe data using VNSC daily data.\"\"\"\n",
    "    print(\"📊 Loading universe data...\")\n",
    "    \n",
    "    start_date = pd.to_datetime(config['backtest_start_date']) - timedelta(days=config['universe']['lookback_days'])\n",
    "    \n",
    "    query = text(\"\"\"\n",
    "        SELECT \n",
    "            ticker,\n",
    "            trading_date,\n",
    "            close_price_adjusted as close,\n",
    "            total_volume as volume,\n",
    "            total_value as value,\n",
    "            market_cap\n",
    "        FROM vcsc_daily_data_complete\n",
    "        WHERE trading_date >= :start_date\n",
    "        AND close_price_adjusted > 0\n",
    "        AND total_volume > 0\n",
    "        ORDER BY ticker, trading_date\n",
    "    \"\"\")\n",
    "    \n",
    "    universe_data = pd.read_sql(query, db_engine, params={'start_date': start_date})\n",
    "    \n",
    "    print(f\"   ✅ Loaded {len(universe_data):,} universe records\")\n",
    "    print(f\"   📊 Coverage: {universe_data['ticker'].nunique()} tickers\")\n",
    "    \n",
    "    return universe_data\n",
    "\n",
    "def calculate_universe_rankings(universe_data: pd.DataFrame, config: dict) -> pd.DataFrame:\n",
    "    \"\"\"Calculate universe rankings based on average daily turnover.\"\"\"\n",
    "    print(\"📊 Calculating universe rankings...\")\n",
    "    \n",
    "    # Calculate average daily turnover for each stock\n",
    "    rankings = universe_data.groupby('ticker').agg({\n",
    "        'volume': 'mean',\n",
    "        'value': 'mean',\n",
    "        'market_cap': 'mean',\n",
    "        'trading_date': 'max'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Calculate average daily turnover (volume * price)\n",
    "    rankings['avg_daily_turnover'] = rankings['volume'] * rankings['market_cap'] / rankings['market_cap']\n",
    "    \n",
    "    # Sort by average daily turnover and get top N\n",
    "    top_n = config['universe']['top_n_stocks']\n",
    "    rankings = rankings.nlargest(top_n * 2, 'avg_daily_turnover')  # Get 2x for filtering\n",
    "    \n",
    "    # Add ranking\n",
    "    rankings['ranking'] = range(1, len(rankings) + 1)\n",
    "    \n",
    "    print(f\"   ✅ Calculated rankings for {len(rankings)} stocks\")\n",
    "    print(f\"   📊 Top stock: {rankings.iloc[0]['ticker']} (turnover: {rankings.iloc[0]['avg_daily_turnover']:,.0f})\")\n",
    "    \n",
    "    return rankings\n",
    "\n",
    "def load_benchmark_data(config: dict, db_engine):\n",
    "    \"\"\"Load benchmark data (VN-Index).\"\"\"\n",
    "    print(\"📊 Loading benchmark data...\")\n",
    "    \n",
    "    query = text(\"\"\"\n",
    "        SELECT \n",
    "            trading_date,\n",
    "            close_price_adjusted as close\n",
    "        FROM vcsc_daily_data_complete\n",
    "        WHERE ticker = 'VNM'\n",
    "        AND trading_date BETWEEN :start_date AND :end_date\n",
    "        ORDER BY trading_date\n",
    "    \"\"\")\n",
    "    \n",
    "    benchmark_data = pd.read_sql(query, db_engine, params={\n",
    "        'start_date': config['backtest_start_date'],\n",
    "        'end_date': config['backtest_end_date']\n",
    "    })\n",
    "    \n",
    "    # Calculate benchmark returns\n",
    "    benchmark_data['returns'] = benchmark_data['close'].pct_change()\n",
    "    \n",
    "    print(f\"   ✅ Loaded {len(benchmark_data)} benchmark records\")\n",
    "    print(f\"   📅 Period: {benchmark_data['trading_date'].min()} to {benchmark_data['trading_date'].max()}\")\n",
    "    \n",
    "    return benchmark_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea024a9",
   "metadata": {},
   "source": [
    "# FACTOR CALCULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67fb342",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def calculate_fundamental_factors(config: dict, db_engine):\n",
    "    \"\"\"Calculate fundamental factors using raw data.\"\"\"\n",
    "    print(\"📊 Calculating fundamental factors...\")\n",
    "    \n",
    "    # Initialize fundamental calculator\n",
    "    fundamental_calc = FundamentalFactorCalculator(db_engine)\n",
    "    \n",
    "    # Calculate factors for the entire period\n",
    "    fundamental_factors = fundamental_calc.calculate_all_factors(\n",
    "        config['backtest_start_date'],\n",
    "        config['backtest_end_date']\n",
    "    )\n",
    "    \n",
    "    print(f\"   ✅ Calculated fundamental factors for {len(fundamental_factors)} records\")\n",
    "    print(f\"   📊 Coverage: {fundamental_factors['ticker'].nunique()} tickers\")\n",
    "    \n",
    "    return fundamental_factors\n",
    "\n",
    "def calculate_momentum_volatility_factors(config: dict, db_engine):\n",
    "    \"\"\"Calculate momentum and volatility factors using VNSC data.\"\"\"\n",
    "    print(\"📊 Calculating momentum and volatility factors...\")\n",
    "    \n",
    "    # Initialize momentum/volatility calculator\n",
    "    momentum_vol_calc = MomentumVolatilityCalculator(db_engine)\n",
    "    \n",
    "    # Calculate factors for the entire period\n",
    "    momentum_vol_factors = momentum_vol_calc.calculate_all_factors(\n",
    "        config['backtest_start_date'],\n",
    "        config['backtest_end_date']\n",
    "    )\n",
    "    \n",
    "    print(f\"   ✅ Calculated momentum/volatility factors for {len(momentum_vol_factors)} records\")\n",
    "    print(f\"   📊 Coverage: {momentum_vol_factors['ticker'].nunique()} tickers\")\n",
    "    \n",
    "    return momentum_vol_factors\n",
    "\n",
    "def combine_all_factors(fundamental_factors: pd.DataFrame, \n",
    "                       momentum_vol_factors: pd.DataFrame,\n",
    "                       universe_rankings: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Combine all factors into a single dataset.\"\"\"\n",
    "    print(\"📊 Combining all factors...\")\n",
    "    \n",
    "    # Get universe tickers\n",
    "    universe_tickers = universe_rankings['ticker'].tolist()\n",
    "    \n",
    "    # Filter factors to universe\n",
    "    fundamental_filtered = fundamental_factors[fundamental_factors['ticker'].isin(universe_tickers)]\n",
    "    momentum_vol_filtered = momentum_vol_factors[momentum_vol_factors['ticker'].isin(universe_tickers)]\n",
    "    \n",
    "    # Convert fundamental date to datetime for merging\n",
    "    fundamental_filtered['date'] = pd.to_datetime(fundamental_filtered['date'])\n",
    "    \n",
    "    # Merge fundamental and momentum/volatility factors\n",
    "    combined_factors = fundamental_filtered.merge(\n",
    "        momentum_vol_factors[['ticker', 'trading_date', 'composite_momentum', 'low_vol_score', 'momentum_vol_score']],\n",
    "        left_on=['ticker', 'date'],\n",
    "        right_on=['ticker', 'trading_date'],\n",
    "        how='outer'\n",
    "    )\n",
    "    \n",
    "    # Fill missing values\n",
    "    combined_factors['roaa'] = combined_factors['roaa'].fillna(0)\n",
    "    combined_factors['pe_ratio'] = combined_factors['pe_ratio'].fillna(50)\n",
    "    combined_factors['fcf_yield'] = combined_factors['fcf_yield'].fillna(0)\n",
    "    combined_factors['f_score'] = combined_factors['f_score'].fillna(0)\n",
    "    combined_factors['composite_momentum'] = combined_factors['composite_momentum'].fillna(0)\n",
    "    combined_factors['low_vol_score'] = combined_factors['low_vol_score'].fillna(0.5)\n",
    "    \n",
    "    print(f\"   ✅ Combined factors for {len(combined_factors)} records\")\n",
    "    print(f\"   📊 Coverage: {combined_factors['ticker'].nunique()} tickers\")\n",
    "    \n",
    "    return combined_factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5a6e49",
   "metadata": {},
   "source": [
    "# FACTOR NORMALIZATION AND SCORING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119a8dea",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def normalize_factor(factor_series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Normalize factor to 0-1 range using winsorization and z-score.\"\"\"\n",
    "    if factor_series.empty or factor_series.isna().all():\n",
    "        return pd.Series(0, index=factor_series.index)\n",
    "    \n",
    "    # Remove outliers using winsorization\n",
    "    factor_clean = factor_series.copy()\n",
    "    q1 = factor_clean.quantile(0.01)\n",
    "    q99 = factor_clean.quantile(0.99)\n",
    "    factor_clean = factor_clean.clip(q1, q99)\n",
    "    \n",
    "    # Calculate z-score\n",
    "    mean_val = factor_clean.mean()\n",
    "    std_val = factor_clean.std()\n",
    "    \n",
    "    if std_val == 0:\n",
    "        return pd.Series(0.5, index=factor_series.index)\n",
    "    \n",
    "    z_scores = (factor_clean - mean_val) / std_val\n",
    "    \n",
    "    # Convert to 0-1 range using sigmoid\n",
    "    normalized = 1 / (1 + np.exp(-z_scores))\n",
    "    \n",
    "    return normalized.fillna(0.5)\n",
    "\n",
    "def calculate_composite_scores(combined_factors: pd.DataFrame, config: dict) -> pd.DataFrame:\n",
    "    \"\"\"Calculate composite factor scores.\"\"\"\n",
    "    print(\"📊 Calculating composite scores...\")\n",
    "    \n",
    "    # Normalize individual factors\n",
    "    combined_factors['roaa_score'] = normalize_factor(combined_factors['roaa'])\n",
    "    combined_factors['pe_score'] = normalize_factor(-combined_factors['pe_ratio'])  # Lower P/E is better\n",
    "    combined_factors['fcf_yield_score'] = normalize_factor(combined_factors['fcf_yield'])\n",
    "    combined_factors['f_score_score'] = normalize_factor(combined_factors['f_score'])\n",
    "    combined_factors['momentum_score'] = normalize_factor(combined_factors['composite_momentum'])\n",
    "    combined_factors['low_vol_score_final'] = normalize_factor(combined_factors['low_vol_score'])\n",
    "    \n",
    "    # Calculate composite scores by category\n",
    "    # Quality factors (1/3 total weight)\n",
    "    quality_score = (\n",
    "        combined_factors['roaa_score'] * 0.5 +  # 50% of quality\n",
    "        combined_factors['f_score_score'] * 0.5   # 50% of quality\n",
    "    )\n",
    "    \n",
    "    # Value factors (1/3 total weight)\n",
    "    value_score = (\n",
    "        combined_factors['pe_score'] * 0.5 +      # 50% of value\n",
    "        combined_factors['fcf_yield_score'] * 0.5  # 50% of value\n",
    "    )\n",
    "    \n",
    "    # Momentum factors (1/3 total weight)\n",
    "    momentum_score = (\n",
    "        combined_factors['momentum_score'] * 0.5 +  # 50% of momentum (4-horizon average)\n",
    "        combined_factors['low_vol_score_final'] * 0.5     # 50% of momentum (low vol)\n",
    "    )\n",
    "    \n",
    "    # Final composite score: 1/3 Quality + 1/3 Value + 1/3 Momentum\n",
    "    combined_factors['composite_score'] = (\n",
    "        quality_score * (1/3) +\n",
    "        value_score * (1/3) +\n",
    "        momentum_score * (1/3)\n",
    "    )\n",
    "    \n",
    "    print(f\"   ✅ Calculated composite scores for {len(combined_factors)} records\")\n",
    "    print(f\"   📊 Score range: {combined_factors['composite_score'].min():.4f} to {combined_factors['composite_score'].max():.4f}\")\n",
    "    \n",
    "    return combined_factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2042d8f0",
   "metadata": {},
   "source": [
    "# BACKTESTING ENGINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cdd39b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class QVMEngineV3jComprehensiveV2:\n",
    "    \"\"\"QVM Engine v3j with comprehensive 6-factor approach using VNSC data.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: dict, db_engine, universe_data: pd.DataFrame, \n",
    "                 fundamental_factors: pd.DataFrame, momentum_vol_factors: pd.DataFrame,\n",
    "                 benchmark_data: pd.DataFrame):\n",
    "        \n",
    "        self.config = config\n",
    "        self.db_engine = db_engine\n",
    "        self.universe_data = universe_data\n",
    "        self.fundamental_factors = fundamental_factors\n",
    "        self.momentum_vol_factors = momentum_vol_factors\n",
    "        self.benchmark_data = benchmark_data\n",
    "        \n",
    "        # Setup data\n",
    "        self._setup_data()\n",
    "        \n",
    "        print(\"✅ QVM Engine v3j Comprehensive v2 initialized\")\n",
    "        print(\"   - 6-factor comprehensive structure with VNSC data\")\n",
    "        print(\"   - Enhanced fundamental data with proper mappings\")\n",
    "        print(\"   - Balanced factor weights\")\n",
    "    \n",
    "    def _setup_data(self):\n",
    "        \"\"\"Setup data for easy access.\"\"\"\n",
    "        # Calculate universe rankings\n",
    "        self.universe_rankings = calculate_universe_rankings(self.universe_data, self.config)\n",
    "        \n",
    "        # Combine all factors\n",
    "        self.combined_factors = combine_all_factors(\n",
    "            self.fundamental_factors,\n",
    "            self.momentum_vol_factors,\n",
    "            self.universe_rankings\n",
    "        )\n",
    "        \n",
    "        # Calculate composite scores\n",
    "        self.combined_factors = calculate_composite_scores(self.combined_factors, self.config)\n",
    "        \n",
    "        print(\"   📊 Data setup complete:\")\n",
    "        print(f\"      - Universe: {len(self.universe_rankings)} stocks\")\n",
    "        print(f\"      - Combined factors: {len(self.combined_factors)} records\")\n",
    "        print(f\"      - Benchmark: {len(self.benchmark_data)} records\")\n",
    "    \n",
    "    def run_backtest(self) -> (pd.Series, pd.DataFrame):\n",
    "        \"\"\"Run comprehensive backtest.\"\"\"\n",
    "        print(\"\\n🚀 Running QVM Engine v3j Comprehensive v2 Backtest...\")\n",
    "        \n",
    "        # Generate rebalancing dates\n",
    "        rebalance_dates = self._generate_rebalance_dates()\n",
    "        \n",
    "        # Run backtesting loop\n",
    "        daily_holdings, diagnostics = self._run_comprehensive_backtesting_loop(rebalance_dates)\n",
    "        \n",
    "        # Calculate net returns\n",
    "        net_returns = self._calculate_net_returns(daily_holdings)\n",
    "        \n",
    "        return net_returns, diagnostics\n",
    "    \n",
    "    def _generate_rebalance_dates(self) -> list:\n",
    "        \"\"\"Generate monthly rebalancing dates.\"\"\"\n",
    "        print(\"   📊 Generating monthly rebalancing dates...\")\n",
    "        \n",
    "        # Get all trading dates from benchmark\n",
    "        all_trading_dates = pd.to_datetime(self.benchmark_data['trading_date'])\n",
    "        \n",
    "        # Generate monthly rebalancing dates\n",
    "        rebal_dates_calendar = pd.date_range(\n",
    "            start=self.config['backtest_start_date'],\n",
    "            end=self.config['backtest_end_date'],\n",
    "            freq=self.config['rebalance_frequency']\n",
    "        )\n",
    "        \n",
    "        actual_rebal_dates = []\n",
    "        for d in rebal_dates_calendar:\n",
    "            if d >= all_trading_dates.min():\n",
    "                idx = all_trading_dates.searchsorted(d, side='left')\n",
    "                if idx > 0:\n",
    "                    actual_rebal_dates.append(all_trading_dates[idx-1])\n",
    "        \n",
    "        actual_rebal_dates = sorted(list(set(actual_rebal_dates)))\n",
    "        rebalancing_dates = [{'date': date, 'allocation': 1.0} for date in actual_rebal_dates]\n",
    "        \n",
    "        print(f\"   ✅ Generated {len(rebalancing_dates)} monthly rebalancing dates\")\n",
    "        return rebalancing_dates\n",
    "    \n",
    "    def _run_comprehensive_backtesting_loop(self, rebalance_dates: list) -> (pd.DataFrame, pd.DataFrame):\n",
    "        \"\"\"Run comprehensive backtesting loop with 6 factors.\"\"\"\n",
    "        print(\"   🔄 Running comprehensive backtesting loop...\")\n",
    "        \n",
    "        current_portfolio = pd.Series(dtype=float)\n",
    "        daily_holdings = []\n",
    "        diagnostics = []\n",
    "        \n",
    "        for i, rebal_info in enumerate(rebalance_dates, 1):\n",
    "            rebal_date = rebal_info['date']\n",
    "            allocation = rebal_info['allocation']\n",
    "            \n",
    "            print(f\"   🔄 Rebalancing {i}/{len(rebalance_dates)}: {rebal_date.strftime('%Y-%m-%d')}\")\n",
    "            \n",
    "            # Get universe for this date\n",
    "            universe = self._get_universe_for_date(rebal_date)\n",
    "            \n",
    "            if len(universe) == 0:\n",
    "                print(f\"   ⚠️  No stocks in universe for {rebal_date}\")\n",
    "                continue\n",
    "            \n",
    "            # Get comprehensive factors for this date\n",
    "            factors_df = self._get_factors_for_date(universe, rebal_date)\n",
    "            \n",
    "            if factors_df.empty:\n",
    "                print(f\"   ⚠️  No factor data for {rebal_date}\")\n",
    "                continue\n",
    "            \n",
    "            # Apply entry criteria\n",
    "            qualified_df = self._apply_entry_criteria(factors_df)\n",
    "            \n",
    "            if qualified_df.empty:\n",
    "                print(f\"   ⚠️  No stocks qualified for {rebal_date}\")\n",
    "                continue\n",
    "            \n",
    "            # Construct portfolio\n",
    "            portfolio = self._construct_portfolio(qualified_df, allocation)\n",
    "            \n",
    "            # Calculate turnover\n",
    "            turnover = self._calculate_turnover(current_portfolio, portfolio)\n",
    "            \n",
    "            # Update current portfolio\n",
    "            current_portfolio = portfolio\n",
    "            \n",
    "            # Store diagnostics\n",
    "            diagnostic = {\n",
    "                'date': rebal_date,\n",
    "                'universe_size': len(universe),\n",
    "                'qualified_size': len(qualified_df),\n",
    "                'portfolio_size': len(portfolio),\n",
    "                'allocation': allocation,\n",
    "                'turnover': turnover\n",
    "            }\n",
    "            diagnostics.append(diagnostic)\n",
    "            \n",
    "            print(f\"   ✅ Universe: {len(universe)}, Portfolio: {len(portfolio)}, Allocation: {allocation:.1%}, Turnover: {turnover:.1%}\")\n",
    "            \n",
    "            # Store daily holdings for this period\n",
    "            next_rebal_date = rebalance_dates[i]['date'] if i < len(rebalance_dates) else self.benchmark_data['trading_date'].max()\n",
    "            \n",
    "            period_dates = self.benchmark_data[\n",
    "                (self.benchmark_data['trading_date'] >= rebal_date) & \n",
    "                (self.benchmark_data['trading_date'] <= next_rebal_date)\n",
    "            ]['trading_date']\n",
    "            \n",
    "            for date in period_dates:\n",
    "                daily_holding = {\n",
    "                    'date': date,\n",
    "                    'portfolio': portfolio.copy()\n",
    "                }\n",
    "                daily_holdings.append(daily_holding)\n",
    "        \n",
    "        daily_holdings_df = pd.DataFrame(daily_holdings)\n",
    "        diagnostics_df = pd.DataFrame(diagnostics)\n",
    "        \n",
    "        return daily_holdings_df, diagnostics_df\n",
    "    \n",
    "    def _get_universe_for_date(self, analysis_date: pd.Timestamp) -> list:\n",
    "        \"\"\"Get universe for a specific date.\"\"\"\n",
    "        # Get universe tickers from rankings\n",
    "        universe_tickers = self.universe_rankings['ticker'].tolist()\n",
    "        \n",
    "        # Filter to stocks that have data on or before the analysis date\n",
    "        available_data = self.combined_factors[\n",
    "            (self.combined_factors['ticker'].isin(universe_tickers)) &\n",
    "            (self.combined_factors['trading_date'] <= analysis_date)\n",
    "        ]\n",
    "        \n",
    "        available_tickers = available_data['ticker'].unique().tolist()\n",
    "        \n",
    "        return available_tickers\n",
    "    \n",
    "    def _get_factors_for_date(self, universe: list, analysis_date: pd.Timestamp) -> pd.DataFrame:\n",
    "        \"\"\"Get factors for a specific date.\"\"\"\n",
    "        # Get the most recent factor data for each stock up to the analysis date\n",
    "        factors_data = []\n",
    "        \n",
    "        for ticker in universe:\n",
    "            ticker_data = self.combined_factors[\n",
    "                (self.combined_factors['ticker'] == ticker) & \n",
    "                (self.combined_factors['trading_date'] <= analysis_date)\n",
    "            ]\n",
    "            \n",
    "            if not ticker_data.empty:\n",
    "                # Get the most recent data\n",
    "                latest_data = ticker_data.iloc[-1]\n",
    "                \n",
    "                factor_row = {\n",
    "                    'ticker': ticker,\n",
    "                    'roaa': latest_data['roaa'],\n",
    "                    'pe_ratio': latest_data['pe_ratio'],\n",
    "                    'fcf_yield': latest_data['fcf_yield'],\n",
    "                    'f_score': latest_data['f_score'],\n",
    "                    'composite_momentum': latest_data['composite_momentum'],\n",
    "                    'low_vol_score': latest_data['low_vol_score'],\n",
    "                    'composite_score': latest_data['composite_score']\n",
    "                }\n",
    "                \n",
    "                factors_data.append(factor_row)\n",
    "        \n",
    "        if not factors_data:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        factors_df = pd.DataFrame(factors_data)\n",
    "        \n",
    "        return factors_df\n",
    "    \n",
    "    def _apply_entry_criteria(self, factors_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Apply entry criteria to filter stocks.\"\"\"\n",
    "        qualified = factors_df.copy()\n",
    "        \n",
    "        # Basic quality filters\n",
    "        qualified = qualified[qualified['roaa'] > -0.5]  # ROAA not too negative\n",
    "        qualified = qualified[(qualified['pe_ratio'] > 0) & (qualified['pe_ratio'] < 100)]  # Reasonable P/E\n",
    "        \n",
    "        # Remove stocks with missing composite scores\n",
    "        qualified = qualified[qualified['composite_score'].notna()]\n",
    "        \n",
    "        # If still no stocks, relax further\n",
    "        if len(qualified) == 0:\n",
    "            print(f\"   ⚠️  No stocks qualified with strict criteria, relaxing filters...\")\n",
    "            qualified = factors_df.copy()\n",
    "            qualified = qualified[qualified['composite_score'].notna()]\n",
    "            \n",
    "            qualified = qualified[qualified['roaa'] > -1.0]  # More relaxed ROAA\n",
    "            qualified = qualified[(qualified['pe_ratio'] > 0) & (qualified['pe_ratio'] < 200)]  # More relaxed P/E\n",
    "        \n",
    "        print(f\"   ✅ {len(qualified)} stocks qualified for portfolio construction\")\n",
    "        return qualified\n",
    "    \n",
    "    def _construct_portfolio(self, qualified_df: pd.DataFrame, allocation: float) -> pd.Series:\n",
    "        \"\"\"Construct portfolio with sector limits.\"\"\"\n",
    "        sorted_df = qualified_df.sort_values('composite_score', ascending=False)\n",
    "        target_size = self.config['universe']['target_portfolio_size']\n",
    "        selected_stocks = sorted_df.head(target_size)\n",
    "        \n",
    "        portfolio = pd.Series(1.0 / len(selected_stocks), index=selected_stocks['ticker'])\n",
    "        portfolio = portfolio * allocation\n",
    "        \n",
    "        return portfolio\n",
    "    \n",
    "    def _calculate_turnover(self, current_portfolio: pd.Series, new_portfolio: pd.Series) -> float:\n",
    "        \"\"\"Calculate portfolio turnover.\"\"\"\n",
    "        if current_portfolio.empty:\n",
    "            return 0.0\n",
    "        \n",
    "        # Calculate turnover as sum of absolute differences\n",
    "        all_tickers = set(current_portfolio.index) | set(new_portfolio.index)\n",
    "        turnover = 0.0\n",
    "        \n",
    "        for ticker in all_tickers:\n",
    "            old_weight = current_portfolio.get(ticker, 0.0)\n",
    "            new_weight = new_portfolio.get(ticker, 0.0)\n",
    "            turnover += abs(new_weight - old_weight)\n",
    "        \n",
    "        return turnover / 2  # Divide by 2 since we're double-counting\n",
    "    \n",
    "    def _calculate_net_returns(self, daily_holdings: pd.DataFrame) -> pd.Series:\n",
    "        \"\"\"Calculate net returns with transaction costs.\"\"\"\n",
    "        print(\"💸 Calculating net returns...\")\n",
    "        \n",
    "        # Get price data for all stocks\n",
    "        all_tickers = set()\n",
    "        for _, holding in daily_holdings.iterrows():\n",
    "            all_tickers.update(holding['portfolio'].index)\n",
    "        \n",
    "        # Load price data for all stocks\n",
    "        price_query = text(\"\"\"\n",
    "            SELECT \n",
    "                ticker,\n",
    "                trading_date,\n",
    "                close_price_adjusted as close\n",
    "            FROM vcsc_daily_data_complete\n",
    "            WHERE ticker IN :tickers\n",
    "            AND trading_date BETWEEN :start_date AND :end_date\n",
    "            ORDER BY ticker, trading_date\n",
    "        \"\"\")\n",
    "        \n",
    "        price_data = pd.read_sql(price_query, self.db_engine, params={\n",
    "            'tickers': tuple(all_tickers),\n",
    "            'start_date': self.config['backtest_start_date'],\n",
    "            'end_date': self.config['backtest_end_date']\n",
    "        })\n",
    "        \n",
    "        # Pivot to get returns matrix\n",
    "        price_data['returns'] = price_data.groupby('ticker')['close'].pct_change()\n",
    "        returns_matrix = price_data.pivot(index='trading_date', columns='ticker', values='returns')\n",
    "        \n",
    "        # Calculate gross returns\n",
    "        gross_returns = pd.Series(0.0, index=returns_matrix.index)\n",
    "        \n",
    "        for _, holding in daily_holdings.iterrows():\n",
    "            date = holding['date']\n",
    "            portfolio = holding['portfolio']\n",
    "            \n",
    "            if not portfolio.empty and date in returns_matrix.index:\n",
    "                stock_returns = returns_matrix.loc[date, portfolio.index]\n",
    "                gross_returns[date] = (portfolio * stock_returns).sum()\n",
    "        \n",
    "        # Apply transaction costs\n",
    "        transaction_cost_bps = self.config['transaction_cost_bps'] / 10000\n",
    "        net_returns = gross_returns.copy()\n",
    "        \n",
    "        # Apply minimal daily cost for simplicity\n",
    "        daily_cost = 0.0001  # 1 basis point per day\n",
    "        net_returns = gross_returns - daily_cost\n",
    "        \n",
    "        total_gross = (1 + gross_returns).prod() - 1\n",
    "        total_net = (1 + net_returns).prod() - 1\n",
    "        cost_drag = total_gross - total_net\n",
    "        \n",
    "        print(f\"   - Total Gross Return: {total_gross:.2%}\")\n",
    "        print(f\"   - Total Net Return: {total_net:.2%}\")\n",
    "        print(f\"   - Total Cost Drag: {cost_drag:.2%}\")\n",
    "        \n",
    "        return net_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0139cd60",
   "metadata": {},
   "source": [
    "# PERFORMANCE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918d2ec6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def calculate_performance_metrics(strategy_returns: pd.Series, benchmark_returns: pd.Series) -> dict:\n",
    "    \"\"\"Calculate comprehensive performance metrics.\"\"\"\n",
    "    print(\"📊 Calculating performance metrics...\")\n",
    "    \n",
    "    # Calculate basic metrics\n",
    "    total_return = (1 + strategy_returns).prod() - 1\n",
    "    benchmark_total_return = (1 + benchmark_returns).prod() - 1\n",
    "    \n",
    "    # Annualized returns\n",
    "    years = len(strategy_returns) / 252\n",
    "    annualized_return = (1 + total_return) ** (1 / years) - 1\n",
    "    benchmark_annualized_return = (1 + benchmark_total_return) ** (1 / years) - 1\n",
    "    \n",
    "    # Volatility\n",
    "    strategy_vol = strategy_returns.std() * np.sqrt(252)\n",
    "    benchmark_vol = benchmark_returns.std() * np.sqrt(252)\n",
    "    \n",
    "    # Sharpe ratios\n",
    "    risk_free_rate = 0.02  # Assume 2% risk-free rate\n",
    "    strategy_sharpe = (annualized_return - risk_free_rate) / strategy_vol\n",
    "    benchmark_sharpe = (benchmark_annualized_return - risk_free_rate) / benchmark_vol\n",
    "    \n",
    "    # Maximum drawdown\n",
    "    strategy_cumulative = (1 + strategy_returns).cumprod()\n",
    "    strategy_peak = strategy_cumulative.expanding().max()\n",
    "    strategy_drawdown = (strategy_cumulative - strategy_peak) / strategy_peak\n",
    "    max_drawdown = strategy_drawdown.min()\n",
    "    \n",
    "    benchmark_cumulative = (1 + benchmark_returns).cumprod()\n",
    "    benchmark_peak = benchmark_cumulative.expanding().max()\n",
    "    benchmark_drawdown = (benchmark_cumulative - benchmark_peak) / benchmark_peak\n",
    "    benchmark_max_drawdown = benchmark_drawdown.min()\n",
    "    \n",
    "    # Information ratio\n",
    "    excess_returns = strategy_returns - benchmark_returns\n",
    "    information_ratio = excess_returns.mean() / excess_returns.std() * np.sqrt(252)\n",
    "    \n",
    "    # Beta\n",
    "    covariance = np.cov(strategy_returns, benchmark_returns)[0, 1]\n",
    "    benchmark_variance = np.var(benchmark_returns)\n",
    "    beta = covariance / benchmark_variance\n",
    "    \n",
    "    # Alpha\n",
    "    alpha = annualized_return - (risk_free_rate + beta * (benchmark_annualized_return - risk_free_rate))\n",
    "    \n",
    "    metrics = {\n",
    "        'total_return': total_return,\n",
    "        'benchmark_total_return': benchmark_total_return,\n",
    "        'annualized_return': annualized_return,\n",
    "        'benchmark_annualized_return': benchmark_annualized_return,\n",
    "        'volatility': strategy_vol,\n",
    "        'benchmark_volatility': benchmark_vol,\n",
    "        'sharpe_ratio': strategy_sharpe,\n",
    "        'benchmark_sharpe': benchmark_sharpe,\n",
    "        'max_drawdown': max_drawdown,\n",
    "        'benchmark_max_drawdown': benchmark_max_drawdown,\n",
    "        'information_ratio': information_ratio,\n",
    "        'beta': beta,\n",
    "        'alpha': alpha\n",
    "    }\n",
    "    \n",
    "    print(f\"   ✅ Calculated {len(metrics)} performance metrics\")\n",
    "    return metrics\n",
    "\n",
    "def generate_tearsheet(strategy_returns: pd.Series, benchmark_returns: pd.Series, \n",
    "                      diagnostics: pd.DataFrame, strategy_name: str):\n",
    "    \"\"\"Generate comprehensive tearsheet.\"\"\"\n",
    "    print(\"📊 Generating tearsheet...\")\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = calculate_performance_metrics(strategy_returns, benchmark_returns)\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle(f'{strategy_name}\\nPerformance Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Plot 1: Cumulative Returns\n",
    "    strategy_cumulative = (1 + strategy_returns).cumprod()\n",
    "    benchmark_cumulative = (1 + benchmark_returns).cumprod()\n",
    "    \n",
    "    axes[0, 0].plot(strategy_cumulative.index, strategy_cumulative.values, label='Strategy', linewidth=2)\n",
    "    axes[0, 0].plot(benchmark_cumulative.index, benchmark_cumulative.values, label='Benchmark', linewidth=2)\n",
    "    axes[0, 0].set_title('Cumulative Returns')\n",
    "    axes[0, 0].set_ylabel('Cumulative Return')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Drawdown\n",
    "    strategy_peak = strategy_cumulative.expanding().max()\n",
    "    strategy_drawdown = (strategy_cumulative - strategy_peak) / strategy_peak\n",
    "    \n",
    "    axes[0, 1].fill_between(strategy_drawdown.index, strategy_drawdown.values, 0, alpha=0.3, color='red')\n",
    "    axes[0, 1].plot(strategy_drawdown.index, strategy_drawdown.values, color='red', linewidth=1)\n",
    "    axes[0, 1].set_title('Drawdown')\n",
    "    axes[0, 1].set_ylabel('Drawdown')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Rolling Sharpe Ratio\n",
    "    rolling_sharpe = strategy_returns.rolling(252).mean() / strategy_returns.rolling(252).std() * np.sqrt(252)\n",
    "    \n",
    "    axes[1, 0].plot(rolling_sharpe.index, rolling_sharpe.values, linewidth=2)\n",
    "    axes[1, 0].set_title('Rolling Sharpe Ratio (252-day)')\n",
    "    axes[1, 0].set_ylabel('Sharpe Ratio')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Portfolio Size Over Time\n",
    "    portfolio_sizes = diagnostics.groupby('date')['portfolio_size'].mean()\n",
    "    \n",
    "    axes[1, 1].plot(portfolio_sizes.index, portfolio_sizes.values, linewidth=2)\n",
    "    axes[1, 1].set_title('Average Portfolio Size')\n",
    "    axes[1, 1].set_ylabel('Number of Stocks')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"tearsheet_{strategy_name.replace(' ', '_')}_{timestamp}.png\"\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"   ✅ Tearsheet saved as {filename}\")\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n📊 PERFORMANCE SUMMARY:\")\n",
    "    print(f\"   Strategy Annualized Return: {metrics['annualized_return']:.2%}\")\n",
    "    print(f\"   Benchmark Annualized Return: {metrics['benchmark_annualized_return']:.2%}\")\n",
    "    print(f\"   Strategy Sharpe Ratio: {metrics['sharpe_ratio']:.2f}\")\n",
    "    print(f\"   Benchmark Sharpe Ratio: {metrics['benchmark_sharpe']:.2f}\")\n",
    "    print(f\"   Strategy Max Drawdown: {metrics['max_drawdown']:.2%}\")\n",
    "    print(f\"   Benchmark Max Drawdown: {metrics['benchmark_max_drawdown']:.2%}\")\n",
    "    print(f\"   Information Ratio: {metrics['information_ratio']:.2f}\")\n",
    "    print(f\"   Beta: {metrics['beta']:.2f}\")\n",
    "    print(f\"   Alpha: {metrics['alpha']:.2%}\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3987e",
   "metadata": {},
   "source": [
    "# MAIN EXECUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f612d1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main execution function for the comprehensive multi-factor strategy.\"\"\"\n",
    "    print(\"🚀 QVM ENGINE V3J COMPREHENSIVE MULTI-FACTOR V2 EXECUTION\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Database connection\n",
    "        print(\"📊 Step 1: Establishing database connection...\")\n",
    "        db_engine = create_db_connection()\n",
    "        \n",
    "        # Step 2: Load universe data\n",
    "        print(\"📊 Step 2: Loading universe data...\")\n",
    "        universe_data = load_universe_data(QVM_CONFIG, db_engine)\n",
    "        \n",
    "        # Step 3: Load benchmark data\n",
    "        print(\"📊 Step 3: Loading benchmark data...\")\n",
    "        benchmark_data = load_benchmark_data(QVM_CONFIG, db_engine)\n",
    "        \n",
    "        # Step 4: Calculate fundamental factors\n",
    "        print(\"📊 Step 4: Calculating fundamental factors...\")\n",
    "        fundamental_factors = calculate_fundamental_factors(QVM_CONFIG, db_engine)\n",
    "        \n",
    "        # Step 5: Calculate momentum and volatility factors\n",
    "        print(\"📊 Step 5: Calculating momentum and volatility factors...\")\n",
    "        momentum_vol_factors = calculate_momentum_volatility_factors(QVM_CONFIG, db_engine)\n",
    "        \n",
    "        # Step 6: Initialize and run comprehensive strategy\n",
    "        print(\"📊 Step 6: Running comprehensive strategy...\")\n",
    "        \n",
    "        engine = QVMEngineV3jComprehensiveV2(\n",
    "            QVM_CONFIG,\n",
    "            db_engine,\n",
    "            universe_data,\n",
    "            fundamental_factors,\n",
    "            momentum_vol_factors,\n",
    "            benchmark_data\n",
    "        )\n",
    "        \n",
    "        strategy_returns, diagnostics = engine.run_backtest()\n",
    "        \n",
    "        # Step 7: Calculate performance metrics\n",
    "        print(\"📊 Step 7: Calculating performance metrics...\")\n",
    "        benchmark_returns = benchmark_data.set_index('trading_date')['returns']\n",
    "        metrics = calculate_performance_metrics(strategy_returns, benchmark_returns)\n",
    "        \n",
    "        # Step 8: Generate tearsheet\n",
    "        print(\"📊 Step 8: Generating comprehensive tearsheet...\")\n",
    "        generate_tearsheet(\n",
    "            strategy_returns, \n",
    "            benchmark_returns,\n",
    "            diagnostics, \n",
    "            QVM_CONFIG['strategy_name']\n",
    "        )\n",
    "        \n",
    "        # Step 9: Display results\n",
    "        print(\"=\" * 80)\n",
    "        print(\"📊 QVM ENGINE V3J: COMPREHENSIVE MULTI-FACTOR V2 RESULTS\")\n",
    "        print(\"=\" * 80)\n",
    "        print(\"📈 Performance Summary:\")\n",
    "        print(f\"   - Strategy Annualized Return: {metrics['annualized_return']:.2%}\")\n",
    "        print(f\"   - Benchmark Annualized Return: {metrics['benchmark_annualized_return']:.2%}\")\n",
    "        print(f\"   - Strategy Sharpe Ratio: {metrics['sharpe_ratio']:.2f}\")\n",
    "        print(f\"   - Benchmark Sharpe Ratio: {metrics['benchmark_sharpe']:.2f}\")\n",
    "        print(f\"   - Strategy Max Drawdown: {metrics['max_drawdown']:.2%}\")\n",
    "        print(f\"   - Benchmark Max Drawdown: {metrics['benchmark_max_drawdown']:.2%}\")\n",
    "        print(f\"   - Information Ratio: {metrics['information_ratio']:.2f}\")\n",
    "        print(f\"   - Beta: {metrics['beta']:.2f}\")\n",
    "        print(f\"   - Alpha: {metrics['alpha']:.2%}\")\n",
    "        \n",
    "        print(\"\\n🔧 Comprehensive Configuration:\")\n",
    "        print(\"   - 6-factor comprehensive structure (ROAA, P/E, Momentum, FCF Yield, F-Score, Low Vol)\")\n",
    "        print(\"   - Balanced factor weights for optimal performance\")\n",
    "        print(\"   - Enhanced risk management with low volatility factor\")\n",
    "        print(\"   - Improved diversification with larger portfolio size\")\n",
    "        print(\"   - Data Source: VNSC daily data + Raw fundamental data for maximum coverage\")\n",
    "        \n",
    "        print(\"\\n✅ QVM Engine v3j Comprehensive v2 strategy execution complete!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during execution: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1658924b",
   "metadata": {},
   "source": [
    "# TESTING AND VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b39378",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def test_strategy_components():\n",
    "    \"\"\"Test individual strategy components.\"\"\"\n",
    "    print(\"🧪 Testing Strategy Components...\")\n",
    "    \n",
    "    try:\n",
    "        # Test database connection\n",
    "        print(\"   🔍 Testing database connection...\")\n",
    "        db_engine = create_db_connection()\n",
    "        print(\"   ✅ Database connection successful\")\n",
    "        \n",
    "        # Test universe data loading\n",
    "        print(\"   🔍 Testing universe data loading...\")\n",
    "        universe_data = load_universe_data(QVM_CONFIG, db_engine)\n",
    "        print(f\"   ✅ Universe data loaded: {len(universe_data):,} records\")\n",
    "        \n",
    "        # Test benchmark data loading\n",
    "        print(\"   🔍 Testing benchmark data loading...\")\n",
    "        benchmark_data = load_benchmark_data(QVM_CONFIG, db_engine)\n",
    "        print(f\"   ✅ Benchmark data loaded: {len(benchmark_data)} records\")\n",
    "        \n",
    "        # Test fundamental factor calculation (small period)\n",
    "        print(\"   🔍 Testing fundamental factor calculation...\")\n",
    "        test_config = QVM_CONFIG.copy()\n",
    "        test_config['backtest_start_date'] = \"2020-01-01\"\n",
    "        test_config['backtest_end_date'] = \"2020-12-31\"\n",
    "        \n",
    "        fundamental_factors = calculate_fundamental_factors(test_config, db_engine)\n",
    "        print(f\"   ✅ Fundamental factors calculated: {len(fundamental_factors)} records\")\n",
    "        \n",
    "        # Test momentum/volatility factor calculation (small period)\n",
    "        print(\"   🔍 Testing momentum/volatility factor calculation...\")\n",
    "        momentum_vol_factors = calculate_momentum_volatility_factors(test_config, db_engine)\n",
    "        print(f\"   ✅ Momentum/volatility factors calculated: {len(momentum_vol_factors)} records\")\n",
    "        \n",
    "        # Test factor combination\n",
    "        print(\"   🔍 Testing factor combination...\")\n",
    "        universe_rankings = calculate_universe_rankings(universe_data, test_config)\n",
    "        combined_factors = combine_all_factors(fundamental_factors, momentum_vol_factors, universe_rankings)\n",
    "        print(f\"   ✅ Factors combined: {len(combined_factors)} records\")\n",
    "        \n",
    "        # Test composite score calculation\n",
    "        print(\"   🔍 Testing composite score calculation...\")\n",
    "        combined_factors = calculate_composite_scores(combined_factors, test_config)\n",
    "        print(f\"   ✅ Composite scores calculated: {len(combined_factors)} records\")\n",
    "        \n",
    "        print(\"✅ All strategy components tested successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Component test failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "def run_quick_backtest():\n",
    "    \"\"\"Run a quick backtest on a smaller period for validation.\"\"\"\n",
    "    print(\"🧪 Running Quick Backtest...\")\n",
    "    \n",
    "    try:\n",
    "        # Create test configuration\n",
    "        test_config = QVM_CONFIG.copy()\n",
    "        test_config['backtest_start_date'] = \"2020-01-01\"\n",
    "        test_config['backtest_end_date'] = \"2020-12-31\"\n",
    "        test_config['universe']['target_portfolio_size'] = 20\n",
    "        \n",
    "        # Step 1: Database connection\n",
    "        db_engine = create_db_connection()\n",
    "        \n",
    "        # Step 2: Load data\n",
    "        universe_data = load_universe_data(test_config, db_engine)\n",
    "        benchmark_data = load_benchmark_data(test_config, db_engine)\n",
    "        \n",
    "        # Step 3: Calculate factors\n",
    "        fundamental_factors = calculate_fundamental_factors(test_config, db_engine)\n",
    "        momentum_vol_factors = calculate_momentum_volatility_factors(test_config, db_engine)\n",
    "        \n",
    "        # Step 4: Run strategy\n",
    "        engine = QVMEngineV3jComprehensiveV2(\n",
    "            test_config,\n",
    "            db_engine,\n",
    "            universe_data,\n",
    "            fundamental_factors,\n",
    "            momentum_vol_factors,\n",
    "            benchmark_data\n",
    "        )\n",
    "        \n",
    "        strategy_returns, diagnostics = engine.run_backtest()\n",
    "        \n",
    "        # Step 5: Calculate metrics\n",
    "        benchmark_returns = benchmark_data.set_index('trading_date')['returns']\n",
    "        metrics = calculate_performance_metrics(strategy_returns, benchmark_returns)\n",
    "        \n",
    "        # Step 6: Display results\n",
    "        print(f\"\\n📊 QUICK BACKTEST RESULTS (2020):\")\n",
    "        print(f\"   - Strategy Annualized Return: {metrics['annualized_return']:.2%}\")\n",
    "        print(f\"   - Benchmark Annualized Return: {metrics['benchmark_annualized_return']:.2%}\")\n",
    "        print(f\"   - Strategy Sharpe Ratio: {metrics['sharpe_ratio']:.2f}\")\n",
    "        print(f\"   - Information Ratio: {metrics['information_ratio']:.2f}\")\n",
    "        print(f\"   - Max Drawdown: {metrics['max_drawdown']:.2%}\")\n",
    "        \n",
    "        print(\"✅ Quick backtest completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Quick backtest failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6b7e18",
   "metadata": {},
   "source": [
    "# EXECUTION CONTROL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c04c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description='QVM Engine v3j Comprehensive Multi-Factor Strategy v2')\n",
    "    parser.add_argument('--mode', choices=['test', 'quick', 'full'], default='full',\n",
    "                       help='Execution mode: test (components), quick (2020), full (2016-2025)')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    if args.mode == 'test':\n",
    "        test_strategy_components()\n",
    "    elif args.mode == 'quick':\n",
    "        run_quick_backtest()\n",
    "    else:\n",
    "        main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
