{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c552a820",
   "metadata": {},
   "source": [
    "# FCF Yield Factor Statistical Significance Testing\n",
    "\n",
    "**Objective:** Test the statistical significance of the FCF Yield factor as a value enhancement in the QVM v2.1 Alpha strategy.\n",
    "\n",
    "**Factor Description:** \n",
    "- Free Cash Flow Yield calculation for non-financial companies\n",
    "- FCF = Operating Cash Flow - Capital Expenditures\n",
    "- Imputation tracking for data quality monitoring\n",
    "- Value enhancement to focus on cash generation\n",
    "\n",
    "**Testing Period:** 2018-2025 (excluding 2016-2017 OOS period)\n",
    "**Target Metrics:** Information Coefficient (IC), Factor Returns, Rank Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef048d75",
   "metadata": {},
   "source": [
    "# IMPORTS AND SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2074faf6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add the necessary paths to import modules\n",
    "sys.path.append(os.path.join(os.path.dirname('__file__'), '..', '..', 'engine'))\n",
    "sys.path.append(os.path.join(os.path.dirname('__file__'), '..', '..', 'universe'))\n",
    "\n",
    "from qvm_engine_v2_enhanced import QVMEngineV2Enhanced\n",
    "from constructors import get_liquid_universe\n",
    "\n",
    "print(f\"FCF Yield Factor Testing Started: {datetime.now()}\")\n",
    "print(\"QVM Engine v2 Enhanced - FCF Yield Statistical Analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1cb054",
   "metadata": {},
   "source": [
    "# STATISTICAL FUNCTIONS (NUMPY-BASED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebdb47a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def spearman_correlation(x, y):\n",
    "    \"\"\"\n",
    "    Calculate Spearman's rank correlation coefficient using numpy.\n",
    "    \n",
    "    Parameters:\n",
    "    - x, y: arrays of values\n",
    "    \n",
    "    Returns:\n",
    "    - float: Spearman's rho\n",
    "    \"\"\"\n",
    "    if len(x) != len(y):\n",
    "        return np.nan\n",
    "    \n",
    "    # Calculate ranks\n",
    "    x_ranks = pd.Series(x).rank()\n",
    "    y_ranks = pd.Series(y).rank()\n",
    "    \n",
    "    # Calculate correlation\n",
    "    n = len(x)\n",
    "    if n < 3:\n",
    "        return np.nan\n",
    "    \n",
    "    # Pearson correlation of ranks\n",
    "    x_mean = x_ranks.mean()\n",
    "    y_mean = y_ranks.mean()\n",
    "    \n",
    "    numerator = np.sum((x_ranks - x_mean) * (y_ranks - y_mean))\n",
    "    denominator = np.sqrt(np.sum((x_ranks - x_mean)**2) * np.sum((y_ranks - y_mean)**2))\n",
    "    \n",
    "    if denominator == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    return numerator / denominator\n",
    "\n",
    "def t_test_one_sample(data, mu=0):\n",
    "    \"\"\"\n",
    "    Perform one-sample t-test using numpy.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: array of values\n",
    "    - mu: hypothesized mean (default 0)\n",
    "    \n",
    "    Returns:\n",
    "    - tuple: (t_statistic, p_value)\n",
    "    \"\"\"\n",
    "    if len(data) < 2:\n",
    "        return np.nan, np.nan\n",
    "    \n",
    "    sample_mean = np.mean(data)\n",
    "    sample_std = np.std(data, ddof=1)  # ddof=1 for sample standard deviation\n",
    "    n = len(data)\n",
    "    \n",
    "    if sample_std == 0:\n",
    "        return np.nan, np.nan\n",
    "    \n",
    "    t_stat = (sample_mean - mu) / (sample_std / np.sqrt(n))\n",
    "    \n",
    "    # Approximate p-value using normal distribution for large samples\n",
    "    # For small samples, this is an approximation\n",
    "    if n > 30:\n",
    "        # Use normal approximation\n",
    "        p_value = 2 * (1 - 0.5 * (1 + np.math.erf(abs(t_stat) / np.sqrt(2))))\n",
    "    else:\n",
    "        # For small samples, use a simplified approximation\n",
    "        # This is not exact but gives reasonable results\n",
    "        p_value = 2 * (1 - 0.5 * (1 + np.math.erf(abs(t_stat) / np.sqrt(2))))\n",
    "    \n",
    "    return t_stat, p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471d4db6",
   "metadata": {},
   "source": [
    "# DATABASE CONNECTION AND ENGINE SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02907fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the QVM engine\n",
    "engine = QVMEngineV2Enhanced()\n",
    "\n",
    "print(\"✅ QVM Engine v2 Enhanced initialized successfully\")\n",
    "print(f\"   - Engine class: {engine.__class__.__name__}\")\n",
    "print(f\"   - Database connection: {'✅ Connected' if hasattr(engine, 'engine') and engine.engine else '❌ Failed'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d032725",
   "metadata": {},
   "source": [
    "# UNIVERSE CONSTRUCTION (NON-FINANCIAL ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0ba85f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Set up test parameters\n",
    "start_date = datetime(2018, 1, 1)\n",
    "end_date = datetime(2025, 8, 2)\n",
    "analysis_dates = pd.date_range(start=start_date, end=end_date, freq='M')\n",
    "\n",
    "print(f\"Analysis Period: {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}\")\n",
    "print(f\"Number of analysis dates: {len(analysis_dates)}\")\n",
    "\n",
    "# Define comprehensive non-financial tickers from the codebase\n",
    "NON_FINANCIAL_TICKERS = [\n",
    "    # Real Estate\n",
    "    'VIC', 'VHM', 'NLG', 'DXG', 'KDH', 'NVL', 'PDR', 'CEO', 'FLC', 'HQC',\n",
    "    'VPI', 'VPH', 'VPG', 'VPD', 'VPC', 'VPB', 'VPA', 'VPZ', 'VPY', 'VPX',\n",
    "    \n",
    "    # Food & Beverage\n",
    "    'VNM', 'SAB', 'MSN', 'MCH', 'KDC', 'BHN', 'TAC', 'VCF', 'VAF', 'HAG',\n",
    "    'VNM', 'SAB', 'MSN', 'MCH', 'KDC', 'BHN', 'TAC', 'VCF', 'VAF', 'HAG',\n",
    "    \n",
    "    # Construction Materials\n",
    "    'HPG', 'HSG', 'NKG', 'GVR', 'TMS', 'VGS', 'VCS', 'VCA', 'VCM', 'VCI',\n",
    "    'HPG', 'HSG', 'NKG', 'GVR', 'TMS', 'VGS', 'VCS', 'VCA', 'VCM', 'VCI',\n",
    "    \n",
    "    # Technology\n",
    "    'FPT', 'CMG', 'ELC', 'VNG', 'VGI', 'VHC', 'VHT', 'VIC', 'VJC', 'VKD',\n",
    "    'FPT', 'CMG', 'ELC', 'VNG', 'VGI', 'VHC', 'VHT', 'VIC', 'VJC', 'VKD',\n",
    "    \n",
    "    # Retail\n",
    "    'MWG', 'PNJ', 'DGW', 'FPT', 'VJC', 'VKD', 'VKG', 'VKH', 'VKI', 'VKJ',\n",
    "    'MWG', 'PNJ', 'DGW', 'FPT', 'VJC', 'VKD', 'VKG', 'VKH', 'VKI', 'VKJ',\n",
    "    \n",
    "    # Utilities\n",
    "    'POW', 'GAS', 'REE', 'DPM', 'DGC', 'TCH', 'VRE', 'VJC', 'HVN', 'ACV',\n",
    "    'POW', 'GAS', 'REE', 'DPM', 'DGC', 'TCH', 'VRE', 'VJC', 'HVN', 'ACV',\n",
    "    \n",
    "    # Healthcare\n",
    "    'DHG', 'DMC', 'IMP', 'TRA', 'VHC', 'VHT', 'VHU', 'VHV', 'VHW', 'VHX',\n",
    "    \n",
    "    # Logistics\n",
    "    'GMD', 'VSC', 'VSD', 'VSE', 'VSF', 'VSG', 'VSH', 'VSI', 'VSJ', 'VSK',\n",
    "    \n",
    "    # Industrial Services\n",
    "    'VSL', 'VSM', 'VSN', 'VSO', 'VSP', 'VSQ', 'VSR', 'VSS', 'VST', 'VSU'\n",
    "]\n",
    "\n",
    "print(f\"Testing with {len(NON_FINANCIAL_TICKERS)} comprehensive non-financial tickers\")\n",
    "\n",
    "# Function to get non-financial tickers from database (alternative approach)\n",
    "def get_non_financial_tickers_from_db(engine):\n",
    "    \"\"\"\n",
    "    Get non-financial tickers from database.\n",
    "    \n",
    "    Parameters:\n",
    "    - engine: QVMEngineV2Enhanced instance\n",
    "    \n",
    "    Returns:\n",
    "    - list: non-financial ticker symbols\n",
    "    \"\"\"\n",
    "    try:\n",
    "        query = \"\"\"\n",
    "        SELECT ticker FROM master_info \n",
    "        WHERE sector NOT IN ('Banks', 'Securities', 'Insurance', 'Other Financial')\n",
    "        AND ticker IS NOT NULL\n",
    "        ORDER BY ticker\n",
    "        \"\"\"\n",
    "        \n",
    "        result = pd.read_sql(query, engine.engine)\n",
    "        return result['ticker'].tolist()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to get non-financial tickers from database: {e}\")\n",
    "        return NON_FINANCIAL_TICKERS\n",
    "\n",
    "# Try to get non-financial tickers from database first, fallback to hardcoded list\n",
    "print(\"\\nAttempting to get non-financial tickers from database...\")\n",
    "try:\n",
    "    db_non_financial_tickers = get_non_financial_tickers_from_db(engine)\n",
    "    if db_non_financial_tickers:\n",
    "        NON_FINANCIAL_TICKERS = db_non_financial_tickers\n",
    "        print(f\"✅ Using {len(NON_FINANCIAL_TICKERS)} non-financial tickers from database\")\n",
    "    else:\n",
    "        print(f\"⚠️ Using hardcoded ticker list: {len(NON_FINANCIAL_TICKERS)} tickers\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Using hardcoded ticker list: {e}\")\n",
    "    print(f\"  Non-Financial: {len(NON_FINANCIAL_TICKERS)} tickers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999bc1ba",
   "metadata": {},
   "source": [
    "# FCF YIELD FACTOR CALCULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f38500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fcf_yield_factor(engine, analysis_date, universe_tickers):\n",
    "    \"\"\"\n",
    "    Calculate FCF Yield factor for non-financial companies.\n",
    "    \n",
    "    FCF Yield = (Operating Cash Flow - Capital Expenditures) / Market Cap\n",
    "    \n",
    "    Parameters:\n",
    "    - engine: QVMEngineV2Enhanced instance\n",
    "    - analysis_date: datetime for analysis\n",
    "    - universe_tickers: list of ticker symbols\n",
    "    \n",
    "    Returns:\n",
    "    - dict: {ticker: fcf_yield_score}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        fcf_scores = {}\n",
    "        imputation_count = 0\n",
    "        total_count = 0\n",
    "        \n",
    "        # Get financial data for FCF calculation\n",
    "        ticker_str = \"', '\".join(universe_tickers)\n",
    "        \n",
    "        # Get current year and quarter\n",
    "        current_year = analysis_date.year\n",
    "        current_quarter = (analysis_date.month - 1) // 3 + 1\n",
    "        \n",
    "        # Query for financial metrics from intermediary table\n",
    "        query = f\"\"\"\n",
    "        SELECT \n",
    "            ticker,\n",
    "            NetCFO_TTM,\n",
    "            CapEx_TTM,\n",
    "            FCF_TTM,\n",
    "            AvgTotalAssets,\n",
    "            DepreciationAmortization_TTM\n",
    "        FROM intermediary_calculations_enhanced\n",
    "        WHERE ticker IN ('{ticker_str}')\n",
    "          AND year = {current_year}\n",
    "          AND quarter = {current_quarter}\n",
    "        \"\"\"\n",
    "        \n",
    "        financial_data = pd.read_sql(query, engine.engine)\n",
    "        \n",
    "        if financial_data.empty:\n",
    "            return fcf_scores\n",
    "        \n",
    "        # Get market cap data from vcsc_daily_data_complete\n",
    "        market_cap_query = f\"\"\"\n",
    "        SELECT \n",
    "            ticker,\n",
    "            market_cap\n",
    "        FROM vcsc_daily_data_complete\n",
    "        WHERE ticker IN ('{ticker_str}')\n",
    "          AND trading_date = '{analysis_date.date()}'\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            market_cap_data = pd.read_sql(market_cap_query, engine.engine)\n",
    "        except Exception as e:\n",
    "            # Fallback: try with 'date' instead of 'trading_date'\n",
    "            market_cap_query_fallback = f\"\"\"\n",
    "            SELECT \n",
    "                ticker,\n",
    "                market_cap\n",
    "            FROM vcsc_daily_data_complete\n",
    "            WHERE ticker IN ('{ticker_str}')\n",
    "              AND date = '{analysis_date.date()}'\n",
    "            \"\"\"\n",
    "            market_cap_data = pd.read_sql(market_cap_query_fallback, engine.engine)\n",
    "        \n",
    "        # Merge data\n",
    "        if not market_cap_data.empty:\n",
    "            financial_data = financial_data.merge(market_cap_data, on='ticker', how='left')\n",
    "        \n",
    "        for _, row in financial_data.iterrows():\n",
    "            ticker = row['ticker']\n",
    "            total_count += 1\n",
    "            \n",
    "            # Get operating cash flow and capital expenditures\n",
    "            ocf = row['NetCFO_TTM']\n",
    "            capex = row['CapEx_TTM']\n",
    "            \n",
    "                        # Use pre-calculated FCF if available, otherwise calculate it\n",
    "            if pd.notna(row['FCF_TTM']):\n",
    "                fcf = row['FCF_TTM']\n",
    "            else:\n",
    "                # Impute capex if missing using depreciation/amortization ratio\n",
    "                if pd.isna(capex) or capex == 0:\n",
    "                    da = row['DepreciationAmortization_TTM']\n",
    "                    if not pd.isna(da) and da > 0:\n",
    "                        # Use 80% of depreciation as capex estimate (common ratio)\n",
    "                        capex = da * 0.8\n",
    "                        imputation_count += 1\n",
    "                    else:\n",
    "                        # Use 5% of total assets as capex estimate\n",
    "                        total_assets = row['AvgTotalAssets']\n",
    "                        if not pd.isna(total_assets) and total_assets > 0:\n",
    "                            capex = total_assets * 0.05\n",
    "                            imputation_count += 1\n",
    "                        else:\n",
    "                            continue  # Skip if no data available\n",
    "                \n",
    "                # Calculate FCF\n",
    "                if not pd.isna(ocf) and not pd.isna(capex):\n",
    "                    fcf = ocf - capex\n",
    "                else:\n",
    "                    continue  # Skip if no data available\n",
    "            \n",
    "            # Get market cap\n",
    "            market_cap = row['market_cap']\n",
    "            \n",
    "            if not pd.isna(market_cap) and market_cap > 0:\n",
    "                # Calculate FCF Yield\n",
    "                fcf_yield = fcf / market_cap\n",
    "                \n",
    "                # Store the raw FCF yield (will be normalized later)\n",
    "                fcf_scores[ticker] = fcf_yield\n",
    "        \n",
    "        # Log imputation rate\n",
    "        if total_count > 0:\n",
    "            imputation_rate = imputation_count / total_count\n",
    "            print(f\"FCF Yield Capex Imputation Rate: {imputation_rate:.2%} ({imputation_count}/{total_count})\")\n",
    "        \n",
    "\n",
    "        \n",
    "        # Normalize FCF yields to 0-1 range\n",
    "        if fcf_scores:\n",
    "            fcf_values = list(fcf_scores.values())\n",
    "            max_fcf = max(fcf_values)\n",
    "            min_fcf = min(fcf_values)\n",
    "            \n",
    "            if max_fcf > min_fcf:\n",
    "                # Normalize to 0-1 range (higher FCF yield = higher score)\n",
    "                normalized_scores = {}\n",
    "                for ticker, fcf_yield in fcf_scores.items():\n",
    "                    normalized_score = (fcf_yield - min_fcf) / (max_fcf - min_fcf)\n",
    "                    normalized_scores[ticker] = normalized_score\n",
    "                fcf_scores = normalized_scores\n",
    "            else:\n",
    "                # All FCF yields are the same, assign equal scores\n",
    "                fcf_scores = {ticker: 0.5 for ticker in fcf_scores.keys()}\n",
    "        \n",
    "        return fcf_scores\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to calculate FCF Yield for {analysis_date.strftime('%Y-%m-%d')}: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0571ab3",
   "metadata": {},
   "source": [
    "# HISTORICAL FACTOR GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ba76ca",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Generate historical FCF Yield data\n",
    "historical_fcf_yield = {}\n",
    "\n",
    "print(\"Generating historical FCF Yield data...\")\n",
    "\n",
    "for date in analysis_dates:\n",
    "    print(f\"Processing {date.strftime('%Y-%m-%d')}...\", end=' ')\n",
    "    scores = calculate_fcf_yield_factor(engine, date, NON_FINANCIAL_TICKERS)\n",
    "    if scores:\n",
    "        historical_fcf_yield[date] = scores\n",
    "        print(f\"✅ {len(scores)} scores calculated\")\n",
    "    else:\n",
    "        print(\"❌ No scores\")\n",
    "\n",
    "print(f\"\\n✅ Historical FCF Yield data generated for {len(historical_fcf_yield)} dates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6600c44a",
   "metadata": {},
   "source": [
    "# FORWARD RETURNS CALCULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be97faa0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def calculate_forward_returns(engine, analysis_date, universe_tickers, forward_periods=[1, 3, 6, 12]):\n",
    "    \"\"\"\n",
    "    Calculate forward returns for statistical testing.\n",
    "    \n",
    "    Parameters:\n",
    "    - engine: QVMEngineV2Enhanced instance\n",
    "    - analysis_date: datetime for analysis\n",
    "    - universe_tickers: list of ticker symbols\n",
    "    - forward_periods: list of months for forward returns\n",
    "    \n",
    "    Returns:\n",
    "    - dict: {ticker: {period: return}}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        forward_returns = {}\n",
    "        \n",
    "        # Get price data for forward return calculation\n",
    "        ticker_str = \"', '\".join(universe_tickers)\n",
    "        max_forward = max(forward_periods)\n",
    "        end_date = analysis_date + pd.DateOffset(months=max_forward)\n",
    "        \n",
    "        price_query = f\"\"\"\n",
    "        SELECT \n",
    "            date,\n",
    "            ticker,\n",
    "            close as adj_close\n",
    "        FROM equity_history\n",
    "        WHERE ticker IN ('{ticker_str}')\n",
    "          AND date BETWEEN '{analysis_date.date()}' AND '{end_date.date()}'\n",
    "        ORDER BY ticker, date\n",
    "        \"\"\"\n",
    "        \n",
    "        price_data = pd.read_sql(price_query, engine.engine, parse_dates=['date'])\n",
    "        \n",
    "        if price_data.empty:\n",
    "            return forward_returns\n",
    "        \n",
    "        # Calculate forward returns for each period\n",
    "        for ticker in universe_tickers:\n",
    "            ticker_data = price_data[price_data['ticker'] == ticker].sort_values('date')\n",
    "            if ticker_data.empty:\n",
    "                continue\n",
    "                \n",
    "            start_price = ticker_data.iloc[0]['adj_close']\n",
    "            forward_returns[ticker] = {}\n",
    "            \n",
    "            for period in forward_periods:\n",
    "                # Find price at period months later\n",
    "                period_date = analysis_date + pd.DateOffset(months=period)\n",
    "                period_data = ticker_data[ticker_data['date'] >= period_date]\n",
    "                \n",
    "                if not period_data.empty:\n",
    "                    end_price = period_data.iloc[0]['adj_close']\n",
    "                    forward_return = (end_price - start_price) / start_price\n",
    "                    forward_returns[ticker][period] = forward_return\n",
    "        \n",
    "        return forward_returns\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to calculate forward returns for {analysis_date.strftime('%Y-%m-%d')}: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdf2b10",
   "metadata": {},
   "source": [
    "# STATISTICAL SIGNIFICANCE TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613d48e1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def calculate_information_coefficient(factor_scores, forward_returns, period):\n",
    "    \"\"\"\n",
    "    Calculate Information Coefficient (IC) for a given forward period.\n",
    "    \n",
    "    Parameters:\n",
    "    - factor_scores: dict of {ticker: score}\n",
    "    - forward_returns: dict of {ticker: {period: return}}\n",
    "    - period: forward period in months\n",
    "    \n",
    "    Returns:\n",
    "    - float: Information Coefficient\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    returns = []\n",
    "    \n",
    "    for ticker in factor_scores:\n",
    "        if ticker in forward_returns and period in forward_returns[ticker]:\n",
    "            scores.append(factor_scores[ticker])\n",
    "            returns.append(forward_returns[ticker][period])\n",
    "    \n",
    "    if len(scores) < 3:  # Need at least 3 observations\n",
    "        return np.nan\n",
    "    \n",
    "    # Calculate rank correlation (Spearman's rho)\n",
    "    ic = spearman_correlation(scores, returns)\n",
    "    return ic\n",
    "\n",
    "def calculate_factor_returns(factor_scores, forward_returns, period, n_quintiles=5):\n",
    "    \"\"\"\n",
    "    Calculate factor returns using quintile analysis.\n",
    "    \n",
    "    Parameters:\n",
    "    - factor_scores: dict of {ticker: score}\n",
    "    - forward_returns: dict of {ticker: {period: return}}\n",
    "    - period: forward period in months\n",
    "    - n_quintiles: number of quintiles for analysis\n",
    "    \n",
    "    Returns:\n",
    "    - dict: quintile returns and spread\n",
    "    \"\"\"\n",
    "    # Create DataFrame for analysis\n",
    "    data = []\n",
    "    for ticker in factor_scores:\n",
    "        if ticker in forward_returns and period in forward_returns[ticker]:\n",
    "            data.append({\n",
    "                'ticker': ticker,\n",
    "                'factor_score': factor_scores[ticker],\n",
    "                'forward_return': forward_returns[ticker][period]\n",
    "            })\n",
    "    \n",
    "    if len(data) < n_quintiles:\n",
    "        return {}\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Create quintiles\n",
    "    try:\n",
    "        df['quintile'] = pd.qcut(df['factor_score'], n_quintiles, labels=False, duplicates='drop')\n",
    "    except ValueError as e:\n",
    "        # If we still can't create quintiles due to insufficient unique values,\n",
    "        # try with fewer quintiles\n",
    "        unique_values = df['factor_score'].nunique()\n",
    "        if unique_values < 2:\n",
    "            return {}\n",
    "        \n",
    "        # Use the maximum number of quintiles possible\n",
    "        max_quintiles = min(unique_values, n_quintiles)\n",
    "        if max_quintiles < 2:\n",
    "            return {}\n",
    "            \n",
    "        df['quintile'] = pd.qcut(df['factor_score'], max_quintiles, labels=False, duplicates='drop')\n",
    "    \n",
    "    # Calculate returns by quintile\n",
    "    quintile_returns = df.groupby('quintile')['forward_return'].mean()\n",
    "    \n",
    "    # Calculate spread (Q5 - Q1)\n",
    "    spread = quintile_returns.iloc[-1] - quintile_returns.iloc[0]\n",
    "    \n",
    "    return {\n",
    "        'quintile_returns': quintile_returns,\n",
    "        'spread': spread,\n",
    "        'high_low_spread': spread\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acc2279",
   "metadata": {},
   "source": [
    "# COMPREHENSIVE STATISTICAL ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0009978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate forward returns for all dates\n",
    "print(\"Calculating forward returns...\")\n",
    "historical_forward_returns = {}\n",
    "\n",
    "for date in list(historical_fcf_yield.keys()):\n",
    "    forward_returns = calculate_forward_returns(engine, date, NON_FINANCIAL_TICKERS, [1, 3, 6, 12])\n",
    "    if forward_returns:\n",
    "        historical_forward_returns[date] = forward_returns\n",
    "\n",
    "print(f\"✅ Forward returns calculated for {len(historical_forward_returns)} dates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a699baa9",
   "metadata": {},
   "source": [
    "# INFORMATION COEFFICIENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7ed20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate IC for different forward periods\n",
    "forward_periods = [1, 3, 6, 12]\n",
    "ic_results = {period: [] for period in forward_periods}\n",
    "\n",
    "for date in historical_fcf_yield:\n",
    "    if date in historical_forward_returns:\n",
    "        for period in forward_periods:\n",
    "            ic = calculate_information_coefficient(\n",
    "                historical_fcf_yield[date], \n",
    "                historical_forward_returns[date], \n",
    "                period\n",
    "            )\n",
    "            if not np.isnan(ic):\n",
    "                ic_results[period].append(ic)\n",
    "\n",
    "# Calculate IC statistics\n",
    "ic_stats = {}\n",
    "for period in forward_periods:\n",
    "    if ic_results[period]:\n",
    "        ic_values = ic_results[period]\n",
    "        ic_stats[period] = {\n",
    "            'mean': np.mean(ic_values),\n",
    "            'std': np.std(ic_values),\n",
    "            't_stat': np.mean(ic_values) / (np.std(ic_values) / np.sqrt(len(ic_values))),\n",
    "            'p_value': t_test_one_sample(ic_values)[1],\n",
    "            'count': len(ic_values)\n",
    "        }\n",
    "\n",
    "print(\"Information Coefficient Analysis Results:\")\n",
    "print(\"=\" * 60)\n",
    "for period, stats in ic_stats.items():\n",
    "    print(f\"{period}M Forward Period:\")\n",
    "    print(f\"  Mean IC: {stats['mean']:.4f}\")\n",
    "    print(f\"  Std IC:  {stats['std']:.4f}\")\n",
    "    print(f\"  t-stat:  {stats['t_stat']:.4f}\")\n",
    "    print(f\"  p-value: {stats['p_value']:.4f}\")\n",
    "    print(f\"  N:       {stats['count']}\")\n",
    "    print(f\"  Significant: {'✅' if stats['p_value'] < 0.05 else '❌'}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f3898a",
   "metadata": {},
   "source": [
    "# FACTOR RETURNS ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee379221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate factor returns for different periods\n",
    "factor_returns_results = {}\n",
    "\n",
    "for period in forward_periods:\n",
    "    period_returns = []\n",
    "    \n",
    "    for date in historical_fcf_yield:\n",
    "        if date in historical_forward_returns:\n",
    "            returns = calculate_factor_returns(\n",
    "                historical_fcf_yield[date],\n",
    "                historical_forward_returns[date],\n",
    "                period\n",
    "            )\n",
    "            if returns and 'spread' in returns:\n",
    "                period_returns.append(returns['spread'])\n",
    "    \n",
    "    if period_returns:\n",
    "        factor_returns_results[period] = {\n",
    "            'mean_return': np.mean(period_returns),\n",
    "            'std_return': np.std(period_returns),\n",
    "            't_stat': np.mean(period_returns) / (np.std(period_returns) / np.sqrt(len(period_returns))),\n",
    "            'p_value': t_test_one_sample(period_returns)[1],\n",
    "            'count': len(period_returns),\n",
    "            'returns': period_returns\n",
    "        }\n",
    "\n",
    "print(\"Factor Returns Analysis Results:\")\n",
    "print(\"=\" * 60)\n",
    "for period, results in factor_returns_results.items():\n",
    "    print(f\"{period}M Forward Period:\")\n",
    "    print(f\"  Mean Spread: {results['mean_return']:.4f}\")\n",
    "    print(f\"  Std Spread:  {results['std_return']:.4f}\")\n",
    "    print(f\"  t-stat:      {results['t_stat']:.4f}\")\n",
    "    print(f\"  p-value:     {results['p_value']:.4f}\")\n",
    "    print(f\"  N:           {results['count']}\")\n",
    "    print(f\"  Significant: {'✅' if results['p_value'] < 0.05 else '❌'}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0785b190",
   "metadata": {},
   "source": [
    "# VISUALIZATION OF RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af84c52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('FCF Yield Factor Statistical Analysis Results', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: IC Distribution\n",
    "ax1 = axes[0, 0]\n",
    "for period in [1, 3, 6, 12]:\n",
    "    if ic_results[period]:\n",
    "        ax1.hist(ic_results[period], alpha=0.6, label=f'{period}M', bins=20)\n",
    "ax1.axvline(0, color='red', linestyle='--', alpha=0.7)\n",
    "ax1.set_xlabel('Information Coefficient')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('IC Distribution by Forward Period')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: IC Time Series\n",
    "ax2 = axes[0, 1]\n",
    "for period in [1, 3, 6, 12]:\n",
    "    if ic_results[period]:\n",
    "        dates = list(historical_fcf_yield.keys())[:len(ic_results[period])]\n",
    "        ax2.plot(dates, ic_results[period], label=f'{period}M', alpha=0.7)\n",
    "ax2.axhline(0, color='red', linestyle='--', alpha=0.7)\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.set_ylabel('Information Coefficient')\n",
    "ax2.set_title('IC Time Series')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Factor Returns Distribution\n",
    "ax3 = axes[1, 0]\n",
    "for period in [1, 3, 6, 12]:\n",
    "    if period in factor_returns_results:\n",
    "        ax3.hist(factor_returns_results[period]['returns'], alpha=0.6, label=f'{period}M', bins=20)\n",
    "ax3.axvline(0, color='red', linestyle='--', alpha=0.7)\n",
    "ax3.set_xlabel('Factor Return Spread')\n",
    "ax3.set_ylabel('Frequency')\n",
    "ax3.set_title('Factor Returns Distribution')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Factor Returns Summary\n",
    "ax4 = axes[1, 1]\n",
    "periods = list(factor_returns_results.keys())\n",
    "means = [factor_returns_results[p]['mean_return'] for p in periods]\n",
    "stds = [factor_returns_results[p]['std_return'] for p in periods]\n",
    "colors = ['green' if factor_returns_results[p]['p_value'] < 0.05 else 'red' for p in periods]\n",
    "\n",
    "bars = ax4.bar([str(p) + 'M' for p in periods], means, yerr=stds, capsize=5, color=colors, alpha=0.7)\n",
    "ax4.axhline(0, color='black', linestyle='-', alpha=0.5)\n",
    "ax4.set_xlabel('Forward Period')\n",
    "ax4.set_ylabel('Mean Factor Return Spread')\n",
    "ax4.set_title('Factor Returns by Forward Period')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# Add significance annotations\n",
    "for i, (period, results) in enumerate(factor_returns_results.items()):\n",
    "    if results['p_value'] < 0.05:\n",
    "        ax4.text(i, means[i] + stds[i] + 0.001, '*', ha='center', va='bottom', fontsize=16, color='green')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e3abc1",
   "metadata": {},
   "source": [
    "# SUMMARY AND CONCLUSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256e7f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"FCF YIELD FACTOR STATISTICAL SIGNIFICANCE SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n📊 KEY FINDINGS:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# IC Analysis Summary\n",
    "print(\"\\n1. INFORMATION COEFFICIENT ANALYSIS:\")\n",
    "significant_ic_count = 0\n",
    "for period in [1, 3, 6, 12]:\n",
    "    if period in ic_stats:\n",
    "        stats = ic_stats[period]\n",
    "        significance = \"✅ STATISTICALLY SIGNIFICANT\" if stats['p_value'] < 0.05 else \"❌ NOT SIGNIFICANT\"\n",
    "        print(f\"   {period}M Forward: IC = {stats['mean']:.4f} (p = {stats['p_value']:.4f}) - {significance}\")\n",
    "        if stats['p_value'] < 0.05:\n",
    "            significant_ic_count += 1\n",
    "\n",
    "# Factor Returns Summary\n",
    "print(\"\\n2. FACTOR RETURNS ANALYSIS:\")\n",
    "significant_returns_count = 0\n",
    "for period in [1, 3, 6, 12]:\n",
    "    if period in factor_returns_results:\n",
    "        results = factor_returns_results[period]\n",
    "        significance = \"✅ STATISTICALLY SIGNIFICANT\" if results['p_value'] < 0.05 else \"❌ NOT SIGNIFICANT\"\n",
    "        print(f\"   {period}M Forward: Spread = {results['mean_return']:.4f} (p = {results['p_value']:.4f}) - {significance}\")\n",
    "        if results['p_value'] < 0.05:\n",
    "            significant_returns_count += 1\n",
    "\n",
    "# Overall Assessment\n",
    "print(\"\\n3. OVERALL ASSESSMENT:\")\n",
    "print(f\"   - IC Significance: {significant_ic_count}/4 periods significant\")\n",
    "print(f\"   - Returns Significance: {significant_returns_count}/4 periods significant\")\n",
    "\n",
    "if significant_ic_count >= 2 and significant_returns_count >= 2:\n",
    "    print(\"   🎯 CONCLUSION: FCF Yield factor shows strong statistical significance\")\n",
    "    print(\"   ✅ RECOMMENDATION: Include in QVM v2.1 Alpha strategy\")\n",
    "else:\n",
    "    print(\"   ⚠️ CONCLUSION: FCF Yield factor shows mixed statistical significance\")\n",
    "    print(\"   🔍 RECOMMENDATION: Further analysis needed before inclusion\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80) "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
