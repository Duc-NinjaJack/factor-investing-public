{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9c93ce2",
   "metadata": {},
   "source": [
    "# Piotroski F-Score Factor Statistical Significance Testing\n",
    "\n",
    "**Objective:** Test the statistical significance of the Piotroski F-Score factor as a quality enhancement in the QVM v2.1 Alpha strategy.\n",
    "\n",
    "**Factor Description:** \n",
    "- Sector-specific F-Score implementations (Non-Financial: 9 tests, Banking: 6 tests, Securities: 5 tests)\n",
    "- Normalized scores (Raw_Score/Max_Possible_Score) to prevent sector bias\n",
    "- Quality enhancement to prevent value traps\n",
    "\n",
    "**Testing Period:** 2018-2025 (excluding 2016-2017 OOS period)\n",
    "**Target Metrics:** Information Coefficient (IC), Factor Returns, Rank Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eca741",
   "metadata": {},
   "source": [
    "# IMPORTS AND SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb8a74aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/raymond/anaconda3/envs/py310_env/lib/python3.10/site-packages/scipy/spatial/_qhull.cpython-310-darwin.so, 0x0002): Library not loaded: @rpath/libgfortran.5.dylib\n  Referenced from: <D37BED4E-7F75-3467-A281-7E7E316989C9> /Users/raymond/anaconda3/envs/py310_env/lib/libopenblas.0.dylib\n  Reason: tried: '/Users/raymond/anaconda3/envs/py310_env/lib/libgfortran.5.dylib' (duplicate LC_RPATH '@loader_path'), '/Users/raymond/anaconda3/envs/py310_env/lib/libgfortran.5.dylib' (duplicate LC_RPATH '@loader_path'), '/Users/raymond/anaconda3/envs/py310_env/lib/python3.10/site-packages/scipy/spatial/../../../../libgfortran.5.dylib' (duplicate LC_RPATH '@loader_path'), '/Users/raymond/anaconda3/envs/py310_env/lib/python3.10/site-packages/scipy/spatial/../../../../libgfortran.5.dylib' (duplicate LC_RPATH '@loader_path'), '/Users/raymond/anaconda3/envs/py310_env/bin/../lib/libgfortran.5.dylib' (duplicate LC_RPATH '@loader_path'), '/Users/raymond/anaconda3/envs/py310_env/bin/../lib/libgfortran.5.dylib' (duplicate LC_RPATH '@loader_path'), '/usr/local/lib/libgfortran.5.dylib' (no such file), '/usr/lib/libgfortran.5.dylib' (no such file, not in dyld cache)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m stats\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m     10\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310_env/lib/python3.10/site-packages/scipy/stats/__init__.py:453\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m.. _statsrefmanual:\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    450\u001b[0m \n\u001b[1;32m    451\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats_py\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_variation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m variation\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/py310_env/lib/python3.10/site-packages/scipy/stats/_stats_py.py:38\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m array, asarray, ma\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NumpyVersion\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistance\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cdist\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mndimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _measurements\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_util\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (check_random_state, MapWrapper,\n\u001b[1;32m     41\u001b[0m                               rng_integers, float_factorial)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310_env/lib/python3.10/site-packages/scipy/spatial/__init__.py:104\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_kdtree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ckdtree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m--> 104\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_qhull\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_spherical_voronoi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SphericalVoronoi\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_plotutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/raymond/anaconda3/envs/py310_env/lib/python3.10/site-packages/scipy/spatial/_qhull.cpython-310-darwin.so, 0x0002): Library not loaded: @rpath/libgfortran.5.dylib\n  Referenced from: <D37BED4E-7F75-3467-A281-7E7E316989C9> /Users/raymond/anaconda3/envs/py310_env/lib/libopenblas.0.dylib\n  Reason: tried: '/Users/raymond/anaconda3/envs/py310_env/lib/libgfortran.5.dylib' (duplicate LC_RPATH '@loader_path'), '/Users/raymond/anaconda3/envs/py310_env/lib/libgfortran.5.dylib' (duplicate LC_RPATH '@loader_path'), '/Users/raymond/anaconda3/envs/py310_env/lib/python3.10/site-packages/scipy/spatial/../../../../libgfortran.5.dylib' (duplicate LC_RPATH '@loader_path'), '/Users/raymond/anaconda3/envs/py310_env/lib/python3.10/site-packages/scipy/spatial/../../../../libgfortran.5.dylib' (duplicate LC_RPATH '@loader_path'), '/Users/raymond/anaconda3/envs/py310_env/bin/../lib/libgfortran.5.dylib' (duplicate LC_RPATH '@loader_path'), '/Users/raymond/anaconda3/envs/py310_env/bin/../lib/libgfortran.5.dylib' (duplicate LC_RPATH '@loader_path'), '/usr/local/lib/libgfortran.5.dylib' (no such file), '/usr/lib/libgfortran.5.dylib' (no such file, not in dyld cache)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add the necessary paths to import modules\n",
    "sys.path.append(os.path.join(os.path.dirname('__file__'), '..', '..', 'engine'))\n",
    "sys.path.append(os.path.join(os.path.dirname('__file__'), '..', '..', 'universe'))\n",
    "\n",
    "from qvm_engine_v2_enhanced import QVMEngineV2Enhanced\n",
    "from constructors import get_liquid_universe\n",
    "\n",
    "print(f\"Piotroski F-Score Factor Testing Started: {datetime.now()}\")\n",
    "print(\"QVM Engine v2 Enhanced - F-Score Statistical Analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253e3836",
   "metadata": {},
   "source": [
    "# DATABASE CONNECTION AND ENGINE SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5f7a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the QVM engine\n",
    "engine = QVMEngineV2Enhanced()\n",
    "\n",
    "print(\"‚úÖ QVM Engine v2 Enhanced initialized successfully\")\n",
    "print(f\"   - Engine class: {engine.__class__.__name__}\")\n",
    "print(f\"   - Database connection: {'‚úÖ Connected' if hasattr(engine, 'engine') and engine.engine else '‚ùå Failed'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d0e5cc",
   "metadata": {},
   "source": [
    "# UNIVERSE CONSTRUCTION BY SECTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ac1c19",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Set up test parameters\n",
    "start_date = datetime(2018, 1, 1)\n",
    "end_date = datetime(2025, 8, 2)\n",
    "analysis_dates = pd.date_range(start=start_date, end=end_date, freq='M')\n",
    "\n",
    "print(f\"Analysis Period: {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}\")\n",
    "print(f\"Number of analysis dates: {len(analysis_dates)}\")\n",
    "\n",
    "# Define sector-specific test tickers\n",
    "NON_FINANCIAL_TICKERS = ['VIC', 'VHM', 'HPG', 'GAS', 'VJC', 'MSN', 'PLX', 'POW', 'FPT', 'MWG']\n",
    "BANKING_TICKERS = ['VCB', 'TCB', 'BID', 'CTG', 'VPB', 'ACB', 'MBB', 'STB', 'SHB', 'EIB']\n",
    "SECURITIES_TICKERS = ['SSI', 'VCI', 'VND', 'HCM', 'VIX', 'FTS', 'ORS', 'BVS', 'CTS', 'APG']\n",
    "\n",
    "print(f\"Testing with sector-specific tickers:\")\n",
    "print(f\"  Non-Financial: {len(NON_FINANCIAL_TICKERS)} tickers\")\n",
    "print(f\"  Banking: {len(BANKING_TICKERS)} tickers\")\n",
    "print(f\"  Securities: {len(SECURITIES_TICKERS)} tickers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62644002",
   "metadata": {},
   "source": [
    "# PIOTROSKI F-SCORE FACTOR CALCULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06757ca",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def calculate_f_score_non_financial(engine, analysis_date, universe_tickers):\n",
    "    \"\"\"\n",
    "    Calculate Piotroski F-Score for non-financial companies (9 tests).\n",
    "    \n",
    "    Tests:\n",
    "    1. ROA > 0\n",
    "    2. CFO > 0  \n",
    "    3. Change in ROA > 0\n",
    "    4. Accruals < CFO\n",
    "    5. Change in Leverage < 0\n",
    "    6. Change in Current Ratio > 0\n",
    "    7. No Share Issuance\n",
    "    8. Change in Gross Margin > 0\n",
    "    9. Change in Asset Turnover > 0\n",
    "    \n",
    "    Returns:\n",
    "    - dict: {ticker: normalized_f_score}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        f_scores = {}\n",
    "        \n",
    "        # Get financial data for F-Score calculation\n",
    "        ticker_str = \"', '\".join(universe_tickers)\n",
    "        \n",
    "        # Query for financial metrics\n",
    "        query = f\"\"\"\n",
    "        SELECT \n",
    "            ticker,\n",
    "            roa,\n",
    "            cfo,\n",
    "            total_assets,\n",
    "            total_equity,\n",
    "            current_assets,\n",
    "            current_liabilities,\n",
    "            gross_profit,\n",
    "            revenue,\n",
    "            total_shares\n",
    "        FROM vcsc_daily_data_complete\n",
    "        WHERE ticker IN ('{ticker_str}')\n",
    "          AND date = '{analysis_date.date()}'\n",
    "        \"\"\"\n",
    "        \n",
    "        current_data = pd.read_sql(query, engine.engine)\n",
    "        \n",
    "        if current_data.empty:\n",
    "            return f_scores\n",
    "        \n",
    "        # Get previous year data for comparisons\n",
    "        prev_date = analysis_date - pd.DateOffset(years=1)\n",
    "        prev_query = f\"\"\"\n",
    "        SELECT \n",
    "            ticker,\n",
    "            roa,\n",
    "            cfo,\n",
    "            total_assets,\n",
    "            total_equity,\n",
    "            current_assets,\n",
    "            current_liabilities,\n",
    "            gross_profit,\n",
    "            revenue,\n",
    "            total_shares\n",
    "        FROM vcsc_daily_data_complete\n",
    "        WHERE ticker IN ('{ticker_str}')\n",
    "          AND date = '{prev_date.date()}'\n",
    "        \"\"\"\n",
    "        \n",
    "        prev_data = pd.read_sql(prev_query, engine.engine)\n",
    "        \n",
    "        # Merge current and previous data\n",
    "        merged_data = current_data.merge(prev_data, on='ticker', suffixes=('_curr', '_prev'))\n",
    "        \n",
    "        for _, row in merged_data.iterrows():\n",
    "            ticker = row['ticker']\n",
    "            score = 0\n",
    "            max_score = 9  # 9 tests for non-financial\n",
    "            \n",
    "            # Test 1: ROA > 0\n",
    "            if row['roa_curr'] > 0:\n",
    "                score += 1\n",
    "            \n",
    "            # Test 2: CFO > 0\n",
    "            if row['cfo_curr'] > 0:\n",
    "                score += 1\n",
    "            \n",
    "            # Test 3: Change in ROA > 0\n",
    "            if row['roa_curr'] > row['roa_prev']:\n",
    "                score += 1\n",
    "            \n",
    "            # Test 4: Accruals < CFO (simplified)\n",
    "            if row['cfo_curr'] > 0:  # Simplified test\n",
    "                score += 1\n",
    "            \n",
    "            # Test 5: Change in Leverage < 0\n",
    "            curr_leverage = row['total_assets_curr'] / row['total_equity_curr'] if row['total_equity_curr'] > 0 else 0\n",
    "            prev_leverage = row['total_assets_prev'] / row['total_equity_prev'] if row['total_equity_prev'] > 0 else 0\n",
    "            if curr_leverage < prev_leverage:\n",
    "                score += 1\n",
    "            \n",
    "            # Test 6: Change in Current Ratio > 0\n",
    "            curr_ratio = row['current_assets_curr'] / row['current_liabilities_curr'] if row['current_liabilities_curr'] > 0 else 0\n",
    "            prev_ratio = row['current_assets_prev'] / row['current_liabilities_prev'] if row['current_liabilities_prev'] > 0 else 0\n",
    "            if curr_ratio > prev_ratio:\n",
    "                score += 1\n",
    "            \n",
    "            # Test 7: No Share Issuance\n",
    "            if row['total_shares_curr'] <= row['total_shares_prev']:\n",
    "                score += 1\n",
    "            \n",
    "            # Test 8: Change in Gross Margin > 0\n",
    "            curr_gm = row['gross_profit_curr'] / row['revenue_curr'] if row['revenue_curr'] > 0 else 0\n",
    "            prev_gm = row['gross_profit_prev'] / row['revenue_prev'] if row['revenue_prev'] > 0 else 0\n",
    "            if curr_gm > prev_gm:\n",
    "                score += 1\n",
    "            \n",
    "            # Test 9: Change in Asset Turnover > 0\n",
    "            curr_at = row['revenue_curr'] / row['total_assets_curr'] if row['total_assets_curr'] > 0 else 0\n",
    "            prev_at = row['revenue_prev'] / row['total_assets_prev'] if row['total_assets_prev'] > 0 else 0\n",
    "            if curr_at > prev_at:\n",
    "                score += 1\n",
    "            \n",
    "            # Normalize score to 0-1 range\n",
    "            normalized_score = score / max_score\n",
    "            f_scores[ticker] = normalized_score\n",
    "        \n",
    "        return f_scores\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to calculate non-financial F-Score for {analysis_date.strftime('%Y-%m-%d')}: {e}\")\n",
    "        return {}\n",
    "\n",
    "def calculate_f_score_banking(engine, analysis_date, universe_tickers):\n",
    "    \"\"\"\n",
    "    Calculate Piotroski F-Score for banking companies (6 tests).\n",
    "    \n",
    "    Tests:\n",
    "    1. ROA > 0\n",
    "    2. NIM > 0\n",
    "    3. Change in ROA > 0\n",
    "    4. Change in Leverage < 0\n",
    "    5. Change in Efficiency Ratio > 0\n",
    "    6. Change in Asset Quality > 0\n",
    "    \n",
    "    Returns:\n",
    "    - dict: {ticker: normalized_f_score}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        f_scores = {}\n",
    "        \n",
    "        # Get banking-specific financial data\n",
    "        ticker_str = \"', '\".join(universe_tickers)\n",
    "        \n",
    "        query = f\"\"\"\n",
    "        SELECT \n",
    "            ticker,\n",
    "            roa,\n",
    "            nim,\n",
    "            total_assets,\n",
    "            total_equity,\n",
    "            net_interest_income,\n",
    "            total_interest_expense,\n",
    "            non_performing_loans,\n",
    "            total_loans\n",
    "        FROM vcsc_daily_data_complete\n",
    "        WHERE ticker IN ('{ticker_str}')\n",
    "          AND date = '{analysis_date.date()}'\n",
    "        \"\"\"\n",
    "        \n",
    "        current_data = pd.read_sql(query, engine.engine)\n",
    "        \n",
    "        if current_data.empty:\n",
    "            return f_scores\n",
    "        \n",
    "        # Get previous year data\n",
    "        prev_date = analysis_date - pd.DateOffset(years=1)\n",
    "        prev_query = f\"\"\"\n",
    "        SELECT \n",
    "            ticker,\n",
    "            roa,\n",
    "            nim,\n",
    "            total_assets,\n",
    "            total_equity,\n",
    "            net_interest_income,\n",
    "            total_interest_expense,\n",
    "            non_performing_loans,\n",
    "            total_loans\n",
    "        FROM vcsc_daily_data_complete\n",
    "        WHERE ticker IN ('{ticker_str}')\n",
    "          AND date = '{prev_date.date()}'\n",
    "        \"\"\"\n",
    "        \n",
    "        prev_data = pd.read_sql(prev_query, engine.engine)\n",
    "        \n",
    "        # Merge data\n",
    "        merged_data = current_data.merge(prev_data, on='ticker', suffixes=('_curr', '_prev'))\n",
    "        \n",
    "        for _, row in merged_data.iterrows():\n",
    "            ticker = row['ticker']\n",
    "            score = 0\n",
    "            max_score = 6  # 6 tests for banking\n",
    "            \n",
    "            # Test 1: ROA > 0\n",
    "            if row['roa_curr'] > 0:\n",
    "                score += 1\n",
    "            \n",
    "            # Test 2: NIM > 0\n",
    "            if row['nim_curr'] > 0:\n",
    "                score += 1\n",
    "            \n",
    "            # Test 3: Change in ROA > 0\n",
    "            if row['roa_curr'] > row['roa_prev']:\n",
    "                score += 1\n",
    "            \n",
    "            # Test 4: Change in Leverage < 0\n",
    "            curr_leverage = row['total_assets_curr'] / row['total_equity_curr'] if row['total_equity_curr'] > 0 else 0\n",
    "            prev_leverage = row['total_assets_prev'] / row['total_equity_prev'] if row['total_equity_prev'] > 0 else 0\n",
    "            if curr_leverage < prev_leverage:\n",
    "                score += 1\n",
    "            \n",
    "            # Test 5: Change in Efficiency Ratio > 0 (simplified)\n",
    "            if row['total_interest_expense_curr'] < row['total_interest_expense_prev']:\n",
    "                score += 1\n",
    "            \n",
    "            # Test 6: Change in Asset Quality > 0\n",
    "            curr_quality = 1 - (row['non_performing_loans_curr'] / row['total_loans_curr']) if row['total_loans_curr'] > 0 else 0\n",
    "            prev_quality = 1 - (row['non_performing_loans_prev'] / row['total_loans_prev']) if row['total_loans_prev'] > 0 else 0\n",
    "            if curr_quality > prev_quality:\n",
    "                score += 1\n",
    "            \n",
    "            # Normalize score\n",
    "            normalized_score = score / max_score\n",
    "            f_scores[ticker] = normalized_score\n",
    "        \n",
    "        return f_scores\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to calculate banking F-Score for {analysis_date.strftime('%Y-%m-%d')}: {e}\")\n",
    "        return {}\n",
    "\n",
    "def calculate_f_score_securities(engine, analysis_date, universe_tickers):\n",
    "    \"\"\"\n",
    "    Calculate Piotroski F-Score for securities companies (5 tests).\n",
    "    \n",
    "    Tests:\n",
    "    1. ROA > 0\n",
    "    2. Brokerage Ratio > 0\n",
    "    3. Change in ROA > 0\n",
    "    4. Change in Efficiency > 0\n",
    "    5. Change in Trading Volume > 0\n",
    "    \n",
    "    Returns:\n",
    "    - dict: {ticker: normalized_f_score}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        f_scores = {}\n",
    "        \n",
    "        # Get securities-specific financial data\n",
    "        ticker_str = \"', '\".join(universe_tickers)\n",
    "        \n",
    "        query = f\"\"\"\n",
    "        SELECT \n",
    "            ticker,\n",
    "            roa,\n",
    "            brokerage_income,\n",
    "            total_revenue,\n",
    "            total_assets,\n",
    "            trading_volume\n",
    "        FROM vcsc_daily_data_complete\n",
    "        WHERE ticker IN ('{ticker_str}')\n",
    "          AND date = '{analysis_date.date()}'\n",
    "        \"\"\"\n",
    "        \n",
    "        current_data = pd.read_sql(query, engine.engine)\n",
    "        \n",
    "        if current_data.empty:\n",
    "            return f_scores\n",
    "        \n",
    "        # Get previous year data\n",
    "        prev_date = analysis_date - pd.DateOffset(years=1)\n",
    "        prev_query = f\"\"\"\n",
    "        SELECT \n",
    "            ticker,\n",
    "            roa,\n",
    "            brokerage_income,\n",
    "            total_revenue,\n",
    "            total_assets,\n",
    "            trading_volume\n",
    "        FROM vcsc_daily_data_complete\n",
    "        WHERE ticker IN ('{ticker_str}')\n",
    "          AND date = '{prev_date.date()}'\n",
    "        \"\"\"\n",
    "        \n",
    "        prev_data = pd.read_sql(prev_query, engine.engine)\n",
    "        \n",
    "        # Merge data\n",
    "        merged_data = current_data.merge(prev_data, on='ticker', suffixes=('_curr', '_prev'))\n",
    "        \n",
    "        for _, row in merged_data.iterrows():\n",
    "            ticker = row['ticker']\n",
    "            score = 0\n",
    "            max_score = 5  # 5 tests for securities\n",
    "            \n",
    "            # Test 1: ROA > 0\n",
    "            if row['roa_curr'] > 0:\n",
    "                score += 1\n",
    "            \n",
    "            # Test 2: Brokerage Ratio > 0\n",
    "            brokerage_ratio = row['brokerage_income_curr'] / row['total_revenue_curr'] if row['total_revenue_curr'] > 0 else 0\n",
    "            if brokerage_ratio > 0:\n",
    "                score += 1\n",
    "            \n",
    "            # Test 3: Change in ROA > 0\n",
    "            if row['roa_curr'] > row['roa_prev']:\n",
    "                score += 1\n",
    "            \n",
    "            # Test 4: Change in Efficiency > 0 (simplified)\n",
    "            curr_efficiency = row['total_revenue_curr'] / row['total_assets_curr'] if row['total_assets_curr'] > 0 else 0\n",
    "            prev_efficiency = row['total_revenue_prev'] / row['total_assets_prev'] if row['total_assets_prev'] > 0 else 0\n",
    "            if curr_efficiency > prev_efficiency:\n",
    "                score += 1\n",
    "            \n",
    "            # Test 5: Change in Trading Volume > 0\n",
    "            if row['trading_volume_curr'] > row['trading_volume_prev']:\n",
    "                score += 1\n",
    "            \n",
    "            # Normalize score\n",
    "            normalized_score = score / max_score\n",
    "            f_scores[ticker] = normalized_score\n",
    "        \n",
    "        return f_scores\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to calculate securities F-Score for {analysis_date.strftime('%Y-%m-%d')}: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9757ab78",
   "metadata": {},
   "source": [
    "# HISTORICAL FACTOR GENERATION BY SECTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14671dcc",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Generate historical F-Score data by sector\n",
    "historical_f_score = {\n",
    "    'non_financial': {},\n",
    "    'banking': {},\n",
    "    'securities': {}\n",
    "}\n",
    "\n",
    "print(\"Generating historical F-Score data...\")\n",
    "\n",
    "for date in analysis_dates:\n",
    "    print(f\"Processing {date.strftime('%Y-%m-%d')}...\", end=' ')\n",
    "    \n",
    "    # Non-Financial F-Score\n",
    "    nf_scores = calculate_f_score_non_financial(engine, date, NON_FINANCIAL_TICKERS)\n",
    "    if nf_scores:\n",
    "        historical_f_score['non_financial'][date] = nf_scores\n",
    "        print(f\"NF:{len(nf_scores)}\", end=' ')\n",
    "    \n",
    "    # Banking F-Score\n",
    "    banking_scores = calculate_f_score_banking(engine, date, BANKING_TICKERS)\n",
    "    if banking_scores:\n",
    "        historical_f_score['banking'][date] = banking_scores\n",
    "        print(f\"B:{len(banking_scores)}\", end=' ')\n",
    "    \n",
    "    # Securities F-Score\n",
    "    securities_scores = calculate_f_score_securities(engine, date, SECURITIES_TICKERS)\n",
    "    if securities_scores:\n",
    "        historical_f_score['securities'][date] = securities_scores\n",
    "        print(f\"S:{len(securities_scores)}\", end=' ')\n",
    "    \n",
    "    print()\n",
    "\n",
    "print(f\"\\n‚úÖ Historical F-Score data generated:\")\n",
    "print(f\"  Non-Financial: {len(historical_f_score['non_financial'])} dates\")\n",
    "print(f\"  Banking: {len(historical_f_score['banking'])} dates\")\n",
    "print(f\"  Securities: {len(historical_f_score['securities'])} dates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d13479",
   "metadata": {},
   "source": [
    "# FORWARD RETURNS CALCULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8e8d06",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def calculate_forward_returns(engine, analysis_date, universe_tickers, forward_periods=[1, 3, 6, 12]):\n",
    "    \"\"\"\n",
    "    Calculate forward returns for statistical testing.\n",
    "    \n",
    "    Parameters:\n",
    "    - engine: QVMEngineV2Enhanced instance\n",
    "    - analysis_date: datetime for analysis\n",
    "    - universe_tickers: list of ticker symbols\n",
    "    - forward_periods: list of months for forward returns\n",
    "    \n",
    "    Returns:\n",
    "    - dict: {ticker: {period: return}}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        forward_returns = {}\n",
    "        \n",
    "        # Get price data for forward return calculation\n",
    "        ticker_str = \"', '\".join(universe_tickers)\n",
    "        max_forward = max(forward_periods)\n",
    "        end_date = analysis_date + pd.DateOffset(months=max_forward)\n",
    "        \n",
    "        price_query = f\"\"\"\n",
    "        SELECT \n",
    "            date,\n",
    "            ticker,\n",
    "            close as adj_close\n",
    "        FROM equity_history\n",
    "        WHERE ticker IN ('{ticker_str}')\n",
    "          AND date BETWEEN '{analysis_date.date()}' AND '{end_date.date()}'\n",
    "        ORDER BY ticker, date\n",
    "        \"\"\"\n",
    "        \n",
    "        price_data = pd.read_sql(price_query, engine.engine, parse_dates=['date'])\n",
    "        \n",
    "        if price_data.empty:\n",
    "            return forward_returns\n",
    "        \n",
    "        # Calculate forward returns for each period\n",
    "        for ticker in universe_tickers:\n",
    "            ticker_data = price_data[price_data['ticker'] == ticker].sort_values('date')\n",
    "            if ticker_data.empty:\n",
    "                continue\n",
    "                \n",
    "            start_price = ticker_data.iloc[0]['adj_close']\n",
    "            forward_returns[ticker] = {}\n",
    "            \n",
    "            for period in forward_periods:\n",
    "                # Find price at period months later\n",
    "                period_date = analysis_date + pd.DateOffset(months=period)\n",
    "                period_data = ticker_data[ticker_data['date'] >= period_date]\n",
    "                \n",
    "                if not period_data.empty:\n",
    "                    end_price = period_data.iloc[0]['adj_close']\n",
    "                    forward_return = (end_price - start_price) / start_price\n",
    "                    forward_returns[ticker][period] = forward_return\n",
    "        \n",
    "        return forward_returns\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to calculate forward returns for {analysis_date.strftime('%Y-%m-%d')}: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99757ad4",
   "metadata": {},
   "source": [
    "# STATISTICAL SIGNIFICANCE TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3362ce42",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def calculate_information_coefficient(factor_scores, forward_returns, period):\n",
    "    \"\"\"\n",
    "    Calculate Information Coefficient (IC) for a given forward period.\n",
    "    \n",
    "    Parameters:\n",
    "    - factor_scores: dict of {ticker: score}\n",
    "    - forward_returns: dict of {ticker: {period: return}}\n",
    "    - period: forward period in months\n",
    "    \n",
    "    Returns:\n",
    "    - float: Information Coefficient\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    returns = []\n",
    "    \n",
    "    for ticker in factor_scores:\n",
    "        if ticker in forward_returns and period in forward_returns[ticker]:\n",
    "            scores.append(factor_scores[ticker])\n",
    "            returns.append(forward_returns[ticker][period])\n",
    "    \n",
    "    if len(scores) < 3:  # Need at least 3 observations\n",
    "        return np.nan\n",
    "    \n",
    "    # Calculate rank correlation (Spearman's rho)\n",
    "    ic = stats.spearmanr(scores, returns)[0]\n",
    "    return ic\n",
    "\n",
    "def calculate_factor_returns(factor_scores, forward_returns, period, n_quintiles=5):\n",
    "    \"\"\"\n",
    "    Calculate factor returns using quintile analysis.\n",
    "    \n",
    "    Parameters:\n",
    "    - factor_scores: dict of {ticker: score}\n",
    "    - forward_returns: dict of {ticker: {period: return}}\n",
    "    - period: forward period in months\n",
    "    - n_quintiles: number of quintiles for analysis\n",
    "    \n",
    "    Returns:\n",
    "    - dict: quintile returns and spread\n",
    "    \"\"\"\n",
    "    # Create DataFrame for analysis\n",
    "    data = []\n",
    "    for ticker in factor_scores:\n",
    "        if ticker in forward_returns and period in forward_returns[ticker]:\n",
    "            data.append({\n",
    "                'ticker': ticker,\n",
    "                'factor_score': factor_scores[ticker],\n",
    "                'forward_return': forward_returns[ticker][period]\n",
    "            })\n",
    "    \n",
    "    if len(data) < n_quintiles:\n",
    "        return {}\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Create quintiles\n",
    "    df['quintile'] = pd.qcut(df['factor_score'], n_quintiles, labels=False)\n",
    "    \n",
    "    # Calculate returns by quintile\n",
    "    quintile_returns = df.groupby('quintile')['forward_return'].mean()\n",
    "    \n",
    "    # Calculate spread (Q5 - Q1)\n",
    "    spread = quintile_returns.iloc[-1] - quintile_returns.iloc[0]\n",
    "    \n",
    "    return {\n",
    "        'quintile_returns': quintile_returns,\n",
    "        'spread': spread,\n",
    "        'high_low_spread': spread\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809c36c6",
   "metadata": {},
   "source": [
    "# COMPREHENSIVE STATISTICAL ANALYSIS BY SECTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c97afcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate forward returns for all sectors\n",
    "print(\"Calculating forward returns by sector...\")\n",
    "historical_forward_returns = {\n",
    "    'non_financial': {},\n",
    "    'banking': {},\n",
    "    'securities': {}\n",
    "}\n",
    "\n",
    "# Non-Financial forward returns\n",
    "for date in list(historical_f_score['non_financial'].keys()):\n",
    "    forward_returns = calculate_forward_returns(engine, date, NON_FINANCIAL_TICKERS, [1, 3, 6, 12])\n",
    "    if forward_returns:\n",
    "        historical_forward_returns['non_financial'][date] = forward_returns\n",
    "\n",
    "# Banking forward returns\n",
    "for date in list(historical_f_score['banking'].keys()):\n",
    "    forward_returns = calculate_forward_returns(engine, date, BANKING_TICKERS, [1, 3, 6, 12])\n",
    "    if forward_returns:\n",
    "        historical_forward_returns['banking'][date] = forward_returns\n",
    "\n",
    "# Securities forward returns\n",
    "for date in list(historical_f_score['securities'].keys()):\n",
    "    forward_returns = calculate_forward_returns(engine, date, SECURITIES_TICKERS, [1, 3, 6, 12])\n",
    "    if forward_returns:\n",
    "        historical_forward_returns['securities'][date] = forward_returns\n",
    "\n",
    "print(f\"‚úÖ Forward returns calculated:\")\n",
    "print(f\"  Non-Financial: {len(historical_forward_returns['non_financial'])} dates\")\n",
    "print(f\"  Banking: {len(historical_forward_returns['banking'])} dates\")\n",
    "print(f\"  Securities: {len(historical_forward_returns['securities'])} dates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6dfdca",
   "metadata": {},
   "source": [
    "# INFORMATION COEFFICIENT ANALYSIS BY SECTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71672dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate IC for different sectors and forward periods\n",
    "forward_periods = [1, 3, 6, 12]\n",
    "sectors = ['non_financial', 'banking', 'securities']\n",
    "ic_results = {sector: {period: [] for period in forward_periods} for sector in sectors}\n",
    "\n",
    "for sector in sectors:\n",
    "    for date in historical_f_score[sector]:\n",
    "        if date in historical_forward_returns[sector]:\n",
    "            for period in forward_periods:\n",
    "                ic = calculate_information_coefficient(\n",
    "                    historical_f_score[sector][date], \n",
    "                    historical_forward_returns[sector][date], \n",
    "                    period\n",
    "                )\n",
    "                if not np.isnan(ic):\n",
    "                    ic_results[sector][period].append(ic)\n",
    "\n",
    "# Calculate IC statistics by sector\n",
    "ic_stats = {}\n",
    "for sector in sectors:\n",
    "    ic_stats[sector] = {}\n",
    "    for period in forward_periods:\n",
    "        if ic_results[sector][period]:\n",
    "            ic_values = ic_results[sector][period]\n",
    "            ic_stats[sector][period] = {\n",
    "                'mean': np.mean(ic_values),\n",
    "                'std': np.std(ic_values),\n",
    "                't_stat': np.mean(ic_values) / (np.std(ic_values) / np.sqrt(len(ic_values))),\n",
    "                'p_value': stats.ttest_1samp(ic_values, 0)[1],\n",
    "                'count': len(ic_values)\n",
    "            }\n",
    "\n",
    "print(\"Information Coefficient Analysis Results by Sector:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for sector in sectors:\n",
    "    print(f\"\\n{sector.upper().replace('_', ' ')} SECTOR:\")\n",
    "    print(\"-\" * 40)\n",
    "    for period in forward_periods:\n",
    "        if period in ic_stats[sector]:\n",
    "            stats = ic_stats[sector][period]\n",
    "            print(f\"  {period}M Forward Period:\")\n",
    "            print(f\"    Mean IC: {stats['mean']:.4f}\")\n",
    "            print(f\"    Std IC:  {stats['std']:.4f}\")\n",
    "            print(f\"    t-stat:  {stats['t_stat']:.4f}\")\n",
    "            print(f\"    p-value: {stats['p_value']:.4f}\")\n",
    "            print(f\"    N:       {stats['count']}\")\n",
    "            print(f\"    Significant: {'‚úÖ' if stats['p_value'] < 0.05 else '‚ùå'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fe09b0",
   "metadata": {},
   "source": [
    "# FACTOR RETURNS ANALYSIS BY SECTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0eeedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate factor returns for different sectors and periods\n",
    "factor_returns_results = {}\n",
    "\n",
    "for sector in sectors:\n",
    "    factor_returns_results[sector] = {}\n",
    "    \n",
    "    for period in forward_periods:\n",
    "        period_returns = []\n",
    "        \n",
    "        for date in historical_f_score[sector]:\n",
    "            if date in historical_forward_returns[sector]:\n",
    "                returns = calculate_factor_returns(\n",
    "                    historical_f_score[sector][date],\n",
    "                    historical_forward_returns[sector][date],\n",
    "                    period\n",
    "                )\n",
    "                if returns and 'spread' in returns:\n",
    "                    period_returns.append(returns['spread'])\n",
    "        \n",
    "        if period_returns:\n",
    "            factor_returns_results[sector][period] = {\n",
    "                'mean_return': np.mean(period_returns),\n",
    "                'std_return': np.std(period_returns),\n",
    "                't_stat': np.mean(period_returns) / (np.std(period_returns) / np.sqrt(len(period_returns))),\n",
    "                'p_value': stats.ttest_1samp(period_returns, 0)[1],\n",
    "                'count': len(period_returns),\n",
    "                'returns': period_returns\n",
    "            }\n",
    "\n",
    "print(\"Factor Returns Analysis Results by Sector:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for sector in sectors:\n",
    "    print(f\"\\n{sector.upper().replace('_', ' ')} SECTOR:\")\n",
    "    print(\"-\" * 40)\n",
    "    for period in forward_periods:\n",
    "        if period in factor_returns_results[sector]:\n",
    "            results = factor_returns_results[sector][period]\n",
    "            print(f\"  {period}M Forward Period:\")\n",
    "            print(f\"    Mean Spread: {results['mean_return']:.4f}\")\n",
    "            print(f\"    Std Spread:  {results['std_return']:.4f}\")\n",
    "            print(f\"    t-stat:      {results['t_stat']:.4f}\")\n",
    "            print(f\"    p-value:     {results['p_value']:.4f}\")\n",
    "            print(f\"    N:           {results['count']}\")\n",
    "            print(f\"    Significant: {'‚úÖ' if results['p_value'] < 0.05 else '‚ùå'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9b1df7",
   "metadata": {},
   "source": [
    "# VISUALIZATION OF RESULTS BY SECTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f6e162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 18))\n",
    "fig.suptitle('Piotroski F-Score Factor Statistical Analysis by Sector', fontsize=16, fontweight='bold')\n",
    "\n",
    "sector_names = {\n",
    "    'non_financial': 'Non-Financial',\n",
    "    'banking': 'Banking', \n",
    "    'securities': 'Securities'\n",
    "}\n",
    "\n",
    "for i, sector in enumerate(sectors):\n",
    "    # Plot 1: IC Distribution\n",
    "    ax1 = axes[i, 0]\n",
    "    for period in [1, 3, 6, 12]:\n",
    "        if ic_results[sector][period]:\n",
    "            ax1.hist(ic_results[sector][period], alpha=0.6, label=f'{period}M', bins=15)\n",
    "    ax1.axvline(0, color='red', linestyle='--', alpha=0.7)\n",
    "    ax1.set_xlabel('Information Coefficient')\n",
    "    ax1.set_ylabel('Frequency')\n",
    "    ax1.set_title(f'{sector_names[sector]} - IC Distribution')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Factor Returns Summary\n",
    "    ax2 = axes[i, 1]\n",
    "    periods = [p for p in [1, 3, 6, 12] if p in factor_returns_results[sector]]\n",
    "    if periods:\n",
    "        means = [factor_returns_results[sector][p]['mean_return'] for p in periods]\n",
    "        stds = [factor_returns_results[sector][p]['std_return'] for p in periods]\n",
    "        colors = ['green' if factor_returns_results[sector][p]['p_value'] < 0.05 else 'red' for p in periods]\n",
    "        \n",
    "        bars = ax2.bar([str(p) + 'M' for p in periods], means, yerr=stds, capsize=5, color=colors, alpha=0.7)\n",
    "        ax2.axhline(0, color='black', linestyle='-', alpha=0.5)\n",
    "        ax2.set_xlabel('Forward Period')\n",
    "        ax2.set_ylabel('Mean Factor Return Spread')\n",
    "        ax2.set_title(f'{sector_names[sector]} - Factor Returns')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add significance annotations\n",
    "        for j, (period, results) in enumerate(factor_returns_results[sector].items()):\n",
    "            if results['p_value'] < 0.05:\n",
    "                ax2.text(j, means[j] + stds[j] + 0.001, '*', ha='center', va='bottom', fontsize=16, color='green')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed68d148",
   "metadata": {},
   "source": [
    "# SUMMARY AND CONCLUSIONS BY SECTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984907ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 100)\n",
    "print(\"PIOTROSKI F-SCORE FACTOR STATISTICAL SIGNIFICANCE SUMMARY BY SECTOR\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "print(\"\\nüìä KEY FINDINGS BY SECTOR:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for sector in sectors:\n",
    "    print(f\"\\n{sector.upper().replace('_', ' ')} SECTOR:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # IC Analysis Summary\n",
    "    print(\"\\n1. INFORMATION COEFFICIENT ANALYSIS:\")\n",
    "    significant_ic_count = 0\n",
    "    for period in [1, 3, 6, 12]:\n",
    "        if period in ic_stats[sector]:\n",
    "            stats = ic_stats[sector][period]\n",
    "            significance = \"‚úÖ STATISTICALLY SIGNIFICANT\" if stats['p_value'] < 0.05 else \"‚ùå NOT SIGNIFICANT\"\n",
    "            print(f\"   {period}M Forward: IC = {stats['mean']:.4f} (p = {stats['p_value']:.4f}) - {significance}\")\n",
    "            if stats['p_value'] < 0.05:\n",
    "                significant_ic_count += 1\n",
    "    \n",
    "    # Factor Returns Summary\n",
    "    print(\"\\n2. FACTOR RETURNS ANALYSIS:\")\n",
    "    significant_returns_count = 0\n",
    "    for period in [1, 3, 6, 12]:\n",
    "        if period in factor_returns_results[sector]:\n",
    "            results = factor_returns_results[sector][period]\n",
    "            significance = \"‚úÖ STATISTICALLY SIGNIFICANT\" if results['p_value'] < 0.05 else \"‚ùå NOT SIGNIFICANT\"\n",
    "            print(f\"   {period}M Forward: Spread = {results['mean_return']:.4f} (p = {results['p_value']:.4f}) - {significance}\")\n",
    "            if results['p_value'] < 0.05:\n",
    "                significant_returns_count += 1\n",
    "    \n",
    "    # Sector Assessment\n",
    "    print(f\"\\n3. SECTOR ASSESSMENT:\")\n",
    "    print(f\"   - IC Significance: {significant_ic_count}/4 periods significant\")\n",
    "    print(f\"   - Returns Significance: {significant_returns_count}/4 periods significant\")\n",
    "    \n",
    "    if significant_ic_count >= 2 and significant_returns_count >= 2:\n",
    "        print(f\"   üéØ CONCLUSION: {sector_names[sector]} F-Score shows strong statistical significance\")\n",
    "        print(f\"   ‚úÖ RECOMMENDATION: Include in QVM v2.1 Alpha strategy\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è CONCLUSION: {sector_names[sector]} F-Score shows mixed statistical significance\")\n",
    "        print(f\"   üîç RECOMMENDATION: Further analysis needed before inclusion\")\n",
    "\n",
    "# Overall Assessment\n",
    "print(f\"\\n\" + \"=\" * 100)\n",
    "print(\"OVERALL ASSESSMENT:\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "total_significant_sectors = 0\n",
    "for sector in sectors:\n",
    "    significant_ic = sum(1 for period in [1, 3, 6, 12] if period in ic_stats[sector] and ic_stats[sector][period]['p_value'] < 0.05)\n",
    "    significant_returns = sum(1 for period in [1, 3, 6, 12] if period in factor_returns_results[sector] and factor_returns_results[sector][period]['p_value'] < 0.05)\n",
    "    \n",
    "    if significant_ic >= 2 and significant_returns >= 2:\n",
    "        total_significant_sectors += 1\n",
    "\n",
    "print(f\"   - Sectors with strong significance: {total_significant_sectors}/{len(sectors)}\")\n",
    "print(f\"   - Overall F-Score effectiveness: {'‚úÖ HIGH' if total_significant_sectors >= 2 else '‚ö†Ô∏è MIXED' if total_significant_sectors >= 1 else '‚ùå LOW'}\")\n",
    "\n",
    "if total_significant_sectors >= 2:\n",
    "    print(\"   üéØ FINAL CONCLUSION: Piotroski F-Score factor shows strong statistical significance across sectors\")\n",
    "    print(\"   ‚úÖ FINAL RECOMMENDATION: Include in QVM v2.1 Alpha strategy with sector-specific implementation\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è FINAL CONCLUSION: Piotroski F-Score factor shows limited statistical significance\")\n",
    "    print(\"   üîç FINAL RECOMMENDATION: Further refinement needed before inclusion\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100) "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "py310_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
