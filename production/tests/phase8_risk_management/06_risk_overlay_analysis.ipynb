{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# Aureus Sigma Capital - Risk Overlay Analysis\n",
    "# Notebook: 06_risk_overlay_analysis.ipynb\n",
    "#\n",
    "# Description:\n",
    "# Phase 8 Risk Management Implementation - Testing three distinct risk overlay\n",
    "# mechanisms to reduce maximum drawdown from -45.2% to institutional target\n",
    "# <25% while preserving validated alpha generation (Sharpe >1.2).\n",
    "#\n",
    "# Author: Duc Nguyen, Quantitative Finance Expert\n",
    "# Date: July 27, 2025\n",
    "# Version: 1.0 - Institutional Risk Management Framework\n",
    "# ============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Visualization environment configured with institutional palette.\n",
      "\n",
      "======================================================================\n",
      "üéØ Aureus Sigma: Phase 8 Risk Overlay Analysis\n",
      "   Version: 1.0 - Date: 2025-07-27 09:07:19\n",
      "======================================================================\n",
      "\n",
      "üéØ Phase 8 Mission:\n",
      "   ‚Ä¢ Reduce maximum drawdown from -45.2% to institutional target <25%\n",
      "   ‚Ä¢ Preserve validated alpha generation (maintain Sharpe >1.2)\n",
      "   ‚Ä¢ Test 3 risk overlay mechanisms on quarterly rebalancing baseline\n",
      "   ‚Ä¢ Optimize for Calmar Ratio (Annual Return / Max Drawdown)\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import warnings\n",
    "from scipy import stats\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import yaml\n",
    "from sqlalchemy import create_engine\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- INSTITUTIONAL PALETTE (Blackstone-inspired) ---\n",
    "FACTOR_COLORS = {\n",
    "    'Strategy': '#16A085',          # Blackstone Teal (primary)\n",
    "    'Benchmark': '#34495E',         # Warm charcoal (secondary)\n",
    "    'Positive': '#27AE60',         # Professional green\n",
    "    'Negative': '#C0392B',         # Sophisticated red\n",
    "    'Drawdown': '#E67E22',         # Sophisticated orange\n",
    "    'Sharpe': '#2980B9',           # Institutional blue\n",
    "    'Grid': '#BDC3C7',\n",
    "    'Text_Primary': '#2C3E50',\n",
    "    'Neutral': '#7F8C8D',\n",
    "    # Risk overlay colors\n",
    "    'Regime': '#9B59B6',           # Purple for regime overlay\n",
    "    'VolTarget': '#E74C3C',        # Red for volatility targeting\n",
    "    'DynReversal': '#F39C12',      # Orange for dynamic reversal\n",
    "    'Control': '#2C3E50'           # Dark for control baseline\n",
    "}\n",
    "\n",
    "GRADIENT_PALETTES = {\n",
    "    'performance': ['#C0392B', '#FFFFFF', '#27AE60'],  # Red-White-Green\n",
    "}\n",
    "\n",
    "# --- ENHANCED VISUALIZATION CONFIGURATION ---\n",
    "plt.style.use('default')\n",
    "plt.rcParams.update({\n",
    "    'figure.dpi': 300, 'savefig.dpi': 300, 'figure.figsize': (15, 8),\n",
    "    'figure.facecolor': 'white', 'font.size': 11,\n",
    "    'axes.facecolor': 'white', 'axes.edgecolor': FACTOR_COLORS['Text_Primary'],\n",
    "    'axes.linewidth': 1.0, 'axes.grid': True, 'axes.axisbelow': True,\n",
    "    'axes.labelcolor': FACTOR_COLORS['Text_Primary'], 'axes.titlesize': 14,\n",
    "    'axes.titleweight': 'bold', 'axes.titlecolor': FACTOR_COLORS['Text_Primary'],\n",
    "    'grid.color': FACTOR_COLORS['Grid'], 'grid.alpha': 0.3, 'grid.linewidth': 0.5,\n",
    "    'legend.frameon': False, 'legend.fontsize': 10,\n",
    "    'xtick.color': FACTOR_COLORS['Text_Primary'], 'ytick.color': FACTOR_COLORS['Text_Primary'],\n",
    "    'xtick.labelsize': 10, 'ytick.labelsize': 10,\n",
    "    'lines.linewidth': 2.0, 'lines.solid_capstyle': 'round'\n",
    "})\n",
    "\n",
    "print(\"üìä Visualization environment configured with institutional palette.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéØ Aureus Sigma: Phase 8 Risk Overlay Analysis\")\n",
    "print(f\"   Version: 1.0 - Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nüéØ Phase 8 Mission:\")\n",
    "print(\"   ‚Ä¢ Reduce maximum drawdown from -45.2% to institutional target <25%\")\n",
    "print(\"   ‚Ä¢ Preserve validated alpha generation (maintain Sharpe >1.2)\")\n",
    "print(\"   ‚Ä¢ Test 3 risk overlay mechanisms on quarterly rebalancing baseline\")\n",
    "print(\"   ‚Ä¢ Optimize for Calmar Ratio (Annual Return / Max Drawdown)\")\n",
    "print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Core Data and Establish Project Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading Phase 7 validated results and core data...\n",
      "   Phase 7 path: /Users/ducnguyen/Library/CloudStorage/GoogleDrive-duc.nguyentcb@gmail.com/My Drive/quant-world-invest/factor_investing_project/production/tests/phase7_institutional_backtesting\n",
      "   Phase 8 path: /Users/ducnguyen/Library/CloudStorage/GoogleDrive-duc.nguyentcb@gmail.com/My Drive/quant-world-invest/factor_investing_project/production/tests/phase8_risk_management\n",
      "‚úÖ Phase 7 validated results loaded:\n",
      "   Monthly strategy performance: 18.97% annual return\n",
      "   Monthly strategy Sharpe: 1.52\n",
      "   Maximum drawdown (monthly): 13.03%\n",
      "\n",
      "üèóÔ∏è Loading sector information...\n",
      "‚úÖ Loaded sector mappings for 728 tickers\n",
      "\n",
      "üîó Data aligned for Phase 8 analysis:\n",
      "   Date range: 2016-01-05 to 2025-07-25\n",
      "   Trading days: 2381\n",
      "   Universe size: 714 stocks\n",
      "   QVM scores shape: (2381, 714)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 2: LOAD PHASE 7 RESULTS AND PROJECT DATA\n",
    "# ============================================================================\n",
    "\n",
    "# Establish project paths\n",
    "project_root = Path.cwd()\n",
    "while not (project_root / 'production').exists() and not (project_root / 'config').exists():\n",
    "    if project_root.parent == project_root:\n",
    "        raise FileNotFoundError(\"Could not find project root\")\n",
    "    project_root = project_root.parent\n",
    "\n",
    "phase7_path = project_root / \"production\" / \"tests\" / \"phase7_institutional_backtesting\"\n",
    "phase8_path = project_root / \"production\" / \"tests\" / \"phase8_risk_management\"\n",
    "\n",
    "print(\"üìÇ Loading Phase 7 validated results and core data...\")\n",
    "print(f\"   Phase 7 path: {phase7_path}\")\n",
    "print(f\"   Phase 8 path: {phase8_path}\")\n",
    "\n",
    "# Load Phase 7 canonical backtest results\n",
    "with open(phase7_path / \"canonical_backtest_results.pkl\", \"rb\") as f:\n",
    "    phase7_results = pickle.load(f)\n",
    "\n",
    "# Load core data objects from Phase 7\n",
    "with open(phase7_path / \"factor_data.pkl\", \"rb\") as f:\n",
    "    factor_data_obj = pickle.load(f)\n",
    "with open(phase7_path / \"daily_returns.pkl\", \"rb\") as f:\n",
    "    returns_data_obj = pickle.load(f)\n",
    "with open(phase7_path / \"benchmark_returns.pkl\", \"rb\") as f:\n",
    "    benchmark_data_obj = pickle.load(f)\n",
    "\n",
    "# Extract data\n",
    "factor_data = factor_data_obj['data']\n",
    "daily_returns = returns_data_obj['data']\n",
    "benchmark_returns = benchmark_data_obj['data']\n",
    "\n",
    "print(\"‚úÖ Phase 7 validated results loaded:\")\n",
    "print(f\"   Monthly strategy performance: {(phase7_results['net_returns'].mean() * 252):.2%} annual return\")\n",
    "print(f\"   Monthly strategy Sharpe: {phase7_results['performance_summary']['sharpe_ratio']:.2f}\")\n",
    "print(f\"   Maximum drawdown (monthly): {phase7_results['performance_summary']['annual_vol']:.2%}\")\n",
    "\n",
    "# Load sector mappings\n",
    "print(\"\\nüèóÔ∏è Loading sector information...\")\n",
    "config_path = project_root / 'config' / 'database.yml'\n",
    "with open(config_path, 'r') as f:\n",
    "    db_config = yaml.safe_load(f)['production']\n",
    "\n",
    "engine = create_engine(\n",
    "    f\"mysql+pymysql://{db_config['username']}:{db_config['password']}@\"\n",
    "    f\"{db_config['host']}/{db_config['schema_name']}\"\n",
    ")\n",
    "\n",
    "sector_info = pd.read_sql(\"SELECT ticker, sector FROM master_info WHERE sector IS NOT NULL\", engine)\n",
    "sector_info = sector_info.drop_duplicates(subset=['ticker']).set_index('ticker')\n",
    "engine.dispose()\n",
    "\n",
    "print(f\"‚úÖ Loaded sector mappings for {len(sector_info)} tickers\")\n",
    "\n",
    "# Align data for Phase 8 analysis\n",
    "common_index = factor_data.index.intersection(daily_returns.index).intersection(benchmark_returns.index)\n",
    "common_tickers = factor_data.columns.get_level_values(1).intersection(daily_returns.columns).unique().intersection(sector_info.index)\n",
    "\n",
    "# Extract QVM scores and align all data\n",
    "qvm_scores = factor_data.loc[common_index, ('qvm_composite_score', common_tickers)]\n",
    "qvm_scores.columns = qvm_scores.columns.droplevel(0)\n",
    "daily_returns_aligned = daily_returns.loc[common_index, common_tickers]\n",
    "benchmark_returns_aligned = benchmark_returns.loc[common_index]\n",
    "\n",
    "print(\"\\nüîó Data aligned for Phase 8 analysis:\")\n",
    "print(f\"   Date range: {common_index.min().date()} to {common_index.max().date()}\")\n",
    "print(f\"   Trading days: {len(common_index)}\")\n",
    "print(f\"   Universe size: {len(common_tickers)} stocks\")\n",
    "print(f\"   QVM scores shape: {qvm_scores.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Market Regime Identification (from Phase 7)\n",
    "\n",
    "Load and validate the market regime framework that will be used for risk overlays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Identifying market regimes using Phase 7 validated methodology...\n",
      "\n",
      "üìä Regime Distribution (Phase 8 Implementation):\n",
      "   Bull      :  1004 days ( 42.2%)\n",
      "   Bear      :   768 days ( 32.3%)\n",
      "   Sideways  :   335 days ( 14.1%)\n",
      "   Stress    :   274 days ( 11.5%)\n",
      "\n",
      "üéØ Risk Overlay Coverage Analysis:\n",
      "   Bear + Stress periods: 1,042 days (43.8%)\n",
      "   Risk reduction opportunities: 43.8% of trading days\n",
      "   ‚úÖ GOOD COVERAGE: Sufficient Bear/Stress periods for risk overlay testing\n",
      "\n",
      "‚úÖ Market regime framework ready for Phase 8 implementation\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 3: MARKET REGIME FRAMEWORK (FROM PHASE 7 ATTRIBUTION ANALYSIS)\n",
    "# ============================================================================\n",
    "\n",
    "def identify_market_regimes(benchmark_returns: pd.Series, \n",
    "                          bear_threshold: float = -0.20,\n",
    "                          vol_window: int = 60,\n",
    "                          trend_window: int = 200) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Identifies market regimes using multiple criteria (from Phase 7 validation):\n",
    "    - Bear: Drawdown > 20% from peak\n",
    "    - Stress: Rolling volatility in top quartile\n",
    "    - Bull: Price above trend MA and not Bear/Stress\n",
    "    - Sideways: Everything else\n",
    "    \"\"\"\n",
    "    print(\"üîç Identifying market regimes using Phase 7 validated methodology...\")\n",
    "    \n",
    "    # Calculate cumulative returns and drawdowns\n",
    "    cumulative = (1 + benchmark_returns).cumprod()\n",
    "    drawdown = (cumulative / cumulative.cummax() - 1)\n",
    "    \n",
    "    # 1. Bear Market Regime\n",
    "    is_bear = drawdown < bear_threshold\n",
    "    \n",
    "    # 2. High-Stress Regime (rolling volatility)\n",
    "    rolling_vol = benchmark_returns.rolling(vol_window).std() * np.sqrt(252)\n",
    "    vol_75th = rolling_vol.quantile(0.75)\n",
    "    is_stress = rolling_vol > vol_75th\n",
    "    \n",
    "    # 3. Bull/Sideways (trend-based)\n",
    "    trend_ma = cumulative.rolling(trend_window).mean()\n",
    "    is_above_trend = cumulative > trend_ma\n",
    "    \n",
    "    # Combine into regime classification\n",
    "    regimes = pd.DataFrame(index=benchmark_returns.index)\n",
    "    regimes['is_bear'] = is_bear\n",
    "    regimes['is_stress'] = is_stress\n",
    "    regimes['is_bull'] = is_above_trend & ~is_bear & ~is_stress\n",
    "    regimes['is_sideways'] = ~is_above_trend & ~is_bear & ~is_stress\n",
    "    \n",
    "    # Create primary regime classification\n",
    "    regimes['regime'] = 'Undefined'\n",
    "    regimes.loc[regimes['is_bear'], 'regime'] = 'Bear'\n",
    "    regimes.loc[regimes['is_stress'] & ~regimes['is_bear'], 'regime'] = 'Stress'\n",
    "    regimes.loc[regimes['is_bull'], 'regime'] = 'Bull'\n",
    "    regimes.loc[regimes['is_sideways'], 'regime'] = 'Sideways'\n",
    "    \n",
    "    # Summary statistics\n",
    "    regime_counts = regimes['regime'].value_counts()\n",
    "    regime_pcts = (regime_counts / len(regimes)) * 100\n",
    "    \n",
    "    print(\"\\nüìä Regime Distribution (Phase 8 Implementation):\")\n",
    "    for regime, pct in regime_pcts.items():\n",
    "        days = regime_counts[regime]\n",
    "        print(f\"   {regime:10s}: {days:5d} days ({pct:5.1f}%)\")\n",
    "    \n",
    "    # Add additional metrics\n",
    "    regimes['drawdown'] = drawdown\n",
    "    regimes['rolling_vol'] = rolling_vol\n",
    "    regimes['cumulative_return'] = cumulative\n",
    "    \n",
    "    return regimes\n",
    "\n",
    "# Execute regime identification\n",
    "market_regimes = identify_market_regimes(benchmark_returns_aligned)\n",
    "\n",
    "# Validate regime signals for risk overlay implementation\n",
    "bear_stress_days = (market_regimes['regime'].isin(['Bear', 'Stress'])).sum()\n",
    "total_days = len(market_regimes)\n",
    "risk_coverage = bear_stress_days / total_days\n",
    "\n",
    "print(f\"\\nüéØ Risk Overlay Coverage Analysis:\")\n",
    "print(f\"   Bear + Stress periods: {bear_stress_days:,} days ({risk_coverage:.1%})\")\n",
    "print(f\"   Risk reduction opportunities: {risk_coverage:.1%} of trading days\")\n",
    "\n",
    "if risk_coverage > 0.35:\n",
    "    print(\"   ‚úÖ GOOD COVERAGE: Sufficient Bear/Stress periods for risk overlay testing\")\n",
    "elif risk_coverage > 0.20:\n",
    "    print(\"   ‚ö†Ô∏è MODERATE COVERAGE: Limited but adequate risk periods\")\n",
    "else:\n",
    "    print(\"   ‚ùå LOW COVERAGE: May not provide sufficient risk reduction opportunities\")\n",
    "\n",
    "print(f\"\\n‚úÖ Market regime framework ready for Phase 8 implementation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Quarterly Baseline Implementation (Control Group)\n",
    "\n",
    "Establish the quarterly rebalancing baseline that will serve as our control group for comparing risk overlay mechanisms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Implementing Quarterly Baseline (Control Group)...\n",
      "\n",
      "--- QUARTERLY BASELINE CONFIGURATION ---\n",
      "backtest_start_date      : 2016-01-01\n",
      "backtest_end_date        : 2025-07-25\n",
      "selection_percentile     : 0.2\n",
      "rebalance_freq           : Q\n",
      "long_only                : True\n",
      "max_sector_weight        : 0.4\n",
      "max_position_weight      : 0.05\n",
      "transaction_cost_bps     : 30\n",
      "üöÄ Running Quarterly Baseline Backtest (Control Group)...\n",
      "   - Identified 38 quarterly rebalance dates.\n",
      "   - Constructed quarterly holdings matrix.\n",
      "   - Shifted holdings by 1 day to prevent look-ahead bias.\n",
      "   - Calculated daily gross returns.\n",
      "   - Applied transaction costs to get net returns.\n",
      "‚úÖ Quarterly baseline backtest complete.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 4: QUARTERLY BASELINE IMPLEMENTATION (CONTROL GROUP)\n",
    "# ============================================================================\n",
    "\n",
    "# Enhanced strategy configuration for Phase 8\n",
    "QUARTERLY_BASELINE_CONFIG = {\n",
    "    \"backtest_start_date\": \"2016-01-01\",\n",
    "    \"backtest_end_date\": \"2025-07-25\",\n",
    "    \"selection_percentile\": 0.20,\n",
    "    \"rebalance_freq\": 'Q',  # QUARTERLY - Phase 8 baseline\n",
    "    \"long_only\": True,\n",
    "    \"max_sector_weight\": 0.40,\n",
    "    \"max_position_weight\": 0.05,\n",
    "    \"transaction_cost_bps\": 30\n",
    "}\n",
    "\n",
    "print(\"üöÄ Implementing Quarterly Baseline (Control Group)...\")\n",
    "print(\"\\n--- QUARTERLY BASELINE CONFIGURATION ---\")\n",
    "for key, value in QUARTERLY_BASELINE_CONFIG.items():\n",
    "    print(f\"{key:<25}: {value}\")\n",
    "\n",
    "# Load constrained portfolio construction and backtesting engine from Phase 7\n",
    "def construct_constrained_portfolio(\n",
    "    factor_scores: pd.Series, \n",
    "    sector_info: pd.DataFrame, \n",
    "    config: dict\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Constructs a single, constrained portfolio for a given rebalance date.\n",
    "    (Validated in Phase 7 - maintaining same logic)\n",
    "    \"\"\"\n",
    "    if factor_scores.empty:\n",
    "        return pd.DataFrame(columns=['weight', 'sector'])\n",
    "\n",
    "    # Select top quintile of stocks\n",
    "    top_quintile_cutoff = factor_scores.quantile(1 - config['selection_percentile'])\n",
    "    selected_stocks_df = factor_scores[factor_scores >= top_quintile_cutoff].to_frame('factor_score')\n",
    "    \n",
    "    # Merge with sector information\n",
    "    portfolio_df = selected_stocks_df.join(sector_info)\n",
    "    \n",
    "    # Handle potential missing sectors after join\n",
    "    if portfolio_df['sector'].isnull().any():\n",
    "        portfolio_df.dropna(subset=['sector'], inplace=True)\n",
    "\n",
    "    if portfolio_df.empty:\n",
    "        return pd.DataFrame(columns=['weight', 'sector'])\n",
    "\n",
    "    # Apply sector constraints\n",
    "    sector_counts = portfolio_df['sector'].value_counts()\n",
    "    max_stocks_in_portfolio = len(portfolio_df)\n",
    "    max_stocks_per_sector = int(max_stocks_in_portfolio * config['max_sector_weight'])\n",
    "    \n",
    "    final_tickers = set()\n",
    "    for sector, count in sector_counts.items():\n",
    "        sector_stocks = portfolio_df[portfolio_df['sector'] == sector]\n",
    "        if count > max_stocks_per_sector and max_stocks_per_sector > 0:\n",
    "            top_in_sector = sector_stocks.nlargest(max_stocks_per_sector, 'factor_score').index\n",
    "            final_tickers.update(top_in_sector)\n",
    "        else:\n",
    "            final_tickers.update(sector_stocks.index)\n",
    "            \n",
    "    final_portfolio = portfolio_df.loc[list(final_tickers)].copy()\n",
    "    \n",
    "    # Assign equal weights\n",
    "    num_stocks = len(final_portfolio)\n",
    "    if num_stocks > 0:\n",
    "        final_portfolio['weight'] = 1.0 / num_stocks\n",
    "    else:\n",
    "        return pd.DataFrame(columns=['weight', 'sector'])\n",
    "        \n",
    "    return final_portfolio[['weight', 'sector']]\n",
    "\n",
    "\n",
    "def run_quarterly_baseline_backtest(\n",
    "    qvm_scores: pd.DataFrame,\n",
    "    daily_returns: pd.DataFrame,\n",
    "    sector_info: pd.DataFrame,\n",
    "    config: dict\n",
    ") -> Tuple[pd.Series, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Runs the quarterly baseline backtest (Control Group for Phase 8).\n",
    "    \"\"\"\n",
    "    print(\"üöÄ Running Quarterly Baseline Backtest (Control Group)...\")\n",
    "    \n",
    "    # 1. IDENTIFY QUARTERLY REBALANCE DATES\n",
    "    ideal_rebalance_dates = pd.date_range(\n",
    "        start=qvm_scores.index.min(), \n",
    "        end=qvm_scores.index.max(), \n",
    "        freq=config['rebalance_freq']\n",
    "    )\n",
    "    print(f\"   - Identified {len(ideal_rebalance_dates)} quarterly rebalance dates.\")\n",
    "\n",
    "    # 2. Construct Daily Holdings Matrix\n",
    "    daily_holdings = pd.DataFrame(index=daily_returns.index, columns=daily_returns.columns).fillna(0.0)\n",
    "    \n",
    "    factor_scores_on_rebal_dates = qvm_scores.reindex(ideal_rebalance_dates, method='ffill')\n",
    "\n",
    "    for i in range(len(factor_scores_on_rebal_dates.index)):\n",
    "        rebal_date = factor_scores_on_rebal_dates.index[i]\n",
    "        \n",
    "        try:\n",
    "            next_rebal_date = factor_scores_on_rebal_dates.index[i+1]\n",
    "        except IndexError:\n",
    "            next_rebal_date = daily_returns.index[-1] + pd.Timedelta(days=1)\n",
    "\n",
    "        factor_scores_at_rebal = factor_scores_on_rebal_dates.loc[rebal_date].dropna()\n",
    "        \n",
    "        if len(factor_scores_at_rebal) > 20:\n",
    "            portfolio_df = construct_constrained_portfolio(factor_scores_at_rebal, sector_info, config)\n",
    "            \n",
    "            if not portfolio_df.empty:\n",
    "                # Define the holding period for this portfolio\n",
    "                relevant_days = daily_returns.index[(daily_returns.index > rebal_date) & (daily_returns.index < next_rebal_date)]\n",
    "                \n",
    "                if not relevant_days.empty:\n",
    "                    # Assign the weight Series to each relevant day\n",
    "                    for day in relevant_days:\n",
    "                        valid_tickers = portfolio_df.index.intersection(daily_holdings.columns)\n",
    "                        daily_holdings.loc[day, valid_tickers] = portfolio_df.loc[valid_tickers, 'weight']\n",
    "\n",
    "    print(\"   - Constructed quarterly holdings matrix.\")\n",
    "\n",
    "    # 3. PREVENT LOOK-AHEAD BIAS\n",
    "    daily_holdings_shifted = daily_holdings.shift(1).fillna(0)\n",
    "    print(\"   - Shifted holdings by 1 day to prevent look-ahead bias.\")\n",
    "\n",
    "    # 4. CALCULATE GROSS PORTFOLIO RETURNS\n",
    "    gross_returns = (daily_holdings_shifted * daily_returns).sum(axis=1)\n",
    "    print(\"   - Calculated daily gross returns.\")\n",
    "\n",
    "    # 5. MODEL TRANSACTION COSTS\n",
    "    turnover = (daily_holdings_shifted - daily_holdings_shifted.shift(1)).abs().sum(axis=1) / 2\n",
    "    transaction_costs = turnover * (config['transaction_cost_bps'] / 10000)\n",
    "    \n",
    "    net_returns = gross_returns - transaction_costs\n",
    "    print(\"   - Applied transaction costs to get net returns.\")\n",
    "    \n",
    "    backtest_log = pd.DataFrame({\n",
    "        'gross_return': gross_returns,\n",
    "        'net_return': net_returns,\n",
    "        'turnover': turnover,\n",
    "        'transaction_cost': transaction_costs,\n",
    "        'positions': (daily_holdings_shifted > 0).sum(axis=1)\n",
    "    })\n",
    "\n",
    "    print(\"‚úÖ Quarterly baseline backtest complete.\")\n",
    "    return net_returns, backtest_log, daily_holdings_shifted\n",
    "\n",
    "# Execute quarterly baseline backtest\n",
    "quarterly_returns, quarterly_log, quarterly_holdings = run_quarterly_baseline_backtest(\n",
    "    qvm_scores=qvm_scores,\n",
    "    daily_returns=daily_returns_aligned,\n",
    "    sector_info=sector_info,\n",
    "    config=QUARTERLY_BASELINE_CONFIG\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üìä QUARTERLY BASELINE PERFORMANCE VALIDATION (CONTROL GROUP)\n",
      "======================================================================\n",
      "Annual Return (%)        :    18.70\n",
      "Annual Volatility (%)    :    13.32\n",
      "Sharpe Ratio             :     1.40\n",
      "Max Drawdown (%)         :   -49.22\n",
      "Calmar Ratio             :     0.38\n",
      "Sortino Ratio            :     1.45\n",
      "Win Rate (%)             :    59.01\n",
      "Total Days               :  2381.00\n",
      "Information Ratio        :     0.54\n",
      "Tracking Error (%)       :    11.48\n",
      "\n",
      "üéØ Phase 8 Target Validation:\n",
      "   Sharpe Ratio Target (>1.2):  ‚úÖ PASS (1.40)\n",
      "   Drawdown Concern (<-25%):     ‚ö†Ô∏è YES (-49.2%)\n",
      "\n",
      "‚ö†Ô∏è RISK MANAGEMENT REQUIRED: Quarterly baseline exceeds -25% drawdown target\n",
      "   Risk overlays are essential for institutional deployment\n",
      "\n",
      "üìà Baseline Calmar Ratio: 0.38\n",
      "   Target: Maximize Calmar while maintaining Sharpe >1.2\n",
      "\n",
      "‚úÖ Quarterly baseline established as Control Group for Phase 8 risk overlay testing\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# QUARTERLY BASELINE PERFORMANCE VALIDATION\n",
    "# ============================================================================\n",
    "\n",
    "def calculate_performance_metrics(returns: pd.Series, \n",
    "                                  benchmark: pd.Series = None,\n",
    "                                  risk_free_rate: float = 0.0) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculate comprehensive performance metrics for Phase 8 analysis.\n",
    "    \"\"\"\n",
    "    # Basic metrics\n",
    "    total_return = (1 + returns).prod() - 1\n",
    "    n_years = len(returns) / 252\n",
    "    annual_return = (1 + total_return) ** (1 / n_years) - 1 if n_years > 0 else 0\n",
    "    annual_vol = returns.std() * np.sqrt(252)\n",
    "    sharpe_ratio = (annual_return - risk_free_rate) / annual_vol if annual_vol > 0 else 0\n",
    "    \n",
    "    # Drawdown analysis\n",
    "    cumulative = (1 + returns).cumprod()\n",
    "    drawdown = (cumulative / cumulative.cummax() - 1)\n",
    "    max_drawdown = drawdown.min()\n",
    "    \n",
    "    # Calmar Ratio (key metric for Phase 8)\n",
    "    calmar_ratio = annual_return / abs(max_drawdown) if max_drawdown < 0 else 0\n",
    "    \n",
    "    # Downside metrics\n",
    "    downside_returns = returns[returns < 0]\n",
    "    downside_vol = downside_returns.std() * np.sqrt(252) if len(downside_returns) > 0 else 0\n",
    "    sortino_ratio = (annual_return - risk_free_rate) / downside_vol if downside_vol > 0 else 0\n",
    "    \n",
    "    # Win rates\n",
    "    win_rate = (returns > 0).mean()\n",
    "    \n",
    "    metrics = {\n",
    "        'Annual Return (%)': annual_return * 100,\n",
    "        'Annual Volatility (%)': annual_vol * 100,\n",
    "        'Sharpe Ratio': sharpe_ratio,\n",
    "        'Max Drawdown (%)': max_drawdown * 100,\n",
    "        'Calmar Ratio': calmar_ratio,\n",
    "        'Sortino Ratio': sortino_ratio,\n",
    "        'Win Rate (%)': win_rate * 100,\n",
    "        'Total Days': len(returns)\n",
    "    }\n",
    "    \n",
    "    # Add benchmark comparison if provided\n",
    "    if benchmark is not None:\n",
    "        common_idx = returns.index.intersection(benchmark.index)\n",
    "        excess_returns = returns.loc[common_idx] - benchmark.loc[common_idx]\n",
    "        tracking_error = excess_returns.std() * np.sqrt(252)\n",
    "        information_ratio = (excess_returns.mean() * 252) / tracking_error if tracking_error > 0 else 0\n",
    "        \n",
    "        metrics['Information Ratio'] = information_ratio\n",
    "        metrics['Tracking Error (%)'] = tracking_error * 100\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Calculate quarterly baseline performance\n",
    "quarterly_metrics = calculate_performance_metrics(quarterly_returns, benchmark_returns_aligned)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìä QUARTERLY BASELINE PERFORMANCE VALIDATION (CONTROL GROUP)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for metric, value in quarterly_metrics.items():\n",
    "    if 'Ratio' in metric or 'Rate' in metric:\n",
    "        print(f\"{metric:<25}: {value:8.2f}\")\n",
    "    else:\n",
    "        print(f\"{metric:<25}: {value:8.2f}\")\n",
    "\n",
    "# Validate against Phase 8 targets\n",
    "print(\"\\nüéØ Phase 8 Target Validation:\")\n",
    "sharpe_target = quarterly_metrics['Sharpe Ratio'] >= 1.2\n",
    "drawdown_concern = quarterly_metrics['Max Drawdown (%)'] < -25\n",
    "\n",
    "print(f\"   Sharpe Ratio Target (>1.2):  {'‚úÖ PASS' if sharpe_target else '‚ùå FAIL'} ({quarterly_metrics['Sharpe Ratio']:.2f})\")\n",
    "print(f\"   Drawdown Concern (<-25%):     {'‚ö†Ô∏è YES' if drawdown_concern else '‚úÖ NO'} ({quarterly_metrics['Max Drawdown (%)']:.1f}%)\")\n",
    "\n",
    "if drawdown_concern:\n",
    "    print(\"\\n‚ö†Ô∏è RISK MANAGEMENT REQUIRED: Quarterly baseline exceeds -25% drawdown target\")\n",
    "    print(\"   Risk overlays are essential for institutional deployment\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ BASELINE ACCEPTABLE: Quarterly baseline meets drawdown requirements\")\n",
    "    print(\"   Risk overlays will focus on further optimization\")\n",
    "\n",
    "# Calculate improvement needed\n",
    "current_calmar = quarterly_metrics['Calmar Ratio']\n",
    "print(f\"\\nüìà Baseline Calmar Ratio: {current_calmar:.2f}\")\n",
    "print(f\"   Target: Maximize Calmar while maintaining Sharpe >1.2\")\n",
    "\n",
    "print(\"\\n‚úÖ Quarterly baseline established as Control Group for Phase 8 risk overlay testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üéØ IMPLEMENTING TEST A: MARKET REGIME OVERLAY\n",
      "======================================================================\n",
      "üîß Implementing Market Regime Overlay (Test A)...\n",
      "    Risk reduction factor: 0.5 (50% exposure during Bear/Stress)\n",
      "    Bear/Stress periods identified: 1,042 days (43.8%)\n",
      "    Applied 0.5 exposure multiplier to 1,042 trading days\n",
      "    Average exposure during normal periods: 94.5%\n",
      "    Average exposure during Bear/Stress: 49.6%\n",
      "üöÄ Running Market Regime Overlay backtest...\n",
      "‚úÖ Market Regime Overlay backtest complete.\n",
      "\n",
      "üìä MARKET REGIME OVERLAY PERFORMANCE (TEST A):\n",
      "==================================================\n",
      "Annual Return (%)        :    12.83\n",
      "Annual Volatility (%)    :    10.30\n",
      "Sharpe Ratio             :     1.25\n",
      "Max Drawdown (%)         :   -39.58\n",
      "Calmar Ratio             :     0.32\n",
      "Sortino Ratio            :     1.22\n",
      "Win Rate (%)             :    59.01\n",
      "Total Days               :  2381.00\n",
      "Information Ratio        :     0.06\n",
      "Tracking Error (%)       :    13.09\n",
      "\n",
      "üîç TEST A vs BASELINE COMPARISON:\n",
      "========================================\n",
      "Metric                    Baseline   Test A     Change    \n",
      "-------------------------------------------------------\n",
      "Annual Return (%)            18.70       12.83       -5.87\n",
      "Sharpe Ratio                  1.40        1.25       -0.16\n",
      "Max Drawdown (%)            -49.22      -39.58       +9.65\n",
      "Calmar Ratio                  0.38        0.32       -0.06\n",
      "\n",
      "üéØ TEST A RISK ASSESSMENT:\n",
      "==============================\n",
      "Sharpe Preservation (>1.2):      ‚úÖ PASS (1.25)\n",
      "Drawdown Improvement:            ‚úÖ YES (-39.6% vs -49.2%)\n",
      "Calmar Improvement:              ‚ùå NO (0.32 vs 0.38)\n",
      "Target Achieved (<-25%):         ‚ùå NO (-39.6%)\n",
      "\n",
      "‚úÖ TEST A PROGRESS: Significant improvement, may need fine-tuning\n",
      "\n",
      "‚úÖ Market Regime Overlay (Test A) analysis complete\n"
     ]
    }
   ],
   "source": [
    "# =================================================================\n",
    "# CELL 5: MARKET REGIME OVERLAY IMPLEMENTATION (TEST A)\n",
    "# =================================================================\n",
    "\n",
    "def apply_market_regime_overlay(\n",
    "    baseline_holdings: pd.DataFrame,\n",
    "    market_regimes: pd.DataFrame,\n",
    "    risk_reduction_factor: float = 0.5\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Apply market regime overlay by reducing exposure during Bear/Stress periods.\n",
    "    \n",
    "    Parameters:\n",
    "    - baseline_holdings: Daily portfolio weights from quarterly baseline\n",
    "    - market_regimes: Regime classification from Phase 7 framework\n",
    "    - risk_reduction_factor: Multiplier for Bear/Stress periods (0.5 = 50% exposure)\n",
    "    \n",
    "    Returns:\n",
    "    - risk_managed_holdings: Adjusted portfolio weights with regime overlay\n",
    "    \"\"\"\n",
    "    print(f\"üîß Implementing Market Regime Overlay (Test A)...\")\n",
    "    print(f\"    Risk reduction factor: {risk_reduction_factor} (50% exposure during Bear/Stress)\")\n",
    "\n",
    "    # Create a copy of baseline holdings\n",
    "    risk_managed_holdings = baseline_holdings.copy()\n",
    "\n",
    "    # Identify Bear and Stress periods\n",
    "    bear_stress_mask = market_regimes['regime'].isin(['Bear', 'Stress'])\n",
    "    bear_stress_dates = market_regimes[bear_stress_mask].index\n",
    "\n",
    "    print(f\"    Bear/Stress periods identified: {len(bear_stress_dates):,} days ({len(bear_stress_dates)/len(market_regimes):.1%})\")\n",
    "\n",
    "    # Apply risk reduction to Bear/Stress periods\n",
    "    common_dates = baseline_holdings.index.intersection(bear_stress_dates)\n",
    "    if len(common_dates) > 0:\n",
    "        risk_managed_holdings.loc[common_dates] *= risk_reduction_factor\n",
    "        print(f\"    Applied {risk_reduction_factor} exposure multiplier to {len(common_dates):,} trading days\")\n",
    "\n",
    "    # Calculate portfolio statistics\n",
    "    normal_exposure = baseline_holdings[~baseline_holdings.index.isin(bear_stress_dates)].sum(axis=1).mean()\n",
    "    reduced_exposure = risk_managed_holdings[risk_managed_holdings.index.isin(bear_stress_dates)].sum(axis=1).mean()\n",
    "\n",
    "    print(f\"    Average exposure during normal periods: {normal_exposure:.1%}\")\n",
    "    print(f\"    Average exposure during Bear/Stress: {reduced_exposure:.1%}\")\n",
    "\n",
    "    return risk_managed_holdings\n",
    "\n",
    "\n",
    "def run_regime_overlay_backtest(\n",
    "    regime_holdings: pd.DataFrame,\n",
    "    daily_returns: pd.DataFrame,\n",
    "    config: dict,\n",
    "    overlay_name: str = \"Regime Overlay\"\n",
    ") -> Tuple[pd.Series, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Run backtest with regime-adjusted holdings.\n",
    "    \"\"\"\n",
    "    print(f\"üöÄ Running {overlay_name} backtest...\")\n",
    "\n",
    "    # Ensure no look-ahead bias (holdings should already be shifted)\n",
    "    # But apply one more shift to be absolutely certain\n",
    "    regime_holdings_shifted = regime_holdings.shift(1).fillna(0)\n",
    "\n",
    "    # Calculate gross returns\n",
    "    gross_returns = (regime_holdings_shifted * daily_returns).sum(axis=1)\n",
    "\n",
    "    # Calculate turnover for transaction costs\n",
    "    turnover = (regime_holdings_shifted - regime_holdings_shifted.shift(1)).abs().sum(axis=1) / 2\n",
    "    transaction_costs = turnover * (config['transaction_cost_bps'] / 10000)\n",
    "\n",
    "    # Net returns\n",
    "    net_returns = gross_returns - transaction_costs\n",
    "\n",
    "    # Backtest log\n",
    "    backtest_log = pd.DataFrame({\n",
    "        'gross_return': gross_returns,\n",
    "        'net_return': net_returns,\n",
    "        'turnover': turnover,\n",
    "        'transaction_cost': transaction_costs,\n",
    "        'positions': (regime_holdings_shifted > 0).sum(axis=1),\n",
    "        'total_exposure': regime_holdings_shifted.sum(axis=1)\n",
    "    })\n",
    "\n",
    "    print(f\"‚úÖ {overlay_name} backtest complete.\")\n",
    "    return net_returns, backtest_log\n",
    "\n",
    "\n",
    "# Execute Market Regime Overlay (Test A)\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéØ IMPLEMENTING TEST A: MARKET REGIME OVERLAY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Apply regime overlay to quarterly baseline holdings\n",
    "regime_overlay_holdings = apply_market_regime_overlay(\n",
    "    baseline_holdings=quarterly_holdings,\n",
    "    market_regimes=market_regimes,\n",
    "    risk_reduction_factor=0.5  # 50% exposure during Bear/Stress\n",
    ")\n",
    "\n",
    "# Run backtest with regime overlay\n",
    "regime_overlay_returns, regime_overlay_log = run_regime_overlay_backtest(\n",
    "    regime_holdings=regime_overlay_holdings,\n",
    "    daily_returns=daily_returns_aligned,\n",
    "    config=QUARTERLY_BASELINE_CONFIG,\n",
    "    overlay_name=\"Market Regime Overlay\"\n",
    ")\n",
    "\n",
    "# Calculate performance metrics for Test A\n",
    "regime_overlay_metrics = calculate_performance_metrics(regime_overlay_returns, benchmark_returns_aligned)\n",
    "\n",
    "print(\"\\nüìä MARKET REGIME OVERLAY PERFORMANCE (TEST A):\")\n",
    "print(\"=\" * 50)\n",
    "for metric, value in regime_overlay_metrics.items():\n",
    "    if 'Ratio' in metric or 'Rate' in metric:\n",
    "        print(f\"{metric:<25}: {value:8.2f}\")\n",
    "    else:\n",
    "        print(f\"{metric:<25}: {value:8.2f}\")\n",
    "\n",
    "# Compare against baseline\n",
    "print(\"\\nüîç TEST A vs BASELINE COMPARISON:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"{'Metric':<25} {'Baseline':<10} {'Test A':<10} {'Change':<10}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "key_metrics = ['Annual Return (%)', 'Sharpe Ratio', 'Max Drawdown (%)', 'Calmar Ratio']\n",
    "for metric in key_metrics:\n",
    "    baseline_val = quarterly_metrics[metric]\n",
    "    overlay_val = regime_overlay_metrics[metric]\n",
    "    change = overlay_val - baseline_val\n",
    "    change_str = f\"{change:+.2f}\"\n",
    "    print(f\"{metric:<25} {baseline_val:8.2f}    {overlay_val:8.2f}    {change_str:>8s}\")\n",
    "\n",
    "# Risk assessment for Test A\n",
    "print(\"\\nüéØ TEST A RISK ASSESSMENT:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "sharpe_preserved = regime_overlay_metrics['Sharpe Ratio'] >= 1.2\n",
    "drawdown_improved = regime_overlay_metrics['Max Drawdown (%)'] > quarterly_metrics['Max Drawdown (%)']\n",
    "calmar_improved = regime_overlay_metrics['Calmar Ratio'] > quarterly_metrics['Calmar Ratio']\n",
    "target_achieved = regime_overlay_metrics['Max Drawdown (%)'] > -25.0\n",
    "\n",
    "print(f\"Sharpe Preservation (>1.2):      {'‚úÖ PASS' if sharpe_preserved else '‚ùå FAIL'} ({regime_overlay_metrics['Sharpe Ratio']:.2f})\")\n",
    "print(f\"Drawdown Improvement:            {'‚úÖ YES' if drawdown_improved else '‚ùå NO'} ({regime_overlay_metrics['Max Drawdown (%)']:.1f}% vs {quarterly_metrics['Max Drawdown (%)']:.1f}%)\")\n",
    "print(f\"Calmar Improvement:              {'‚úÖ YES' if calmar_improved else '‚ùå NO'} ({regime_overlay_metrics['Calmar Ratio']:.2f} vs {quarterly_metrics['Calmar Ratio']:.2f})\")\n",
    "print(f\"Target Achieved (<-25%):         {'‚úÖ YES' if target_achieved else '‚ùå NO'} ({regime_overlay_metrics['Max Drawdown (%)']:.1f}%)\")\n",
    "\n",
    "if target_achieved and sharpe_preserved:\n",
    "    print(\"\\nüéâ TEST A SUCCESS: Market Regime Overlay achieves institutional targets!\")\n",
    "elif drawdown_improved and sharpe_preserved:\n",
    "    print(\"\\n‚úÖ TEST A PROGRESS: Significant improvement, may need fine-tuning\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è TEST A MIXED: Review trade-offs between risk reduction and alpha preservation\")\n",
    "\n",
    "print(\"\\n‚úÖ Market Regime Overlay (Test A) analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXECUTIVE SUMMARY: Test A (Market Regime Overlay) shows mixed \n",
    "  results - significant drawdown improvement (+9.6%) but still\n",
    "  exceeds institutional target. Sharpe ratio preserved (1.25 > 1.2)\n",
    "  but Calmar ratio deteriorated due to return sacrifice. Need Test B\n",
    "  and C to find optimal mechanism.\n",
    "\n",
    "  DETAILED ANALYSIS:\n",
    "\n",
    "  Test A Results Assessment:\n",
    "\n",
    "  ‚úÖ Positive Outcomes:\n",
    "  - Drawdown Reduction: -39.6% vs -49.2% baseline (+9.6% improvement)\n",
    "  - Sharpe Preservation: 1.25 > 1.2 institutional requirement ‚úÖ\n",
    "  - Volatility Control: 10.30% vs 13.32% baseline (significant risk\n",
    "  reduction)\n",
    "  - Operational Success: Applied 50% exposure reduction to 43.8% of\n",
    "  trading days\n",
    "\n",
    "  ‚ö†Ô∏è Areas of Concern:\n",
    "  - Target Miss: -39.6% still exceeds -25% institutional target by\n",
    "  14.6%\n",
    "  - Return Sacrifice: 12.83% vs 18.70% baseline (-5.87% annual return\n",
    "   loss)\n",
    "  - Calmar Deterioration: 0.32 vs 0.38 baseline (net risk-adjusted\n",
    "  performance decline)\n",
    "\n",
    "  üìä Key Insights:\n",
    "  - Risk Coverage: 43.8% Bear/Stress periods provide substantial\n",
    "  intervention opportunities\n",
    "  - Mechanism Effectiveness: 50% exposure reduction during risk\n",
    "  periods works but may be too conservative\n",
    "  - Trade-off Balance: Substantial risk reduction comes at\n",
    "  significant return cost\n",
    "\n",
    "  IMPLEMENTATION NOTES:\n",
    "\n",
    "  Test A validates the regime overlay approach but suggests\n",
    "  calibration needs:\n",
    "  1. Fine-tuning Opportunity: 50% reduction may be excessive - could\n",
    "  test 60-70% exposure\n",
    "  2. Institutional Gap: 14.6% gap to -25% target requires additional\n",
    "  risk management\n",
    "  3. Return Preservation: Need mechanism that maintains more alpha\n",
    "  while reducing risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üéØ IMPLEMENTING TEST B: VOLATILITY TARGETING OVERLAY\n",
      "======================================================================\n",
      "üîß Implementing Volatility Targeting Overlay (Test B)...\n",
      "    Target volatility: 15.0%\n",
      "    Volatility window: 60 days\n",
      "    Exposure range: 20.0% to 100.0%\n",
      "    Average volatility scaling: 0.94\n",
      "    Scaling volatility: 0.12\n",
      "    High volatility days (>80% reduction): 341\n",
      "    Low volatility days (>100% exposure): 0\n",
      "üöÄ Running Volatility Targeting Overlay backtest...\n",
      "‚úÖ Volatility Targeting Overlay backtest complete.\n",
      "\n",
      "üìä VOLATILITY TARGETING OVERLAY PERFORMANCE (TEST B):\n",
      "==================================================\n",
      "Annual Return (%)        :    17.62\n",
      "Annual Volatility (%)    :    11.84\n",
      "Sharpe Ratio             :     1.49\n",
      "Max Drawdown (%)         :   -41.71\n",
      "Calmar Ratio             :     0.42\n",
      "Sortino Ratio            :     1.54\n",
      "Win Rate (%)             :    59.18\n",
      "Total Days               :  2381.00\n",
      "Information Ratio        :     0.44\n",
      "Tracking Error (%)       :    11.58\n",
      "\n",
      "üîç TEST B vs BASELINE COMPARISON:\n",
      "========================================\n",
      "Metric                    Baseline   Test B     Change    \n",
      "-------------------------------------------------------\n",
      "Annual Return (%)            18.70       17.62       -1.08\n",
      "Sharpe Ratio                  1.40        1.49       +0.08\n",
      "Max Drawdown (%)            -49.22      -41.71       +7.51\n",
      "Calmar Ratio                  0.38        0.42       +0.04\n",
      "\n",
      "üéØ TEST B RISK ASSESSMENT:\n",
      "==============================\n",
      "Sharpe Preservation (>1.2):      ‚úÖ PASS (1.49)\n",
      "Drawdown Improvement:            ‚úÖ YES (-41.7% vs -49.2%)\n",
      "Calmar Improvement:              ‚úÖ YES (0.42 vs 0.38)\n",
      "Target Achieved (<-25%):         ‚ùå NO (-41.7%)\n",
      "\n",
      "‚úÖ TEST B PROGRESS: Significant improvement, may need fine-tuning\n",
      "\n",
      "‚úÖ Volatility Targeting Overlay (Test B) analysis complete\n"
     ]
    }
   ],
   "source": [
    "# =================================================================\n",
    "# CELL 6: VOLATILITY TARGETING OVERLAY IMPLEMENTATION (TEST B)\n",
    "# =================================================================\n",
    "\n",
    "def calculate_portfolio_volatility(\n",
    "    portfolio_returns: pd.Series,\n",
    "    window: int = 60\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Calculate rolling portfolio volatility (annualized).\n",
    "    \"\"\"\n",
    "    rolling_vol = portfolio_returns.rolling(window).std() * np.sqrt(252)\n",
    "    return rolling_vol\n",
    "\n",
    "\n",
    "def apply_volatility_targeting_overlay(\n",
    "    baseline_holdings: pd.DataFrame,\n",
    "    baseline_returns: pd.Series,\n",
    "    target_volatility: float = 0.15,\n",
    "    vol_window: int = 60,\n",
    "    max_leverage: float = 1.0,\n",
    "    min_exposure: float = 0.2\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Apply volatility targeting overlay by scaling exposure based on realized volatility.\n",
    "    \n",
    "    Parameters:\n",
    "    - baseline_holdings: Daily portfolio weights from quarterly baseline\n",
    "    - baseline_returns: Portfolio returns to calculate volatility\n",
    "    - target_volatility: Target portfolio volatility (15%)\n",
    "    - vol_window: Rolling window for volatility calculation (60 days)\n",
    "    - max_leverage: Maximum exposure multiplier (1.0 = no leverage)\n",
    "    - min_exposure: Minimum exposure multiplier (0.2 = 20% minimum)\n",
    "    \n",
    "    Returns:\n",
    "    - vol_targeted_holdings: Adjusted portfolio weights with volatility targeting\n",
    "    \"\"\"\n",
    "    print(f\"üîß Implementing Volatility Targeting Overlay (Test B)...\")\n",
    "    print(f\"    Target volatility: {target_volatility:.1%}\")\n",
    "    print(f\"    Volatility window: {vol_window} days\")\n",
    "    print(f\"    Exposure range: {min_exposure:.1%} to {max_leverage:.1%}\")\n",
    "\n",
    "    # Calculate rolling portfolio volatility\n",
    "    rolling_vol = calculate_portfolio_volatility(baseline_returns, window=vol_window)\n",
    "\n",
    "    # Calculate volatility scaling factor\n",
    "    vol_scaling = target_volatility / rolling_vol\n",
    "\n",
    "    # Apply constraints\n",
    "    vol_scaling = np.clip(vol_scaling, min_exposure, max_leverage)\n",
    "\n",
    "    # Handle NaN values (early periods without enough data)\n",
    "    vol_scaling = vol_scaling.fillna(1.0)\n",
    "\n",
    "    # Apply scaling to holdings\n",
    "    vol_targeted_holdings = baseline_holdings.copy()\n",
    "\n",
    "    for date in vol_targeted_holdings.index:\n",
    "        if date in vol_scaling.index:\n",
    "            scaling_factor = vol_scaling[date]\n",
    "            vol_targeted_holdings.loc[date] *= scaling_factor\n",
    "\n",
    "    # Calculate statistics\n",
    "    avg_scaling = vol_scaling[vol_scaling.notna()].mean()\n",
    "    scaling_std = vol_scaling[vol_scaling.notna()].std()\n",
    "    high_vol_days = (vol_scaling < 0.8).sum()  # Days with >80% reduction\n",
    "    low_vol_days = (vol_scaling > 1.0).sum()    # Days with leverage (if any)\n",
    "\n",
    "    print(f\"    Average volatility scaling: {avg_scaling:.2f}\")\n",
    "    print(f\"    Scaling volatility: {scaling_std:.2f}\")\n",
    "    print(f\"    High volatility days (>80% reduction): {high_vol_days:,}\")\n",
    "    print(f\"    Low volatility days (>100% exposure): {low_vol_days:,}\")\n",
    "\n",
    "    return vol_targeted_holdings, vol_scaling\n",
    "\n",
    "\n",
    "# Execute Volatility Targeting Overlay (Test B)\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéØ IMPLEMENTING TEST B: VOLATILITY TARGETING OVERLAY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Apply volatility targeting to quarterly baseline holdings\n",
    "vol_target_holdings, vol_scaling_factors = apply_volatility_targeting_overlay(\n",
    "    baseline_holdings=quarterly_holdings,\n",
    "    baseline_returns=quarterly_returns,\n",
    "    target_volatility=0.15,  # 15% target volatility\n",
    "    vol_window=60,\n",
    "    max_leverage=1.0,\n",
    "    min_exposure=0.2\n",
    ")\n",
    "\n",
    "# Run backtest with volatility targeting\n",
    "vol_target_returns, vol_target_log = run_regime_overlay_backtest(\n",
    "    regime_holdings=vol_target_holdings,\n",
    "    daily_returns=daily_returns_aligned,\n",
    "    config=QUARTERLY_BASELINE_CONFIG,\n",
    "    overlay_name=\"Volatility Targeting Overlay\"\n",
    ")\n",
    "\n",
    "# Calculate performance metrics for Test B\n",
    "vol_target_metrics = calculate_performance_metrics(vol_target_returns, benchmark_returns_aligned)\n",
    "\n",
    "print(\"\\nüìä VOLATILITY TARGETING OVERLAY PERFORMANCE (TEST B):\")\n",
    "print(\"=\" * 50)\n",
    "for metric, value in vol_target_metrics.items():\n",
    "    if 'Ratio' in metric or 'Rate' in metric:\n",
    "        print(f\"{metric:<25}: {value:8.2f}\")\n",
    "    else:\n",
    "        print(f\"{metric:<25}: {value:8.2f}\")\n",
    "\n",
    "# Compare against baseline\n",
    "print(\"\\nüîç TEST B vs BASELINE COMPARISON:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"{'Metric':<25} {'Baseline':<10} {'Test B':<10} {'Change':<10}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for metric in key_metrics:\n",
    "    baseline_val = quarterly_metrics[metric]\n",
    "    overlay_val = vol_target_metrics[metric]\n",
    "    change = overlay_val - baseline_val\n",
    "    change_str = f\"{change:+.2f}\"\n",
    "    print(f\"{metric:<25} {baseline_val:8.2f}    {overlay_val:8.2f}    {change_str:>8s}\")\n",
    "\n",
    "# Risk assessment for Test B\n",
    "print(\"\\nüéØ TEST B RISK ASSESSMENT:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "sharpe_preserved_b = vol_target_metrics['Sharpe Ratio'] >= 1.2\n",
    "drawdown_improved_b = vol_target_metrics['Max Drawdown (%)'] > quarterly_metrics['Max Drawdown (%)']\n",
    "calmar_improved_b = vol_target_metrics['Calmar Ratio'] > quarterly_metrics['Calmar Ratio']\n",
    "target_achieved_b = vol_target_metrics['Max Drawdown (%)'] > -25.0\n",
    "\n",
    "print(f\"Sharpe Preservation (>1.2):      {'‚úÖ PASS' if sharpe_preserved_b else '‚ùå FAIL'} ({vol_target_metrics['Sharpe Ratio']:.2f})\")\n",
    "print(f\"Drawdown Improvement:            {'‚úÖ YES' if drawdown_improved_b else '‚ùå NO'} ({vol_target_metrics['Max Drawdown (%)']:.1f}% vs {quarterly_metrics['Max Drawdown (%)']:.1f}%)\")\n",
    "print(f\"Calmar Improvement:              {'‚úÖ YES' if calmar_improved_b else '‚ùå NO'} ({vol_target_metrics['Calmar Ratio']:.2f} vs {quarterly_metrics['Calmar Ratio']:.2f})\")\n",
    "print(f\"Target Achieved (<-25%):         {'‚úÖ YES' if target_achieved_b else '‚ùå NO'} ({vol_target_metrics['Max Drawdown (%)']:.1f}%)\")\n",
    "\n",
    "if target_achieved_b and sharpe_preserved_b:\n",
    "    print(\"\\nüéâ TEST B SUCCESS: Volatility Targeting achieves institutional targets!\")\n",
    "elif drawdown_improved_b and sharpe_preserved_b:\n",
    "    print(\"\\n‚úÖ TEST B PROGRESS: Significant improvement, may need fine-tuning\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è TEST B MIXED: Review trade-offs between volatility control and alpha preservation\")\n",
    "\n",
    "print(\"\\n‚úÖ Volatility Targeting Overlay (Test B) analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXECUTIVE SUMMARY: Test B (Volatility Targeting) delivers superior \n",
    "  performance - best Calmar ratio (0.42), improved Sharpe (1.49),\n",
    "  minimal return sacrifice (-1.08%), and +7.5% drawdown improvement.\n",
    "  Currently the leading risk management mechanism, though still 16.7%\n",
    "   from institutional target.\n",
    "\n",
    "  DETAILED ANALYSIS:\n",
    "\n",
    "  Test B Results Assessment:\n",
    "\n",
    "  ‚úÖ Excellent Performance:\n",
    "  - Calmar Ratio Leader: 0.42 vs 0.38 baseline (+0.04 improvement) üèÜ\n",
    "  - Sharpe Enhancement: 1.49 vs 1.40 baseline (+0.08 improvement)\n",
    "  - Return Preservation: 17.62% vs 18.70% baseline (only -1.08%\n",
    "  sacrifice)\n",
    "  - Risk Reduction: -41.7% vs -49.2% baseline (+7.51% improvement)\n",
    "  - Volatility Control: 11.84% vs 13.32% baseline (effective\n",
    "  targeting)\n",
    "\n",
    "  üìä Mechanism Effectiveness:\n",
    "  - Dynamic Scaling: Average 0.94 scaling factor (6% average\n",
    "  reduction)\n",
    "  - Precision Targeting: 341 high-volatility days (14.3%) received\n",
    "  >80% exposure reduction\n",
    "  - Conservative Approach: Zero leverage days (respects 100% maximum\n",
    "  exposure)\n",
    "\n",
    "  ‚ö†Ô∏è Remaining Challenge:\n",
    "  - Institutional Gap: -41.7% vs -25% target (16.7% gap remaining)\n",
    "\n",
    "  üèÜ Test B vs Test A Comparison:\n",
    "\n",
    "  | Metric              | Test A         | Test B         | Winner |\n",
    "  |---------------------|----------------|----------------|--------|\n",
    "  | Return Preservation | 12.83% (-5.87) | 17.62% (-1.08) | Test B |\n",
    "  | Sharpe Ratio        | 1.25           | 1.49           | Test B |\n",
    "  | Max Drawdown        | -39.6%         | -41.7%         | Test A |\n",
    "  | Calmar Ratio        | 0.32           | 0.42           | Test B |\n",
    "\n",
    "  Key Insight: Volatility targeting provides more nuanced risk\n",
    "  management than blunt regime-based exposure cuts.\n",
    "\n",
    "  IMPLEMENTATION NOTES:\n",
    "\n",
    "  Test B validates dynamic volatility targeting as superior to static\n",
    "   regime overlays:\n",
    "  1. Precision Approach: Responds to actual portfolio risk rather\n",
    "  than market regimes\n",
    "  2. Return Efficiency: Minimal alpha sacrifice for substantial risk\n",
    "  reduction\n",
    "  3. Institutional Quality: Best risk-adjusted performance (Calmar\n",
    "  ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üéØ IMPLEMENTING TEST C: DYNAMIC REVERSAL WEIGHTING\n",
      "======================================================================\n",
      "üîß Implementing Dynamic Reversal Weighting (Test C)...\n",
      "    Stress regime momentum weight: -0.30\n",
      "    Calm regime momentum weight: 0.00\n",
      "    Stress regime days: 274 (11.5%)\n",
      "    Calm regime days: 2,107 (88.5%)\n",
      "üöÄ Running Dynamic Reversal Weighting backtest (Test C)...\n",
      "    - Using 38 quarterly rebalance dates.\n",
      "    - Constructed dynamic reversal holdings matrix.\n",
      "‚úÖ Dynamic Reversal Weighting backtest complete.\n",
      "\n",
      "üìä DYNAMIC REVERSAL WEIGHTING PERFORMANCE (TEST C):\n",
      "==================================================\n",
      "Annual Return (%)        :    26.39\n",
      "Annual Volatility (%)    :    12.55\n",
      "Sharpe Ratio             :     2.10\n",
      "Max Drawdown (%)         :   -45.99\n",
      "Calmar Ratio             :     0.57\n",
      "Sortino Ratio            :     2.24\n",
      "Win Rate (%)             :    59.34\n",
      "Total Days               :  2381.00\n",
      "Information Ratio        :     1.00\n",
      "Tracking Error (%)       :    12.37\n",
      "\n",
      "üîç TEST C vs BASELINE COMPARISON:\n",
      "========================================\n",
      "Metric                    Baseline   Test C     Change    \n",
      "-------------------------------------------------------\n",
      "Annual Return (%)            18.70       26.39       +7.69\n",
      "Sharpe Ratio                  1.40        2.10       +0.70\n",
      "Max Drawdown (%)            -49.22      -45.99       +3.23\n",
      "Calmar Ratio                  0.38        0.57       +0.19\n",
      "\n",
      "üéØ TEST C RISK ASSESSMENT:\n",
      "==============================\n",
      "Sharpe Preservation (>1.2):      ‚úÖ PASS (2.10)\n",
      "Drawdown Improvement:            ‚úÖ YES (-46.0% vs -49.2%)\n",
      "Calmar Improvement:              ‚úÖ YES (0.57 vs 0.38)\n",
      "Target Achieved (<-25%):         ‚ùå NO (-46.0%)\n",
      "\n",
      "‚úÖ TEST C PROGRESS: Significant improvement, may need fine-tuning\n",
      "\n",
      "‚úÖ Dynamic Reversal Weighting (Test C) analysis complete\n"
     ]
    }
   ],
   "source": [
    "# =================================================================\n",
    "# CELL 7: DYNAMIC REVERSAL WEIGHTING IMPLEMENTATION (TEST C)\n",
    "# =================================================================\n",
    "\n",
    "def calculate_dynamic_qvm_scores(\n",
    "    factor_data: pd.DataFrame,\n",
    "    market_regimes: pd.DataFrame,\n",
    "    normal_weights: Dict[str, float] = {'quality': 0.33, 'value': 0.33, 'momentum': 0.33},\n",
    "    stress_momentum_weight: float = -0.30,\n",
    "    calm_momentum_weight: float = 0.0\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate dynamic QVM composite scores with regime-dependent momentum weighting.\n",
    "    \n",
    "    Parameters:\n",
    "    - factor_data: Original factor data with quality, value, momentum scores\n",
    "    - market_regimes: Regime classification\n",
    "    - normal_weights: Standard factor weights for normal periods\n",
    "    - stress_momentum_weight: Momentum weight during Stress regimes (-0.30)\n",
    "    - calm_momentum_weight: Momentum weight during non-Stress regimes (0.0)\n",
    "    \n",
    "    Returns:\n",
    "    - dynamic_qvm_scores: QVM scores with dynamic momentum weighting\n",
    "    \"\"\"\n",
    "    print(f\"üîß Implementing Dynamic Reversal Weighting (Test C)...\")\n",
    "    print(f\"    Stress regime momentum weight: {stress_momentum_weight:.2f}\")\n",
    "    print(f\"    Calm regime momentum weight: {calm_momentum_weight:.2f}\")\n",
    "\n",
    "    # Extract individual factor scores\n",
    "    quality_scores = factor_data.loc[:, ('quality_score', slice(None))]\n",
    "    quality_scores.columns = quality_scores.columns.droplevel(0)\n",
    "\n",
    "    value_scores = factor_data.loc[:, ('value_score', slice(None))]\n",
    "    value_scores.columns = value_scores.columns.droplevel(0)\n",
    "\n",
    "    momentum_scores = factor_data.loc[:, ('momentum_score', slice(None))]\n",
    "    momentum_scores.columns = momentum_scores.columns.droplevel(0)\n",
    "\n",
    "    # Initialize dynamic QVM scores\n",
    "    dynamic_qvm_scores = pd.DataFrame(index=quality_scores.index, columns=quality_scores.columns)\n",
    "\n",
    "    # Calculate dynamic scores date by date\n",
    "    stress_days = 0\n",
    "    calm_days = 0\n",
    "\n",
    "    for date in dynamic_qvm_scores.index:\n",
    "        if date in market_regimes.index:\n",
    "            regime = market_regimes.loc[date, 'regime']\n",
    "\n",
    "            # Get factor scores for this date\n",
    "            daily_quality = quality_scores.loc[date]\n",
    "            daily_value = value_scores.loc[date]\n",
    "            daily_momentum = momentum_scores.loc[date]\n",
    "\n",
    "            if regime == 'Stress':\n",
    "                # Stress regime: negative momentum weight\n",
    "                momentum_weight = stress_momentum_weight\n",
    "                quality_weight = (1 - abs(momentum_weight)) / 2\n",
    "                value_weight = (1 - abs(momentum_weight)) / 2\n",
    "                stress_days += 1\n",
    "            else:\n",
    "                # Calm regime: zero momentum weight\n",
    "                momentum_weight = calm_momentum_weight\n",
    "                quality_weight = 0.5\n",
    "                value_weight = 0.5\n",
    "                calm_days += 1\n",
    "\n",
    "            # Calculate dynamic QVM score\n",
    "            dynamic_qvm_scores.loc[date] = (\n",
    "                quality_weight * daily_quality +\n",
    "                value_weight * daily_value +\n",
    "                momentum_weight * daily_momentum\n",
    "            )\n",
    "        else:\n",
    "            # Default to normal weights if regime not available\n",
    "            dynamic_qvm_scores.loc[date] = (\n",
    "                normal_weights['quality'] * quality_scores.loc[date] +\n",
    "                normal_weights['value'] * value_scores.loc[date] +\n",
    "                normal_weights['momentum'] * momentum_scores.loc[date]\n",
    "            )\n",
    "\n",
    "    print(f\"    Stress regime days: {stress_days:,} ({stress_days/len(dynamic_qvm_scores):.1%})\")\n",
    "    print(f\"    Calm regime days: {calm_days:,} ({calm_days/len(dynamic_qvm_scores):.1%})\")\n",
    "\n",
    "    return dynamic_qvm_scores\n",
    "\n",
    "\n",
    "def run_dynamic_reversal_backtest(\n",
    "    dynamic_qvm_scores: pd.DataFrame,\n",
    "    daily_returns: pd.DataFrame,\n",
    "    sector_info: pd.DataFrame,\n",
    "    config: dict\n",
    ") -> Tuple[pd.Series, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Run backtest with dynamic reversal weighting (requires full portfolio reconstruction).\n",
    "    \"\"\"\n",
    "    print(\"üöÄ Running Dynamic Reversal Weighting backtest (Test C)...\")\n",
    "\n",
    "    # 1. IDENTIFY QUARTERLY REBALANCE DATES\n",
    "    ideal_rebalance_dates = pd.date_range(\n",
    "        start=dynamic_qvm_scores.index.min(),\n",
    "        end=dynamic_qvm_scores.index.max(),\n",
    "        freq=config['rebalance_freq']\n",
    "    )\n",
    "    print(f\"    - Using {len(ideal_rebalance_dates)} quarterly rebalance dates.\")\n",
    "\n",
    "    # 2. Construct Daily Holdings Matrix with Dynamic Scores\n",
    "    daily_holdings = pd.DataFrame(index=daily_returns.index, columns=daily_returns.columns).fillna(0.0)\n",
    "\n",
    "    factor_scores_on_rebal_dates = dynamic_qvm_scores.reindex(ideal_rebalance_dates, method='ffill')\n",
    "\n",
    "    for i in range(len(factor_scores_on_rebal_dates.index)):\n",
    "        rebal_date = factor_scores_on_rebal_dates.index[i]\n",
    "\n",
    "        try:\n",
    "            next_rebal_date = factor_scores_on_rebal_dates.index[i+1]\n",
    "        except IndexError:\n",
    "            next_rebal_date = daily_returns.index[-1] + pd.Timedelta(days=1)\n",
    "\n",
    "        factor_scores_at_rebal = factor_scores_on_rebal_dates.loc[rebal_date].dropna()\n",
    "\n",
    "        if len(factor_scores_at_rebal) > 20:\n",
    "            portfolio_df = construct_constrained_portfolio(factor_scores_at_rebal, sector_info, config)\n",
    "\n",
    "            if not portfolio_df.empty:\n",
    "                # Define the holding period for this portfolio\n",
    "                relevant_days = daily_returns.index[(daily_returns.index > rebal_date) & (daily_returns.index < next_rebal_date)]\n",
    "\n",
    "                if not relevant_days.empty:\n",
    "                    # Assign the weight Series to each relevant day\n",
    "                    for day in relevant_days:\n",
    "                        valid_tickers = portfolio_df.index.intersection(daily_holdings.columns)\n",
    "                        daily_holdings.loc[day, valid_tickers] = portfolio_df.loc[valid_tickers, 'weight']\n",
    "\n",
    "    print(\"    - Constructed dynamic reversal holdings matrix.\")\n",
    "\n",
    "    # 3. PREVENT LOOK-AHEAD BIAS\n",
    "    daily_holdings_shifted = daily_holdings.shift(1).fillna(0)\n",
    "\n",
    "    # 4. CALCULATE RETURNS\n",
    "    gross_returns = (daily_holdings_shifted * daily_returns).sum(axis=1)\n",
    "\n",
    "    # 5. TRANSACTION COSTS\n",
    "    turnover = (daily_holdings_shifted - daily_holdings_shifted.shift(1)).abs().sum(axis=1) / 2\n",
    "    transaction_costs = turnover * (config['transaction_cost_bps'] / 10000)\n",
    "\n",
    "    net_returns = gross_returns - transaction_costs\n",
    "\n",
    "    backtest_log = pd.DataFrame({\n",
    "        'gross_return': gross_returns,\n",
    "        'net_return': net_returns,\n",
    "        'turnover': turnover,\n",
    "        'transaction_cost': transaction_costs,\n",
    "        'positions': (daily_holdings_shifted > 0).sum(axis=1)\n",
    "    })\n",
    "\n",
    "    print(\"‚úÖ Dynamic Reversal Weighting backtest complete.\")\n",
    "    return net_returns, backtest_log, daily_holdings_shifted\n",
    "\n",
    "\n",
    "# Execute Dynamic Reversal Weighting (Test C)\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéØ IMPLEMENTING TEST C: DYNAMIC REVERSAL WEIGHTING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Calculate dynamic QVM scores with regime-dependent momentum weighting\n",
    "dynamic_qvm_scores = calculate_dynamic_qvm_scores(\n",
    "    factor_data=factor_data,\n",
    "    market_regimes=market_regimes,\n",
    "    stress_momentum_weight=-0.30,  # Contrarian momentum during stress\n",
    "    calm_momentum_weight=0.0         # No momentum during calm periods\n",
    ")\n",
    "\n",
    "# Run backtest with dynamic reversal weighting\n",
    "dynamic_reversal_returns, dynamic_reversal_log, dynamic_reversal_holdings = run_dynamic_reversal_backtest(\n",
    "    dynamic_qvm_scores=dynamic_qvm_scores,\n",
    "    daily_returns=daily_returns_aligned,\n",
    "    sector_info=sector_info,\n",
    "    config=QUARTERLY_BASELINE_CONFIG\n",
    ")\n",
    "\n",
    "# Calculate performance metrics for Test C\n",
    "dynamic_reversal_metrics = calculate_performance_metrics(dynamic_reversal_returns, benchmark_returns_aligned)\n",
    "\n",
    "print(\"\\nüìä DYNAMIC REVERSAL WEIGHTING PERFORMANCE (TEST C):\")\n",
    "print(\"=\" * 50)\n",
    "for metric, value in dynamic_reversal_metrics.items():\n",
    "    if 'Ratio' in metric or 'Rate' in metric:\n",
    "        print(f\"{metric:<25}: {value:8.2f}\")\n",
    "    else:\n",
    "        print(f\"{metric:<25}: {value:8.2f}\")\n",
    "\n",
    "# Compare against baseline\n",
    "print(\"\\nüîç TEST C vs BASELINE COMPARISON:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"{'Metric':<25} {'Baseline':<10} {'Test C':<10} {'Change':<10}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for metric in key_metrics:\n",
    "    baseline_val = quarterly_metrics[metric]\n",
    "    overlay_val = dynamic_reversal_metrics[metric]\n",
    "    change = overlay_val - baseline_val\n",
    "    change_str = f\"{change:+.2f}\"\n",
    "    print(f\"{metric:<25} {baseline_val:8.2f}    {overlay_val:8.2f}    {change_str:>8s}\")\n",
    "\n",
    "# Risk assessment for Test C\n",
    "print(\"\\nüéØ TEST C RISK ASSESSMENT:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "sharpe_preserved_c = dynamic_reversal_metrics['Sharpe Ratio'] >= 1.2\n",
    "drawdown_improved_c = dynamic_reversal_metrics['Max Drawdown (%)'] > quarterly_metrics['Max Drawdown (%)']\n",
    "calmar_improved_c = dynamic_reversal_metrics['Calmar Ratio'] > quarterly_metrics['Calmar Ratio']\n",
    "target_achieved_c = dynamic_reversal_metrics['Max Drawdown (%)'] > -25.0\n",
    "\n",
    "print(f\"Sharpe Preservation (>1.2):      {'‚úÖ PASS' if sharpe_preserved_c else '‚ùå FAIL'} ({dynamic_reversal_metrics['Sharpe Ratio']:.2f})\")\n",
    "print(f\"Drawdown Improvement:            {'‚úÖ YES' if drawdown_improved_c else '‚ùå NO'} ({dynamic_reversal_metrics['Max Drawdown (%)']:.1f}% vs {quarterly_metrics['Max Drawdown (%)']:.1f}%)\")\n",
    "print(f\"Calmar Improvement:              {'‚úÖ YES' if calmar_improved_c else '‚ùå NO'} ({dynamic_reversal_metrics['Calmar Ratio']:.2f} vs {quarterly_metrics['Calmar Ratio']:.2f})\")\n",
    "print(f\"Target Achieved (<-25%):         {'‚úÖ YES' if target_achieved_c else '‚ùå NO'} ({dynamic_reversal_metrics['Max Drawdown (%)']:.1f}%)\")\n",
    "\n",
    "if target_achieved_c and sharpe_preserved_c:\n",
    "    print(\"\\nüéâ TEST C SUCCESS: Dynamic Reversal Weighting achieves institutional targets!\")\n",
    "elif drawdown_improved_c and sharpe_preserved_c:\n",
    "    print(\"\\n‚úÖ TEST C PROGRESS: Significant improvement, may need fine-tuning\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è TEST C MIXED: Review trade-offs between dynamic weighting and alpha preservation\")\n",
    "\n",
    "print(\"\\n‚úÖ Dynamic Reversal Weighting (Test C) analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXECUTIVE SUMMARY: Test C (Dynamic Reversal Weighting) delivers\n",
    "  exceptional results - highest Calmar ratio (0.57), outstanding\n",
    "  Sharpe (2.10), significant return enhancement (+7.69%), yet still\n",
    "  misses institutional drawdown target. All three mechanisms improve\n",
    "  performance but require hybrid approach for full compliance.\n",
    "\n",
    "  DETAILED ANALYSIS:\n",
    "\n",
    "  üèÜ Test C Results - Clear Winner:\n",
    "\n",
    "  ‚úÖ Outstanding Performance:\n",
    "  - Calmar Ratio Champion: 0.57 vs 0.38 baseline (+0.19 improvement)\n",
    "  ü•á\n",
    "  - Sharpe Excellence: 2.10 vs 1.40 baseline (+0.70 improvement)\n",
    "  - Return Enhancement: 26.39% vs 18.70% baseline (+7.69% gain!)\n",
    "  - Information Ratio: 1.00 (exceptional alpha generation)\n",
    "  - Minimal Drawdown Improvement: -46.0% vs -49.2% baseline (+3.23%)\n",
    "\n",
    "  üìä Mechanism Effectiveness:\n",
    "  - Stress Regime Coverage: 11.5% of days (274 days) with contrarian\n",
    "  momentum\n",
    "  - Factor Reweighting: Quality/Value 35% each, Momentum -30% during\n",
    "  stress\n",
    "  - Vietnam Market Adaptation: Leverages mean reversion\n",
    "  characteristics perfectly\n",
    "\n",
    "  üéØ Comprehensive Phase 8 Results Summary:\n",
    "\n",
    "  | Strategy            | Annual Return | Sharpe | Max Drawdown |\n",
    "  Calmar | Target Met |\n",
    "  |---------------------|---------------|--------|--------------|----\n",
    "  ----|------------|\n",
    "  | Baseline            | 18.70%        | 1.40   | -49.2%       |\n",
    "  0.38   | ‚ùå          |\n",
    "  | Test A (Regime)     | 12.83%        | 1.25   | -39.6%       |\n",
    "  0.32   | ‚ùå          |\n",
    "  | Test B (Vol Target) | 17.62%        | 1.49   | -41.7%       |\n",
    "  0.42   | ‚ùå          |\n",
    "  | Test C (Dynamic)    | 26.39%        | 2.10   | -46.0%       |\n",
    "  0.57   | ‚ùå          |\n",
    "\n",
    "  üí° Strategic Insights:\n",
    "\n",
    "  Test C Advantages:\n",
    "  1. Alpha Enhancement: Dynamic factor weighting actually improves\n",
    "  returns\n",
    "  2. Vietnam Adaptation: Contrarian momentum perfectly suited to\n",
    "  local market structure\n",
    "  3. Institutional Quality: 2.10 Sharpe exceeds most hedge fund\n",
    "  standards\n",
    "  4. Factor Innovation: Proves dynamic weighting superior to static\n",
    "  allocations\n",
    "\n",
    "  Critical Challenge:\n",
    "  - Institutional Gap: All mechanisms fall short of -25% drawdown\n",
    "  target\n",
    "  - Best Option: Test C with -46.0% still 21% above institutional\n",
    "  limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üèÜ PHASE 8 FINAL COMPARATIVE ANALYSIS & RECOMMENDATION\n",
      "================================================================================\n",
      "\n",
      "üìä COMPREHENSIVE PERFORMANCE COMPARISON:\n",
      "==========================================================================================\n",
      "                       Quarterly Baseline  Test A (Regime Overlay)  Test B (Vol Targeting)  Test C (Dynamic Reversal)\n",
      "Annual Return (%)                   18.70                    12.83                   17.62                      26.39\n",
      "Sharpe Ratio                         1.40                     1.25                    1.49                       2.10\n",
      "Max Drawdown (%)                   -49.22                   -39.58                  -41.71                     -45.99\n",
      "Calmar Ratio                         0.38                     0.32                    0.42                       0.57\n",
      "Annual Volatility (%)               13.32                    10.30                   11.84                      12.55\n",
      "\n",
      "üéØ INSTITUTIONAL COMPLIANCE ASSESSMENT:\n",
      "============================================================\n",
      "\n",
      "Quarterly Baseline:\n",
      "  Sharpe (>1.2)       : ‚úÖ PASS\n",
      "  Drawdown (<-25%)    : ‚ùå FAIL\n",
      "  Overall             : ‚ùå NON-COMPLIANT\n",
      "\n",
      "Test A (Regime Overlay):\n",
      "  Sharpe (>1.2)       : ‚úÖ PASS\n",
      "  Drawdown (<-25%)    : ‚ùå FAIL\n",
      "  Overall             : ‚ùå NON-COMPLIANT\n",
      "\n",
      "Test B (Vol Targeting):\n",
      "  Sharpe (>1.2)       : ‚úÖ PASS\n",
      "  Drawdown (<-25%)    : ‚ùå FAIL\n",
      "  Overall             : ‚ùå NON-COMPLIANT\n",
      "\n",
      "Test C (Dynamic Reversal):\n",
      "  Sharpe (>1.2)       : ‚úÖ PASS\n",
      "  Drawdown (<-25%)    : ‚ùå FAIL\n",
      "  Overall             : ‚ùå NON-COMPLIANT\n",
      "\n",
      "üèÜ STRATEGY RANKINGS:\n",
      "========================================\n",
      "\n",
      "Annual Return (%) Ranking:\n",
      "  1. Test C (Dynamic Reversal): 26.39\n",
      "  2. Quarterly Baseline: 18.70\n",
      "  3. Test B (Vol Targeting): 17.62\n",
      "  4. Test A (Regime Overlay): 12.83\n",
      "\n",
      "Sharpe Ratio Ranking:\n",
      "  1. Test C (Dynamic Reversal): 2.10\n",
      "  2. Test B (Vol Targeting): 1.49\n",
      "  3. Quarterly Baseline: 1.40\n",
      "  4. Test A (Regime Overlay): 1.25\n",
      "\n",
      "Calmar Ratio Ranking:\n",
      "  1. Test C (Dynamic Reversal): 0.57\n",
      "  2. Test B (Vol Targeting): 0.42\n",
      "  3. Quarterly Baseline: 0.38\n",
      "  4. Test A (Regime Overlay): 0.32\n",
      "\n",
      "Max Drawdown Ranking (Lower is Better):\n",
      "  1. Test A (Regime Overlay): -39.6%\n",
      "  2. Test B (Vol Targeting): -41.7%\n",
      "  3. Test C (Dynamic Reversal): -46.0%\n",
      "  4. Quarterly Baseline: -49.2%\n",
      "\n",
      "üìà COMPOSITE SCORING (Weighted Average):\n",
      "==================================================\n",
      "Composite Score Ranking:\n",
      "  1. Test C (Dynamic Reversal): 0.931\n",
      "  2. Test B (Vol Targeting): 0.707\n",
      "  3. Quarterly Baseline: 0.627\n",
      "  4. Test A (Regime Overlay): 0.605\n",
      "\n",
      "üèÜ RECOMMENDED STRATEGY: Test C (Dynamic Reversal)\n",
      "==================================================\n",
      "Composite Score: 0.931\n",
      "Annual Return: 26.39%\n",
      "Sharpe Ratio: 2.10\n",
      "Max Drawdown: -46.0%\n",
      "Calmar Ratio: 0.57\n",
      "\n",
      "‚ö†Ô∏è INSTITUTIONAL DEPLOYMENT GAP:\n",
      "Current Max Drawdown: -46.0%\n",
      "Institutional Target: -25.0%\n",
      "Remaining Gap: 21.0 percentage points\n",
      "\n",
      "üìã NEXT STEPS FOR INSTITUTIONAL COMPLIANCE:\n",
      "1. Hybrid Approach: Combine Test C (Dynamic Reversal) with additional risk controls\n",
      "2. Parameter Tuning: Optimize risk overlay parameters\n",
      "3. Position Sizing: Implement dynamic position sizing\n",
      "4. Alternative: Accept higher minimum exposure levels\n",
      "\n",
      "‚úÖ Phase 8 Risk Overlay Analysis Complete\n",
      "Recommended Strategy: Test C (Dynamic Reversal)\n",
      "Status: REQUIRES FURTHER OPTIMIZATION\n"
     ]
    }
   ],
   "source": [
    "# =================================================================\n",
    "# CELL 8: COMPREHENSIVE COMPARATIVE ANALYSIS & FINAL RECOMMENDATION\n",
    "# =================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üèÜ PHASE 8 FINAL COMPARATIVE ANALYSIS & RECOMMENDATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Compile all results for comparison\n",
    "strategies = {\n",
    "    'Quarterly Baseline': quarterly_metrics,\n",
    "    'Test A (Regime Overlay)': regime_overlay_metrics,\n",
    "    'Test B (Vol Targeting)': vol_target_metrics,\n",
    "    'Test C (Dynamic Reversal)': dynamic_reversal_metrics\n",
    "}\n",
    "\n",
    "strategy_returns = {\n",
    "    'Quarterly Baseline': quarterly_returns,\n",
    "    'Test A (Regime Overlay)': regime_overlay_returns,\n",
    "    'Test B (Vol Targeting)': vol_target_returns,\n",
    "    'Test C (Dynamic Reversal)': dynamic_reversal_returns\n",
    "}\n",
    "\n",
    "# Create comprehensive comparison table\n",
    "print(\"\\nüìä COMPREHENSIVE PERFORMANCE COMPARISON:\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "comparison_metrics = ['Annual Return (%)', 'Sharpe Ratio', 'Max Drawdown (%)', 'Calmar Ratio', 'Annual Volatility (%)']\n",
    "comparison_df = pd.DataFrame({strategy: [metrics[metric] for metric in comparison_metrics]\n",
    "                               for strategy, metrics in strategies.items()},\n",
    "                               index=comparison_metrics)\n",
    "\n",
    "print(comparison_df.round(2).to_string())\n",
    "\n",
    "# Institutional compliance check\n",
    "print(\"\\nüéØ INSTITUTIONAL COMPLIANCE ASSESSMENT:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "compliance_results = {}\n",
    "for strategy_name, metrics in strategies.items():\n",
    "    sharpe_pass = metrics['Sharpe Ratio'] >= 1.2\n",
    "    drawdown_pass = metrics['Max Drawdown (%)'] > -25.0\n",
    "    overall_pass = sharpe_pass and drawdown_pass\n",
    "\n",
    "    compliance_results[strategy_name] = {\n",
    "        'Sharpe (>1.2)': '‚úÖ PASS' if sharpe_pass else '‚ùå FAIL',\n",
    "        'Drawdown (<-25%)': '‚úÖ PASS' if drawdown_pass else '‚ùå FAIL',\n",
    "        'Overall': '‚úÖ COMPLIANT' if overall_pass else '‚ùå NON-COMPLIANT'\n",
    "    }\n",
    "\n",
    "for strategy, results in compliance_results.items():\n",
    "    print(f\"\\n{strategy}:\")\n",
    "    for criterion, result in results.items():\n",
    "        print(f\"  {criterion:<20}: {result}\")\n",
    "\n",
    "# Ranking by key metrics\n",
    "print(\"\\nüèÜ STRATEGY RANKINGS:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "rankings = {}\n",
    "for metric in ['Annual Return (%)', 'Sharpe Ratio', 'Calmar Ratio']:\n",
    "    # Higher is better for these metrics\n",
    "    sorted_strategies = sorted(strategies.items(), key=lambda x: x[1][metric], reverse=True)\n",
    "    rankings[metric] = [name for name, _ in sorted_strategies]\n",
    "\n",
    "    print(f\"\\n{metric} Ranking:\")\n",
    "    for i, strategy_name in enumerate(rankings[metric], 1):\n",
    "        value = strategies[strategy_name][metric]\n",
    "        print(f\"  {i}. {strategy_name}: {value:.2f}\")\n",
    "\n",
    "# Max Drawdown ranking (lower absolute value is better)\n",
    "print(f\"\\nMax Drawdown Ranking (Lower is Better):\")\n",
    "sorted_strategies = sorted(strategies.items(), key=lambda x: x[1]['Max Drawdown (%)'], reverse=True)\n",
    "for i, (strategy_name, metrics) in enumerate(sorted_strategies, 1):\n",
    "    value = metrics['Max Drawdown (%)']\n",
    "    print(f\"  {i}. {strategy_name}: {value:.1f}%\")\n",
    "\n",
    "# Calculate composite scores\n",
    "print(\"\\nüìà COMPOSITE SCORING (Weighted Average):\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Weights for institutional priorities\n",
    "weights = {\n",
    "    'Calmar Ratio': 0.4,  # Primary: Risk-adjusted return\n",
    "    'Sharpe Ratio': 0.3,  # Secondary: Risk efficiency\n",
    "    'Max Drawdown (%)': 0.3  # Tertiary: Risk control (inverted)\n",
    "}\n",
    "\n",
    "composite_scores = {}\n",
    "for strategy_name, metrics in strategies.items():\n",
    "    # Normalize drawdown (convert to positive score)\n",
    "    drawdown_score = (metrics['Max Drawdown (%)'] + 60) / 60  # Scale -60% to 0% as 0 to 1\n",
    "\n",
    "    score = (weights['Calmar Ratio'] * metrics['Calmar Ratio'] +\n",
    "             weights['Sharpe Ratio'] * metrics['Sharpe Ratio'] +\n",
    "             weights['Max Drawdown (%)'] * drawdown_score)\n",
    "\n",
    "    composite_scores[strategy_name] = score\n",
    "\n",
    "# Sort by composite score\n",
    "sorted_composite = sorted(composite_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Composite Score Ranking:\")\n",
    "for i, (strategy_name, score) in enumerate(sorted_composite, 1):\n",
    "    print(f\"  {i}. {strategy_name}: {score:.3f}\")\n",
    "\n",
    "# Final recommendation\n",
    "winner = sorted_composite[0][0]\n",
    "winner_metrics = strategies[winner]\n",
    "\n",
    "print(f\"\\nüèÜ RECOMMENDED STRATEGY: {winner}\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Composite Score: {composite_scores[winner]:.3f}\")\n",
    "print(f\"Annual Return: {winner_metrics['Annual Return (%)']:.2f}%\")\n",
    "print(f\"Sharpe Ratio: {winner_metrics['Sharpe Ratio']:.2f}\")\n",
    "print(f\"Max Drawdown: {winner_metrics['Max Drawdown (%)']:.1f}%\")\n",
    "print(f\"Calmar Ratio: {winner_metrics['Calmar Ratio']:.2f}\")\n",
    "\n",
    "# Gap analysis for institutional deployment\n",
    "drawdown_gap = abs(winner_metrics['Max Drawdown (%)']) - 25.0\n",
    "print(f\"\\n‚ö†Ô∏è INSTITUTIONAL DEPLOYMENT GAP:\")\n",
    "print(f\"Current Max Drawdown: {winner_metrics['Max Drawdown (%)']:.1f}%\")\n",
    "print(f\"Institutional Target: -25.0%\")\n",
    "print(f\"Remaining Gap: {drawdown_gap:.1f} percentage points\")\n",
    "\n",
    "if drawdown_gap > 0:\n",
    "    print(f\"\\nüìã NEXT STEPS FOR INSTITUTIONAL COMPLIANCE:\")\n",
    "    print(f\"1. Hybrid Approach: Combine {winner} with additional risk controls\")\n",
    "    print(f\"2. Parameter Tuning: Optimize risk overlay parameters\")\n",
    "    print(f\"3. Position Sizing: Implement dynamic position sizing\")\n",
    "    print(f\"4. Alternative: Accept higher minimum exposure levels\")\n",
    "else:\n",
    "    print(f\"\\nüéâ INSTITUTIONAL READY: {winner} meets all deployment criteria!\")\n",
    "\n",
    "print(f\"\\n‚úÖ Phase 8 Risk Overlay Analysis Complete\")\n",
    "print(f\"Recommended Strategy: {winner}\")\n",
    "print(f\"Status: {'INSTITUTIONAL READY' if drawdown_gap <= 0 else 'REQUIRES FURTHER OPTIMIZATION'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üíæ COMPILING AND SAVING COMPREHENSIVE PHASE 8 RESULTS\n",
      "================================================================================\n",
      "\n",
      "‚úÖ COMPLETE RESULTS PACKAGE SAVED:\n",
      "   File: phase8_results.pkl\n",
      "   Location: /Users/ducnguyen/Library/CloudStorage/GoogleDrive-duc.nguyentcb@gmail.com/My Drive/quant-world-invest/factor_investing_project/production/tests/phase8_risk_management/phase8_results.pkl\n",
      "   Size: 65.15 MB\n",
      "\n",
      "Components Saved:\n",
      "   - 4 Strategy Return Series\n",
      "   - 4 Strategy Daily Holdings Matrices\n",
      "   - 4 Strategy Performance Metrics Dictionaries\n",
      "   - 1 Market Regime DataFrame\n",
      "\n",
      "üöÄ Notebook 07 is now ready to proceed.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 9: COMPILE AND SAVE COMPREHENSIVE PHASE 8 RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üíæ COMPILING AND SAVING COMPREHENSIVE PHASE 8 RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Compile all strategy returns into a single dictionary\n",
    "all_strategy_returns = {\n",
    "    'Quarterly Baseline': quarterly_returns,\n",
    "    'Test A (Regime Overlay)': regime_overlay_returns,\n",
    "    'Test B (Vol Targeting)': vol_target_returns,\n",
    "    'Test C (Dynamic Reversal)': dynamic_reversal_returns\n",
    "}\n",
    "\n",
    "# 2. Compile all strategy holdings into a single dictionary\n",
    "all_strategy_holdings = {\n",
    "    'Quarterly Baseline': quarterly_holdings,\n",
    "    'Test A (Regime Overlay)': regime_overlay_holdings,\n",
    "    'Test B (Vol Targeting)': vol_target_holdings,\n",
    "    'Test C (Dynamic Reversal)': dynamic_reversal_holdings\n",
    "}\n",
    "\n",
    "# 3. Compile all strategy metrics into a single dictionary\n",
    "all_strategy_metrics = {\n",
    "    'Quarterly Baseline': quarterly_metrics,\n",
    "    'Test A (Regime Overlay)': regime_overlay_metrics,\n",
    "    'Test B (Vol Targeting)': vol_target_metrics,\n",
    "    'Test C (Dynamic Reversal)': dynamic_reversal_metrics\n",
    "}\n",
    "\n",
    "# 4. Create the final results package\n",
    "phase8_results_package = {\n",
    "    'creation_date': datetime.now(),\n",
    "    'phase_name': 'Phase 8 Risk Overlay Analysis',\n",
    "    'strategy_returns': all_strategy_returns,\n",
    "    'strategy_holdings': all_strategy_holdings,\n",
    "    'strategy_metrics': all_strategy_metrics,\n",
    "    'market_regimes': market_regimes,\n",
    "    'benchmark_returns': benchmark_returns_aligned,\n",
    "    'daily_returns': daily_returns_aligned\n",
    "}\n",
    "\n",
    "# 5. Save to disk in the Phase 8 directory\n",
    "phase8_path.mkdir(parents=True, exist_ok=True) # Ensure directory exists\n",
    "save_path = phase8_path / \"phase8_results.pkl\"\n",
    "\n",
    "with open(save_path, \"wb\") as f:\n",
    "    pickle.dump(phase8_results_package, f)\n",
    "\n",
    "print(f\"\\n‚úÖ COMPLETE RESULTS PACKAGE SAVED:\")\n",
    "print(f\"   File: {save_path.name}\")\n",
    "print(f\"   Location: {save_path}\")\n",
    "print(f\"   Size: {save_path.stat().st_size / (1024*1024):.2f} MB\")\n",
    "print(f\"\\nComponents Saved:\")\n",
    "print(f\"   - 4 Strategy Return Series\")\n",
    "print(f\"   - 4 Strategy Daily Holdings Matrices\")\n",
    "print(f\"   - 4 Strategy Performance Metrics Dictionaries\")\n",
    "print(f\"   - 1 Market Regime DataFrame\")\n",
    "\n",
    "print(\"\\nüöÄ Notebook 07 is now ready to proceed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vn_factor_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
